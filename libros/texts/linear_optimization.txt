M I c
° K I B R A R I T S
T H E
LINEAR OPTIMAL CONTROL SYSTEMS
Digitized by the Internet Archive
in 2022 with funding from
Kahle/Austin Foundation
httos://archive.org/details/linearoptimalconO000kwak
Linear Optimal
Control systems
HUIBERT KWAKERNAAK
Twente University of Technology
Enschede, The Netherlands
RAPHAEL SIVAN
Technion, Israel Institute of Technology
Haifa, Israel
WILEY-INTERSCIENCE, a Division of John Wiley & Sons, Inc.
New York Chichester Brisbane Toronto Singapore
Copyright © 1972, by John Wiley & Sons, Inc.
All rights reserved. Published simultaneously in Canada.
Reproduction or translation of any part of this work beyond
that permitted by Sections 107 or 108 of the 1976 United States
Copyright Act without the permission of the copyright owner
is unlawful. Requests for permission or further information
should be addressed to the Permissions Department, John
Wiley & Sons, Inc.
Library of Congress Cataloging in Publication Data:
Kwakernaak, Huibert.
Linear optimal control systems.
Bibliography: p.
1. Control theory. 2, Automatic control.
I. Sivan, Raphael, joint author. I. Title
QA402.3.K89 629.832 72-3576
ISBN 0-471-51110-2
Printed in the United States of America
20 19S LER 6m Ismael m2
4% ° °
To Helene, Annemarie, and Martin
H. K.
In memory of my parents Yehuda and Tova and to my wife Ilana
R.S.
Ti
|
ee 4G < ne’y
pest
a tei
= - 7 a - - aff : .
or
-
a
1%
PREFACE
During the last few years modern linear control theory has advanced rapidly
and is now being recognized as a powerful and eminently practical tool for
the solution of linear feedback control problems. The main characteristics of
modern linear control theory are the state space description of systems,
optimization in terms of quadratic performance criteria, and incorporation
of Kalman—Bucy optimal state reconstruction theory. The significant ad-
vantage of modern linear control theory over the classical theory is its ap-
plicability to control problems involving multiinput multioutput systems and
time-varying situations; the classical theory is essentially restricted to single-
input single-output time-invariant situations.
The use of the term ‘‘modern’’ control theory could suggest a disregard for
*‘classical,”’ or “‘conventional,”’ control theory, namely, the theory that con-
sists of design methods based upon suitably shaping the transmission and
loop gain functions, employing pole-zero techniques. However, we do not
share such a disregard; on the contrary, we believe that the classical approach
is well-established and proven by practice, and distinguishes itself by a col-
lection of sensible and useful goals and problem formulations.
This book attempts to reconcile modern linear control theory with classical
control theory. One of the major concerns of this text is to present design
methods, employing modern techniques, for obtaining control systems that
stand up to the requirements that have been so well developed in the classical
expositions of control theory. Therefore, among other things, an entire
chapter is devoted to a description of the analysis of control systems, mostly
following the classical lines of thought. In the later chapters of the book, in
which modern synthesis methods are developed, the chapter on analysis is
recurrently referred to. Furthermore, special attention is paid to subjects that
are standard in classical control theory but are frequently overlooked in
modern treatments, such as nonzero set point control systems, tracking
systems, and control systems that have to cope with constant disturbances.
Also, heavy emphasis is placed upon the stochastic nature of control problems
because the stochastic aspects are so essential.
viii Preface
We believe that modern and classical control theory can very well be taught
simultaneously, since they cover different aspects of the same problems.
There is no inherent reason for teaching the classical theory first in under-
graduate courses and to defer the modern theory, particularly the stochastic
part of it, to graduate courses. In fact, we believe that a modern course
should be a blend of classical, modern, and stochastic contro] theory. This is
the approach followed in this book.
The book has been organized as follows. About half of the material,
containing most of the analysis and design methods, as well as a large number
of examples, is presented in unmarked sections. The finer points, such as
conditions for existence, detailed results concerning convergence to steady-
state solutions, and asymptotic properties, are dealt with in sections whose
titles have been marked with an asterisk. The unmarked sections have been so
written that they form a textbook for a two-semester first course on control
theory at the senior or first-year graduate level. The marked sections consist
of supplementary material of a more advanced nature. The control engineer
who is interested in applying the material will find most design methods in
the unmarked sections but may have to refer to the remaining sections for
more detailed information on difficult points.
The following background is assumed. The reader should have had a
first course on linear systems or linear circuits and should possess some
introductory knowledge of stochastic processes. It is also recommended that
the reader have some experience in digital computer programming and that he
have access to a computer. We do not believe that it is necessary for the
reader to have followed a course on classical control theory before studying
the material of this book.
A chapter-by-chapter description of the book follows.
In Chapter 1, “Elements of Linear System Theory,” the description of
linear systems in terms of their state is the starting point, while transfer matrix
and frequency response concepts are derived from the state description.
Topics important for the steady-state analysis of linear optimal systems are
carefully discussed. They are: controllability, stabilizability, reconstructibility,
detectability, and duality. The last two sections of this chapter are devoted to
a description of vector stochastic processes, with special emphasis on the
representation of stochastic processes as the outputs of linear differential
systems driven by white noise. In later chapters this material is extensively
employed.
Chapter 2, ‘Analysis of Control Systems,” gives a general description of
control problems. Furthermore, it includes a step-by-step analysis of the
various aspects of control system performance. Single-input single-output
and multivariable control systems are discussed in a unified framework by
the use of the concepts of mean square tracking error and mean square input.
Preface ix
Chapter 3, “Optimal Linear State Feedback Control Systems,”’ not only
presents the usual exposition of the linear optimal regulator problem but
also gives a rather complete survey of the steady-state properties of the
Riccati equation and the optimal regulator. It deals with the numerical
solution of Riccati equations and treats stochastic optimal regulators, optimal
tracking systems, and regulators with constant disturbances and nonzero
set points. As a special feature, the asymptotic properties of steady-state
control laws and the maximally achievable accuracy of regulators and track-
ing systems are discussed.
Chapter 4, “‘Optimal Linear Reconstruction of the State,” derives the
Kalman-Bucy filter starting with observer theory. Various special cases, such
as singular observer problems and problems with colored observation noise,
are also treated. The various steady-state and asymptotic properties of
optimal observers are reviewed.
In Chapter 5, “Optimal Linear Output Feedback Control Systems,’ the
state feedback controllers of Chapter 3 are connected to the observers of
Chapter 4. A heuristic and relatively simple proof of the separation principle
is presented based on the innovations concept, which is discussed in Chapter
4. Guidelines are given for the design of various types of output feedback
control systems, and a review of the design of reduced-order controllers is
included.
In Chapter 6, “‘Linear Optimal Control Theory for Discrete-Time Systems,”
the entire theory of Chapters 1 through 5 is repeated in condensed form for
linear discrete-time control systems. Special attention is given to state dead-
beat and output deadbeat control systems, and to questions concerning the
synchronization of the measurements and the control actuation.
Throughout the book important concepts are introduced in definitions,
and the main results summarized in the form of theorems. Almost every
section concludes with one or more examples, many of which are numerical.
These examples serve to clarify the material of the text and, by their physical
significance, to emphasize the practical applicability of the results. Most
examples are continuations of earlier examples so that a specific problem is
developed over several sections or even chapters. Whenever numerical values
are used, care has been taken to designate the proper dimensions of the
various quantities. To this end, the SI system of units has been employed,
which is now being internationally accepted (see, e.g., Barrow, 1966; IEEE
Standards Committee, 1970). A complete review of the SI system can be
found in the Recommendations of the International Organization for Stand-
ardization (various dates).
The book contains about 50 problems. They can be divided into two
categories: elementary exercises, directly illustrating the material of the text;
and supplementary results, extending the material of the text. A few of the
x Preface
problems require the use of a digital computer. The problems marked with
an asterisk are not considered to belong to the textbook material. Suitable
term projects could consist of writing and testing the computer subroutines
listed in Section 5.8.
Many references are quoted throughout the book, but no attempt has
been made to reach any degree of completeness or to do justice to history.
The fact that a particular publication is mentioned simply means that it has
been used by us as source material or that related material can be found in it.
The references are indicated by the author’s name, the year of publication,
and a letter indicating which publication is intended (e.g., Miller, 1971b).
HUIBERT KWAKERNAAK
RAPHAEL SIVAN
Enschede, The Netherlands
Haifa, Israel
January 1972
ACKNOWLEDGMENTS
The first author wishes to express his thanks to the Department of Applied
Physics at the Delft University of Technology, where he worked until April,
1970, and to the Department of Applied Mathematics at the Twente Uni-
versity of Technology for invaluable support during the writing of this book
in terms of time granted and facilities made available. The second author
extends his thanks to the Technion, the Israel Institute of Technology, for
supporting the writing of the book. Time on the preparation of the manuscript
was spent by the second author while he was a National Research Council
Senior Research Associate at the NASA Langley Research Center, Hampton,
Virginia, during the academic year 1970-1971. Without the assistance of
these institutions, and their help in financing various trips to Israel, the
Netherlands, and the United States, it would not have been possible to
complete this book.
Several typists spent their efforts on the various versions of the manuscript.
Special mention should be made of the extremely diligent and competent
work of Miss Marja Genemans of Delft and Mrs. Dini Rengelink of Twente.
The line drawings were made by Mr. M. G. Langen of Delft, who is com-
mended for his accurate and careful work.
Final thanks are due to one of the first author’s former students, Mr. J. H.
van Schuppen, for his comments on the text and for programming and
working examples, and to Mr. R. C. W. Strijbos of Twente and Prof. J. van
de Vegte, Toronto, for their comments on early versions of the manuscript.
The final manuscript was read by Prof. L. Hasdorff of the Virginia Poly-
technic Institute and Dr. Paul Alper of Twente; their constructive criticism
and remarks are greatly appreciated. The second author is grateful to his
graduate students, in particular to Victor Shenkar, for helping to correct
early versions of the manuscript.
ly Ke:
R, 8:
xi
_
a oy Vie ty
a ; 6
gai Be. ae
» ey eg ay
( ey =e +e
ne lignes =
<3 3662 pa
7
ie
CONTENTS
Notation and Symbols
Chapter 1 Elements of Linear System Theory
1.1
1.2
1.3
1.4
1.5
Introduction, 1
State Description of Linear Systems, 1
1.2.1 State Description of Nonlinear and Linear
Differential Systems, 1
1.2.2 Linearization, 2
25> Examples; 3
1.2.4 State Transformations, 10
Solution of the State Differential Equation of Linear
Systems, 11
1.3.1 The Transition Matrix and the Impulse
Response Matrix, 11
1.3.2. The Transition Matrix of a Time-Invariant
System, 13
1.3.3. Diagonalization, 15
1.3.4* The Jordan Form, 19
Stability, 24
1.4.1 Definitions of Stability, 24
1.4.2 Stability of Time-Invariant Linear Systems,
Pal
1.4.3* Stable and Unstable Subspaces for Time-In-
variant Linear Systems, 29
1.4.4* Investigation of the Stability of Nonlinear
Systems through Linearization, 31
Transform Analysis of Time-Invariant Systems, 33
1.5.1 Solution of the State Differential Equation
through Laplace Transformation, 33
* See the Preface for the significance of the marked sections.
21
xiii
xiv Contents
1.6*
bY fe
1.8*
£.9*
1.10
5.2
| Pins:
1.5.4
Sse
Frequency Response, 37
Zeroes of Transfer Matrices, 39
Interconnections of Linear Systems, 43
Root Loci, 51
Controllability, 53
La
Definition of Controllability, 53
L62"
Controllability of Linear Time-Invariant
Systems, 55
Ve Si
1.6.4*
16:5"
The Controllable Subspace, 57
Stabilizability, 62
Controllability of Time-Varying Linear
Systems, 64
Reconstructibility, 65
Lie
Definition of Reconstructibility, 65
Ve72t
Reconstructibility of Linear Time-Invariant
Systems, 67
bei5e
1.7.4*
Rate!
The Unreconstructible Subspace, 70
Detectability, 76
Reconstructibility of Time-Varying Linear
Systems, 78
Duality of Linear Systems, 79
Phase-Variable Canonical Forms, 82
Vector Stochastic Processes, 85
LAiGst
1.10.2
1.10.3
Definitions, 85
Power Spectral Density Matrices, 90
The Response of Linear Systems to Sto-
chastic Inputs, 91
1.10.4
Quadratic Expressions, 94
The Response of Linear Differential Systems to White
Noise, 97
Fed
EZ
US lee:
1.11.4
Laliss
White Noise, 97
Linear Differential Systems Driven by
White Noise, 100
The Steady-State Variance Matrix for the
Time-Invariant Case, 103
Modeling of Stochastic Processes, 106
Quadratic Integral Expressions, 108
1.12 Problems, 113
Contents
Chapter 2 Analysis of Linear Control] Systems
2.1
2.2
2.3
2.4
2.5
2.6
2.7
2.8
2.9
Introduction, 119
The Formulation of Control Problems, 121
2.2.1 Introduction, 121
2.2.2 |The Formulation of Tracking and Regulator
Problems, 121
2.2.3. The Formulation of Terminal Control
Problems, 127
Closed-Loop Controllers; The Basic Design
Objective, 128
The Stability of Control Systems, 136
The Steady-State Analysis of the Tracking
Properties, 140
2.5.1 The Steady-State Mean Square Tracking
Error and Input, 140
2.5.2 2.5.3. The Single-Input Single-Output Case, 144
The Multiinput Multioutput Case, 155
The Transient Analysis of the Tracking Properties,
165
The Effects of Disturbances in the Single-Input Single-
Output Case, 167
The Effects of Observation Noise in the Single-Input
Single-Output Case, 174
The Effect of Plant Parameter Uncertainty in the
Single-Input Single-Output Case, 178
2.10*
The Open-Loop Steady-State Equivalent Control
Scheme, 183
2.11
Conclusions, 188
2.12
Problems, 189
Chapter 3
Optimal Linear State Feedback Control Systems
3.1
3.2
Introduction, 193
Stability Improvement of Linear Systems by State
Feedback, 193
3.2.1. Linear State Feedback Control, 193
XV
119
193
Xvi Contents
3.3
3.4
35
3.6
ot
3.8"
3.2.2* Conditions for Pole Assignment and
Stabilization, 198
The Deterministic Linear Optimal Regulator
Problem, 201
3.3.1 Introduction, 201
3.3.2 Solution of the Regulator Problem, 207
3.3.3 Derivation of the Riccati Equation, 216
Steady-State Solution of the Deterministic Linear
Optimal Regulator Problem, 220
3.4.1 Introduction and Summary of Main Results,
220
3.4.2* Steady-State Properties of Optimal
Regulators, 230
3.4.3* Steady-State Properties of the Time-
Invariant Optimal Regulator, 237
3.4.4* Solution of the Time-Invariant Regulator
Problem by Diagonalization, 243
Numerical Solution of the Riccati Equation, 248
3.5.1 Direct Integration, 248
3.5.2 The Kalman—Englar Method, 249
3.5.3* Solution by Diagonalization, 250
3.5.4* Solution by the Newton—Raphson Method,
251
Stochastic Linear Optimal Regulator and Tracking
Problems, 253
3.6.1 Regulator Problems with Disturbances—
The Stochastic Regulator Problem, 253
3.6.2 Stochastic Tracking Problems, 257
3.6.3. Solution of the Stochastic Linear Optimal
Regulator Problem, 259
Regulators and Tracking Systems with Nonzero Set
Points and Constant Disturbances, 270
3.7.1 Nonzero Set Points, 270
3.7.2* Constant Disturbances, 277
Asymptotic Properties of Time-Invariant Optimal
Control Laws, 281
3.8.1* Asymptotic Behavior of the Optimal Closed-
Loop Poles, 281
Contents xvii
3.8.2* Asymptotic Properties of the Single-Input
Single-Output Nonzero Set Point Regulator,
297
3.8.3* The Maximally Achievable Accuracy of
Regulators and Tracking Systems, 306
3.9* Sensitivity of Linear State Feedback Control Systems,
312
3.10 Conclusions, 318
3.11 Problems, 319
Chapter 4 Optimal Linear Reconstruction of the State 4.1 Introduction, 328
4.2 Observers, 329
4.2.1. Full-Order Observers, 329
4.2.2* Conditions for Pole Assignment and
Stabilization of Observers, 334
4.2.3* Reduced-Order Observers, 335
4.3. The Optimal Observer, 339
4.3.1. A Stochastic Approach to the Observer
Problem, 339
4.3.2 The Nonsingular Optimal Observer Problem
with Uncorrelated State Excitation and
Observation Noises, 341
4.3.3* The Nonsingular Optimal Observer Problem
with Correlated State Excitation and
Observation Noises, 351
4,.3.4* The Time-Invariant Singular Optimal
Observer Problem, 352
4.3.5* The Colored Noise Observation Problem,
356
4.3.6* Innovations, 361
4.4* The Duality of the Optimal Observer and the Optimal
Regulator; Steady-State Properties of the Optimal
Observer, 364
4.4.1* Introduction, 364
4.4.2* The Duality of the Optimal Regulator and
the Optimal Observer Problem, 364
328
XViii Contents
Chapter 5
4.4.3* Steady-State Properties of the Optimal
Observer, 365
4.4.4* Asymptotic Properties of Time-Invariant
Steady-State Optimal Observers, 368
4.5 Conclusions, 373
4.6 Problems, 373
Optimal Linear Output Feedback Control Systems 5.1. Introduction, 377
5.2 The Regulation of Linear Systems with Incomplete
Measurements, 378
5.2.1 The Structure of Output Feedback Control
Systems, 378
5.2.2* Conditions for Pole Assignment and
Stabilization of Output Feedback Control
Systems, 388
5.3. Optimal Linear Regulators with Incomplete and
Noisy Measurements, 389
5.3.1 Problem Formulation and Solution, 389
5.3.2 Evaluation of the Performance of Optimal
Output Feedback Regulators, 391
5.3.3* Proof of the Separation Principle, 400
5.4 Linear Optimal Tracking Systems with Incomplete
and Noisy Measurements, 402
5.5 Regulators and Tracking Systems with Nonzero Set
Points and Constant Disturbances, 409
5.5.1 Nonzero Set Points, 409
5.5.2* Constant Disturbances, 414
5.6* Sensitivity of Time-Invariant Optimal Linear Output
Feedback Control Systems, 419
5.7* Linear Optimal Output Feedback Controllers of
Reduced Dimensions, 427
5.7.1* Introduction, 427
5.7.2* Controllers of Reduced Dimensions, 428
5.7.3* Numerical Determination of Optimal Con-
trollers of Reduced Dimensions, 432
Te)
Contents
5.8
Conclusions, 436
5.9
Problems, 438
Chapter 6* Linear Optimal Control Theory for Discrete-Time Systems
6.1
6.2
6.3
6.4
Introduction, 442
Theory of Linear Discrete-Time Systems, 442
O:24
6.2.2
Introduction, 442
State Description of Linear Discrete-Time
Systems, 443
6.2.3
Interconnections of Discrete-Time and Con-
tinuous-Time Systems, 443
6.2.4
62:5
6.2.6
Solution of State Difference Equations, 452
Stability, 454
Transform Analysis of Linear Discrete-Time
Systems, 455
6.2.7
6.2.8
ype)
6.2.10
6.2.11
Controllability, 459
Reconstructibility, 462
Duality, 465
Phase-Variable Canonical Forms, 466
Discrete-Time Vector Stochastic Processes,
467
6.2.12
Linear Discrete-Time Systems Driven by
White Noise, 470
Analysis of Linear Discrete-Time Control Systems,
475
Onset
G32
G:3:3
Introduction, 475
Discrete-Time Linear Control Systems, 475
The Steady-State and the Transient Analysis
of the Tracking Properties, 478
6.3.4
Further Aspects of Linear Discrete-Time
Control System Performance, 487
Optimal Linear Discrete-Time State Feedback
Control Systems, 488
6.4.1
Introduction, 488
6.4.2
Stability Improvement by State Feedback,
488
6.4.3
The Linear Discrete-Time Optimal
Regulator Problem, 490
xix
442
xx Contents
6.4.4 Steady-State Solution of the Discrete-Time
Regulator Problem, 495
6.4.5 TheStochastic Discrete-Time Linear Optimal
Regulator, 502
6.4.6 Linear Discrete-Time Regulators with Non-
zero Set Points and Constant Disturbances,
504
6.4.7. Asymptotic Properties of Time-Invariant
Optimal Control Laws, 509
6.4.8 Sensitivity, 520
6.5 Optimal Linear Reconstruction of the State of Linear
Discrete-Time Systems, 522
6.5.1 Introduction, 522
6.5.2 The Formulation of Linear Discrete-Time
Reconstruction Problems, 522
6.5.3. Discrete-Time Observers, 525
6.5.4 Optimal Discrete-Time Linear Observers,
528
6.5.5 Innovations, 533
6.5.6 Duality of the Optimal Observer and
Regulator Problems; Steady-State Prop-
erties of the Optimal Observer, 533
6.6 Optimal Linear Discrete-Time Output Feedback
Systems, 536
6.6.1 Introduction, 536
6.6.2 The Regulation of Systems with Incomplete
Measurements, 536
6.6.3. Optimal Linear Discrete-Time Regulators
with Incomplete and Noisy Measurements,
532
6.6.4 Nonzero Set Points and Constant Distur-
bances, 543
6.7 Conclusions, 546
6.8 Problems, 547
References 553
Index 563
NOTATION AND SYMBOLS
Chapters are subdivided into sections, which are numbered 1.1, 1.2, 1.3, and
so on. Sections may be divided into subsections, which are numbered 1.1.1,
1.1.2, and so on. Theorems, examples, figures, and similar features are
numbered consecutively within each chapter, prefixed by the chapter number.
The section number is usually given in parentheses if reference is made to an
item in another section.
Vectors are denoted by lowercase letters (such as x and u), matrices by
uppercase letters (such as A and B) and scalars by lower case Greek letters
(such as « and f). It has not been possible to adhere to these rules completely
consistently; notable exceptions are ¢ for time, i and / for integers, and so on.
The components of vectors are denoted by lowercase Greek letters which
correspond as closely as possible to the Latin letter that denotes the vector;
thus the n-dimensional vector x has as components the scalars &,, &,--+, é,,,
the m-dimensional vector y has as components the scalars 7), %2,°**, ms
and so on. Boldface capitals indicate the Laplace or z-transform of the
corresponding lowercase time functions [X(s) for the Laplace transform of
x(t), Y(z) for the z-transform of y(Z), etc.].
Operations
ae transpose of the vector «
COIN acess ney) column vector with components &, &,°°°, &,
(1, Ne» °°» Nn) row vector with components 7, 2,°** , %n
ay partitioning of a column vector into subvectors 2,
, COl (21, Xz)
( and x,
|| || norm of a vector x
dim (2) dimension of the vector x
Ae transpose of the matrix 4
Be inverse of the square matrix A
tr (A) trace of the square matrix A
det (A) determinant of the square matrix A
Xxi
xxii Notation and Symbols
alae (Ag Ags An)
(Cyan €,,)
ii
ie
diagonal matrix with diagonal entries 2,, 4.,°*+, A,
partitioning of a matrix into its columns @, @:,°**, pn
partitioning of a matrix into its rows f{, fo,°** > Sn
partitioning of a matrix into column blocks 7},
Tae oe n
partitioning of a matrix into row blocks U,, U;,::*,
U m
U
AB
GD
diag Cinco oe)
M>0,M>0
M>N,M 2.N
a(t) or a)
L {x(t)}
Re (a)
Im (a)
min (a, /)
min
max
a
partitioning of a matrix into blocks A, B, C, and D
block diagonal matrix with diagonal blocks J,,
A pee morn B.\
the real symmetric or Hermitian matrix is positive-
definite or nonnegative-definite, respectively
the real symmetric or Hermitian matrix M — N is
positive-definite or nonnegative-definite, respec-
tively
time derivative of the time-varying vecto1 2(t)
Laplace transform of 2(t)
real part of the complex number «
imaginary part of the complex number «
the smallest of the numbers « and 6
the minimum with respect to «
the maximum with respect to «
Commonly used symbols
0
A(t), A(i), A
zero; zero vector; zero matrix
plant matrix of a finite-dimensional linear differential
system
Bt), Bi), B
Cf); Care
C(t), Co)» Coco
C,(t), GC.) Cae
D(t), D(i), D
e
e(t) or e(i)
e;
VS;
E(i) t F(t), F(i), F, F
G(s), G(z)
H(s), H(z)
j
if
Jj J(s), J@) K(t), K(i), K, K
K(s) HG), A)
n
N(s), N@)
ie PQ)ePO) Ae
P(s), P(z)
Py g 2
Q(t), Qi), O
Qo Q(t), OC)
riper)
R(t), Ryd), Ry
R,(t), Ro(i), Re
Notation and Symbols xxiii
input matrix of a finite-dimensional linear differential
system (B becomes 5 in the single-input case)
output matrix of a finite-dimensional linear differential
system; output matrix for the observed variable
(C becomes c in the single-output case)
mean square tracking or regulating error
mean square input
output matrix for the controlled variable (D becomes
d in the single-output case)
base of the natural logarithm
tracking or regulating error; reconstruction error
i-th characteristic vector
expectation operator
gain matrix of the direct link of a plant (Ch. 6 only)
frequency
regulator gain matrix (F becomes fin the single-input
case)
controller transfer matrix (from y to —u)
plant transfer matrix (from u to y)
integer
unit matrix
ies: integer
return difference matrix or function
observer gain matrix (K becomes k in the single-
output case)
plant transfer matrix (from wu to z)
closed-loop transfer matrix
dimension of the state x
transfer matrix or function from r to uw in a control
system
controllability matrix
solution of the regulator Riccati equation
controller transfer matrix (from r to u)
terminal state weighting matrix
reconstructibility matrix
variance matrix; solution of the observer Riccati
equation
initial variance matrix
second-order moment matrix
reference variable
weighting matrix of the state
weighting matrix of the input
XXiv Notation and Symbols
R,(t), R,(i), R; weighting matrix of the tracking of regulating error
R(t, ty), Rit se ty), R,(i, J), R(t —J)
covariance function of the stochastic process v
5
variable of the Laplace transform
S(s), S(2)
sensitivity matrix or function
b
time
T(s) or T(z)
transmission
u(t), u(i)
input variable
v(t), v(i)
stochastic process
Un(t), Vrald)
observation noise, measurement noise
U9
constant disturbance
Uo(t), Voli)
equivalent disturbance at the controlled variable
v(t), Vp(i)
disturbance variable
V(t), Vii)
intensity of a white noise process
w(t), w(i)
white noise process
W(t), W.(i), W.
weighting matrix of the tracking or regulating error
Wt), Wi), Wi,
weighting matrix of the input
a(t), w(i)
state variable
&(t), €(7)
reconstructed state variable
Xo
initial state
y(t), y(i)
output variable; observed variable
z-transform variable
at), 2(i)
controlled variable
Z
compound matrix of system and adjoint differential
equations
O(t)
delta function
A
sampling interval
C(t), E(i)
scalar controlled variable
ee n(i)
scalar output variable; scalar observed variable
time difference; time constant; normalized angular
frequency
A;
i-th characteristic value
L(t), (i)
scalar input variable
v(t), (i)
scalar stochastic process
v;
i-th zero
E(t), &(7)
scalar state variable
in
i-th pole
weighting coefficient of the integrated or mean square
Input
X,(@), U(9)
spectral density matrix of the stochastic process v
$(s), $(2)
characteristic polynomial
PS), De(2)
closed-loop characteristic polynomial
D(t, to), D(i, ig)
y(s), pl)
@
ST units
Notation and Symbols
XXVY
transition matrix
numerator polynomial
angular frequency
ampere
hertz
kilogram
kilomole
meter
newton
radian
second
volt
ohm
rane ” wai) en? 7
is : ot ae
aw ; a SS pean
SS =e sions
We. e
= >
a “a
es “
> = Loh
us =e G
- =
7 oo
e é
i i
» >
a ay
o> Mu
7
Ca
J in PE
al
—
LINEAR OPTIMAL
CONTROL SYSTEMS
Il ELEMENTS OF LINEAR
SYSTEM THEORY
1.1 INTRODUCTION
This book deals with the analysis and design of linear control systems. A
prerequisite for studying linear control systems is a knowledge of linear
system theory. We therefore devote this first chapter to a review of the most
important ingredients of linear system theory. The introduction of control
problems is postponed until Chapter 2.
The main purpose of this chapter is to establish a conceptua! framework,
introduce notational conventions, and give a survey of the basic facts of
linear system theory. The starting point is the state space description of linear
systems. We then proceed to discussions of the solution of linear state
differential equations, the stability of linear systems, and the transform
analysis of such systems. The topics next dealt with are of a more advanced
nature; they concern controllability, reconstructibility, duality, and phase-
variable canonical forms of linear systems. The chapter concludes with a
discussion of vector stochastic processes and the response of linear systems
to white noise. These topics play an important role in the development of
the theory.
Since the reader of this chapter is assumed to have had an introduction to
linear system theory, the proofs of several well-known theorems are omitted.
References to relevant textbooks are provided, however. Some topics are
treated in sections marked with an asterisk, notably controllability, recon-
structibility, duality and phase-variable canonical forms. The asterisk
indicates that these notions are of a more advanced nature, and needed only
in the sections similarly marked in the remainder of the book.
1.2 STATE DESCRIPTION OF LINEAR SYSTEMS
1.2.1 State Description of Nonlinear and Linear Differential Systems
Many systems can be described by a set of simultaneous differential equations
of the form
a(t) = f [x(t), u(t), ¢]. 1-1
1
74 Elements of Linear System Theory
Here ¢ is the time variable, x(t) is a real n-dimensional time-varying column
vector which denotes the state of the system, and u(t) is a real k-dimensional
column vector which indicates the input variable or control variable. The
function f is real and vector-valued. For many systems the choice of the
state follows naturally from the physical structure, and 1-1, which will be
called the state differential equation, usually follows directly from the ele-
mentary physical laws that govern the system.
Let y(t) be a real /-dimensional system variable that can be observed or
through which the system influences its environment. Such a variable we call
an output variable of the system. It can often be expressed as
y(t) = gix(t), u(t), ¢]- 1-2
This equation we call the output equation of the system.
We call a system that is described by 1-1 and 1-2 a finite-dimensional
differential system or, for short, a differential system. Equations 1-1 and 1-2
together are called the system equations. If the vector-valued function g
contains u explicitly, we say that the system has a direct link.
In this book we are mainly concerned with the case where fand g are linear
functions. We then speak of a (finite-dimensional) linear differential system.
Its state differential equation has the form
a(t) = A(t)x(t) + B(t)u(t), 1-3
where A(t) and B(t) are time-varying matrices of appropriate dimensions.
We call the dimension n of x the dimension of the system. The. output equation
for such a system takes the form
y(t) = C(t)x(t) + D(t)u(t). 4
If the matrices A, B, C, and D are constant, the system is time-invariant.
1.2.2 Linearization
It is the purpose of this section to show that if u(t) is a given input to a system
described by the state differential equation 1-1, and x(t) is a known solution
of the state differential equation, we can find approximations to neighboring
solutions, for small deviations in the initial state and in the input, from a
linear state differential equation. Suppose that x9(f) satisfies
%o(t) = f [xo(t), uo(t), ft], fost by 1-5
We refer to uw as a nominal input and to x as a nominal trajectory. Often we
can assume that the system is operated close to nominal conditions, which
means that wv and x deviate only slightly from uy and xy. Let us therefore write
u(t) = u(t) + a(t), Lcd ad
x 1-6
X(t) = Lo(to) + #(to),
1.2 State Description of Linear Systems 3
where a(t) and #(t)) are small perturbations. Correspondingly, let us intro-
duce #(t) by
x(t) = x(t) + £1), era or 1-7
Let us now substitute x and u into the state differential equation and make
a Taylor expansion. It follows that
Ho(t) + F(t) = f [ao(t), wold), t] + Jelxo(t), wo(t), t}e(0)
“i J lt (0), Up(t), t]a(t) i h(t), tg = t < th. 1-8
Here J, and J,, are the Jacobian matrices of f with respect to x and u, re-
spectively, that is, J, is a matrix the (i, j)-th element of which is
Of;
(J tsb aS
) oP) dé,
, 1-9
where f; is the i-th component of f and &, the j-th component of x. J, is
similarly defined. The term A(t) is an expression that is supposed to be
“‘small’’ with respect to and a. Neglecting h, we see that and # approxi-
mately satisfy the /inear equation
&(t) = A(H#(t) + BINA), t<t<t, 1-10
where A(t) = J,[x9(t), uo(t), t] and B(t) = J,,[%9(t), uo(t), t]. We call 1-10 the
linearized state differential equation. The initial condition of 1-10 is €(¢).
The linearization procedure outlined here is very common practice in the
solution of control problems. Often it is more convenient to linearize the
system differential equations before arranging them in the form of state
differential equations. This leads to the same results, of course (see the
examples of Section 1.2.3).
It can be inferred from texts on differential equations (see, e.g., Roseau,
1966) that the approximation to x(t) obtained in this manner can be made
arbitrarily accurate, provided the function f possesses partial derivatives with
respect to the components of x and w near the nominal values xo, %, the
interval [fo, t,] is finite, and the initial deviation #(t)) and the deviation of the
input @ are chosen sufficiently small.
In Section 1.4.4 we present further justification of the extensive use of
linearization in control engineering.
1.2.3. Examples
In this section several examples are given which serve to show how physical
equations are converted into state differential equations and how linearization
is performed. We discuss these examples at some length because later they
are extensively used to illustrate the theory that is given.
4 Elements of Linear System Theory
pendulum
carriage
Fig. 1.1. An inverted pendulum positioning
SF \Gaes/ system.
Example 1.1. Inverted pendulum positioning system.
Consider the inverted pendulum of Figure 1.1 (see also, for this example,
Cannon, 1967; Elgerd, 1967). The pivot of the pendulum is mounted on a
carriage which can move in a horizontal direction. The carriage is driven by a
small motor that at time ¢ exerts a force w(t) on the carriage. This force is
the input variable to the system.
Figure 1.2 indicates the forces and the displacements. The displacement of
the pivot at time ¢ is s(t), while the angular rotation at time ¢ of the pendulum
is ¢(t). The mass of the pendulum is m, the distance from the pivot to the
center of gravity L, and the moment of inertia with respect to the center of
gravity J. The carriage has mass M. The forces exerted on the pendulum are
center of gravity
} Ss
pivot
Fig. 1.2. Inverted pendulum: forces and displacements.
1.2 State Description of Linear Systems 5
the force mg in the center of gravity, a horizontal reaction force H(t), and a
vertical reaction force V(t) in the pivot. Here g is the gravitational acceleration.
The following equations hold for the system:
da’
as [s(t) + L sin $(t)] = A(t), 1-11
d?
m WP [L cos (t)] = V(t) — meg, 1-12
J. ae = LV(t) sin ¢(t) — LH(t) cos ¢(t), 1-13
d’s(t) io - ds(t)
M ae M(t) — H(t) — F Te 1-14
Friction is accounted for only in the motion of the carriage and not at the
pivot; in 1-14, F represents the friction coefficient. Performing the differenti-
ations indicated in 1-11 and 1-12, we obtain
m5(t) + mLd(t) cos ¢(t) — mL¢*(t) sin d(t) = H(t), —mL#(t) sin d(t) — mL¢2(t) cos ¢(t) = V(t) — mg, Jé(t) = LV(t) sin 6(t) — LH(t) cos (2), M3(t) = w(t) — H(t) — Fs(t). 1-15
1-16
1-17
1-18
To simplify the equations we assume that m is small with respect to M and
therefore neglect the horizontal reaction force H(t) on the motion of the
carriage. This allows us to replace 1-18 with
Ms(t) = w(t) — FS(t). 1-19
Elimination of H(t) and V(t) from 1-15, 1-16, and 1-17 yields
(J + mL?)h(t) — mgL sin d(t) + mLs(t) cos ¢(t) = 0. 1-20
Division of this equation by J + mL? yields
e we
Ae : sin g(t) + 5, 5(t) cos A(t) = 0, 1-21
where
2
pe J+ mE 1-22
mL
6 Elements of Linear System Theory
This quantity has the significance of “‘effective pendulum length’ since a
mathematical pendulum of length L’ would also yield 1-21.
Let us choose as the nominal solution p(t) =0, s(t)=0, A(t) = 0.
Linearization can easily be performed by using Taylor series expansions for
sin ¢(t) and cos ¢(t) in 1-21 and retaining only the first term of the series.
This yields the linearized version of 1-21:
g ie
d(t) r (t) y (t)
t) — = d(t) + — S(t) = 0. 1-23
We choose the components of the state x(t) as
E(t) = s(t),
&,(t) = s(t),
1-24
&3(t) = s(t) + L'g(0),
E,(t) = s(t) + L’$().
The third component of the state represents a linearized approximation to
the displacement of a point of the pendulum at a distance L’ from the pivot.
We refer to &,(t) as the displacement of the pendulum. With these definitions
we find from 1-19 and 1-23 the linearized state differential equation
E(t) — E(t),
fara NY oes 2 = E
E(t) = Wet E(t),
é,(t) = €,(t), 1-25
BG) tea ; ORO
In vector notation we write
mn @ inet 0
0 => 0 oO a
re xth+]f “iu, 1-26
C= 405 shoes 0
by les
where x(t) = col [&,(¢), S2(t), &3(t), E4(t)].
1.2 State Description of Linear Systems a
Later the following numerical values are used:
£024 ar
M
4 = ike,
M 1-27
2 = 656-7,
L
L = 0.842 m
Example 1.2. A stirred tank.
As a further example we treat a system that is to some extent typical of
process control systems. Consider the stirred tank of Fig. 1.3. The tank is fed
valves
feed Fy feed Fa
concentration cy concentration cg
volume V
Gees 2 ~ concentration c
propellor
outgoing flow F
concentration c
Fig. 1.3. A stirred tank.
with two incoming flows with time-varying flow rates F,(t) and F,(t). Both
feeds contain dissolved material with constant concentrations c, and ¢,,
respectively. The outgoing flow has a flow rate F(t). It is assumed that the
tank is stirred well so that the concentration of the outgoing flow equals the
concentration c(t) in the tank.
8 Elements of Linear System Theory
The mass balance equations are
a = F,(t) + F(t) — F(t), 1-28
7 [eV ()] = cyt) + egF a(t) — c()F CO), 1-29
a
where V(t) is the volume of the fluid in the tank. The outgoing flow rate
F(t) depends upon the head h(f) as follows
F(t) = kVh(), 1-30
where k is an experimental constant. If the tank has constant cross-sectional
area S, we can write
FQ) =k jee 1-31
S
so that the mass balance equations are
OO = Fy) + Ful) — ‘| ull dt cs
1-32
PACOG) = ¢F\(t) + cF(t) — c(t)k ‘ oe 1-33
Let us first consider a steady-state situation where all quantities are constant,
say Fio, Fyo, and Fy for the flow rates, Vy for the volume, and cy for the con-
centration in the tank. Then the following relations hold:
0 = Fyo + Fo — Fos 0 = cy Fio + CoF 29 — CoFo, 1-34
1-35
roa k | ¥, 1-36
S
For given Fy and Fy9, these equations can be solved for Fy, Vj, and co. Let
us now assume that only small deviations from steady-state conditions occur.
We write
Fy(t) = Fy + (0),
Fy(t) = Foo + Me(t),
V(t) = Vo t+ &(t),
c(t) = ce + &.(t),
1-37
1.2 State Description of Linear Systems 9
where we consider mw, and mw, input variables and &, and &, state variables.
By assuming that these four quantities are small, linearization of 1-32 and
1-33 gives
ve _& |%
E(t) = y(t) + w(t) Ny e E,(t), 0
1-38
E(t)Vo iy Co6i(t) = Cyy(t) + Cofte(t) — Co Ll FD |% (t). 1-39
Substitution of 1-36 into these equations yields
: 1F
E(t) = w(t) + pot) — = > &(0), 1-40
OV.
; ‘hanes
Ex(t)Vo + cobi(t) = Cia(t) + Come(t) — 5 V. E(t) — Foé(t). 1-41
0
We define
Vi
+ = 0, 1-42
Fo
and refer to 9 as the holdup time of the tank. Elimination of £, from 1-41
results in the linearized state differential equation
/
20
a1) = 1 a(t) + u(t), 1-43
O —
0
0
where x(t) = col [&(t), &(t)] and u(t) = col [u,(t), u(t)]. If we moreover
define the output variables
vie 1
= ig Ge are tt) SS (D);
m(t) = F(t) — Fo ay, M0 ol
not) = c(t) — Co = S2(d),
we can complement 1-43 with the linearized output equation
ar
yt) = {29 — Jain), Ord
1-44
1-45
10 Elements of Linear System Theory
where y(t) = col [7,(t), 12(t)]. We use the following numerical values:
Fig = 0.015 m?/s,
Fig = 0.005 m?/s;
Fy = 0.02 m*/s,
= kimnol m=, 1-46
¢, = 2.kmol/m’,
Cy = 1.25 kmol/m?,
Vo = 1 mes
6 = 50s.
This results in the linearized system equations
—0.01 0 ( 1 1 “)
at — CE + u(t :
0 —0.02 —O25 70713 1-47
0.01 0
ne = A 1)20:
1.2.4 State Transformations
As we shall see, it is sometimes useful to employ a transformed representa-
tion of the state. In this section we briefly review linear state transformations
for time-invariant linear differential systems. Consider the linear time-
invariant system
a(t) = Ax(t) + Bu(t),
y(t) = C(t). roe
Let us define a transformed state variable
meee Tart). 1-49
where 7 is a constant, nonsingular transformation matrix. Substitution of
a(t) = T-1x’(t) into 1-48 yields
T4'(t) = AT 2'(t) + Ba); y(t) = CT4a/(), :
150
or
a(t) = TAT—2'(t) + TBu(t),
y(t) = CT—2'(t). oh
1.3 Solution of State Equation 11
These are the state differential equation and the output equation of the system
in terms of the new state x(t). It is clear that the transformed representation
is completely equivalent to the original system, since we can always re-
construct the behavior of the system in terms of the original state by the
relation x(t) = T-12’(t). This derivation shows that the choice of the state
is to some extent arbitrary and therefore can be adapted to suit various
purposes. Many properties of linear, time-invariant systems remain un-
changed under a state transformation (Problems 1.3, 1.6, 1.7).
1.3 SOLUTION OF THE STATE DIFFERENTIAL
EQUATION OF LINEAR SYSTEMS
1.3.1 The Transition Matrix and the Impulse Response Matrix
In this section we discuss the solution of the linear state differential equation
a(t) = A(t)x(t) + B(t)u(t). 1-52
We first have the following result (Zadeh and Desoer, 1963; Desoer, 1970).
Theorem 1.1. Consider the homogeneous equation
a(t) = A(t)x(t). 1-53
Then if A(t) is continuous for all t, 1-53 always has a solution which can be
expressed as
x(t) = Dt, to)x(t%), for all t. 1-54
The transition matrix D(t, to) is the solution of the matrix differential equation
a OC t= AOE). “feral,
ce = 1-55
| P(t; to) = 1,
where I is the unit matrix. :
For a general time-varying system, the transition matrix rarely can be ob-
tained in terms of standard functions, so that one must resort to numerical
integration techniques. For time-invariant systems of low dimensions or of a
simple structure, the transition matrix can be computed by any of the methods
discussed in Sections 1.3.2, 1.3.3, and 1.5.1. For complicated time-invariant
problems, one must employ numerical methods such as described in Section
Nee BP
The transition matrix can be shown to possess the following properties
(Zadeh and Desoer, 1963).
12 Elements of Linear System Theory
Theorem 1.2. The transition matrix ®(t, to) of a linear differential system has
the following properties :
(a) D(t,, )O(t, to) = D(tg, to) for all to, ty, te; (b) P(t, to) is nonsingular for all t, to; (C\eDA Get DO sae Wonalkigis: 1-56
1-57
1-58
(d) © Oto, {) ss = AO" (an i for-alld ie 1-59
t
where the superscript T denotes the transpose.
Property (d) shows that the system #(t) = —A*(t)x(t) has the transition
matrix ®7(f),f). This can be proved by differentiating the identity
Ot OC t) =
Once the transition matrix has been found, it is easy to obtain solutions
to the state differential equation 1-52.
Theorem 1.3. Consider the linear state differential equation
a(t) = A(t)a(t) + B(t)u(t). 1-60
Then if A(t) is continuous and B(t) and u(t) are piecewise continuous for allt,
the solution of 1-60 is
a(t) = O(F, tp)%(to) +| 00, 7)B(r)u(r) dr 1-61
for all t. ?
This result is easily verified by direct substitution into the state differential
equation (Zadeh and Desoer, 1963).
Consider now a system with the state differential equation 1-60 and the
output equation
ue) == Chany 1-62
For the output variable we write
t
Y(t) = C(HD(E, ty)a(to) + C(t) [ D(t, 7) B(r)u(z) dr. 1-63
J to
If the system is initially in the zero state, that is, x(t)) = 0, the response of
the output variable is given by
t
y(t) =| K(t, r)u(r) dr, Litas 1-64
to
where
K(t. 7) = C(t)®(t, 7)B(r), OE 1-65
1.3 Solution of State Equation 13
The matrix K(f, 7) is called the impulse response matrix of the system because
the (7, j)-th element of this matrix is the response at time ¢ of the i-th com-
ponent of the output variable to an impulse applied at the j-th component of
the input at time + > fy while all other components of the input are zero
and the initial state is zero. The step response matrix S(t, 7) is defined as
t
SC) -| K(t, tr’) dr’, i: Sa 1-66
The (i, 7)-th element of the step response matrix is the response at time ¢ of
the i-th component of the output when the j-th component of the input is a
step function applied at time 7 > fy while all other components of the input
are zero and the initial state is the zero state.
1.3.2 The Transition Matrix of a Time-Invariant System
For a time-invariant system, the transition matrix can be given in an explicit
form (Zadeh and Desoer, 1963; Desoer, 1970; Polak and Wong, 1970).
Theorem 1.4. The time-invariant system
“(t) = Ax(t) 1-67
has the transition matrix
Dips) es 1-68
where the exponential of a square matrix M is defined as
M 1 2 I 3
e St Ma aie doses, 1-69
This series converges for all M.
For small dimensions or simple structures of the matrix A, this result can be
used to write down the transition matrix explicitly in terms of elementary
functions (see Example 1.3). For high dimensions of the matrix A, Theorem
1.4 is quite useful for the computation of the transition matrix by a digital
computer since the repeated multiplications and additions are easily pro-
grammed and performed. Such programs must include a stopping rule to
truncate the infinite series after a finite number of terms. A usual stopping
rule is to truncate when the addition of a new term changes each of the
elements of the partial sum by less than a specified fraction. Numerical
difficulties may occur when M is too large; this means that t — f) in 1-68
cannot be chosen too large (see Kalman, 1966; Kalman and Englar, 1966).
Having a program for computing matrix exponentials is essential for anyone
who wishes to simulate linear time-invariant systems. There are numerous
references on the computation of matrix exponentials and simulating linear
14 Elements of Linear System Theory
systems; some of these are: Everling (1967), Liou (1966a,b, 1967, 1968),
Whitney (1966a-c), Bickart (1968), Fath (1968), Plant (1969), Wallach
(1969), Levis (1969), Rohrer (1970), Mastascusa and Simes (1970), and
Krouse and Ward (1970). Melsa (1970) gives listings of FORTRAN com-
puter programs.
By using 1-68 the time-invariant version of 1-63 becomes
y(t) = Cet*a(t.) + C i eA Bu(r) dr. t
to
1-70
Comparing 1-64 and 1-70 we see that the impulse response matrix of a time-
invariant linear differential system depends on ¢ — 7 only and can be ex-
pressed as
K(t —.7) = Ce" B, t>r. 1-71
Example 1.3. Stirred tank.
The homogeneous part of the linearized state differential equation of the
stirred tank of Example 1.2 is given by
ea, 20
a(t) = x(t). 1-72
afar
It is easily found that its transition matrix is given by
DG) See, 1-73
where
t bP ENO eae eg aren pine 290 2 \30) “3 0\54, i
|
0) 1 —
|
= 2 ie
+ N |= aT oi ~~
+
beet Le CES Gejil|bes =
e7 t/28 0 ‘
= ( 0 si) 1-74
The impulse response matrix of the system is
ee on (t-1)/20 o on tt-7)/20
20 20
K(t — 7) = F 1-75
Crane on tt-1)/0 Co — Co ,—(t-1)/0
Vo Vo
1.3 Solution of State Equation 15
We find for the step response matrix of the stirred tank:
fe e (t1)/20 1 e (t-1)/20
Sit—7) = eae ies ey C2 — Co (1 nad ee oy
lie Fo
. 1-76
In Fig. 1.4 the step responses are sketched for the numerical data of Example
EPA:
step in feed Fy, of step in feed Fp of
3
incremental 0.002 m3/s 0.002 m3/s
outgoing | |
flow
0.00 2|— =
Ny1(t)
1 i
) 100 200 t —(s)
incremental
outgoing
concentration
Fig. 1.4. Response of the stirred tank to a step of 0.002 m*/s in the feed F, (left column)
and to a step of 0.002 m/s in the feed F, (right colurnn).
1.3.3. Diagonalization
An explicit form of the transition matrix of a time-invariant system can be
obtained by diagonalization of the matrix A. The following result is available
(Noble, 1969).
Theorem 1.5. Suppose that the constant n Xn matrix A has n distinct
characteristic values 2, A2,°**,4,. Let the corresponding characteristic
vectors be e, €:,°** , €n. Define then X n matrices
1 (Cres ys en) 1-77a
AeadiagiAy Agee tea). 1-77b
16 Elements of Linear System Theory
Then T is nonsingular and A can be represented as
A = TAT. 1-78
Here the notation 1-77a implies that the vectors e,, é@,°**,@, are the
columns of the matrix 7, and 1-77b means that A is a diagonal matrix with
Ay, 425° °°, A, as diagonal elements. It is said that T diagonalizes A.
The following fact is easily verified.
Theorem 1.6. Consider the matrix A that satisfies the assumptions of
Theorem 1.5. Then
(a) ef = Ter, 1-79
(b) eA’ = diag (eo e7%4- = se"). 1-80
This result makes it simple to compute exp (A?) once A is diagonalized. It is
instructive to present the same result in a different form.
Theorem 1.7. Consider the time-invariant system
a(t) = Ax); 1-81
where A satisfies the assumptions of Theorem 1.5. Write the matrix T~ in the
form
a
i
/ tar . ; 1-82
de
that is, the row vectors fi, fo,*** » fn are the rows of T. Then the solution of
1-81 can be written as
a(t) = > ere f.a(0). 1-83
i=l
This is easily shown by expanding a(t) = T exp (At)T—2(0) in terms of
e;, f;, and exp (A,t), i= 1,2,+++,m. We write 1-83 in the form
a(t )vee Ste "en 1-84
i=1
where the yu, are the scalars f,x(0), i = 1, 2,---,n. This clearly shows that
the response of the system 1-81 is a composition of motions along the
characteristic vectors of the matrix A. We call such a motion a mode of the
system. A particular mode is excited by choosing the initial state to have a
component along the corresponding characteristic vector.
1.3 Solution of State Equation 17
It is clear that the characteristic values 4,,i = 1, 2,---+,n,toaconsiderable
extent determine the dynamic behavior of the system. We often refer to these
numbers as the poles of the system.
Even if the matrix A has multiple characteristic values, it can be diagonalized
provided that the number of linearly independent characteristic vectors for
each characteristic value equals the multiplicity of the characteristic value.
The more complicated case, where the matrix A cannot be diagonalized, is
discussed in Section 1.3.4.
Example 1.4. Inverted pendulum.
The homogeneous part of the state differential equation of the inverted
pendulum balancing system of Example 1.1 is
0 1 Ory
0 me 0 0
M
n= BL), 1-85
0 0 OE |
154 j pee
The characteristic values and characteristic vectors of the matrix A can be
found to be
1 1 0 0
oe . 6
0 M
i i i ca ot st kal Vl ee 1
0 es a — /&
Be VL
1-86
where
s&
gee Lies 1-87
g ne
18 Elements of Linear System Theory
and where we assume that the denominator of « differs from zero. The matrix
T and its inverse are
presets wineholiy
M
te tbe: fe 1 1 ;
=, =
FF g g
0 —«— JE =
NES NTS ig NE
1 wt 0 0
F
0 ae 0 0
F a
ab ,
poe | fe ee 1-88
2 F ng Nas
M pe
a ae pene
2 F 2 Fira) Nad 4
2, fe
M L
The modes of the system are
1 1 0 0
F
0 —_—— 0 0
M — —
[ oo (F/ Mt (Vol Li etVoiL
1 a : 1 1
0 ee = » ee
M hy L)
1-89
The first mode represents the indifference of the system with respect to
horizontal translations, while the third mode exhibits the unstable character
of the inverted pendulum.
1.3 Solution of State Equation 19
1.3.4* The Jordan Form
In the preceding section we saw that the representation of the transition
matrix can be facilitated by diagonalizing the matrix A. This diagonalization
is not possible if the n x n matrix A does not have n linearly independent
characteristic vectors. In this case, however, it is possible to bring A into the
so-called Jordan normal form which is almost diagonal and from which the
transition matrix can easily be obtained.
We first recall a few facts from linear algebra. If M is a matrix, the null
space of M is defined as
HM) =o eGo Ma = Oy, 1-90
where @” is the n-dimensional complex vector space. Furthermore, if /,
and .@, are two linear subspaces of an n-dimensional space, a linear subspace
M, is said to be the direct sum of -@, and -@,, written as
M,= M,& Ms, 1-91
if any vector x, € @, can be written in one and only one way as #3 = 2, + %,
where x, € @, and x, € Wj.
We have the following result (Zadeh and Desoer, 1963).
Theorem 1.8. Suppose that the n x n matrix A has k distinct characteristic
values 1;,i = 1,2,+-°+,k. Let the multiplicity of each characteristic value 1,
in the characteristic polynomial of A be given by m,. Define
M,=(A-AD™, 1-92
ay (Vea), 1-93
and let
Then
(a) The dimension of the linear subspace N’,; is m;,,i = 1,2,°--,k;
(b) The whole n-dimensional complex space 6" is the direct sum of the null
SPACES NW jh 1,2, Ky that ts;
$1 =N,ON>8* OWN» 1-94
When the matrix A has n distinct characteristic values, the null spaces /’;
reduce to one-dimensional subspaces each of which is spanned by a charac-
teristic vector of A.
We have the following fact (Noble, 1969).
Theorem 1.9. Consider the matrix A with the same notation as in Theorem
1.8. Then it is always possible to find a nonsingular transformation matrix T
* See the Preface for the significance of the sections marked with an asterisk.
20 Elements of Linear System Theory
which can be partitioned as
i hig UEP We arial 1A 1-95
such that
A= TITS: 1-96
where
a diag (Ces Jes ieee > Jy). 1-97
The block J; has dimensions m, X m,,i = 1, 2,+++,k, and the partitioning of
T matches that of J. The columns of T, form a specially chosen basis for the
null space N’;, i = 1,2,+++,k. The blocks J; can be subpartitioned as
J; = diag Ji, Jin, °° * » Ji,); where each subblock J;; is of the form
eet re
1-98
Ost eal Oe
de, erty neers. ote ore ee 1-99
Orecres OA
@) ACRE ae nC) @) yA
J is called the Jordan normal form of A.
Expression 1-96 suggests the following practical method of computing the
transformation matrix T (Noble, 1969). From 1-96 it follows
AT = TJ. 1-100
Let us denote the columns of T as q,, q2,°** 54, Then from the form of J, it
follows with 1-100 that
Aq; = 14: + Vi4i 1-101
where y; is either 0 or 1, depending on J, and where 4 is a characteristic value
of A. Let us subpartition the block T, of T corresponding to the subpartition-
ing 1-98 of J; as T,,, Tie, *** , Ti, Then the number y, is zero whenever the
corresponding column q, of T is the first column of a subblock. Since if
y;, = 0 the vector gq, is a characteristic vector of A, we see that we can find
the first columns of each subblock as the characteristic vectors of A. The
remaining columns of each subblock then follow from 1-101 with y; = 1.
Those remaining columns are known as generalized characteristic vectors of
the matrix A. We stop this process when 1-101 fails to have a solution.
Example 1.5 at the end of this section illustrates the procedure.
Once the matrix A has been brought into Jordan normal form, the ex-
ponential of A is easily found.
1.3 Solution of State Equation 21
Theorem 1.10. Consider the matrix A with the same notation as in Theorems
1.8 and 1.9. Then
(ier Sher 1-102
(b) 27 = diag (7c = ce (c) elit = diag (2700 ev 2t ee eum). 1-103
1-104
Pies
72! (n,; ap A
(ae = oom of eee 1-105
(n,;; — 2)!
@) Cee ee 0D eo ce 1
where n,; is the dimension of J;;.
It is seen from this theorem that the response of the system
&(t) = Ax(t) 1-106
may contain besides purely exponential terms of the form exp (/,f) also
terms of the form f exp (A;f), t? exp (A,t), and so on.
Completely in analogy with Section 1.3.3, we have the following fact
(Zadeh and Desoer, 1963).
Theorem 1.11. Consider the time-invariant linear system
a(t) = Az(t). 1-107
Express the initial state x(Q) as
k
iO) => 2, with v, ENV ,, Pai ao nee, 1-108
j=1
Write
U;
U;
Tl = : ; 1-109
22 Elements of Linear System Theory
where the partitioning corresponds to that of T in Theorem 1.9. Then the
response of the system can be expressed as
k
a(t) = > T, exp (J,t)U,;. 1-110
From this theorem we see that if the initial state is within one of the null
spaces ,, the nature of the response of the system to this initial state is
completely determined by the corresponding characteristic value. In analogy
with the simple case of Section 1.3.3, we call the response of the system to
any initial state within one of the null spaces a mode of the system.
Example 1.5. Inverted pendulum.
Consider the inverted pendulum of Example 1.1, but suppose that we
neglect the friction of the carriage so that F = 0. The homogeneous part of
the linearized state differential equation is now given by #(t) = Ax(t), where
0 1 One
0 Oo @
SOS Oy eG
ii d
The characteristic values of A can be found to be
0) Ole eee n= —/E. 1-112
Ds if
It is easily found that corresponding to the double characteristic value 0
there is only one characteristic vector, given by
0
I
0
To A, and A, correspond the characteristic vectors
0 0
0 0
1-113
a ty |9 |
|
aan — & [e9]
1.3 Solution of State Equation 23
Since the characteristic values A, and A, are single, the. corresponding null
spaces have dimension one and are spanned by the corresponding charac-
teristic vectors. Since zero is a double characteristic value, the corresponding
null space is two-dimensional. The fact that there do not exist two linearly
independent characteristic vectors gives rise to one subblock in the Jordan
form of size 2 x 2. Let the characteristic vector 1-113 be the first column q,
of the transformation matrix 7. Then the second column g, must follow from
Aq, = 90° G2+ 4. 1-115
It is easily found that the general solution to this equation is
0 1
1 0
q2 = , + 6 ak 1-116
1 0
where f is an arbitrary constant. We take / = 0. Since gz and q, have to be
the characteristic vectors given by 1-114, we find for the transformation
matrix 7,
The De ; Laing
1 01) fel NOE iE,
The corresponding Jordan normal form of A is
1-118
The exponential of A can now easily be found from 1-102, 1-117, and 1-118.
24 Elements of Linear System Theory
1.4 STABILITY
1.4.1 Definitions of Stability
In this section we are interested in the overall time behavior of differential
systems. Consider the general nonlinear state differential equation
a(t) = f (z(t), u(t), ¢]. 1-119
An important property of the system is whether or not the solutions of the
state differential equation tend to grow indefinitely as t—> oo. In order to
simplify this question, we assume that we are dealing with an autonomous
system, that is, a system without an input uw or, equivalently, a system where
u is a fixed time function. Thus we reduce our attention to the system
a(t) =f [x(2), t]. 1-120
Just as in Section 1.2.2 on linearization, we introduce a nominal solution x)(t)
which satisfies the state differential equation:
ao(t) = f [xo(2), ft]. 1-121
A case of special interest occurs when 2,(t) is a constant vector x,; in this
case we say that x, is an equilibrium state of the system.
We now discuss the stability of solutions of state differential equations.
First we have the following definition (for the whole sequence of definitions
that follows, see also Kalman and Bertram, 1960; Zadeh and Desoer, 1963;
Brockett, 1970).
Definition 1.1. Consider the state differential equation
a(t) = f (x(t), ¢] 1-122
with the nominal solution x(t). Then the nominal solution is stable in the sense
of Lyapunov if for any ty and any ¢ > 0 there exists a O(€, to) > 0 (depending
upon «€ and possibly upon ty) such that ||x(ty) — Xo(to)|| <6 implies
z(t) — 2(t)|| < ¢ for all t > ty.
Here ||x|| denotes the norm of a vector x; the Euclidean norm
lle|| = J des, 1-123
where the ¢,,7 = 1,.2)--« ,n, are the components of x, can be used. Other
norms are also possible.
Stability in the sense of Lyapunov guarantees that the state can be pre-
vented from departing too far from the nominal solution by choosing the
initial state close enough to the nominal solution. Stability in the sense of
1.4 Stability 25
Lyapunov is a rather weak form of stability. We therefore extend our
concept of stability.
Definition 1.2. The nominal solution x,(t) of the state differential equation
a(t) = f (x(t), t] 1-124
is asymptotically stable if
(a) It is stable in the sense of Lyapunov;
(b) For all ty there exists a p(t) > 0 (possibly depending upon ty) such that
|X (to) — Xo(to)|l < p implies
\|x(t) — a(t)|| > 0 as t— ov.
Thus asymptotic stability implies, in addition to stability in the sense of
Lyapunov, that the solution always approaches the nominal solution,
provided the initial deviation is within the region defined by
\|z(to) — %o(to)|l < p.
Asymptotic stability does not always give information for large initial
deviations from the nominal solution. The following definition refers to the
case of arbitrary initial deviations.
Definition 1.3. The nominal solution x,(t) of the state differential equation
a(t) = f (x(t), t] 1-125
is asymptotically stable in the large if
(a) It is stable in the sense of Lyapunov;
(b) For any x(t ) and any to
z(t) — xo(t)|| + 0 1-126
ASCO:
A solution that is asymptotically stable in the large has therefore the property
that all other solutions eventually approach it.
So far we have discussed only the stability of solutions. For nonlinear
systems this is necessary because of the complex phenomena that may occur.
In the case of linear systems, however, the situation is simpler, and we find it
convenient to speak of the stability of systems rather than that of solutions.
To make this point clear, let x(t) be any nominal solution of the linear
differential system
ata Aart), 1-127
and denote by x(t) any other solution of 1-127. Since both x(t) and x(t) are
solutions of the linear state differential equation 1-127 x(t) — 2,(t) is also a
26 Elements of Linear System Theory
solution, that is, 4
es [x(t) — x(t)] = AM) [a(t) — x(t)]. 1-128
This shows that in order to study the stability of the nominal solution z,(¢),
we may as well study the stability of the zero solution, that is, the
solution a(t)=0. If the zero solution is stable in any sense (of
Lyapunov, asymptotically or asymptotically in the large), any other
solution will also be stable in that sense. We therefore introduce the following
terminology.
Definition 1.4. The linear differential system
a(t) = A(t)x(t) 1-129
is stable ina certain sense (of Lyapunov, asymptotically or asymptotically in
the large), if the zero solution x9(t) = 0 is stable in that sense.
In addition to the fact that all nominal solutions of a linear differential
system exhibit the same stability properties, for linear systems there is no
need to make a distinction between asymptotic stability and asymptotic
stability in the large as stated in the following theorem.
Theorem 1.12. The linear differential system
a(t) = A(t)a(t) 1-130
is asymptotically stable if and only if it is asymptotically stable in the large.
This theorem follows from the fact that for linear systems solutions may be
scaled up or down without changing their behavior.
We conclude this section by introducing another form of stability, which
we define only for linear systems (Brockett, 1970).
Definition 1.5. The linear time-varying differential system
a(t) = A(t)x(t) 1-131
is exponentially stable if there exist positive constants « and B such that
x(t) < ae a(t), 1D to, 1-132
for every initial state x(t).
A system that is exponentially stable has the property that the state converges
exponentially to the zero state irrespective of the initial state.
We clarify the concepts introduced in this section by some examples.
Example 1.6. Inverted pendulum.
The equilibrium position s(t) =0, d(t) =0, u(t) =0 of the inverted
pendulum of Example 1.1 (Section 1.2.3) obviously is not stable in any sense.
1.4 Stability 27
Example 1.7. Suspended pendulum.
Consider the pendulum discussed in Example 1.1 (Section 1.2.3). Suppose
that «(t) = 0. From physical considerations it is clear that the solution
s(t) = 0, ¢(t) = = (corresponding to a suspended pendulum) is stable in the
sense of Lyapunov; by choosing sufficiently small initial offsets and velocities,
the motions of the system can be made to remain arbitrarily small. The system
is not asymptotically stable, however, since no friction is assumed for the
pendulum; once it is in motion, it remains in motion. Moreover, if the
carriage has an initial displacement, it will not return to the zero position
without an external force.
Example 1.8. Stirred tank.
Consider the stirred tank of Example 1.2 (Section 1.2.3). For u(t) = 0 the
linearized system is described by
2
te RE) 1-133
which has the solution
E(t) = e%E,(0), tL 0,
1-134
E(t) = e"%E0), 1 D0.
Obviously &,(t) and &(t) always approach the value zero as ¢ increases
since 0 > 0. As a result, the linearized system is asymptotically stable.
Moreover, since the convergence to the equilibrium state is exponential, the
system is exponentially stable.
In Section 1.4.4 it is seen that if a linearized system is asymptotically
stable then the equilibrium state about which the linearization is performed
is asymptotically stable but not necessarily asymptotically stable in the large.
Physical considerations, however, lead us to expect that in the present case
the system is also asymptotically stable in the large.
1.4.2 Stability of Time-Invariant Linear Systems
In this section we establish under what conditions time-invariant linear
systems possess any of the forms of stability we have discussed. Consider the
system
“(t) = Ax(t), 1-135
where A is a constant m X n matrix. In Section 1.3.3 we have seen that if A
has n distinct characteristic values A,, A,,- ++ , A,, and corresponding charac-
teristic vectors e,, €:,°°* , @,, the response of the system to any initial state
28 Elements of Linear System Theory
can be represented as
at) =) > pechey, 1-136
j=1
where the scalars w;, i = 1,2,--+-,” follow from the initial state x(0). For
systems with nondiagonizable A, this expression contains additional terms
of the form t* exp (A,t) (Section 1.3.4). Clearly, the stability of the system in
both cases is determined by the characteristic values /,. We have the following
result.
Theorem 1.13. The time-invariant linear system
x(t) = Ax(t) 1-137
is stable in the sense of Lyapunov if and only if
(a) all of the characteristic values of A have nonpositive real parts, and
(b) to any characteristic value on the imaginary axis with multiplicity m there
correspond exactly m characteristic vectors of the matrix A.
Condition (b) is necessary to prevent terms that grow as ¢* (see Section 1.3.4).
This condition is always satisfied if A has no multiple characteristic values
on the imaginary axis. For asymptotic stability we need slightly stronger
conditions.
Theorem 1.14. The time-invariant system
&(t) = A(t) 1-138
is asymptotically stable if and only if all of the characteristic values of A have
strictly negative real parts.
This result is also easily recognized to be valid. We furthermore see that if a
time-invariant linear system is asymptotically stable the convergence of the
state to the zero state is exponential. This results in the following theorem.
Theorem 1.15. The time-invariant system
“(t) = Ax(t) 1-139
is exponentially stable if and only if it is asymptotically stable.
Since it is really the matrix A that determines whether a time-invariant
system is asymptotically stable, it is convenient to use the following ter-
minology.
Definition 1.6. Then X n constant matrix A is asymptotically stable if all its
characteristic values have strictly negative real parts.
The characteristic values of A are the roots of the characteristic polynomial
det (AJ — A). Through the well-known Routh-Hurwitz criterion (see, e.g.,
1.4 Stability 29
Schwarz and Friedland, 1965) the stability of A can be tested directly from
the coefficients of the characteristic polynomial without explicitly evaluating
the roots. With systems that are not asymptotically stable, we find it con-
venient to refer to those characteristic values of A that have strictly negative
real parts as the stable poles of the system, and to the remaining ones as the
unstable poles.
We conclude this section with a simple example. An additional example is
given in Section 1.5.1.
Example 1.9. Stirred tank.
The matrix A of the linearized state differential equation of the stirred tank
of Example 1.2 has the characteristic values —(1/20) and —(1/0). As we
concluded before (Example 1.8), the linearized system is asymptotically
stable since 0 > 0.
1.4.3* Stable and Unstable Subspaces for Time-Invariant Linear
Systems
In this section we show how the state space of a linear time-invariant
differential system can be decomposed into two subspaces, such that the
response of the system from an initial state in the first subspace always con-
verges to the zero state while the response from a nonzero initial state in the
other subspace never converges.
Let us consider the time-invariant system
L(y A(t) 1-140
and assume that the matrix A has distinct characteristic values (the more
general case is discussed later in this section). Then we know from Section
1.3.3 that the response of this system can be written as
n
ai) ==> jee, 1-141
p=
where 4,, A,,°-°,A, are the characteristic values of A, and e,,°--,e, are
the corresponding characteristic vectors. The numbers py, Mg,°** , My are
the coefficients that express how the initial state x(0) is decomposed along the
VOCLOTa ey; Cat Pe;
Let us now suppose that the system is not asymptotically stable, which
means that some of the characteristic values 2; have nonnegative real parts.
Then it is clear that the state will converge to the zero state only if the initial
state has components only along those characteristic vectors that correspond
to stable poles.
If the initial state has components only along the characteristic vectors that
correspond to unstable poles, the response of the state will be composed of
nondecreasing exponentials. This leads to the following decomposition of the
state space.
30 Elements of Linear System Theory
Definition 1.7. Consider the n-dimensional system a(t) = Ax(t) with A a
constant matrix. Suppose that A has n distinct characteristic values. Then we
define the stable subspace for this system as the real linear subspace spanned
by those characteristic vectors of A that correspond to characteristic values
with strictly negative real parts. The unstable subspace for this system is the
real subspace spanned by those characteristic vectors of A that correspond to
characteristic values with nonnegative real parts.
We now extend this concept to more general time-invariant systems. In
Section 1.3.4 we saw that the response of the system can be written as
k
a(t) = > T, exp (J;t)U,v,, 1-142
Gk
where the v, are in the null spaces ./,, i= 1,2,-+-,k. The behavior of
the factor exp (J,t) is determined by the characteristic value /,; only if A; has
a strictly negative real part does the corresponding component of the state
approach the zero state. This leads us in analogy with the simple case of
Definition 1.7 to the following decomposition:
Definition 1.8. Consider the n-dimensional linear time-invariant system
x(t) = Ax(t). Then we define the stable subspace for this system as the real
subspace of the direct sum of those null spaces N, that correspond to charac-
teristic values of A with strictly negative real parts. Similarly, we define the
unstable subspace of A as the real subspace of the direct sum of those null
spaces N’, that correspond to characteristic values of A with nonnegative real
parts.
As a result of this definition the whole real n-dimensional space #” is the
direct sum of the stable and the unstable subspace.
Example 1.10. Inverted pendulum.
In Example 1.4 (Section 1.3.3), we saw that the matrix A of the linearized
state differential equation of the inverted pendulum has the characteristic
values and vectors: . 3 =
4=0, h=-=, a= JE, a= J 1-143
L ie
1 1 0 0
F
0 es M 0 0
Panes i Sei es ee > =
1 a 1 1
0 Pape Jf = Is
M VE
1-144
1.4 Stability 31
Apparently, the stable subspace of this system is spanned by the vectors e,
and e,, while the unstable subspace is spanned by e, and es.
Example 1.11. Inverted pendulum without friction.
In Example 1.5 (Section 1.3.4), we discussed the Jordan normal form of
the A matrix of the inverted pendulum with negligible friction. There we
found a double characteristic value 0 and the single characteristic values
V (g/L) and mal (GLY. The null space corresponding to the characteristic
value 0 is spanned by the first two columns of the transformation matrix 7,
that is, by
| 0
0 1
and : 1-145
i 0
0) 1
These two column vectors, together with the characteristic vector corre-
sponding to V (g/L), that is,
1-146
Jf
Ly
span the unstable subspace of the system. The stable subspace is spanned by
the remaining characteristic vector
1-147
- J
L
1.4.4* Investigation of the Stability of Nonlinear Systems through
Linearization
Most of the material of this book is concerned with the design of linear
control systems. One major goal in the design of such systems is stability. In
32 Elements of Linear System Theory
later chapters very powerful techniques for finding stable linear feedback
control systems are developed. As we have seen, however, actual systems
are never linear, and the linear models used are obtained by linearization.
This means that we design systems whose linearized models possess good
properties. The question now is: What remains of these properties when the
actual nonlinear system is implemented? Here the following result is helpful.
Theorem 1.16. Consider the time-invariant system with state differential
equation #(t) = f [a(t)]. 1-148
Suppose that the system has an equilibrium state x, and that the function f
possesses partial derivatives with respect to the components of x at x,. Suppose
that the linearized state differential equation about x, is
&(t) = A&(t), 1-149
where the constant matrix A is the Jacobian of f at x,. Then if A is asymp-
totically stable, the solution x(t) = x, is an asymptotically stable solution of
1-148.
For a proof we refer the reader to Roseau (1966). Note that of course we
cannot conclude anything about stability in the large from the linearized
state differential equation.
This theorem leads to a reassuring conclusion. Suppose that we are con-
fronted with an initially unstable system, and that we use linearized equations
to find a controller that makes the linearized system stable. Then it can be
shown from the theorem that the actual nonlinear system with this controller
will at least be asymptotically stable for small deviations from the equi-
librium state.
Note, however, that the theorem is reassuring only when the system con-
tains “smooth” nonlinearities. If discontinuous elements occur (dead zones,
stiction) this theory is of no help.
We conclude by noting that if some of the characteristic values of A have
zero real parts while all the other characteristic values have strictly negative
real parts no conclusions about the stability of x, can be drawn from the
linearized analysis. If A has some characteristic values with positive real
parts, however, x, is not stable in any sense (Roseau, 1966).
An example of the application of this theorem is given in Chapter 2
(Example 2.6, Section 2.4).
1.5 Transform Analysis 33
1.5 TRANSFORM ANALYSIS OF TIME-INVARIANT
SYSTEMS
1.5.1 Solution of the State Differential Equation through Laplace
Transformation
Often it is helpful to analyze time-invariant linear systems through Laplace
transformation. We define the Laplace transform of a time-varying vector
2(t) as follows
ZS 1218) = [Pon dt, 1-150
where s is a complex variable. A boldface capital indicates the Laplace
transform of the corresponding lowercase time function. The Laplace
transform is defined for those values of s for which 1-150 converges. We see
that the Laplace transform of a time-varying vector z(t) is simply a vector
whose components are the Laplace transforms of the components of z(f).
Let us first consider the homogeneous state differential equation
a(t) = Ax(t), 1-151
where A is a constant matrix. Laplace transformation yields
sX(s) — x(0) = AX(s), 1-152
since all the usual rules of Laplace transformations for scalar expressions
carry over to the vector case (Polak and Wong, 1970). Solution for X(s)
yields
GS) = (57 A (0). 1-153
This is the equivalent of the time domain expression
a(t) = e4'x(0). 1-154
We conclude the following.
Theorem 1.17. Let A be a constant n Xn matrix. Then (sI — A)+ =
Le", or, equivalently, e* = £>[(sIl — A).
The Laplace transform of a time-varying matrix is obtained by transforming
each of its elements. Theorem 1.17 is particularly convenient for obtaining
the explicit form of the transition matrix as long as n is not too large,
irrespective of whether or not 4 is diagonalizable.
The matrix function (s/ — A)~ is called the resolvent of A. The following
result is useful (Zadeh and Desoer, 1963; Bass and Gura, 1965).
34 Elements of Linear System Theory
Theorem 1.18. Consider the constant n x n matrix A with characteristic
polynomial
det (sf — A) = 5s” + a, 18" + °°+ + O45 + Hp. Then the resolvent of A can be written as
1-155
1 on
sf = Ay? = ————__9 sR, 1-156
( ) det (sI — Do
where the matrices R, are given by
Ri= DS GAee ceil AS ROE HOS CHF 1-157
=i
with a, = 1. The coefficients «; and the matrices R,, i = 1,2,+++,n can be
obtained through the following algorithm. Set
Gol. R, = 1. 1-158
Then
ae at (are dy, 1-159
Rey => COR | aa aR ets 1-160
fork =1,2,:+--,n. Fork =n we have
Ry =8. 1-161
Here we have employed the notation
Oeil
if M is ann X n matrix with diagonal elements M,,, i= 1,2,---,n. We
refer to the algorithm of the theorem as Leverrier’s algorithm (Bass and
Gura, 1965). It is also known as Souriau’s method or Faddeeva’s method
(Zadeh and Desoer, 1963). The fact that Ry = 0 can be used as a numerical
check. The algorithm is very convenient for a digital computer. It must be
pointed out, however, that the algorithm is relatively sensitive to round-off
errors (Forsythe and Strauss, 1955), and double precision is usually employed
in the computations. Melsa (1970) gives a listing of a FORTRAN computer
program.
Let us now consider the inhomogeneous equation
a(t) = Ax(t) + Bu(t), where A and B are constant. Laplace transformation yields
sX(s) — x(0) = AX(s) + BU(s), 1-163
1-164
1.5 Transform Analysis 35
which can be solved for X(s). We find
X(s) = (sf — A)*2(0) + (sf — A)*BU(s). 1-165
Let the output equation of the system be given by
y(t) = Cx(t), 1-166
where C is constant. Laplace transformation and substitution of 1-165 yields
Y(s) = CX(s) = C(sJ — A)~a(0) + C(sI — A)“ BU(s), 1-167
which is the equivalent in the Laplace transform domain of the time domain
expression 1-70 with t, = 0:
y(t) = Ce“'a(0) + C I eA" Bu(r) dr. 1-168
For x(0) = 0 the expression 1-167 ies to
Y¥(s) = A(s)U(s), 1-169
a H(s) = C(sI — AB. 1-170
The matrix H(s) is called the transfer matrix of the system. If H(s) and U(s)
are known, the zero initial state response of the system can be found by
inverse Laplace transformation of 1-169.
By Theorem 1.17 it follows immediately from 1-170 that the transfer matrix
H(s) is the Laplace transform of the matrix function K(t) = C exp (Ad)B,
t > 0. It is seen from 1-168 that K(t — 7), t > 7, is precisely the impulse
response matrix of the system.
From Theorem 1.18 we note that the transfer matrix can be written in the
form
1
H(s) ene P(s), 1-171
where P(s) is a matrix whose elements are polynomials in s. The elements of
the transfer matrix H(s) are therefore rational functions of s. The common
denominator of the elements of H(s) is det (sJ — A), unless cancellation occurs
of factors of the form s — A;, where A, is a characteristic value of A, in all
the elements of H(s).
We call the roots of the common denominator of H(s) the poles of the
transfer matrix H(s). If no cancellation occurs, the poles of the transfer
matrix are precisely the poles of the system, that is, the characteristic values
of A.
If the input u(t) and the output variable y(t) are both one-dimensional,
the transfer matrix reduces to a scalar transfer function. For multiinput
multioutput systems, each element H,;(s) of the transfer matrix H(s) is the
transfer function from the j-th component of the input to the i-th component
of the output.
36 Elements of Linear System Theory
Example 1.12. A nondiagonizable system.
Consider the system
Cod
ah = x(t). 1-172
0 0
It is easily verified that this system has a double characteristic value 0 but
only a single characteristic vector, so that it is not diagonizable. We compute
its transition matrix by Laplace transformation. The resolvent of the system
can be found to be
(sf — A)* =
L 52
jh 1
coe s*
n“”
= : 1-173.
Ome yi
RY
Inverse Laplace transformation yields
: i oy
ec iias : 1-174
|
Note that this system is not stable in the sense of Lyapunov.
Example 1.13. Stirred tank.
The stirred tank of Example 1.2 is described by the linearized state differen-
tial equation
id eee ae 0 1 1
26
, x(t) + | cy — Co Cyo— Cy Ju(t) 1-175
Ons ie V, Vo
and the output equation
The resolvent of the matrix A is
Ob
y(t) = | 26 x(t). 1-176
Oe al
1
1 0
s+ —
: 20
(oi Ay = k 1-177
0
1.5 Transform Analysis 37
The system has the transfer matrix
ge at
20 20
s+ _ s+ =
H(s) = 20 26 . 1-178
Cy ee I Co — "Cp
Vo 1 Yo 1
Sor Ss =
60 os 6
The impulse response matrix 1-75 of the system follows immediately by
inverse Laplace transformation of 1-178.
1.5.2 Frequency Response
In this section we study the frequency response of time-invariant systems,
that is, the response to an input of the form
ut) = te’, t>0, 1-179
where u,,, is a constant vector. We express the solution of the state differential
equation
a(t) = Ax(t) + Bu(t) 1-180
in terms of the solution of the homogeneous equation plus a particular
solution. Let us first try to find a particular solution of the form
DE )\eseet 1-181
where x,, is a constant vector to be determined. It is easily found that this
particular solution is given by
a(t) = (jal — A) *Bu,,e, pray 1-182
The general solution of the homogeneous equation a(t) = Ax(t) can be
written as
x,(t) = ea, 1-183
where a is an arbitrary constant vector. The general solution of the inhomo-
geneous equation 1-180 is therefore
a(t) = e4’a + (jwI — A) "Bu, ec’, t>0. 1-184
The constant vector a can be determined from the initial conditions. If the
system 1-180 is asymptotically stable, the first term of the solution will
eventually vanish as ¢ increases, and the second term represents the steady-
state response of the state to the input 1-179. The corresponding steady-state
38 Elements of Linear System Theory
response of the output
y(t) = Cx(t) 1-185
is given by
y(t) = C(jwI — A) Bu,,e*”
= H(jw)u,,e°". 1-186
We note that in this expression the transfer matrix H(s) appears with s
replaced by jw. We call H( jw) the frequency response matrix of the system.
Once we have obtained the response to complex periodic inputs of the
type 1-179, the steady-state response to real, sinusoidal inputs is easily found.
Suppose that the k-th component y,(t) of the input u(t) is given as follows
u,(t) = fi, sin (wt + 4,), t>0. 1-187
Assume that all other components of the input are identically zero. Then the
steady-state response of the i-th component 7,(t) of the output y(t) is given by
nit) = |Hu(jo)| &, sin (ot + o, + Vix), 1-188
where H,,,( ja) is the (7, k)-th element of H(jw) and
Yu = arg [H,.(jo)]. 1-189
A convenient manner of representing scalar frequency response functions is
through asymptotic Bode plots (D’Azzo and Houpis, 1966). Melsa (1970)
gives a FORTRAN computer program for plotting the modulus and the
argument of a scalar frequency response function.
In conclusion, we remark that it follows from the results of this section that
the steady-state response of an asymptotically stable system with frequency
response matrix H( ja) to a constant input
u(t) = u,, 1-190
is given by
y(t) = H(O)u,,. 1-191
Example 1.14. Stirred tank.
The stirred tank of Example 1.2 has the transfer matrix (Example 1.13)
i ue
20 26
ae geal
H(s) = 20 20 é 1-192
Cy io Co 1 Co Ls! Co 1
Re oa ee
1.5 Transform Analysis 39
The system is asymptotically stable so that it makes sense to consider the
frequency response matrix. With the numerical data of Example 1.2, we have
0.01 0.01
Go) jo+0.01 jo + 0.01
io) = . 1-193
: ~0.25 0.75
jo + 0.02 jw + 0.02
1.5.3 Zeroes of Transfer Matrices
Let us consider the single-input single-output system
#(t) = Aa(t) + bud),
1-194
n{t) = cx(t),
where y(t) and 7(t) are the scalar input and output variable, respectively, b is
a column vector, and c a row vector. The transfer matrix of this system
reduces to a transfer function which is given by
H(s) = c(sI — A). Denote the characteristic polynomial of A as
1-195
det (sf — A) = ¢(s). 1-196
Then H(s) can be written as
H(s) = ws) ; 1-197
f(s)
where, if A is ann X n matrix, then ¢(s) is a polynomial of degree n and y(s)
a polynomial of degree n — | or less. The roots of p(s) we call the zeroes of
the system 1-194. Note that we determine the zeroes before cancelling any
common factors of p(s) and ¢(s). The zeroes of H(s) that remain after
cancellation we call the zeroes of the transfer function.
In the case of a multiinput multioutput system, H(s) is a matrix. Each
entry of H(s) is a transfer function which has its own zeroes. It is not obvious
how to define “‘the zeroes of H(s)’’ in this case. In the remainder of this
section we give a definition that is motivated by the results of Section 3.8.
Only square transfer matrices are considered.
First we have the following result (Haley, 1967).
Theorem 1.19. Consider the system
a(t) = Ax(t) + Bu(t),
y(t) = Cx(t), 1-198
40 Elements of Linear System Theory
where the state x has dimension(n-and both the input u and the output variable
y have dimension m. Let H(s) = C(sI — A)*B be the transfer matrix of the
system. Then
_ ¥(s) ;
det [H(s)] = 41s)" 1-199
where
1-200
$(s) = det (sf — A), and y(s) is a polynomial in s of degree n — mor less.
Since this result is not generally known we shall prove it. We first state the
following fact from matrix theory.
Lemma 1.1. Let M and N be matrices of dimensions m X n and n X m,
respectively, and let I, and I,, denote unit matrices of dimensions m X m and
n Xn. Then
(a) det U,, + MN) = det U/, + NM). 1-201
(b) Suppose det (I, + MN) # 0; then
(Um + MN)? = I, — MU, + NM) iN. 1-202
The proof of (a) follows from considerations involving the characteristic
values of J,, + MN (Plotkin, 1964; Sain, 1966). Part (b) is easily verified.
It is not needed until later.
To prove Theorem 1.19 consider the expression
det [Al,, + C(sI, — A)“ B], 1-203
where A is a nonzero arbitrary scalar which later we let approach zero.
Using part (a) of the lemma, we have
det [AI + C(sI,, — A)1B] = det (AI, det I, + = CsI, = ays
= A™ det E + Hee - Ay*BC |
am det | sl, — A + BC |
Se 1-204
det (sI,, — A)
We see that the left-hand and the right-hand side of 1-204 are polynomials
in A that are equal for all nonzero A; hence by letting A > 0 we obtain
det [C(sI — A)'B] = cae) f(s)
1-205
1.5 Transform Analysis 41
where
y(s) = lim A” det (s1, —A+t BC). 1-206
2-0
This immediately shows that p(s) is a polynomial in s. We now consider the
degree of this polynomial. For |s|—» 00 we see from Theorem 1.18 that
lim s(sf — A)* = I. 1-207
|s| >
Consequently,
(i) tins det (CT ty BT
|s| +00 f(s) |s|>o
= lim det [Cs(sI — A)'B] = det (CB). 1-208
|s| > 00
This shows that the degree of ¢(s) is greater than that of p(s) by at least m,
hence p(s) has degree n — m or less. If det (CB) ¥ 0, the degree of y(s) is
exactly n — m. This terminates the proof of Theorem 1.19.
We now introduce the following definition.
Definition 1.9. The zeroes of the system
a(t) = Ax(t) + Bu(t),
1-209
y(t) = Cx(t),
where the state x has dimension n and both the input u and the output y have
dimension m, are the zeroes of the polynomial p(s), where
det [H(s)] = um) : 1-210
P(s)
Here H(s) = C(sI — A)“B is the transfer matrix and $(s) = det (sI — A)
the characteristic polynomial of the system.
An n-dimensional system with m-dimensional input and output thus has at
most m — m zeroes. Note that for single-input single-output systems our
definition of the zeroes of the system reduces to the conventional definition
as described in the beginning of this section. In this case the system has at
most n — | zeroes.
The numerical computation of the numerator polynomial for a system of
some complexity presents problems. One possible way of going about this
is to write the numerator polynomial as
w(s) = $(s) det [H(s)], 1-211
where ¢(s) is the characteristic polynomial of the system. The coefficients of
w(s) can then be found by substituting n — m + | suitable values for s into
42 Elements of Linear System Theory
the right-hand side of 1-211 and solving the resulting linear equations.
Another, probably more practical, approach results from using the fact that
from 1-206 we have
y(s) = lim y(s, A), 1-212
where -
w(s, A) = A™ det (1 —A+ + BC). 1-213
Inspection shows that we can write
WS, A) = ¥ tind), 1-214
where o.(5).7— 0, [5-77 are cane in s. These polynomials can
be computed by calculating p(s, A) for m different values of 2. The desired
polynomial p(s) is precisely «9(s).
We illustrate the results of this section by the following example.
Example 1.15. Stirred tank.
The stirred tank of Example 1.2 (Section 1.2.3) has the transfer matrix
ll Le
26 20
af i
H(s) = Shy ST Op : 1-215
Cy — Cy 1 Co-lo _ 1
ne 1 ie 1
Sars Sinica
6 6
The characteristic polynomial of the system is
Boy (s ti Fal ( is al 20 6
We find for the determinant of the transfer matrix
1-216
a Co =F Cy
20,
det [H(s)] = —————__ 1-217
(s+ ae) (+ 5)
Apparently, the transfer matrix has no zeroes. This is according to expectation,
since in this case n — m = 0 so that the degree of y(s) is zero.
1.5 Transform Analysis 43
1.5.4 Interconnections of Linear Systems
In this section we discuss interconnections of linear systems. Two important
examples of interconnected systems that we frequently encounter are the
series connection of Fig. 1.5 and the feedback configuration or closed-loop
system of Fig. 1.6.
system system y(t)
1 2
Fig. 1.5. Series connection.
system y; (t) = u(t)
1
system
2
Fig. 1.6. Feedback connection.
We often describe interconnections of systems by the state augmentation
technique. In the series connection of Fig. 1.5, let the individual systems be
described by the state differential and output equations
a(t) = Ay(t)a,(t) + P| yy (t) = Cy(t)ay(t) + Dy (t)uy(t) system 1,
1-218
a(t) = Ap(t)w2(t) + chs system 2.
Yo(t) = Ca(t)xo(t) + Do(t)ue(t)
Defining the augmented state
«,(t)
AG 1-219
a (io)
44 Elements of Linear System Theory
the interconnected system is described by the state differential equation
a(t) = | A,(t) 0 B,(t)
Jeo « | ile FAG ae 7
Bi(t)Cy(t) A2(t) B,(t)D,(t)
where we have used the relation u,(t) = y,(t). Taking y(t) as the output of
the interconnected system, we obtain for the output equation
yo(t) = [Da()Ci(1), CoO ]e() + Da(t) Di (ua (). 1-221
In the case of time-invariant systems, it is sometimes convenient to describe
an interconnection in terms of transfer matrices. Suppose that the individual
transfer matrices of the systems | and 2 are given by H,(s) and H,(s), respec-
tively. Then the overall transfer matrix is H,(s)H,(s), as can be seen from
Y2(s) = H,(s)U,(s) = H2(s)H,(s)U,(s). 1-222
Note that the order of H, and H, generally cannot be interchanged.
In the feedback configuration of Fig. 1.6, r(t) is the input to the overall
system. Suppose that the individual systems are described by the state
differential and output equations
a(t) = Ay(t)a,(t) + By(t)u,(t)
y(t) = Cy(t)ay(t)
H(t) = Ag(t)ra(t) + By(t)uo(t)
Yo(t) = Cy(t)xy(t) + Da (t)us(t)
| system 1,
1-223
| system 2.
Note that we have taken system | without a direct link. This is to avoid
implicit algebraic equations. In terms of the augmented state a(t) =
col [x,(t), 7,(t)], the feedback connection can be described by the state
differential equation
A(t) — BND (NC) —B,(t)C,(t) B,(t)
ae x(t) + ( r(t),
BA(t)Cy(t) A,(t)
1-224
where we have used the relations u.(t) = y,(t) and u,(t) = r(t) — y,(t). If
y,(t) is the overall output of the system, we have for the output equation
Y(t) = [C,(t), O]x(t). 1-225
Consider now the time-invariant case. Then we can write in terms of transfer
matrices
Yi(s) = A,(s)[R(s) — H2(s)¥,(s)], 1-226
1.5 Transform Analysis 45
where H,(s) and H,(s) are the transfer matrices of the individual systems.
Solving for Y,(s), we find
Yi(s) = + Ay(s)H2(s)) Ay (s)R(s). 1-227
It is convenient to give the expression J + H,(s)H,(s) a special name:
Definition 1.10. Consider the feedback configuration of Fig. 1.6. and let the
systems I and 2 be time-invariant systems with transfer matrices H,(s) and
H,(s), respectively. Then the matrix function
J(s) =1+ H,(s)H,(s) 1-228
is called the return difference matrix. The matrix function
L(s) = H,(s)H,(s) 1-229
is called the loop gain matrix.
The term “return difference’’ can be clarified by Fig. 1.7. Here the loop is cut
at the point indicated, and an external input variable u(t) is connected.
Fig. 1.7. [Illustration of return difference.
This yields (putting r(t) = 0)
Y,(s) = —A,(s)H,(s)U,(s). 1-230
The difference between the “returned variable” y,(t) and the “‘injected
variable’’ u(t) is
U,(s) — Yi(s) = [7 + Ay(s)H2(s)]U2(s) = J(s)U,(s).
{O31
Note that the loop can also be cut elsewhere, which will result in a different
return difference matrix. We strictly adhere to the definition given above,
however. The term “loop gain matrix’’ is self-explanatory.
46 Elements of Linear System Theory
A matter of great interest in control engineering is the stability of inter-
connections of systems. For series connections we have the following result,
which immediately follows from a consideration of the characteristic poly-
nomial of the augmented state differential equation 1-220.
Theorem 1.20. Consider the series connection of Fig. 1.5, where the systems
I and 2 are time-invariant systems with characteristic polynomials $,(s) and
f2(s), respectively. Then the interconnection has the characteristic polynomial
41(s)h2(s). Hence the interconnected system is asymptotically stable if and
only if both system 1 and system 2 are asymptotically stable.
In terms of transfer matrices, the stability of the feedback configuration of
Fig. 1.6 can be investigated through the following result (Chen, 1968a; Hsu
and Chen, 1968).
Theorem 1.21. Consider the feedback configuration of Fig. 1.6 in which the
systems I and 2 are time-invariant linear systems with transfer matrices
H,(s) and H,(s) and characteristic polynomials $,(s) and $,(s), respectively,
and where system I does not have a direct link. Then the characteristic poly-
nomial of the interconnected system is
1(s)Po(s) det [J + Hy(s)H,(s)]. 1-232
Hence the interconnected system is stable if and only if the polynomial 1-232
has zeroes with strictly negative real parts only.
Before proving this result we remark the following. The expression
det [J + H,(s)H,(s)] is a rational function in s. Unless cancellations take
place, the denominator of this function is 4,(s)¢.(s) so that the numerator of
det [J + H,(s)H,(s)] is the characteristic polynomial of the interconnected
system. We often refer to 1-232 as the closed-loop characteristic polynomial.
Theorem 1.21 can be proved as follows. In the time-invariant case, it
follows from 1-224 for the state differential equation of the interconnected
system
Av BLDG 8G, B,
a(t) = a(t) + r(t). 1-233
‘BiG Ay 0
We show that the characteristic polynomial of this system is precisely 1-232.
For this we need the following result from matrix theory.
Lemma 1.2. Let M be a square, partitioned matrix of the form
M, M,
M= 1-234
1.5 Transform Analysis 47
Then if det (M,) # 0,
det (M) = det (M,) det (M, — M,M;'M,). 1-235
If det (M,) 4 0,
det (M) = det (M,) det (M, — M,Mjz1M,). 1-236
The lemma is easily proved by elementary row and column operations on
M. With the aid of Lemmas 1.2 and 1.1 (Section 1.5.3), the characteristic
polynomial of 1-233 can be written as follows.
st = A, + B,D.Cy Bas
det
— B,C, st ap As
= det (s] — A,) det [sJ — A, + B,D,C, + B,C,(s7 — A,)B,C,]
= det (sJ — A,) det (sJ — A,)
‘det {7 + B,[D, + C,(sl — A2)*B ]C,(sI — A,)“}
= det (sJ — A,) det (sJ — A.)
- det {7 + C,(sl — A,)*B,[C,(s7 — A,)1B, + D,]. 1-237
Since
det (sf — A,) = 4,(s),
det (sJ — A,) = ¢,(s), C,(sl — A;)*B, = Ay(s),
C,(s1 — Az) *B, + Dz, = H,(s),
1-238
1-237 can be rewritten as
fi(s)bo(s) det [J + H,(s)H,(s)]. 1-239
This shows that 1-232 is the characteristic polynomial of the interconnected
system; thus the stability immediately follows from the roots of 1-232.
This method for checking the stability of feedback systems is usually more
convenient for single-input single-output systems than for multivariable
systems. In the case of single-input single-output systems, we write
Hy(s) =
mS) ey 1-240
$,(s) pals)
where y,(s) and y,(s) are the numerator polynomials of the systems. By
Theorem 1.21 stability now follows from the roots of the polynomial
(400) 1 aie nr = $,(3)ba(s) + vilspals).
wy(s) pols) bs. 1-241
It often happens in designing linear feedback control systems that either
48 Elements of Linear System Theory
in the feedback path or in the feedforward path a gain factor is left undeter-
mined until a late stage in the design. Suppose by way of example that
S
Gyr Oe. 1-242
$,(s)
where p is the undetermined gain factor. The characteristic values of the
interconnected system are now the roots of
pi(s)Po(s) + pyr(s)ype(s). 1-243
An interesting problem is to construct the loci of the roots of this poly-
nomial as a function of the scalar parameter p. This is a special case of the
more general problem of finding in the complex plane the loci of the roots of
d(s) + py(s) 1-244
as the parameter p varies, where $(s) and p(s) are arbitrary given polynomials.
The rules for constructing such loci are reviewed in the next section.
Example 1.16. Inverted pendulum
Consider the inverted pendulum of Example 1.1 (Section 1.2.3) and suppose
that we wish to stabilize it. It is clear that if the pendulum starts
falling to the right the carriage must also move to the right. We therefore
attempt a method of control whereby we apply a force y(t) to the carriage
which is proportional to the angle ¢(t). This angle can be measured by a
potentiometer at the pivot; the force u(t) is exerted through a small servo-
motor. Thus we have Ber etcy 1-245
where k is a constant. It is easily found that the transfer function from u(t)
to ¢(t) is given by
Hie) iraramas aaa 1-246
The transfer function of the feedback part of the system follows from 1-245:
H,(s) = —k. 1-247
The characteristic polynomial of the pendulum positioning system is
Ip . &
o) = 5 s+=)( -£), $1(s) ( M s U
1-248
while the characteristic polynomial of the feedback part is
$a(s) =. 1-249
1.5 Transform Analysis 49
It follows from 1-246 and 1-247 that in this case
F veefneiten8) Et
We) pe Bed
while from 1-248 and 1-249 we obtain
F pares
$(s).(s) (> a | (s al 1-251
We note that in this case the denominator of 1 + H,(s)H,(s) is not the
product of the characteristic polynomials 1-251, but that a factor s has been
canceled. Therefore, the numerator of 1-250 is not the closed-loop char-
acteristic polynomial. By multiplication of 1-250 and 1-251, it follows that
the characteristic polynomial of the feedback system is
ss 2 Ls 4. ee _ s) — ar 1-252
M EM L ML
We see that one of the closed-loop characteristic values is zero. Moreover,
since the remaining factor contains a term with a negative coefficient,
according to the well-known Routh-Hurwitz criterion (Schwarz and
Friedland, 1965) there is at least one root with a positive real part. This
means that the system cannot be stabilized in this manner. Example 2.6
(Section 2.4) presents a more sophisticated control scheme which succeeds
in stabilizing the system.
Example 1.17. Stirred tank
Consider the stirred tank of Example 1.2 (Section 1.2.3). Suppose that it
is desired to operate the system such that a constant flow F(t) and a
constant concentration c(t) are maintained. One way of doing this is to use
the main flow F, to regulate the flow F, and the minor flow F, to regulate the
concentration c. Let us therefore choose ju, and “, according to
f(t) = —k,ny(t),
1-253
[ia(t) = —keno(t).
This means that the system in the feedback loop has the transfer matrix
k
H,(s) = G | 1-254
v2
It is easily found with the numerical data of Example 1.2 that the transfer
50 Elements of Linear System Theory
matrix of the system in the forward loop is given by
0.01 0.01
s+0.01 s+0.01
H,(s) = 1-255
2035 0.75
s+0.02 s +0.02
With this the return difference matrix is
s + 0.01k, + 0.01 0.01 Ks
s + 0.01 s + 0.01 "7
en oa 1-25
Cron ie =0.25k, 5 + 0.75ky + 0.02
s+ 0.02 s + 0.02
For the characteristic polynomials of the two systems, we have
f(s) = (s + 0.01)(s + 0.02),
OAS)
1-257
It follows from 1-256 that
0.01k, + 0.01 0.75k, + 0.02) + 0.0025k,k,
det [J(s)] = (s + 001k, + O.01)(s + 0.75ks + 0.02) + 0.0025kik» _ 1-258
(s + 0.01)(s + 0.02)
Since the denominator of this expression is the product 4,(s)¢,(s), its
numerator is the closed-loop characteristic polynomial. Further evaluation
yields for the closed-loop characteristic polynomial
s? + s(0.01k, + 0.75k, + 0.03) + (0.0002k,
+ 0.0075k, + 0.01k,k, + 0.0002). AndS?
This expression shows that for positive k, and k, the feedback system is
stable. Let us choose for the gain coefficients k,; = 10 and k, = 0.1. This
gives for the characteristic polynomial
s? + 0.2055 + 0.01295. 1-260
The characteristic values are
—0.1025 + j0.04944. 1-261
The effectiveness of such a control scheme 1-253 is investigated in Example
2.8 (Section 2.5.3).
1.5 Transform Analysis 51
1.5.5* Root Loci
In the preceding section we saw that sometimes it is of interest to find in the
complex plane the loci of the roots of an expression of the form
b(s) + py(s), 1-262
where ¢(s) and y(s) are polynomials in s, as the scalar parameter p varies.
In this section we give some rules pertaining to these loci, so as to allow us
to determine some special points of the loci and, in particular, to determine
the asymptotic behavior. These rules make it possible to sketch root loci
quite easily for simple problems; for more complicated problems the assist-
ance of a digital computer is usually indispensable. Melsa (1970) gives a
FORTRAN computer program for computing root loci.
We shall assume the following forms for the polynomials ¢(s) and p(s):
Ws) = IL = 7),
= 1-263
p(s) = [I (s — »).
j=1
We refer to the 7,, i= 1,2,---,m, as the open-loop poles, and to the
vy; = 1,2,°-++,m, as the open-loop zeroes. The roots of 1-262 will be called
the closed-loop poles. This terminology stems from the significance that the
polynomials 4(s) and y(s) have in Section 1.5.4. We assume that m < n;
this is no restriction since if m > n the roles of ¢(s) and y(s) can be reversed
by choosing |/p as the parameter.
The most important properties of the root loci are the following.
(a) Number of roots: The number of roots of 1-262 is n. Each of the roots
traces a continuous locus as p varies from — © to ©.
(b) Origin of loci: The loci originate for p = 0 at the poles 7,, i= 1, 2,
...,n. This is obvious, since for p = 0 the roots of 1-262 are the roots of
p(s).
(c) Behavior of loci as p > +0: As p—> 4, m of the loci approach the
zeroes v¥;,i = 1,2,°++,m. The remaining n —m loci go to infinity. This
follows from the fact that the roots of 1-262 are also the roots of
7 HS) + v6) 1-264
(d) Asymptotes of loci: Those n —m loci that go to infinity approach
asymptotically n — m straight lines which make angles
a+ k2r
n—m”
k=0,1,°:*,n—m —1, 1-265
52 Elements of Linear System Theory
with the positive real axis as p —> + 00, and angles
k2a
n—m
k=0,1,°°°,n—m — I, 1-266
as p—» —0. The n — m asymptotes intersect in one point on the real axis
given by
ya ES 1-267
n—m
These properties can be derived as follows. For large s we approximate
1-262 by 3° pps”. 1-268
The roots of this polynomial are
( a8 pee, 1-269
which gives a first approximation for the faraway roots. A more refined
analysis shows that a better approximation for the roots is given by
as (0) ere 1-270
n—m
This proves that the asymptotic behavior is as claimed.
(e) Portions of root loci on real axis: If p assumes only positive values,
any portion of the real axis to the right of which an odd number of poles and
zeroes lies on the real axis is part of a root locus. If p assumes only negative
values, any portion of the real axis to the right of which an even number of
poles and zeroes lies on the real axis is part of a root locus. This can be seen as
follows. The roots of 1-262 can be found by solving
Hs) _
ah Tol
p(s)
If we assume p to be positive, 1-271 is equivalent to the real equations
16)
= p, 1-272
y(s)
arg oa = 7+ 27k, 1-273
where k is any integer. If s is real, there always exists a p for which 1-272
is satisfied. To satisfy 1-273 as well, there must be an odd number of zeroes
and poles to the right of s. For negative p a similar argument holds.
Several other properties of root loci can be established (D’Azzo and
Houpis, 1966) which are helpful in sketching root locus plots, but the rules
listed above are sufficient for our purpose.
1.6 Controllability 53
|
|
|
| |
| |
|
Fig. 1.8. Root locus for inverted pendulum. x, open-loop poles; ©, open-loop zero.
Example 1.18. Inverted pendulum
Consider the proposed proportional feedback scheme of Example 1.16
where we found for the closed-loop characteristic polynomial
o(s ay =) (s = £) =f i s*. M L' LUM
1-274
Here k is varied from 0 to oo. The poles are at 0, —F/M, Vell, and
ae, while there is a double zero at 0. The asymptotes make angles of
m/2 and —7/2 with the real axis as k > oo sincen — m = 2. The asymptotes
intersect at —43(F/M). The portions of the real axis between g/L’ and 0,
and between —F/M and —\/g/L’ belong to a locus. The pole at 0 coincides
with a zero; this means that 0 is always one of the closed-loop poles. The loci
of the remaining roots are sketched in Fig. 1.8 for the numerical values given
in Example 1.1. It is seen that the closed-loop system is not stable for any k,
as already concluded in Example 1.16.
1.6* CONTROLLABILITY
1.6.1* Definition of Controllability
For the solution of control problems, it is important to know whether or not
a given system has the property that it may be steered from any given state
54 Elements of Linear System Theory
to any other given state. This leads to the concept of controllability (Kalman,
1960), which is discussed in this section. We give the following definition.
Definition 1.11. The linear system with state differential equation
a(t) = A(t)x(t) + B(t)u(t) 1-275
is said to be completely controllable if the state of the system can be transferred
from the zero state at any initial time t, to any terminal state x(t,) = «,
within a finite time ty — to.
Here, when we say that the system can be transferred from one state to
another, we mean that there exists a piecewise continuous input u(t), fo <
t < t,, which brings the system from one state to the other.
Definition 1.11 seems somewhat limited, since the only requirement is
that the system can be transferred from the zero state to any other state. We
shall see, however, that the definition implies more. The response from an
arbitrary initial state is by 1-61 given by
U(t,) = D(ty, fo)e(to) + | "@(t, 1)B(r)u(r) dr, so that i
x(ty) — D(ty, to) x(to) =| O(t,, 7)B(r)u(r) dr. 1-276
1-277
This shows that transferring the system from the state 2(t)) = 2, to the state
x(t,) = x, is achieved by the same input that transfers x(t)) = 0 to the state
x(t) = x, — D(t,, fo)%. This implies the following fact.
Theorem 1.22. The linear differential system
x(t) = A(t)x(t) + B(du(t) 1-278
is completely controllable if and only if it can be transferred from any initial
state %, at any initial time ty to any terminal state x(t,) = x, within a finite time
ty ar To.
Example 1.19. Stirred tank
Suppose that the feeds F, and F, of the stirred tank of Example 1.2 (Section
1.2.3) have equal concentrations c, = cy = ¢. Then the steady-state concen-
tration Cy in the tank is also ¢, and we find for the linearized state differential
equation
—-=— 0 (ae
a(t) = : Be x(t) + (' ‘)ut 1-279
6
1.6 Controllability BG
It is clear from this equation that the second component of the state, which is
the incremental concentration, cannot be controlled by manipulating the
input, whose components are the incremental incoming flows. This is also
clear physically, since the incoming feeds are assumed to have equal con-
centrations.
Therefore, the system obviously is not completely controllable if c, = cy.
If c, ¥ cy, the system is completely controllable, as we shall see in Example
RAY
1.6.2* Controllability of Linear Time-Invariant Systems
In this section the controllability of linear time-invariant systems is studied.
We first state the main result.
Theorem 1.23. The n-dimensional linear time-invariant system
a(t) + Ax(t) + Bu(t) 1-280
is completely controllable if and only if the column vectors of the controllability
matrix
P= (5, AB, AB, > AB) 1-281
span the n-dimensional space.
This result can be proved formally as follows. We write for the state at t,,
when at time fy the system is in the zero state,
ty
a(t) = | e4'4—) Bu (zr) dr. to
1-282
The exponential may be represented in terms of its Taylor series; doing this
we find
Hee | aes Bl (t one
ti = 2
+ a°B| rae ugar =>*. 1-283
to lf
We see that the terminal state is in the linear subspace spanned by the column
vectors of the infinite sequence of matrices B, AB, A?B,--:. In this sequence
there must eventually be a matrix, say A'B, the column vectors of which are
all linearly dependent upon the combined column vectors of the preceding
matrices B, AB,--:, A’ 1B. There must be such a matrix since there cannot
be more than n linearly independent vectors in n-dimensional space. This
also implies that / < n.
56 Elements of Linear System Theory
Let us now consider A’*1B = A(A’B). Since the column vectors of A'B
depend linearly upon the combined column vectors of B, AB,-:: , A'*B,
we can write
A'B = BA, + ABA, + ::+ + A’"BA,,, 1-284
where the A,, i=0,1,---,/— 1 are matrices which provide the correct
coefficients to express each of the column vectors of A’B in terms of the
column vectors of B, AB,---: , A’1B. Consequently, we write
AB = ABA, + A°BA, +:°:: + A'BA, 4, 1-285
which very clearly shows that the columns of A'1B also depend linearly
upon the column vectors of B, AB,--- , A’ 1B. Similarly, it follows that the
column vectors of all matrices A*B for k > / depend linearly upon the column
vectors of B, AB,:-:, A’B.
Returning now to 1-283, we see that the terminal state x(t,) is in the linear
subspace spanned by the column vectors of B, AB,:--,A'B. Since
1 <n we can just as well say that 2(t,) is in the subspace spanned by the
column vectors of B, AB,:-:,A”1B. Now if these column vectors do not
span the n-dimensional space, clearly only states in a linear subspace that is
of smaller dimension than the entire n-dimensional space can be reached,
hence the system is not completely controllable. This proves that if the system
is completely controllable the column vectors of the controllability matrix P
span the n-dimensional space.
To prove the other direction of the theorem, assume that the columns of P
span the n-dimensional space. Then by a suitable choice of the input u(7),
to <7T <4 (e.g., involving orthogonal polynomials), the coefficient vectors
ti z
i a7) u(r) dr 1-286
to Um
in 1-283 can always be chosen so that the right-hand side of 1-283 equals any
given vector in the space spanned by the columns of P. Since by assumption
the columns of P span the entire n-dimensional space, this means that any
terminal state can be reached, hence that the system is completely control-
lable. This terminates the proof of Theorem 1.23.
The controllability of the system 1-280 is of course completely determined
by the matrices A and B. It is therefore convenient to introduce the following
terminology.
Definition 1.12, Let A be ann X nand Bann x k matrix. Then we say that
the pair {A, B} is completely controllable if the system
&(t) = Ax(t) + Bu(t) 1-287
is completely controllable.
1.6 Controllability 57
Example 1.20. Inverted pendulum
The inverted pendulum of Example 1.1 (Section 1.2.3) is a single-input
system which is described by the state differential equation
0 1 0 0 0
poe O20 ale
Hy = M a(t) +9 M Qut). 1-288
0 Os Derg 0
L LE
The controllability matrix of the system is
eee em ae (Ey
M MM M/ M
1 Fi /FY1 FY als
M MM eae aby
P= 1-289
0 0 0 oe LM
0 0 wy | ie JP
EM LMM
It is easily seen that P has rank four for all values of the parameters, hence
that the system is completely controllable.
1.6.3* The Controllable Subspace
In this section we analyze in some detail the structure of linear time-invariant
systems that are not completely controllable. If a system is not completely
controllable, clearly it is of interest to know what part of the state space can
be reached. This motivates the following definition.
Definition 1.13. The controllable subspace of the linear time-invariant system
a(t) = Ax(t) + Bu(t) 1-290
is the linear subspace consisting of the states that can be reached from the
zero State within a finite time.
In view of the role that the controllability matrix P plays, the following result
is not surprising.
58 Elements of Linear System Theory
Theorem 1.24. The controllable subspace of the n-dimensional linear time-
invariant system
x(t) = Ax(t) + Bu(t) 1-291
is the linear subspace spanned by the columns of the controllability matrix
P= BZAB MS! RAPS BR): 1-292
This theorem immediately follows from the proof of Theorem 1.23 where we
showed that any state that can be reached from the zero state is spanned by
the columns of P, and any state not spanned by the columns of P cannot be
reached. The controllable subspace possesses the following property.
Lemma 1.3. The controllable subspace of the system #t) = Ax(t) + Bu(t)
is invariant under A, that is, if a vector x is in the controllable subspace, Ax
is also in this subspace.
The proof of this lemma follows along the lines of the proof of Theorem 1.23.
The controllable subspace is spanned by the column vectors of B, AB,---,
A"1B. Thus the vector Ax, where « is in the controllable subspace, is in the
linear subspace spanned by the column vectors of AB, A®B,--: , A"B. The
column vectors of A"B, however, depend linearly upon the column vectors of
B, AB,---, A” 4B; therefore Ax is in the subspace spanned by the column
vectors of B, AB,:::,A"1B, which means that Az is in the controllable
subspace. The controllable subspace is therefore invariant under A.
The concept of a controllable subspace can be further clarified by the
following fact.
Theorem 1.25. Consider the linear time-invariant system #(t) = Aa(t) +
Bu(t). Then any initial state xq in the controllable subspace can be transferred
to any terminal state x, in the controllable subspace within a finite time.
We prove this result by writing for the state of the system at time ¢,:
ty
ah, = eo a, +] e4(4—) Bu(r) dr. 1-293
to
Now if a, is in the controllable subspace, exp [A(t, — f9)]ao is also in the
controllable subspace, since the controllable subspace is invariant under A
and exp [A(t, — t)] = 7 + A(t, — to) + 4A2(t, — to) + ° ++. Therefore, if
az, is in the controllable subspace, x, — exp [A(t, — to)]%o is also in the con-
trollable subspace. Expression 1-293 shows that any input that transfers the
zero state to the state x, — exp [A(t, — fy)]a also transfers x) to 2,. Since
a, — exp [A(t, — fo)]xo is in the controllable subspace, such an input exists;
Theorem 1.25 is thus proved. :
1.6 Controllability 59
We now find a state transformation that represents the system in a canoni-
cal form, which very clearly exhibits the controllability properties of the
system. Let us suppose that P has rank m < n, that is, P possesses m linearly
independent column vectors. This means that the controllable subspace of the
system 1-290 has dimension m. Let us choose a basis e;, €,,°** , é,, for the
controllable subspace. Furthermore, let @,44,@mi2,°°',@, be n—m
linearly independent vectors which together with e,, e,,°-+*,e,, span the
whole n-dimensional space. We now form the nonsingular transformation
matrix
i= (7; 7), 1-294
where
T, = (e,, 2, Sikes rhe 1-295
and
1-296
T? a (Cnaae Cmt2. °°" > Gye Finally, we introduce a transformed state variable x’(t) defined by
TA =): 1-297
Substituting this into the state differential equation 1-290, we obtain
Ta! (t) = ATx'(t) + Bu(t) 1-298
or
“(t)= T*ATe) + AB). 1-299
We partition 7 as follows
U;
Pe ; 1-300
Us
where the partitioning corresponds to that of 7 in the sense that U, has m
rows and U, has n — m rows. With this partitioning it follows
U, U, T, U,T; Ln 0
baie = (Ta Zo) = = . 1-301
U, UnT, U,T, 0 | Pa
From this we conclude that
UT, = 0. 1-302
T, is composed of the vectors e,, @:,°** ,@, Which span the controllable
subspace. This means that 1-302 implies that
Ut ==.0 1-303
for any vector x in the controllable subspace.
60 Elements of Linear System Theory
With the partitionings 1-294 and 1-300, we write
U
U,AT, ae
TAT se ( 1) ct T= ( 2
U,AT, U,AT3
1-304
and
ot Us U,B
TB = B= 1-305
U, UB
All the columns of 7, are in the controllable subspace. This means that
all the columns of AT, are also in the controllable subspace, since the con-
trollable subspace is invariant under A (Lemma 1.3). However, then 1-303
implies that
U,A T; = 0. 1-306
The columns of B are obviously all in the controllable subspace, since B is
part of the controllability matrix. Therefore, we also have
U,B = 0. 1-307
Our findings can be summarized as follows.
Theorem 1.26. Consider the n-dimensional time-invariant system
a(t) = Ax(t) + Bu(t). 1-308
Form a nonsingular transformation matrix T = (T,, Tz) where the columns of
T, form a basis for the m-dimensional (m <n) controllable subspace of
1-308 and the column vectors of T, together with those of T, form a basis for the
whole n-dimensional space. Define the transformed state
a! (¢) == Ta): 1-309
Then the state differential equation 1-308 is transformed into the controllability
canonical form
ye FRAG © ie Bi
a(t) = ( a(t) + u(t). 1-310
0 Abs 0
Here A}, isanm X m matrix, and the pair {Aj,, By} is completely controllable.
Partitioning
AO)
a(t) = ; 1-311
wi(t) vb
where x; has dimension m and x, dimension n — m, we see from Theorem 1.26
that the transformed system can be represented as in Fig. 1.9. We note that
1.6 Controllability 61
A(t) = Aly x4 (t) + Ag x} (t) +Bh ult)
X5 (t) =A'ng x(t)
Fig. 1.9. The controllability canonical form of a linear time-invariant differential system.
x, behaves completely independently, while 2; is influenced both by x and
the input uv. The fact that {Aj,, By} is completely controllable follows from
the fact that any state of the form col (29, 0) is in the controllable subspace
of the system 1-310. The proof is left as an exercise.
It should be noted that the controllability canonical form is not at all
unique, since both 7, and 7, can to some extent be freely chosen. It is easily
verified, however, that no matter how the transformation T is chosen the
characteristic values of both Aj, and A, are always the same (Problem 1.5).
Quite naturally, this leads us to refer to the characteristic values of A}, as the
controllable poles of the system, and to the characteristic values of Ao, as the
uncontrollable poles. Let us now assume that all the characteristic values of
the system 1-310 are distinct (this is not an essential restriction). Then it is
not difficult to recognize (Problem 1.5) that the controllable subspace of the
system 1-310 is spanned by the characteristic vectors corresponding to the
controllable poles of the system. This statement is also true for the original
representation 1-308 of the system. Then a natural definition for the
uncontrollable subspace of the system, which we have so far avoided, is the
subspace spanned by the characteristic vectors corresponding to the uncon-
trollable poles of the system.
Example 1.21. Stirred tank
The stirred tank of Example 1.2 (Section 1.2.3) is described by the state
differential equation
=e 5 1 1
a(t) a 1 x(t) 4 Cy = Co C2 ——, Co u(t). 1-312
py Ee Vy Vo
62 Elements of Linear System Theory
The controllability matrix is
Il 1 = as = =
26 20
P= 5 1-313
Gi Sb (By, = Gy gfe Moa a eg ae a
Yo Vo eM 6 VY
P has rank two provided c, # cy. The system is therefore completely con-
trollable i ci C3.
If c, = cg = é, then cy = ¢ also and the controllability matrix takes the
form
tne et
Pes 20 = «20 J. 1-314
OO a0 0
The controllable subspace is therefore spanned by the vector col(1, 0). This
means, as we saw in Example 1.19, that only the volume of fluid in the tank
can be controlled but not the concentration.
We finally remark that if c, = cp = cy = ¢ the state differential equation
1-312 takes the form 1-279, which is already in controllability canonical
form. The controllable pole of the system is —1/(20); the uncontrollable
poleis —1/0.
1.6.4* Stabilizability
In this section we develop the notion of stabilizability (Galperin and Krasov-
ski, 1963; Wonham 1968a). The terminology will be motivated in Section 3.2.
In Section 1.4.3 we defined the stable and unstable subspaces for a time-
invariant system. Any initial state x(0) can be uniquely written as
x(0) = «,(0) + 2,(0), 1-315
where x,(0) is in the stable subspace and x,,(0) in the unstable subspace.
Clearly, in order to control the system properly, we must require that the
unstable component can be completely controlled. This is the case if the un-
stable component x,,(0) is in the controllable subspace. We thus state.
Definition 1.14, The linear time-invariant system
a(t) = Ax(t) + Bu(t) 1-316
is stabilizable if its unstable subspace is contained in its controllable subspace,
that is, any vector « in the unstable subspace is also in the controllable subspace.
It is sometimes convenient to employ the following abbreviated terminology.
1.6 Controllability 63
Definition 1.15. The pair {A, B} is stabilizable if the system
a(t) = Ax(t) + Bu(t) 1-317
is stabilizable.
Obviously, we have the following result.
Theorem 1.27. Any asymptotically stable time-invariant system is stabilizable.
Any completely controllable system is stabilizable.
The stabilizability of a system can conveniently be checked when the state
differential equation is in controllability canonical form. This follows from
the following fact.
Theorem 1.28. Consider the time-invariant linear system
a(t) = Ax(t) + Bu(t). 1-318
Suppose that it is transformed according to Theorem 1-26 into the controllability
canonical form ye! Sitdlt ES, oer Bi
2'(t) = a(t) + u(t), 1-319
0 A, 0
22
where the pair {Aj,, By} is completely controllable. Then the system 1-318 is
stabilizable if and only if the matrix Ay. is asymptotically stable.
This theorem can be summarized by stating that a system is stabilizable if
and only if its uncontrollable poles are stable. We prove the theorem as
follows.
(a) Stabilizability implies Ag. asymptotically stable. Suppose that the system
1-318 is stabilizable. Then the transformed system 1-319 is also stabilizable
(Problem 1.6). Let us partition
x'(t) = ( pal 1-320
where the dimension m of 2;(t) is the dimension of the controllable subspace
of the original system 1-318. Suppose that Aj, is not stable. Choose an
(n — m)-dimensional vector x, in the unstable subspace of Aj. Then
obviously, the n-dimensional columnn vector col (0, #3) is in the unstable
subspace of 1-319. This vector, however, is clearly not in the controllable
subspace of 1-319. This means that there is a vector that is in the un-
stable subspace of 1-319 but not in the controllable subspace. This contradicts
the assumption of stabilizability. This proves that if the system 1-318 is
stabilizable Aj. must be stable.
(b) Aj, stable implies stabilizability: Assume that A322 is stable. Then any
vector that is in the unstable subspace of 1-319 must be of the form
64 Elements of Linear System Theory
col (a1, 0). However, since the pair {A;,, By} is completely controllable, this vec-
tor is also in the controllable subspace of 1-319. This shows that any vector in
the unstable subspace of 1-319 is also in the controllable subspace, hence
that 1-319 is stabilizable. Consequently (Problem 1.6), the original system
1-318 is also stabilizable.
Example 1.22. Stirred tank
The stirred tank of Example 1.2 (Section 1.2.3) is described by the state
differential equation
Se ea Ue
a(t) = a(t) + ( Jue 1-321
‘ae OO
if we assume that c; = c, = Cy) = ¢. As we have seen before, this system is
not completely controllable. The state differential equation is already in
the decomposed form for controllability. We see that the matrix A%. has the
characteristic value —1/0, which implies that the system is stabilizable. This
means that even if the incremental concentration &,(t) initially has an in-
correct value it will eventually approach zero.
1.6.5* Controllability of Time-Varying Linear Systems
The simple test for controllability of Theorem 1.24 does not apply to time-
varying linear systems. For such systems we have the following result, which
we shall not prove.
Theorem 1.29. Consider the linear time-varying system with state differential
equation
a(t) = A(t)e(t) + B(t)u(t). 1-322
Define the nonnegative-definite symmetric matrix function
t
Wik. t= [ (t, 7) B(r) B71 (r)®7 (t, 7) dr, 1-323
to
where @(t, to) is the transition matrix of the system. Then the system is com-
pletely controllable if and only if there exists for all ty a t, with ty < t, <
such that W(to, ty) is nonsingular.
For a proof of this theorem, the reader is referred to Kalman, Falb, and
Arbib (1969).
The matrix W(t, ¢,) is related to the minimal “control energy’’ needed
to transfer the system from one state to another when the ‘‘control energy”
1.7 Reconstructibility 65
is measured as
1
| u7(t)u(t) dt. 1-324
to
A stronger form of controllability results if certain additional conditions
are imposed upon the matrix W(t), t) (Kalman, 1960):
Definition 1.16. The time-varying system 1-322 is uniformly completely
controllable if there exist positive constants 0, %, %4, By, and B, such that
(a) ol<oWth,tt+o)<al forall t; 1-325
(b) Bol < P(t, ty + G)W(to, to + O)O* (ty, tp +0) < Bl forall to,
1-326
where W(t, t) is the matrix 1-323 and V(t, tg) is the transition matrix of the
system.
Uniform controllability implies not only that the system can be brought from
any state to any other state but also that the control energy involved in this
transfer and the transfer time are roughly independent of the initial time.
In view of this remark, the following result for time-invariant systems is not
surprising.
Theorem 1.30. The time-invariant linear system
a(t) = Ax(t) + Bu(t) 1-327
is uniformly completely controllable if and only if it is completely controllable.
1.7* RECONSTRUCTIBILITY
1.7.1* Definition of Reconstructibility
In Chapter 4 we discuss the problem of reconstructing the behavior of the
state of the system from incomplete and possibly inaccurate observations.
Before studying such problems it is important to know whether or not a given
system has the property that it is at all possible to determine from the behavior
of the output what the behavior of the state is. This leads to the concept of
reconstructibility (Kalman, Falb, and Arbib, 1969), which is the subject of
this section.
We first consider the following definition.
Definition 1.17. Let y(t; t), v9, u) denote the response of the output variable
y(t) of the linear differential system
a(t) = A(t)a(t) + B(t)u(d), :
y(t) = C(t)x(t), 1-328
66 Elements of Linear System Theory
to the initial state x(ty) = Xp». Then the system is called completely recon-
structible if for all t, there exists a ty with — 0 < ty < t, such that
y(t; to, v5 u) = y(t; to; os u), to < t = h, 1-329
for all u(t), t) < t < ty, implies x9 = x.
The definition implies that if a system is completely reconstructible, and the
output variable is observed up to any time 4, there always exists a time
ty < t, at which the state of the system can be uniquely determined. If x(t)
is known, of course a(t,) can also be determined.
The following result shows that in order to study the reconstructibility of
the system 1-328 we can confine ourselves to considering a simpler situation.
Theorem 1.31. The system 1-328 is completely reconstructible if and only if
for all t, there exists a ty with — 00 < ty < t, such that
y(t; to, Xo, 0) = 0, to << t < th, 1-330
implies that x) = 0.
This result is not difficult to prove. Of course if the system 1-328 is completely
reconstructible, it follows immediately from the definition that if 1-330
holds then x = 0. This proves one direction of the theorem. However,
since
y(t; to; Xo, u) = C(t) Ee to) Xo +] O(t, 7) B(7)u(7) ar|, t
to
1-331
the fact that
INES tysLis Hh) SUES tgs Mos for =60j. <tr 1-332
implies and is implied by
COOGE, to) ey = COO, wz, for .f, <a tite 1-333
This in turn is equivalent to
C(t)D(t, to)(a% — 24) = 0 fOr t, Sate. 1-334
Evidently if 1-334 implies that x — x) = 0, that is, v = 2, the system is
completely reconstructible. This finishes the proof of the other direction of
Theorem 1.31.
The definition of reconstructibility is due to Kalman (Kalman, Falb, and
Arbib, 1969). It should be pointed out that reconstructibility is complementary
to observability. A system of the form 1-328 is said to be completely observ-
able if for all tf) there exists a t; < oo such that
y(t; to, Xo» u) = y(t; to, Xo, u), to = t — h, 1-335
for all u(t), t)<t< 4%, implies that 2) = a. We note that observability
1.7 Reconstructibility 67
means that is it possible to determine the state at time ft) from the future
output. In control and filtering problems, however, usually only past output
values are available. It is therefore much more natural to consider recon-
structibility, which regards the problem of determining the present state from
past observations. It is easy to recognize that for time-invariant systems com-
plete reconstructibility implies and is implied by complete observability.
Example 1.23. Inverted pendulum
Consider the inverted pendulum of Example 1.1 (Section 1.2.3) and take
as the output variable the angle ¢(t). Let us compare the states
0 as
° and 1-336
0 dy
0 0
The second state differs from the zero state in that both carriage and
pendulum are displaced over a distance d); otherwise, the system is at rest.
If an input identical to zero is applied, the system stays in these positions,
and ¢(t) = 0 in both cases. It is clear that if only the angle #(f) is observed it
is impossible to decide at a given time whether the system is in one state or
the other; as a result, the system is not completely reconstructible.
1.7.2* Reconstructibility of Linear Time-Invariant Systems
In this section the reconstructibility of linear time-invariant systems is dis-
cussed. The main result is the following.
Theorem 1.32. The n-dimensional linear time-invariant system
a(t) = Ax(t) + Bu(t),
1-337
y(t) = Cx(t),
is completely reconstructible if and only if the row vectors of the reconstructi-
bility matrix
Ons 1-338
Ca
span the n-dimensional space.
68 Elements of Linear System Theory
This can be proved as follows. Let us first assume that the system 1-337 is
completely reconstructible. Then it follows from Theorem 1.31 that for all
t, there exists a fy such that
Gene Oy es On tg ah ea 1-339
implies that 7) = 0. Expanding exp [A(t — 1))] in terms of its Taylor series,
1-339 is equivalent to
— tt.) weil 3
Je + cat — 4) + caw SHY 4 cas S—BY 4 |ay = 0,
Pen Set Peet Pee
Now if the reconstructibility matrix Q does not have full rank, there exists
a nonzero 2, such that
Czy=0, Cde=0, <*', CA™ x, =0. 1-341
By using the Cayley-Hamilton theorem, it is not difficult to see also that
CA'x, = 0 for/ > n. Thus if QO does not have full rank there exists a nonzero
xy such that 1-340 holds. Clearly, in this case 1-339 does not imply x) = 0,
and the system is not completely reconstructible. This contradicts our
assumption, which proves that Q must have full rank.
We now prove the other direction of Theorem 1.32. Asume that Q has full
rank. Suppose that
y(t) = Cet" ny, = 0 for tp<t< bt. It follows by repeated differentiation of y(t) that
1-342
Y(t) = Cay =),
y'(to) = CAxy = 0,
YAN = GA, =), 1-343
y'™—") (t,) = CAr1 t= 0,
Or
Ox = 0. 1-344
Since Q has full rank, 1-344 implies that z) = 0. Hence by Theorem 1.31 the
system is completely reconstructible. This terminates the proof of Theorem
SPA
Since the reconstructibility of the system 1-337 depends only on the matrices
A and C, it is convenient to employ the following terminology.
1.7 Reconstructibility 69
Definition 1.18. Let A be ann X n and C an! Xn matrix. Then we call
the pair {A, C} completely reconstructible if the system
a(t) = Ax(t), 1-345
y(t) = Cz(t), 1-346
is completely reconstructible.
Example 1.24. Inverted pendulum
The inverted pendulum of Example 1.1 (Section 1.2.3) is described by the
state differential equation
0 io ie 0
(ne ee ae er ak
TO) == a(t) + t). -
) as (t) (t) 1-347
\ 0 DreoneH o |
ee ea 0
L L
If we take as the output variable 7(t) the angle (t), we have
1 1
Nal, o% =, 0) x(t). 1-348
y(t) ( 7 LU (t)
The reconstructibility matrix is
sae 0 Sa
LE iB}
; el ag al
- = 1-349
eet es g 1 |
POE. ML CE
9 -£1_(£)1 9 #1
| Bigs & M/ L fing 8
This matrix has rank three; the system is therefore not completely recon-
structible. This confirms the conclusion of Example 1.23. If we add as a
second component of the output variable the displacement s(¢) of the carriage,
we have eae es
yt=\) EL LE }a(t). 1-350
Rone 0
70 Elements of Linear System Theory
This yields for the reconstructibility matrix
fal 0 20
L L
0 0 0
: a Reon:
L L
0 1 (ea
one 2 as Bre 1-351
L MLE LL
0 = 0 0
M
-£1_ (fyi Bid
LL \M/E UL
2
0 a fo
M
With this output the system is completely reconstructible, since Q has rank
four.
1.7.3* The Unreconstructible Subspace
In this section we analyze in some detail the structure of systems that are not
completely reconstructible. If a system is not completely reconstructible, it is
never possible to establish uniquely from the output what the state of the
system is. Clearly, it is of interest to know exactly what uncertainty remains.
This introduces the following definition.
Definition 1.19. The unreconstructible subspace of the linear time-invariant
a a(t) = Ax(t) + Bu(t),
1-352
y(t) = Cx(t),
is the linear subspace consisting of the states x9 for which
OE Ge. Lon) nO alt Fe 1-353
The following theorem characterizes the unreconstructible subspace.
Theorem 1.33. The unreconstructible subspace of the n-dimensional linear
time-invariant system a(t) = Ax(t) + Bu(t),
y(t) = Cx(t), Sr
1.7 Reconstructibility 71
is the null space of the reconstructibility matrix
Q= : 1-355
CA"
The proof of this theorem immediately follows from the proof of Theorem
1.32 where we showed that any initial state in the null space of Q produces an
output that is identical to zero in response to a zero input. Any initial state
not in the null space of Q produces a nonzero response, which proves that
the null space of Q is the unreconstructible subspace. The unreconstructible
subspace possesses the following property.
Lemma 1.4. The unreconstructible subspace of the system a(t) = Ax(t),
y(t) = Cx(t) is invariant under A.
We leave the proof of this lemma as an exercise.
The concept of unreconstructible subspace can be clarified by the following
fact.
Theorem 1.34. Consider the time-invariant system
a(t) = Ax(t) + Bu(t),
1-356
y(t) = Cx(t).
Suppose that the output y(t) and the input u(t) are known over an interval
to <t <t,. Then the initial state of the system at time ty is determined within
the addition of an arbitrary vector in the unreconstructible subspace. As a
result, also the terminal state at time t, is determined within the addition of an
arbitrary vector in the unreconstructible subspace.
To prove the first part of the theorem, we must show that if two initial states
x(t o) = %q and (ty) = xo produce the same output y(t), fy < t < 4, for any
input u(t), 4 << t < ty, then x — ay lies in the unreconstructible subspace.
This is obviously true since by the linearity of the system,
W(t ta, Fos) sy eta ean) Fi ere 1-357
is equivalent to
y(t; to, % — %, 0) = 0, fe ek Sodas 1-358
which shows that 2) — 2o is in the unreconstructible subspace.
The second part of the theorem is proved as follows. The addition of an
arbitrary vector xj in the unreconstructible subspace to 2, results in the
72 Elements of Linear System Theory
addition of exp [A(t, — fo)]xo to the terminal state. Since exp [A(t, — %))]
can be expanded in powers of A, and the unreconstructible subspace is in-
variant under A, exp [A(t,; — ¢o)]o is also in the unreconstructible subspace.
Moreover, since exp [A(t, — to)] is nonsingular, this proves that also the
terminal state is determined within the addition of an arbitrary vector in the
unreconstructible subspace.
We now discuss a state transformation that represents the system in a
canonical form, which clearly exhibits the reconstructibility properties of the
system. Let us suppose that Q has rank m < n, that is, Q possesses m linearly
independent row vectors. This means that the null space of Q, hence the un-
reconstructible subspace of the system, has dimension n — m. The row
vectors of Q span an m-dimensional linear subspace; let the row vectors
Sis fo, ** * > fm be a basis for this subspace. An obvious choice for this basis is a
set of m independent row vectors from Q. Furthermore, let f.41,finio.° °° >
Jf, ben — m linearly independent row vectors which together with f,,--- ,f,,
span the whole n-dimensional space. Now form the nonsingular transforma-
tion matrix
U;
U= ; 1-359
U2
where
i Fin
tr Jeces
U,=] | and U, = : 1-360
Sm Sn
Finally, introduce a transformed state variable x’(t) as
u(t) = Un(t). 1-361
Substitution into 1-356 yields
or
U24'(t) = AU—2'(t) + Bu(t),
y(t) = CU-%x'(t), tees
#’(t) = UAU-x'(t) + UBu(t),
y(t) = CU-1x'(t),
1-363
We partition U~ as follows
U* == (14,75); 1-364
1.7 Reconstructibility 73
where the partitioning corresponds to that of U so that T, has m and 7,
n — mcolumns. We have
=i U, U,T, U,T; Ie 0
UU = (Tj, T,) = = : 1-365
U; U.T, U,T, I.
from which we conclude that
The rows of U, are made up of linear combinations of the linearly independent
rows of the reconstructibility matrix Q. This means that any vector x that
satisfies U,x = 0 also satisfies Qx = 0, hence is in the unreconstructible
subspace. Since
U,T, = 0, 1-367
all column vectors of 7, must be in the unreconstructible subspace. Because
T, has n — m linearly independent column vectors, and the unreconstrucible
subspace has dimension n — m, the column vectors of T, form a basis for the
subspace. With this it follows from 1-367 that U,x = 0 for any x in the sub-
space.
With the partitionings 1-359 and 1-364, we have
U, UAT, UAT.
UAU4 = | Jacr, T,) = ( 1-368
; UAT, OULAT,
and CU- = (CT,, CT,). 1-369
All column vectors of T, are in the unreconstructible subspace; because the
subspace is invariant under A (Lemma 1.4), the columns of AT, are also in
the subspace, and we have from 1-367
U,AT, = 0. 1-370
Since the rows of C are rows of the reconstructibility matrix Q, and the
columns of 7, are in the unreconstructible subspace, hence in the null space
of Q, we must also have
Gi 0: 1-371
We summarize our results as follows.
Theorem 1.35. Consider the n-th order time-invariant linear system
a(t) = Ax(t) + Bu(t),
Wt) = Crt). 1-372
74 Elements of Linear System Theory
Form a nonsingular transformation matrix
U
Us '. 1-373
U,
where the m rows of U, form a basis for the m-dimensional (m < n) subspace
spanned by the rows of the reconstructibility matrix of the system. Then — m
rows of U, form together with the m rows of U, a basis for the whole n-dimen-
sional space. Define a transformed state variable x'(t) by
w(t) == Cx(t). 1-374
Then in terms of the transformed state variable the system is represented in
the reconstructibility canonical form
Ah) x'(t) + u(t),
(1) (“ = () (aco
Ai Aly By tile
y(t) = (Cy, O)a"(t).
Here Aj, is an m X m matrix, and the pair {Aj,, Ci} is completely recon-
structible.
Partitioning
a(t) = ( a 1-376
«3(t)
where x; has dimension m and x3 dimension n — m, we see from Theorem
1.35 that the system can be represented as in Fig. 1.10. We note that nothing
about x, can be inferred from observing the output y. The fact that the pair
{Aj,, Cj} is completely reconstructible follows from the fact that if an initial
x} (t) = Ag, x}(t) +B u(t)
x (t) =A\, x(t) +Aly 9 xy (t) +B) u(t)
Fig. 1.10. Reconstructibility canonical form of a time-invariant linear differential system.
1.7. Reconstructibility 75
state x'(f,) produces a zero input response identical to zero, it must be of the
form x'(to) = col (0, 2%). The complete proof is left as an exercise.
We finally note that the reconstructibility canonical form is not unique
because both U, and U, can to some extent be arbitrarily chosen. No matter
how the transformation is performed, however, the characteristic values of
Aj, and As, can be shown to be always the same. This leads us to refer to the
characteristic values of Aj, as the reconstructible poles, and the characteristic
values of A, as the unreconstructible poles of the system 1-372. Let us assume
for simplicity that all characteristic values of the system are distinct. Then it
can be proved that the unreconstructible subspace of the system is spanned by
those characteristic vectors of the system that correspond to the unreconstruct-
ible poles. This is true both for the transformed version 1-375 and the original
representation 1-372 of the system. Quite naturally, we now define the
reconstructible subspace of the system 1-372 as the subspace spanned by the
characteristic vectors of the system corresponding to the reconstructible poles.
Example 1.25. Inverted pendulum
In Example 1.24 we saw that the inverted pendulum is not completely
reconstructible if the angle ¢(t) is chosen as the observed variable. We now
determine the unreconstructible subspace and the reconstructibility canonical
form. It is easy to see that the rows of the reconstructibility matrix Q as given
by 1-349 are spanned by the row vectors
(1 0e ly) Or 1) and O21 e040): 1377
Any vector « = col (&, &, &3, €4) in the null space of Q must therefore
satisfy
—€, + oe = 0,
—& + &,=0, 1-378
Si.
This means that the unreconstructible subspace of the system is spanned by
col (15.0; 15:0); 1-379
Any initial state proportional to this vector is indistinguishable from the
zero state, as shown in Example 1.23.
To bring the system equations into reconstructibility canonical form, let
us choose the row vectors 1-377 as the first three rows of the transformation
matrix U. For the fourth row we select, rather arbitrarily, the row vector
(1,20; O70): 1-380
76 Elements of Linear System Theory
With this we find for the transformation matrix U and its inverse
il 0 I 0 OF Om Oras
OP ee! 0 1 0 0 io
U= ; Ult= . 1-381
0 1 0 oO 020441
I ee te, OF eta
It follows for the transformed representation
One MeOiaclcO 0
| 1
te ar a
L M | M
a(t) = a(t) + H(t), 1-382
Gis oe O -
M | M
0-0) 0 0
n(t) = Fe O70; : 0) a'(t).
1e
The components of the transformed state are, from 1-24,
E(t) = —8() + 6:1) = L460),
E(t) = — E(t) + S(t) = LO),
1-383
E3(t) = 2(t) = s(t),
E4(t) = &1(t) = s(t).
In this representation the position and velocity of the pendulum relative to
the carriage, as well as the velocity of the carriage, can be reconstructed from
the observed variable, but not the position of the carriage.
It is easily seen that the reconstructible poles of the system are — F/M and
+,/g/L’. The unreconstructible pole is 0.
1.7.4* Detectablity
In the preceding section it was found that if the output variable of a not com-
pletely reconstructible system is observed there is always an uncertainty about
the actual state of the system since to any possible state we can always add an
arbitrary vector in the unreconstructible subspace (Theorem 1.34). The best
we can hope for in such a situation is that any state in the unreconstructible
subspace has the property that the zero input response of the system to this
1.7 Reconstructibility 77
state converges to zero. This is the case when any state in the unreconstruct-
ible subspace is also in the stable subspace of the system. Then, whatever we
guess for the unreconstructible component of the state, the error will never
grow indefinitely. A system with this property will be called detectable
(Wonham, 1968a). We define this property as follows.
Definition 1.20. The linear time-invariant system
x(t) = Ax(t) + Bult),
y(t) = Cx(t),
1-384
is detectable if its unreconstructible subspace is contained in its stable subspace.
It is convenient to employ the following abbreviated terminology.
Definition 1.21. The pair {A, C} is detectable if the system
at) == Age)
y(t) = Cx(t), 1-385
is detectable.
The following result is an immediate consequence of the definition:
Theorem 1.36. Any asymptotically stable system of the form 1-384 is de-
tectable. Any completely reconstructible system of the form 1-384 is de-
tectable.
Detectable systems possess the following property.
Theorem 1.37. Consider the linear time-invariant system
e(t) = A(t), 1-386
y(t) = Cx(t).
Suppose that it is transformed according to Theorem 1.35 into the form
Ay
a(t) = | x(t),
Hie SAG 1-387
y(t) = (Ci, O)x'"(0),
where the pair {Aj,, Ci} is completely reconstructible. Then the system is
detectable if and only if the matrix A. is asymptotically stable.
This theorem can be summarized by stating that a system is detectable if and
only if its unreconstructible poles are stable. We prove the theorem as
follows.
78 Elements of Linear System Theory
(a) Detectability implies Aj, asymptotically stable: Let us partition the
transformed state variable as
x;(t)
z'(t) = | : ) 1-388
x(t)
where the dimension m of x;(t) is equal to the rank m of the reconstructibility
matrix. The fact that the system is detectable implies that any initial state in
the unreconstructible subspace gives a response that converges to zero. Any
initial state in the unreconstructible subspace has in the transformed repre-
sentation the form
0
x'(0) = ) 1-389
x3(0)
The response of the transformed state to this initial state is given by
0
a'(t) = ; ; 1-390
e@474(0)
Since this must give a response that converges to zero, Aj must be stable.
(b) As, asymptotically stable implies detectability: Any initial state x(0)
in the unreconstructible subspace must in the transformed representation
have the form
0
CO) = ( ) 1-391
x3(0)
The response to this initial state is
“(t) = ; : 1-392
a a2t/(0)
Since Ag, is stable, this response converges to zero, which shows that x(0),
which was assumed to be in the unreconstructible subspace, is also in the
stable subspace. This implies that the system is detectable.
Example 1.26. Inverted pendulum
Consider the inverted pendulum in the transformed representation of
Example 1.25. The matrix Ay. has the characteristic value 0, which implies
that the system is not detectable. This means that if initially there is an un-
certainty about the position of the carriage, the error made in guessing it will
remain constant in time.
1.7.5* Reconstructibility of Time-Varying Linear Systems
The reconstructibility of time-varying linear systems can be ascertained by
the following test.
1.8 Duality of Linear Systems 79
Theorem 1.38. Consider the linear time-varying system
&(t) = A(t)a(t) + B(t)u(t), y(t) = C(t)x(t).
1-393
Define the nonnegative-definite matrix function
ty
M(t) =| ©%, NCCE OG, dr, 1-394
t
where D(t, to) is the transition matrix of the system. Then the system is com-
pletely reconstructible if and only if for all t, there exists a ty with -w <
ty < t, such that M(t, t,) is nonsingular.
For a proof we refer the reader to Bucy and Joseph (1968) and Kalman,
Falb, and Arbib (1969). A stronger form of reconstructibility results by
imposing further conditions on the matrix M (Kalman, 1960):
Definition 1.22. The time-varying system 1-393 is uniformly completely
reconstructible if there exist positive constants 0, %, %, By, and By such that
(a) al< M(it,—o0,4)< a7 forall t,; 1-395
(b) Bol < O7 (4, — 6,1) M(t, — 6,1) O(h — 6,1) <ul forall ty,
1-396
where M(t, t;) is the matrix function 1-394.
Uniform reconstructibility guarantees that identification of the state is
always possible within roughly the same time. For time-invariant systems the
following holds.
Theorem 1.39. The time-invariant linear system
a(t) = Ax(t) + Bu(t),
1-397
y(t) = Cx(t),
is uniformly completely reconstructible if and only if it is completely recon-
structible.
1.8* DUALITY OF LINEAR SYSTEMS
In the discussion of controllability and reconstructibility, we have seen that
there is a striking symmetry between these properties. This symmetry can be
made explicit by introducing the idea of duality (Kalman, 1960; Kalman,
Falb, and Arbib, 1969).
80 Elements of Linear System Theory
Definition 1.23. Consider the linear time-varying system
&(t) = A(t)e(t) + B(t)u(2),
y(t) = C(t)x(t), 1-398
and also the system
&*(t) = AT(t* — tha*(t) + C7(t* — tu*(t),
1-399
y*(t) = BT(t* — t)a*(2),
where t* is an arbitrary fixed time. Then 1-399 is called the dual of the system
1-398 with respect to the time t*.
The purpose of introducing the dual system becomes apparent in Chapter 4
when we discuss the duality of linear optimal control problems and linear
optimal observer problems. The following result is immediate.
Theorem 1.40. The dual of the system 1-399 with respect to the time t* is the
original system 1-398.
There is a close connection between the reconstructibility and controllability
of a system and its dual.
Theorem 1.41. Consider the system 1-398 and its dual 1-399 where t* is
arbitrary.
(a) The system 1-398 is (uniformly) completely controllable if and only if its
dual is (uniformly) completely reconstructible.
(b) The system 1-398 is (uniformly) completely reconstructible if and only if its
dual is (uniformly) completely controllable.
(c) Assume that 1-398 is time-invariant. Then 1-398 is stabilizable if and only
if its dual is detectable.
(d) Assume that 1-398 is time-invariant. Then 1-398 is detectable if and only
if its dual is stabilizable.
We give the proof only for time-invariant systems. The reconstructibility
matrix of the dual system is given by
Bt
B7(A’)
I
O° = Pe, 1-400
BrCA sae
1.8 Duality of Linear Systems 81
where P is the controllability matrix of the original system. This immediately
proves (a).
Part (b) of the theorem follows similarly. The controllability matrix of the
dual system is given by
DEC ed Oc ne (Aye CO, 1-401
where Q is the reconstructibility matrix of the original system. This implies
the validity of (b).
Part (c) can be proved as follows. The original system can be transformed
by a transformation x’ = Tx according to Theorem 1.26 (Section 1.6.3)
into the controllability canonical form
met oe eee
Eg x(t) + u(t), 1-402
0 A 0
y(t) = (Ci, C3)2'(t).
If 1-398 is stabilizable, the pair {A},, Bj} is completely controllable and A},
is stable. The dual of the transformed system is
us Ait 0 ne Cr 2
#'*(1) = at eee 1-403
12 22 2
y*(t) = (By, O)a’*(2).
Since {A{,, Bi,} is completely controllable, {4;/, Bj} is completely re-
constructible [part (a)]. Since Ao, is stable, A32 is also stable. This implies
that the system 1-403 is detectable. By the transformation T7x* = a’*
(see Problem 1.8), the system 1-403 is transformed into the dual of the original
system. Therefore, since 1-403 is detectable, the dual of the original system is
also detectable. By reversing the steps of the proof, the converse of Theorem
1.41(c) can also be proved. Part (d) can be proved completely analogously.
The proofs of (a) and (b) for the time-varying case are left as an exercise for
the reader.
We conclude this section with the following fact, relating the stability of a
system and its dual.
Theorem 1.42. The system 1-398 is exponentially stable if and only if its
dual 1-399 is exponentially stable.
This result is easily proved by first verifying that if the system 1-398 has the
transition matrix ®(f, fy) its dual 1-399 has the transition matrix OT (t* — ty,
t* — t), and then verifying Definition 1.5 (Section 1.4.1).
82 Elements of Linear System Theory
1.9* PHASE-VARIABLE CANONICAL FORMS
For single-input time-invariant linear systems, it is sometimes convenient
to employ the so-called phase-variable canonical form.
Definition 1.24. A single-input time-invariant linear system is in phase-
variable canonical form if its system equations have the form
0 1 Wogocn ncn 0 0
Pon 0 Ons J a0! ee 0 0
a(t)+ |---|] u(t) , 1-404
(Wena ae ee owt 0
<5 0, senses a ae 1
y(t) = Ca(t).
Note that no special form is imposed upon the matrix C in this definition.
It is not difficult to see that the numbers «;, / = 0,--:,”— 1 are the co-
efficients of the characteristic polynomial
>» %
as! 1-405
=0
of the system, where a, = 1.
It is easily verified that the system 1-404 is always completely controllable.
In fact, any completely controllable single-input system can be transformed
into phase-variable canonical form.
Theorem 1.43. Consider the completely controllable single-input time -
invariant linear system
a(t) = Ax(t) + bu(t),
1-406
y(t) = Cx(t),
where b is a column vector. Let P be the controllability matrix of the system,
P= (b Ab Abs Ab). 1-407
and let
det (sl — A) =a, 1-408
i=0
where «, = 1, be the characteristic polynomial of the matrix A. Then the
system is transformed into phase-variable canonical form by a transformation
1.9 Phase-Variable Canonical Forms 83
a(t) = Tx'(t). T is the nonsingular transformation matrix
where
T= PM,
Pe a,
Oe hy oO
Von (ae eee ee ; 1-409
tag, ORs: 0
a, Orrrrreeees 0
If the system 1-406 is not completely controllable, no such transformation
exists.
This result can be proved as follows (Anderson and Luenberger, 1967).
That the transformation matrix T is nonsingular is easily shown: P is non-
singular due to the assumption of complete controllability, and det (M) = 1
because «, = 1. We now prove that 7 transforms the system into phase-
variable canonical form. By postmultiplying P by M, it is easily seen that T
can be written
an be written as Price cet i tie py 1-410
where the column vectors ¢, of T are given by
t, = 0b + a Ab + agA2b +--+ + 0,A"— 1b,
to = Oy + a3Ab + as + tnA”b,
1-411
ty-1 = %, 10 + «,Ab,
t, = @,D.
It is seen from 1-411 that
Al = t4)— Ot; Wak RO, F 1-412
since b = f,,.
Now in terms of the new state variable, the state differential equation of the
system is given by
a (y= Lf Ale @) 7 bu). 1-413
Let us consider the matrix 7-1AT. To this end denote the rows of 7-1 by
Pe ye le2sn Phen fore =, oe? eo and 7 a2,5,73 "3s 7, the
(i, j)-th entry of TAT is given by
1 ifi=j—1,
(TAT), = 1 (Al) = Tb — Gat) = 4 —%1 wi=n, 1-414
0 otherwise.
84 Elements of Linear System Theory
This proves that the last n — 1 columns of T-+AT have the form as required
in the phase-variable canonical form. To determine the first column, we
observe from 1-411 that
At, = (0A + 04? +°-°++ 04,A")b = —a9b = —aApf,, 1-415
since according to the Cayley-Hamilton theorem
Otol + 0A + aA? +°--+4,A" = 0. 1-416
Thus we have for 7 = 1, 2,--- , 7,
(TAT),, = rf At) = —aort, = 1-417
0 otherwise.
Similarly, we can show that T~76 is in the form required, which terminates the
proof of the first part of Theorem 1.43. The last statement of Theorem 1.43 is
easily verified: if the system 1-406 is not completely controllable, no non-
singular transformation can bring the system into phase-variable canonical
form, since nonsingular transformations preserve controllability properties
(see Problem 1.6). An alternate method of finding the phase-variable canoni-
cal form is given by Ramaswami and Ramar (1968). Computational rules
are described by Tuel (1966), Rane (1966), and Johnson and Wonham
(1966).
For single-input systems represented in phase-variable canonical form,
certain linear optimal control problems are much easier to solve than if the
system is given in its general form (see, e.g., Section 3.2). Similarly, certain
filtering problems involving the reconstruction of the state from observations
of the output variable are more easily solved when the system is in the dual
phase-variable canonical form.
Definition 1.25. A single-output linear time-invariant system is in dual
Phase-variable canonical form if it is represented as follows:
OO. es < Oe a,
PO 09 es 9.0) aa;
at)=f O 1 0 +--+ 0 ~a, Fa(t) + Bu(t),
U caireicn a aineU eR Ce ai eta oi Tear: 1-418
‘y (oasaoe 01 —a,_4
n(t)= (0 0 0 +++ O 1)a(2).
It is noted that the definition imposes no special form on the matrix B. By
“dualizing” Theorem 1.43, it is not difficult to establish a transformation to
transform completely reconstructible systems into dual canonical form.
1.10 Vector Stochastic Processes 85
Related canonical forms can be derived for multiinput and multioutput
systems (Anderson and Luenberger, 1967; Luenberger, 1967; Johnson,
1971a; Wolovich and Falb, 1969).
1.10 VECTOR STOCHASTIC PROCESSES
1.10.1 Definitions
In later chapters of this book we use stochastic processes as mathematical
models for disturbances and noise phenomena. Often several disturbances
and noise phenomena simultaneously influence a given system. This makes it
necessary to introduce vector-valued stochastic processes, which constitute
the topic of this section.
A stochastic process can be thought of as a family of time functions. Each
time function we call a realization of the process. Suppose that »,(t), »2(t),
*++,¥4,(t) are n scalar stochastic processes which are possibly mutually
dependent. Then we call
v(t) = col [,(t), ¥9(t), eet y,(t)] 1-419
a vector stochastic process. We always assume that each of the components of
v(t) takes real values, and that ¢ > fo, with f) given.
A stochastic process can be characterized by specifying the joint probability
distributions
P{v(t) < V1, v(t.) < Ups a V(tm) = Deas 1-420
for all real ug, °°: 5 0,,,10r all 7),,2,,°° 46, 2 t and for every natural
number m. Here the vector inequality v(t,) < v; is by definition satisfied if
the inequalities v(t) <%y f=l,2,-++50, 1-421
are simultaneously satisfied. The »,,; are the components of v,, that is, v, =
col (¥ 51, Via, °° * > Yin)- va
A special class of stochastic processes consists of those processes the statisti-
cal properties of which do not change with time. We define more precisely.
Definition 1.26. A stochastic process v(t) is stationary if
P{v(ty) ae Dy 55 V(t) = ee:
= P{o(t) + 9) <4, +++, Um + 8) S Om} 1-422
for all ty, t2,° ++, tm, for all v1, °** , Um, for every natural number m, and for
all 0.
The joint probability distributions that characterize a stationary stochastic
process are thus invariant with respect to a shift in the time origin.
86 Elements of Linear System Theory
In many cases we are interested only in the first and second-order properties
of a stochastic process, namely, in the mean and covariance matrix or, equiva-
lently, the second-order joint moment matrix. We define these notions as
follows.
Definition 1.27. Consider a vector-valued stochastic process v(t). Then we
so my Banta) 1-423
the mean of the process,
R(t, te) = E{[v(t,) — m(t,)][v(t.) — m(ty)]7} 1-424
the covariance matrix, and
CALs to) = E{v(t,)v7 (te)} 1-425
the second-order joint moment matrix of v(t). R,(t, t) = Q(t) is termed the
variance matrix, while C(t, t) = Q’(t) is the second-order moment matrix of
the process.
Here E is the expectation operator. We shall often assume that the stochastic
process under consideration has zero mean, that is, m(t) = 0 for all f; in this
case the covariance matrix and the second-order joint moment matrix
coincide. The joint moment matrix written out more explicitly is
E{y,(t)r4(ts)} Fg E{r4(ty)¥p(te)}
Ey v(t)? (te St Ey v (ty) m( te
C(t, to) = E{v(t,)v7 (t)} = : oS ” : Men .
E{yn(ts)ra(te)} eae E {y(t m(te)}
1-426
Each element of C,(t;, f,) is a scalar joint moment function. Similarly, each
element of R,,(t,, fg) is a scalar covariance function. It is not difficult to prove
the following.
Theorem 1.44. The covariance matrix R,(t,,t,) and the second-order Joint
moment matrix C,(t,, t,) of a vector-valued stochastic process v(t) have the
following properties.
(a) Rift.) = Ro (hs fe) for all ints. and 1-427
C(h i= CA (ist) © sfomalhtet: 1-428
(6), O@) = Rie 1) > 0 for all t, and 1-429
O (ft) =e iat) = Oe for aiid: 1-430
(C) °C, (tite) Rita) a nee onal at 1-431
where m(t) is the mean of the process.
1.10 Vector Stochastic Processes 87
Here the notation M > 0, where M is a square symmetric real matrix, means
that M is nonnegative-definite, that is,
a”Mx>0O forall real x. 1-432
The theorem is easily proved from the definitions of R,(t,, t2) and C,(t,, to).
Since the second-order properties of the stochastic process are equally well
characterized by the covariance matrix as by the joint moment matrix, we
usually consider only the covariance matrix.
For stationary processes we have the following result.
Theorem 1.45. Suppose that v(t) is a stationary stochastic process. Then
its mean m(t) is constant and its covariance matrix R(t, t.) depends on
t, — ty only.
This is easily shown from the definition of stationarity.
It sometimes happens that a stochastic process has a constant mean and a
covariance matrix that depends on ¢, — ft, only, while its other statistical
properties are not those of a stationary process. Since frequently we are
interested only in the first- and second-order properties of a stochastic proc-
ess, we introduce the following notion.
Definition 1.28. The stochastic process v(t) is called wide-sense stationary if
its second-order moment matrix C,(t, t) is finite for all t, its mean m(t) is
constant, and its covariance matrix R,(t,, t.) depends on t, — tz only.
Obviously, any stationary process with finite second-order moment matrix is
also wide-sense stationary.
Let v,(t) and v,(t) be two vector stochastic processes. Then v, and v, are
called independent processes if {v,(t1), Ui (to), °°, Ui(t,)} and {vp(t7), ve(te),
+++, V(t;,)} are independent sets of stochastic variables for all t,, fg,° °°, t;,
ti, t3,°°*,tm >t) and for all natural numbers m and /. Furthermore, v,;
and v, are called uncorrelated stochastic processes if v,(¢,) and v,(f,) are un-
correlated vector stochastic variables for all t,, tg > ft, that is,
E{[v,(t1) — my(t))] [e2(t2) — m5(ty) |" } =0
for all t, and f,, where m, is the mean of v, and m, that of v9.
Example 1.27. Gaussian stochastic process
A Gaussian stochastic process v is a stochastic process where for each set
of instants of time f,, f2,°**,¢, 2 ft the n-dimensional vector stochastic
variables v(t;), v(t2),°** , V(t) have a Gaussian joint probability distribution.
88 Elements of Linear System Theory
If the compound covariance matrix
Ree ty) R,(t, ty) isan R(t, )
RE Via a mace mene oe 8
rm v(te, t1) (tg, ta) (t. rs
Kt, ty) RAG. te) ne Kee Lia)
is nonsingular, the corresponding probability density function can be written
as Kian ae
P\, Va; ee) (20) det CR
exp [4 fo, — me) }A,f0, — m(e)}}. 1-434
The n x n matrices A,; are obtained by partitioning A = R™ corresponding
to the partitioning of R as follows:
Ay Ayo Nig
We Agi Nop ee Nom 1-435
Nat Nas nak
Note that this process is completely characterized by its mean and covariance
matrix; thus a Gaussian process is stationary if and only if it is wide-sense
stationary.
Example 1.28. Exponentially correlated noise
A well-known type of wide-sense stationary stochastic process is the so-
called exponentially correlated noise. This is a scalar stochastic process
y(t) with the covariance function
R,(r) = o° exp (- iy 1-436
where o” is the variance of the process and 0 the “time constant.’’ Many
practical processes possess this covariance function.
Example 1.29. Processes with uncorrelated increments
A process v(t), f > t), with uncorrelated increments can be defined as
follows.
1. The initial value is given by
D(tg) =O. 1-437
1.10 Vector Stochastic Processes 89
2. For any sequence of instants f,, fa, ts, and t4, with fy < t; < t, < ts < ty,
the increments v(t.) — v(t,) and v(t,) — v(t) have zero means and are un-
correlated, that is,
E{v(t,) — v(t,)} = E{v(ty) — v(ts)} = 0,
> 1-438
E{[v(t2) — v(t,)][v(t.) — v(t,)]7} = 0.
The mean of such a process is easily determined:
m(t) = Efv(t)} = Efv(t) — v(t)}
= 0, Lg. 1-439
Suppose for the moment that f, > ¢t,. Then we have for the covariance
matrix
R(t, te) = E{v(t,)v7(t)}
= E{[v(t,) — v(to)][v(tz) — v(t) + v(t.) — v(t))]7}
= E{[v(t) — v(to)][v(t,) — v(t) }*}
= Efv(t,)v*(t)}
= Qh), tk >t 2 bo 1-440
where
Q(t) = E{v(tv7(1)} 1-441
is the variance matrix of the process. Similarly,
R(t, te) = O(te) FOL fp aise dn 1-442
Clearly, a process with uncorrelated increments cannot be stationary or wide-
sense stationary, except in the trivial case in which Q(t) = 0, t > fo.
Let us now consider the variance matrix of the process. We can write for
te 2 ty S| bo:
Q(t.) = E{v(t,)v"(te)}
= E{[v(te) — v(t) + v(t) — v(t) ][v(te) — 0(ty) + v(t) — v(to)]7}
= E{[v(t,) — v(t,)][o(t2) — 0(t:)]7} + Q(t). 1-443
Obviously, Q(t) is a monotonically nondecreasing matrix function of ¢ in the
sense that
O(ts) > O(ty) Oral iy ty Jp: 1-444
Here, if A and B are two symmetric real matrices, the notation
AD>B 1-445
implies that the matrix A — Bis nonnegative-definite. Let us now assume that
90 Elements of Linear System Theory
the matrix function Q(t) is absolutely continuous, that is, we can write
Q(t) = | Vide 1-446
where V(t) is a nonnegative-definite symmetric matrix function. It then
follows from 1-443 that the variance matrix of the increment v(t.) — v(t,)
is given by
E{[v(tz) — v(t,)][v(t2) — v(t,)]7} = O(te) — Q(t)
ta -| V(r) dr. 1-447
f1
Combining 1-440 and 1-442, we see that if 1-446 holds the covariance matrix
of the process can be expressed as
min(t1,t2)
R,(t;; fs) = | V(r) dr. 1-448
0
One of the best-known processes with uncorrelated increments is the
Brownian motion process, also known as the Wiener process or the Wiener—
Lévy process. This is a process with uncorrelated increments where each of
the increments v(t,) — v(t,) is a Gaussian stochastic vector with zero mean
and variance matrix (t, — t,)J, where / is the unit matrix. A generalization of
this process is obtained when it is assumed that each increment v(t.) — v(t,)
is a Gaussian stochastic vector with zero mean and variance matrix given in
the form 1-447. Since in the Brownian motion process the increments are
uncorrelated and Gaussian, they are independent. Obviously, Brownian
motion is a Gaussian process. It is an important tool in the theory of sto-
chastic processes.
1.10.2 Power Spectral Density Matrices
For scalar wide-sense stationary stochastic processes, the power spectral
density function is defined as the Fourier transform of the covariance func-
tion. Similarly, we define for vector stochastic processes:
Definition 1.29. The power spectral density matrix X,(w) of a wide-sense
stationary vector stochastic process is defined as the Fourier transform, if it
exists, of the covariance matrix R,(t, — ty) of the process, that is,
(0). = | e7°"R (7) dr. 1-449
Note that we have allowed a slight inconsistency in the notation of the co-
variance matrix by replacing the two variables ft, and ¢, by the single variable
t, — ty. The power spectral density matrix has the following properties.
1.10 Vector Stochastic Processes 91
Theorem 1.46. Suppose that %,(w) is the spectral density matrix of a
wide-sense stationary process v(t). Then X,(w) is a complex matrix that has
the properties:
(a) X(—@)=2,7(@) for alle; 1-450
(b) %,*(@) =X,(@) foralla; 1-451
(c) X(w) > 0 for allo. 1-452
Here the asterisk denotes the complex conjugate transpose, while M > 0,
where M is a complex matrix, indicates that M is a nonnegative-definite
matrix, that is, <* Mx > 0 for all complex x.
The proofs of parts (a) and (b) follow in a straightforward manner from
the definition of &,,(w) and Theorem 1.44. In order to prove part (c), one can
extend the proof given by Davenport and Root (1958, Chapter 6) to the
vector case. The reason for the term power spectral density matrix becomes
apparent in Section 1.10.4.
Example 1.30. Exponentially correlated noise
In Example 1.28 we considered exponentially correlated noise, a scalar
wide-sense stationary process »(f) with covariance function
i
R(t, — tz) = o° exp (- ttl) 1-453
By Fourier transformation it easily follows that »(t) has the power spectral
density function
2,(@) =
20°76 paras 1-454
1S ai)
provided 6 > 0.
1.10.3 The Response of Linear Systems to Stochastic Inputs
In this section we study the statistical properties of the response of a linear
system if the input is a realization of a stochastic process. We have the follow-
ing result.
Theorem 1.47. Consider a linear system with impulse response matrix
K(t, t) which at time ty is in the zero state. Suppose that the input to the system
is a realization of a stochastic process u(t) with mean m,(t) and covariance
matrix R,,(t,, te). Then the output of the system is a realization of a stochastic
process y(t) with mean
t
m,(t) = i K(t, 7)m,(1) dr, to
1-455
92 Elements of Linear System Theory
and covariance matrix
ty te
R(t, ty) -| ar, K(t,, 7)R,(74, 72) K* (te, T2) dt», to to
1-456
provided the integrals exist.
We present a formal proof of these results. The output y, which is a sto-
chastic process, is given by
y(t) = i RG ihn 1-457
Taking the expectation of both sides of 1-457, interchanging the order of the
integration and the expectation, one obtains 1-455.
Similarly, we can write (assuming for simplicity that m,(¢) = 0)
R(ty, te) = E{y(ty)y7 (te)}
t1 te HE
= {| [Gran drs]] [KC route) ar,] |
to Leto
ty tg
= al | ar, dry K(ty, 7)u(71)U"(72)K (te, |
t t
ty ° tg '
=| ar, dry K(t,, 7:)E{u(7,)u"(12)}K7 (ty, T2)
t to
A tg
-| a, dt K(ty, 7)Ry(715 T2)K7* (to, To). to to
1-458
For a time-invariant system and a wide-sense stationary input process,
we have the following result.
Theorem 1.48. Suppose that the linear system of Theorem 1.47 is an asymptot-
ically stable time-invariant system with impulse response matrix K(t — 7),
and that the input stochastic process u(t) is wide-sense stationary with co-
variance matrix R(t; — t2). Then if the input to the system is a realization of
the process u(t), which is applied from time — 0 on, the output is a realization
of a wide-sense stationary stochastic process y(t) with covariance matrix
R(t — tz) -| ar, | dr, K(7,)R,(t, — te + T. — 71)K*7 (19). 1-459
0 0
Note that we have introduced a slight inconsistency in the notation of the
impulse response matrix K and the covariance matrix R,. It is in Section
1.3.2 that we saw that the impulse response matrix of a time-invariant system
1.10 Vector Stochastic Processes 93
depends on ¢ — 7 only. The result 1-459 can be found from 1-456 by letting
ty ~ — co and making some simple substitutions.
For wide-sense stationary processes, it is of interest to consider the power
density matrix.
Theorem 1.49. Consider an asymptotically stable time-invariant linear
system with transfer matrix H(s). Suppose that the input is a realization of a
wide-sense stationary stochastic process u(t) with power spectral density
matrix &,,(w) which is applied from time — on. Then the output is a realiza-
tion of a wide-sense stationary stochastic process y(t) with power spectral
density matrix
x,(@) = H(jow)=,(w)H* (—jo). 1-460
This result follows easily by Fourier transforming 1-459 after replacing
t; — t, with a variable 7, using the fact that H(s) is the Laplace transform
of K(r).
Example 1.31. Stirred tank
Consider the stirred tank of Example 1.2 (Section 1.2.3) and assume that
fluctuations occur in the concentrations c, and c, of the feeds. Let us therefore
write
y(t) = Cro + (2),
1-461
Co(t) = Coo + 2(t),
where C1) and Cy, are the average concentrations and »,(f)and ¥,(t) fluctuations
about the average. It is not difficult to show that the linearized system equa-
tions must be modified to the following:
— A 0) 1 1
iS 1 at) 10. Co €29 = 2 Co uli)
8 vy Me
0
(v(t)
+ 1 Frio Feo > 1-462
Wo 7 v(t)
0 0
Aa
Ome
If we take the input u(t) = 0, the transfer matrix from the disturbances
94 Elements of Linear System Theory
v(t) = col [»,(t), v2(t)] to the output variable y(t) can be found to be
0 0
Fy9/Vo Foo/ Vo ; 1-463
1 1
i a ae 8
Sa: 9
Obviously, the disturbances affect only the second component of the output
variable 7,(t) = &,(t). Let us assume that ,(t) and »,(t) are two independent
exponentially correlated noise processes, so that we can write for the co-
variance matrix of v(t)
o,2 exp (- ty 7 !) 0
Rie , _ 1-464
0 peep (- al
t, — tl
6.
With this we find for the power spectral density matrix of v(t)
20,°0 1 x 0
1+ 06,
26) = bres : 1-465
O05 9
0 . = 9
1+ oO,"
It follows from 1-460 for the power spectral density matrix of the contribu-
tion of the disturbances v(t) to the output variable y(r)
0 0
Xi (@) = Se Saal 1-466
1 1+ w°6,° 1+ w6,"
1.10.4 Quadratic Expressions
In later chapters of this book it will be convenient to use a measure for the
mean square value of a stochastic process. For vector stochastic processes
we introduce to this end quadratic expressions of the form
E{v7(t)W(t)v(t)}, 1-467
where W(t) is a symmetric weighting matrix. If v(t) = col [»,(t),- ++ , v,(t)]
1.10 Vector Stochastic Processes 95
and W has elements W,,, i, 7 = 1, 2,--+-+ ,n, 1-467 can be written as
E{v7(t)W(t)o()} = EX > > v()W,,(t)r(o}, 1-468
j=1 j=1
which is the expectation of a quadratic expression in the components »,(t)
of v(t). Usually, W(t) is chosen to be nonnegative-definite so that the ex-
pression assumes nonnegative values only.
It is helpful to develop expressions for quadratic expressions of this type in
terms of the covariance matrix and power spectral density matrix of v(t).
We have the following result.
Theorem 1.50. Let v(t) be a vector-valued stochastic process. Then if W(t)
is a symmetric matrix,
E{v7(t)W(t)v(t)} = tr [W()C,(t, 0], 1-469
where C,(t,t,) is the second-order joint moment matrix of v(t). If v(t) is
wide-sense stationary with zero mean and covariance matrix R,(t, — te),
and W is constant,
E{v7(t)Wv(t)} = tr [WR,(0)]. 1-470
If v(t) has zero mean and the power spectral density matrix &,(@),
E{vT(t)Wo(t)} = tr | WX,(@) a |, 1-471
where =
i = Olam: 1-472
Furthermore,
R,(0) = i X,(@) df. 1-473
By tr(A) we mean the trace of the matrix A, that is,
tr(A) = 2 ae, 1-474
where «,;, i= 1,°°:*,m are the diagonal elements of the matrix. The first
result of the theorem follows in an elementary manner:
E{eOW(OD} = ELE HOW (OP(O
2,j=
= > WADED»)
= > WDC akt 9)
1, 3=0
=i ([WOC Ato], 1-475
96 Elements of Linear System Theory
where C,, ,;(t, t) is the (i, j)-th element of C,(t, t). The second result, 1-470,
is immediate since under the assumptions stated C,(t, t) = R,(0). The third
result can be shown by recalling that the power spectral density matrix
Z,(@) is the Fourier transform of R,(7), and that consequently R,(7) is the
inverse transform of &,,(@):
Rr) = | X,(a)e?”" df. 1-476
For 7 = 0 we immediately obtain 1-471 and 1-473.
Equation 1-471 gives an interpretation of the term power spectral density
matrix. Apparently, the total “power” E{v"(t)Wv(t)} of a zero-mean wide-
sense stationary process v(t) is obtained by integrating tr [W2X,(w)] over all
frequencies. Thus tr [W2,,(w)] can be considered as a measure for the power
“density’’ at the frequency w. The weighting matrix W determines the con-
tributions of the various components of v(t) to the power.
Example 1.32. Stirred tank
We continue Example 1.31 where we computed the spectral density matrix
of the output y(t) due to disturbances v(t) in the concentrations of the feeds
of the stirred tank. Suppose we want to compute the mean square value of
the fluctuations 7.(t) in the concentration of the outgoing flow. This mean
square value can be written as
E{ya(t)} = Efy"()Wy()}, 1-477
where the weighting matrix W has the simple form
W = i yp 1-478
One
Thus we find for the mean square error
E{y"(t)wy(t)} = |e [WX ,(w)] df
-|" Sos [Fula (Fo/ a df
2n 2 2p 2
ot + 1+ 6, 1+ 8,
oa (Fyo/Vo)"o1"0,0° (F99/Vo)"o0"0.0" 1-479
0 + 6, 6 + 6,
Integrals of rational functions of the type appearing in 1-479 frequently occur
in the computation of quadratic expressions as considered in this section.
Tables of such integrals can be found in Newton, Gould, and Kaiser (1957,
Appendix E) and Seifert and Steeg (1960, Appendix).
1.11 Response to White Noise 97
1.11 THE RESPONSE OF LINEAR DIFFERENTIAL
SYSTEMS TO WHITE NOISE
1.11.1 White Noise
One frequently encounters in practice zero-mean scalar stochastic processes
w with the property that w(¢,) and w(¢,) are uncorrelated even for values of
|t. — t,| that are quite small, that is,
Ro test) ca for |t, —t|>e«, 1-480
where « is a “‘small’? number. The covariance function of such stochastic
processes can be idealized as follows.
Ry (te, 4) = V(h) (te ==); V(t) = 0. 1-481
Here d(¢, — t,) is a delta function and V(t) is referred to as the intensity of
the process at time f. Such processes are called white noise processes for
reasons explained later. We can of course extend the notion of a white noise
process to vector-valued processes:
Definition 1.30. Let w(t) be a zero mean vector-valued stochastic process with
covariance matrix
Ry (te, ty) = V(t,) O(ty Faun hy), 1-482
where V(t) > 0. The process w(t) is then said to be a white noise stochastic
process with intensity V(t).
In the case in which the intensity of the white noise process is constant, the
process is wide-sense stationary and we can introduce its power spectral
density matrix. Formally, taking the Fourier transform of V6(7), we see that
wide-sense stationary white noise has the power spectral density matrix
X(w) = V. 1-483
This shows that a wide-sense stationary white noise process has equal power
density at all frequencies. This is why, in analogy with light, such processes
are called white noise processes. This result also agrees with our physical
intuition. A process with little correlation between two nearby values w(t,)
and w(t.) is very irregular and thus contains power at quite high frequencies.
Unfortunately, when one computes the total power of a white noise proc-
ess using Eq. 1-470 or 1-471, one obtains an infinite value, which immediately
points out that although white noise processes may be convenient to work
with, they do not exist in the physical world. Also, from a strict mathematical
viewpoint, white noise processes are not really well-defined. As we shall see
98 Elements of Linear System Theory
in Example 1.33, white noise is the ‘derivative’? of a process with uncor-
related increments; however, such a process can be shown to have no deriva-
tive. Once the white noise has passed at least one integration, however, we
are again on a firm mathematical ground and the following integration rules,
which are needed extensively, can be proved.
Theorem 1.51. Let w(t) be a vector-valued white noise process with intensity
V(t). Also, let A,(t), Ag(t), and A(t) be given time-varying matrices. Then
(4) B| i “ACD a =: 1-484
(b) B| [| Acomen ar| “Ww Lf Asem) ar‘
es i tr [V(t)A,Z()WA,(t)] dt, 1-485
Ei
where I is the intersection of [t,, t.] and tg, ts] and W is any weighting matrix;
(c) al[ [concn at| [J Aserwe) ar| ‘|
-| A,(t)V(t)A,7(t) dt, 1-486
where I is as defined before. :
Formally, one can prove (a) by using the fact that w(t) is a zero-mean pro-
cess, while (b) can be made plausible as follows.
al[ [Acown ar| wy [Aceon a'||
Fr Alf. af dt! wi(DAr (QWA W(t | 1-487a
4 Al, af. tr [w(rwh (AWA) ar} 1-487b
-|/ anf tr [E{w(t)w"(t)}Ay7()WAt')] dt! 1-487¢
-|/ an tr [V(1)Ay"(t)WA,(t')] O(t — t') dt’ 1-487d
= [ tr [V(1)A, “(t)W A,(1)] dt. 1-487e
The transition from 1-487c to 1-487d uses 1-482, and the transition from
1-487d to 1-487e follows from the properties of the delta function. We have
1.11 Response to White Noise 99
also used the fact that tr(AB) = tr(BA) for any two matrices A and B of
compatible dimensions.
The proof of (c) is similar to that of (b).
Example 1.33. White noise as the derivative of a process with uncorrelated
increments
In Example 1.29 (Section 1.10.1) we considered processes v(t), t > to,
with uncorrelated increments, which we showed to be processes with zero
means and covariance matrices of the form
Q(t) LOR high ty,
Rit t) =| irae 1-488
O( te) LOL, ty ts 1:
Proceeding completely formally, let us show that the covariance matrix of
the derivative process
i(t) = aw) ; Liles dt
1-489
consists of a delta function. For the mean of the derivative process, we have
E{o(t)} = “ Ee} a eal Fe 1-490
For the covariance matrix of the derivative process we write, completely
formally,
R(t, te) = E{0(t,)07 (ty)}
0° 7(1,)}
Ejv(t)v- (t
myer {u(t)v" (ta)
iets), ih, to te -
efi 1-491
a ar to R,( Nez) BE 0
Now, successively carrying out the partial differentiations, we obtain
Ry(ty, te) = O(ty) O(t, — te), ty, te > to, 1-492
where
Oe a 1-493
This shows that the derivative of a process with uncorrelated increments is a
white noise process. When each increment v(t,) — v(t,) of the process has a
variance matrix that may be written in the form
te | V(t) dt, 1-494
t b1
100 Elements of Linear System Theory
the intensity of the white noise process that derives from the process with un-
correlated increments is V(t), since (see Example 1.29)
on = { VO 1-495
A special case that is of considerable interest occurs when the process v(t)
from which the white noise process derives is Brownian motion (see Example
1.29). The white noise process then obtained is often referred to as Gaussian
white noise.
In the rigorous theory of white noise, the white noise process is never
defined. Instead, the theory is developed in terms of increments of processes
with uncorrelated increments. In particular, integrals of the type appearing
in Theorem 1.51 are redefined in terms of such processes. Let us consider the
integral
tz | A(t)w(t) dt. 1-496
This is replaced with é
te n—1
i A(t) dvo(t) = lim > A(z;)[v(ti41) — v(7,)], 1-497
t1 600
where v(t) is the process with uncorrelated increments from which the white
noise process w(t) derives and where 4, = 7) < 7; < *** <7, = fa, with
€ = max |7;,, — 7;|, 1-498
is a partitioning of the interval [t,, f.]. The limit in 1-497 can be so defined
that it is a proper stochastic variable, satisfying the properties of Theorem
1.51. For detailed treatments we refer the reader to Doob (1953), Gikhman
and Skorokhod (1969), Astrém (1970), and Kushner (1971). For an extensive
and rigorous discussion of white noise, one should consult Hida (1970).
The material in this example is offered only for background. For our
purposes, in the context of linear systems, it is sufficient to have Theorem 1.51
available.
1.11.2 Linear Differential Systems Driven by White Noise
It will turn out that a linear differential system driven by white noise is a very
convenient model for formulating and solving linear control problems that
involve disturbances and noise. In this section we obtain some of the
statistical properties of the state of a linear differential system with a white
noise process as input. In particular, we compute the mean, the covari-
ance, joint moment, variance, and moment matrices of the state x.
1.11 Response to White Noise 101
Theorem 1.52. Suppose that x(t) is the solution of -
a(t) = A(t)x(t) + B(t)w(t),
1-499
«(ty) = Xo,
where w(t) is white noise with intensity V(t) and x, is a stochastic variable
independent of w(t), with mean my and Q) = E{(xy — my)(x) — my)" } as its
variance matrix. Then x(t) has mean
Hit) = OU a ites 1-500
where (ft, ty) is the transition matrix of the system 1-499. The covariance
matrix of x(t) is
Rit, tg) = DE, to) Q,O7 (ta, to)
min(t;,t2)
+] O(t,, 7)B(t)V(7)B7(r) O7 (ty, 7) dr. 1-501
t 0
The variance matrix Q(t) = R,(t, t) satisfies the matrix differential equation
O(t) = A(HQ(t) + Q(NAN(t) + BV ()B"(1), 1-502
Q(to) = Qo.
Furthermore,
Qt )O* (te, ), te Dh,
R(t, te) = 1-503
D(t,, t2)Q(te), ty > ty.
The second-order joint moment matrix of x(t) is
C,{tis te) = E{x(t,)x7(te)}
— O(t,, to) C,(to, Lye (:, to)
min(¢1,¢2)
+| t 0
O(t,, 7) B(7) V(r) BT (7)? (tp, t) dr. 1-504
The moment matrix C,(t, t) = Q'(t) satisfies the matrix differential equation
O'(t) = A(t)O'(t) + O'(t)AT(t) + B(t)V(t)B7(t), 1-505
Q' (ty) = E{ xoxo" }. 1-506
Finally,
Q'(t)O7 (te, ty), t>h, 1-507
Cutis te) =
Dt), t2)Q' (te), t, > to.
These results are easily proved by using the integration rules given in Theorem
1.51. Since
t
a(t) = OCF, 14)% +| M(t, +)B(7)w(7) dr, 1-508
102 Elements of Linear System Theory
it follows by 1-484 that m,(t) is given by 1-500. To find the covariance and
joint moment matrices, consider
E{x(t,)x7(t,)} = D(t, one atom stad to)
tg b/g
+ £10, to)e]] | (1, 7)B(r)w() ar]
ih B| | | Ot, ABET en) dn [D(t2, i) |
= z| i Ot, 7)B(r)w(r) dn | | Os 7) B(r)w(r) ar] if 1-509
Because of the independence of x) and w(t) and the fact that w(t) has zero
mean, the second and third terms of the right-hand side of 1-509 are zero.
The fourth term is simplified by applying 1-486 so that 1-509 reduces to
1-504. Similarly, 1-501 can be obtained. The variance Q(t) is obtained by
setting ¢t; = tf, = tin 1-501:
Q(t) = D(t, ty)QoP*(t, ty) + i “O(t, 7) B(r) V(r) BT (r)O7 (t,t) dr. 1-510
The differential equation 1-502 is found by differentiating Q(t) in 1-510 with
respect to ¢. The initial condition 1-502 is obtained by setting t = fy. The
differential equation for C,(t, t) = Q’(t) follows similarly. Finally, 1-503 and
1-507 follow-directly from 1-501 and 1-504, respectively.
In passing, we remark that if x) is a Gaussian stochastic variable and the
white noise w(t) is Gaussian (see Example 1.33), then x(t) is a Gaussian
stochastic process. We finally note that in the analysis of linear systems it is
often helpful to have a computer program available for the simulation of a
linear differential system driven by white noise (see, e.g., Mehra, 1969).
Example 1.34. A first-order differential system driven by white noise
Consider the first-order stochastic differential equation
Ae EO ae. 1-511
where w(t) - scalar white noise with constant intensity uw. Let us suppose
that €(0) = &, where &) is a scalar stochastic variable with mean zero and
variance £(&,") = o”. It is easily found that &(t) has the covariance function
ACN Se es
R,(ty, t:) = G "ye Cae aie leerls | er Sip, st?
1.11 Response to White Noise 103
The variance of the process is
6 6
OO = (<* — oa near’ a) 1-513
1.11.3 The Steady-State Variance Matrix for the Time-Invariant Case
In the preceding section we found an expression [Eq. 1-510] for the variance
matrix of the state of a differential linear system driven by white noise. In
this section we are interested in the asymptotic behavior of the variance
matrix in the time-invariant case, that is, when A, B, and V are constant
matrices. In this case 1-510 can be written as
t
O(t) ae eAlt—tol AN (t—t0) + | eA PBy BA de 1-514
to
It is not difficult to see that if, and only if, A is asymptotically stable, Q(t)
has the following limit for arbitrary Qo:
lim Q(t) = lim Q(t) = O =| e* BV BT eA” dr. 1-515
t> oo to+>—oo 0
Since Q(t) is the solution of the differential equation 1-502, its limit @ must
also satisfy that differential equation, so that
AO + OAT + BVBT =0. 1-516
It is quite helpful to realize that this algebraic matrix equation in Q has a
unique solution, which must then necessarily be given by 1-515. This follows
from the following result from matrix theory (Frame, 1964).
Lemma 1.5. Let M,, M,, and M, be realn X n,m X m,andn X mmatrices.
Let Aa t = 1D Wt 0nd Ji LD, Genote ihe characteristic
values of M, and Mg, respectively. Then the matrix equation
M,X + XM,7 = M, 1-517
has a unique n X m solution X if and only if for all i, j
A, + by #9. 1-518
In applying this lemma to 1-516, we ict, = 4, Mu, = A’. It follows that
m=nand wu; = A;,j = 1,2,°-+,m. Since by assumption A is asymptoti-
cally stable, all characteristic values have strictly negative real parts, and
necessarily
A, +4; 40 1-519
for all i, 7. Thus 1-516 has a unique solution.
104 Elements of Linear System Theory
We summarize as follows.
Theorem 1.53. Consider the stochastic differential equation
a(t) = Ax(t) + Bw(d), x(to) = Xo >
1-520
where A and B are constant and w(t) is white noise with constant intensity V.
Then if A is asymptotically stable and tj» —© or t-+ ©, the variance
matrix of x(t) tends to the constant nonnegative-definite matrix
O= [ e4*BV Bl et dt, 1-521
0
which is the unique solution of the matrix equation
0 = AO + OAT + BVB?. 1-522
The matrix O can thus be found as the limit of the solution of the differential
equation 1-502, with an arbitrary positive-semidefinite Q, as initial condition,
from the integral 1-521 or from the algebraic equation 1-522.
Matrix equations of the form 1-522 are also encountered in stability
theory and are sometimes known as Lyapunov equations. Although the matrix
equation 1-522 is linear in Q, its solution cannot be directly obtained by
simple matrix inversion. MacFarlane (1963) and Chen and Shieh (1968a)
give useful suggestions for setting up linear equations from which Q can be
solved. Barnett and Storey (1967), Davison and Man (1968), Smith (1968),
Jameson (1968), Rome (1969), Kleinman (1970a), Miiller (1970), Lu (1971),
and Smith (1971) give alternative approaches. Hagander (1972) has made a
comparison of various methods of solution, but his conclusions do not rec-
ommend one particular method. Also Barnett and Storey (1970) and
Rothschild and Jameson (1970) review several methods of solution,
We remark that if A is asymptotically stable and t) = — 00, the output of
the differential system 1-499 is a wide-sense stationary process. The power
spectral density of the state x is
x,(@) = (jol — A)" BVB?(—jaI — AT)". Thus using 1-473 one can obtain yet another expression for O,
1-523
O= | (joI — A) BVBT(—joI — AT) df. 1-524
The steady-state variance matrix Q has thus far been found in this section
as the asymptotic solution of the variance differential equation for ty — co
or t—» 0. Suppose now that we choose the steady-state variance matrix
1.11 Response to White Noise 105
O as the initial variance at time fy, that is, we set
Q = Q. 1-525
By 1-502 this leads to
OD =O." tei, 1-526
The process x(t) thus obtained has all the properties of a wide-sense station-
ary process.
Example 1.35. The steady-state covariance and variance functions of a
first-order system
Consider as in Example 1.34 the scalar first-order differential equation
driven by white noise,
E(t) = — uO + w(t), 1-527
where the scalar white noise w(t) has intensity ~ and 0 > 0. Denoting by O
the limit of Q(t) as t > oo, one sees from 1-513 that
gz a 1-528
The Lyapunov equation 1-522 reduces to
Pde ge
a ste ech 1-529
which agrees with 1-528. Also, 1-521 yields the same result:
= ees 6
O = nf e 9 dt = 1-530
0
Finally, one can also check that 1-524 yields:
+00 fa)
=| pe 1-531
Note that the covariance function R,(¢,, fg) given in 1-512 converges to
“wo ( ty =a ty
aad | Pa ek Ss
oe 6
1-532
as t; + ty > 00 with 4, — f, finite. R-(t,, t,) equals this limit at finite 7, and ft,
if the variance of the initial state is
c= al f 1-533
2
106 Elements of Linear System Theory
Apparently, 1-527 represents exponentially correlated noise, provided §(to)
is a zero-mean stochastic variable with variance 1-533.
1.11.4 Modeling of Stochastic Processes
In later chapters of this book we make almost exclusive use of linear differ-
ential systems driven by white noise to represent stochastic processes. This
representation of a stochastic process v(t) usually takes the following form.
Suppose that v(t) is given by
v(t) = C(t)x(t), 1-534
with
a(t) = A(t)u(t) + B(t)w(t), 1-535
where w(t) is white noise. Choosing such a representation for the stochastic
process v, we call modeling of the stochastic process v. The use of such models
can be justified as follows.
(a) Very often practical stochastic phenomena are generated by very fast
fluctuations which act upon a much slower differential system. In this case the
model of white noise acting upon a differential system is very appropriate.
A typical example of this situation is thermal noise in an electronic circuit.
(b) As we shall see, in linear control theory almost always only the mean
and covariance of the stochastic processes matter. Through the use of a linear
model, it is always possible to approximate any experimentally obtained mean
and covariance matrix arbitrarily closely.
(c) Sometimes the stochastic process to be modeled is a stationary process
with known power spectral density matrix. Again, one can always generate
a stochastic process by a linear differential equation driven by white noise
so that its power spectral density matrix approximates arbitrarily closely the
power spectral density matrix of the original stochastic process.
Examples 1.36 and 1.37, as well as Problem 1.11, illustrate the technique of
modeling.
Example 1.36. First-order differential system
Suppose that the covariance function of a stochastic scalar process », which
is known to be stationary, has been measured and turns out to be the ex-
ponential function
R,(ty, te.) = oe !t—t2l/0, 1-536
One can model this process for t > f as the state of a first-order differential
system (see Example 1.35):
hie 50 sey 1-537
1.11 Response to White Noise 107
with w(t) white noise with intensity 20?/9 and where »(t,) is a stochastic
variable with zero mean and variance o?.
Example 1.37. Stirred tank
Consider the stirred tank of Example 1.31 (Section 1.10.3) and suppose
that we wish to compute the variance matrix of the output variable y(t).
In Example 1.31 the fluctuations in the concentrations in the feeds were
assumed to be exponentially correlated noises and can thus be modeled as the
solution of a first-order system driven by white noise. We now extend the
state differential equation of the stirred tank with the models for the sto-
chastic processes 7,(t) and v,(t). Let us write
4(t) = &(¢), 1-538
where i
850) = — 5 (0) + o1(0). 1-539
1
Here ,(t) is scalar white noise with intensity 4; to make the variance of
y,(t) precisely 042, we take uw, = 20,7/0,. For »:(t) = &,(t), we use a similar
model. Thus we obtain the augmented system equation
See oi. Shy airs
20
a(t) = : j wT)
CL Oe to
6,
0 0 0 me 05
1 1 0 0
Cio — Co C20 — Co ‘nes
Fe Vo Vo u(t) + w(t), 1-540
0 0 [0
0 0 Ona
where w(t) = col [«,(f), @2(t)]. The two-dimensional white noise w(t) has
intensity
2 25?
0;
V= u 1-541
; 205"
108 Elements of Linear System Theory
Solution of 1-522 for the variance matrix Q yields, assuming that u(t) = 0
in 1-540,
0 O 0 0
= O dex Ges ea
QO= ; 1.542
0 does oy" 0
0 da O Oy
where
ee (Fy9/Vo)o1°070, (F9/Vo)"o9°0"05 1-543
* 6+ 6, (a eee
25 200
eee (F19/Vo) 0, UU, 1-544
6 ot 6,
2_2
we ae 1-545
2
The variance of 7,(t) = &,(t) is g22, which is in agreement with the result of
Example 1.32 (Section 1.10.4).
1.11.5 Quadratic Integral Expressions
Consider the linear differential system
a(t) = A(t)x(t) + B(t)w(t), 1-546
where w(t) is white noise with intensity V(t) and where the initial state x(t) is
assumed to be a stochastic variable with second-order moment matrix
Efa(t,)@" (t)} = Op: 1-547
In later chapters of this book we extensively employ quadratic integral
expressions of the form
B| } * eT(A)R(t)a(2) dt + x7(t,)P,2x(t,)}, 1-548
to
where R(t) is a symmetric nonnegative-definite weighting matrix for all
to <t< 4%, and where P, is symmetric and nonnegative-definite. In this
section formulas for such expressions are derived. These formulas of course
are also applicable to the deterministic case, where w(t) = 0, t > fo, x(t) is
a deterministic variable, and the expectation sign does not apply.
For the solution of the linear differential equation 1-546, we write
a(t) = M(t, ty)2(to) +] M(t, 7)B(r) w(t) dr, 1-549
1.11 Response to White Noise 109
so that
i ‘eM OROH dt + x? (t,)P,2(t,)
z i ; [=O ee | wh )BT NOM s ar]
- R(t) ke ty)2e(ty) + | 0, 7)B(r)w(r) ar] dt
+ [2t0Pa 0) + | wtea"aO"G,) dr|
oP [(, Cane i Ot, BCG dr. 1-550
Taking the expectation of this expression and using the integration rules of
Theorem 1.51, we obtain the result
elf et OROA dt + (1) Pratt]
=tr | | { ‘0 (t, to)R(t)@(t, to) dt + O7(t,, t))P:P(t,, 1) [0
ie i : | | V(a)BT (ny (1, z)R(t)®(t, 7)B(r) ar] dt
to
ty
+ ( V(1)B7(1)O7(t,, 7) P(t, 7)B(r) dr| 1-551
to
Now if M and WN are arbitrary matrices of compatible dimensions, it
is easily shown that tr (MN) = tr (VM). Application of this fact to the last
two terms of 1-551 and an interchange of the order of integration in the third
term yields
tr | ; | { V(r)B(r)®" (1, 7)R(O(t, 7) B(x) ar] dt
+ | : V (1) BT (r)®(t,, )P,P(t,, 7)B(7) ar|
=tr | i ’ | [ BOM BT)ON, r)R()O(t, 7) ar dt
. | “BG) V()BT (2) ©" (t,, 7)P,P(t,, 7) ar|
er | | “BG) V(1)B7(1) | i "OT (1, r)R(1)O(t, 7) dt
+ O7(t,, 7)P,P(t,, | dr| 1-552
110 Elements of Linear System Theory
Substitution of this into 1-551 shows that we can write
B| i 22 (t)R(t)2(1) dt + Mn) Pretty)
t1
= tr {PC} +] B(t)V(t)B" (t)P(t) ai), 1-553
to
where the symmetric matrix P(t) is given by
1
PC) =| "OP, DROID, 1) dr +O, NPD. 1584
t
By using Theorem 1.2 (Section 1.3.1), it is easily shown by differentiation
that P(t) satisfies the matrix differential equation
—P(t) = A7(t)P(t) + P(t)A(t) + R(2). Setting ¢ = ¢, in 1-554 yields the terminal condition
1-555
P(t) = Pe 1-556
We summarize these results as follows.
Theorem 1.54. Consider the linear differential system
z(t) = A(t)x(t) + B(t)w(t), 1-557
where w(t) is white noise with intensity V(t) and where x(ty) = %o is a stochastic
variable with E{x x)"} = Qo. Let R(t) be symmetric and nonnegative-definite
for t) <t <t, and P, constant, symmetric, and nonnegative-definite. Then
B| i "eT ()R(t)a(t) dt + Te )Pax(t)]
to
=tr [PC +] BOre@stnren ar}, 1-558
where P(t) is the symmetric nonnegative-definite matrix
P(t) = | "OU (c, )R(a)O(r, t) dr + OT (ty, 1)P,O(t,, 1). 1-559
O(t, to) is the transition matrix of the system 1-557. P(t) satisfies the matrix
differential equation
—P(t) = AT(t)P(t) + P(t)A(t) + R(t) 1-560
with the terminal condition
P(t) => Be 1-561
1.11 Response to White Noise 111
In particular, if the differential system 1-557 reduces to an autonomous differ-
ential system:
a(t) = A(t)x(t), 1-562
that is, V(t) = 0 and x(t) is deterministic, then
[= (t)R(t)x(t) dt + a7 (t,)Pya(t,) = x7 (ty)P(to)x(to). 1-563
0
We conclude this section with a discussion of the asymptotic behavior of
the matrix P(t) as the terminal time ¢, goes to infinity. We limit ourselves to
the time-invariant case where the matrices A, B, V, and R are constant, so
that 1-559 reduces to:
t
P(t) -| eA) p gAlr—t) ge = ef (4p eA. 1-564
t
If A is asymptotically stable, we obtain in the limit t, — oo:
P()> P= | et IO ReAG-Y gy. t
1-565
A change of integration variable shows that P can be written as
P =| et YReAt dt’, 1-566
0
which very clearly shows that P is a constant matrix. Since P satisfies the
matrix differential equation 1-560, we have
O= ATP + PA+R. 1-567
Since by assumption A is asymptotically stable, Lemma 1.5 (Section 1.11.3)
guarantees that this algebraic equation has a unique solution.
In the time-invariant case, it is not difficult to conjecture from 1-558 that
for t,; > ty we can approximate
B| | eRORAG) dt M(1,)Py2x(t)| ~ tr[PO, + (4, — t))BVB™P]. 1-568
This shows that as ft, — 00 the criterion 1-558 asymptotically increases with
t, at the rate tr(BVB’P).
Example 1.38. Stirred tank
Consider the stirred tank extended with the model for the disturbances of
Example 1.37. Assume that u(t) = 0 and suppose that we are interested in the
integral expression ty B| E,*(t) at 1-569
to
This integral gives an indication of the average deviation of the concentra-
tion &,(t) from zero, where the average is taken both statistically and over
112 Elements of Linear System Theory
time. This expression is of the general form 1-548 if we set
OR OR ORO
® wb @ @
Ik = ‘ Py): 1-570
OMOSO: 20
OOM ORO
Solution of the algebraic equation
0=ATP+PA+R 1-571
yields the steady-state solution
OP Op 0G
5 0 P22 P23 Pea
[P= : 1-572
0 P23 P33 Pa
0 Poa Psa Paa
where
Pp ae
22 5°
0 Fry
P23 1 a fi >
G60;
0 F 59
Das
[BN 2 ,
ec
ed Mala h
(2) % 1-573
V, 2)
P33 = >
ia
Get.
leg (i Vo 2 1 1
pc Tat las in te to, CI
Go Os GO 08
(fx : 66.
VV, 2
Pa = :
1.12 Problems 113
If we assume for V the form 1-541, as we did in Example 1.37, we find for the
rate at which the integral criterion 1-569 asymptotically increases with 1,
[see 1-568]: ‘ ?
Galen (Elen
tr (BVB"P) = ou + eve 1-574
aes ae
6 8; oop
Not unexpectedly, this is precisely the steady-state value of E{é,2(t)} com-
puted in Example 1.37.
1.12 PROBLEMS
1.1. Revolving satellite
Consider a satellite that revolves about its axis of symmetry (Fig. 1.11).
The angular position of the satellite at time ¢ is ¢(t), while the satellite has a
Fig. 1.11. A revolving satellite. axis of
P(t) symmetry
constant moment of inertia J. By means of gas jets, a variable torque u(t)
can be exerted, which is considered the input variable to the system. The
satellite experiences no friction.
(a) Choose as the components of the state the angular position ¢(t) and
the angular speed f(t). Let the output variable be 7(t) = 4(t). Show that the
state differential equation and the output equation of the system can be repre-
sented as
a(t) = nee a(t) + P L(t), ee
(t) = (1, O)x(t),
where P= LJ.
(b) Compute the transition matrix, the impulse response function, and the
step response function of the system. Sketch the impulse response and step
response functions. . .
(c) Is the system stable in the sense of Lyapunov? Is it asymptotically
stable?
(d) Determine the transfer function of the system.
114 Elements of Linear System Theory
Q
torque
L(t)
Fig. 1.12. Input torque for satellite
repositioning.
(e) Consider the problem of rotating the satellite from one position in
which it is at rest to another position, where it is at rest. In terms of the state,
this means that the system must be transferred from the state x(t) =
col (dy, 0) to the state x(t,) = col (41, 0), where ¢y and ¢, are given angles.
Suppose that two gas jets are available; they produce torques in opposite
directions such that the input variable assumes only the values —«, 0, and
+a, where « is a fixed, given number. Show that the satellite can be rotated
with an input of the form as sketched in Fig. 1.12. Calculate the switching
time t, and the terminal time ¢,. Sketch the trajectory of the state in the
state plane.
1.2. Amplidyne
An amplidyne is an electric machine used to control a large de power
through a small de voltage. Figure 1.13 gives a simplified representation
(D’Azzo and Houpis, 1966). The two armatures are rotated at a constant
speed (in fact they are combined on a single shaft). The output voltage of each
armature is proportional to the corresponding field current. Let L, and R,
denote the inductance and resistance of the first field windings and L, and R,
those of the first armature windings together with the second field windings.
Ry 14
a) 4 eo
field ormature field armature
Fig. 1.13. Schematic representation of an amplidyne.
1.12 Problems 115
The induced voltages are given by
e = ky, 1-576
ia) — Koi,.
The following numerical values are used:
Ri/L, = 10's, Roby ls,
R, = 5 Q, R, = 10Q, 1-577
k, = 20V/A, ky = SO V/A.
(a) Take as the components of the state €,(t) = i,(t) and &,(f) = i,(t) and
show that the system equations are
pet Eee neh ‘
. Ly at
=) Jot + [E Jato,
=e 0 1-578
ie in
n(t) = (0, ke)a(t),
where u(t) = e,(t) and 7(t) = e,(t).
(b) Compute the transition matrix, the impulse response function, and the
step response function of the system. Sketch for the numerical values given
the impulse and step response functions.
(c) Is the system stable in the sense of Lyapunov? Is it asymptotically
stable?
(d) Determine the transfer function of the system. For the numerical values
given, sketch a Bode plot of the frequency response function of the system.
(e) Compute the modes of the system.
1.3. Properties of time-invariant systems under state transformations
Consider the linear time-invariant system
&(t) = Ax(t) + Bu(t),
1-579
Ut) Out);
We consider the effects of the state transformation 2 = Tz.
(a) Show that the transition matrix D(t, fo) of the system 1-579 and the
transition matrix '(t,, fy) of the transformed system are related by
Q(t) =TOG7,)1 2. 1-580
(b) Show that the impulse response matrix and the step response matrix
of the system do not change under a state transformation.
116 Elements of Linear System Theory
(c) Show that the characteristic values of the system do not change under a
state transformation.
(d) Show that the transformed system is stable in the sense of Lyapunov
if and only if the original system 1-579 is stable in the sense of Lyapunov.
Similarly, prove that the transformed system is asymptotically stable if and
only if the original system 1-579 is asymptotically stable.
(e) Show that the transfer matrix of the system does not change under a
state transformation.
1.4. Stability of amplidyne with feedback
In an attempt to improve the performance of the amplidyne of Problem
1.2, the following simple proportional feedback scheme is considered.
w(t) = Aln,(t) — H(t) 1-581
Here 7,(t) is an external reference voltage and / a gain constant to be deter-
mined.
(a) Compute the transfer matrix of the amplidyne interconnected with the
feedback scheme 1-581 from the reference voltage 7,(t) to the output voltage
n(t). (b) Determine the values of the gain constant A for which the feedback
system is asymptotically stable.
1.5*. Structure of the controllable subspace
Consider the controllability canonical form of Theorem 1.26 (Section
1:6.3),
(a) Prove that no matter how the transformation matrix T is chosen the
characteristic values of Aj, and A, are always the same.
(b) Define the characteristic values of Aj, as the controllable poles and the
characteristic values of Ay. as the uncontrollable poles of the system. Prove
that the controllable subspace of the system 1-310 is spanned by the char-
acteristic vectors and generalized characteristic vectors of the system that
correspond to the controllable poles.
(c) Conclude that in the original representation 1-308 of the system
the controllable subspace is similarly spanned by the characteristic vectors
and generalized characteristic vectors corresponding to the controllable
poles.
1.6*. Controllability and stabilizability of a time-invariant system under a
State transformation
Consider the state transformation 2’ = 7x for the linear time-invariant
system . a(t) = Ax(t) + Bu(t). 1-582
* See the preface for the significance of the problems marked with an asterisk.
1.12 Problems 117
(a) Prove that the transformed system is completely controllable if and
only if the original system 1-582 is completely controllable.
(b) Prove directly (without using Theorem 1.26) that the transformed
system is stabilizable if and only if the original system 1-582 is stabilizable.
1.7*. Reconstructibility and detectability of a time-invariant system under
a state transformation
Consider the state transformation x’ = Tw for the time-invariant system
&(t) = Ax(t), y(t) = Cx(t). 1-583
(a) Prove that the transformed system is completely reconstructible if and
only if the original system 1-583 is completely reconstructible.
(b) Prove directly (without using Theorem 1.35) that the transformed
system is detectable if and only if the original system 1-583 is detectable.
1.8*. Dual of a transformed system
Consider the time-invariant system
a(t) = Ax(t) + Bu(t),
y(t) = Ca(Z).
1-584
Transform this system by defining w(t) = Tx(t) where T is a nonsingular
transformation matrix. Show that the dual of the system 1-584 is transformed
into the dual of the transformed system by the transformation x*(t) =
Te Xe),
1.9. “Damping” of stirred tank
Consider the stirred tank with fluctuations in the concentrations c, and c,
as described in Examples 1.31 and 1.32 (Sections 1.10.3 and 1.10.4). Assume
that u(t) = 0. The presence of the tank has the effect that the fluctuations in
the concentrations c, and c, are reduced. Define the “damping factor”’ of the
tank as the square root of the ratio of the mean square value of the fluctua-
tions in the concentrations c(t) of the outgoing flow and the mean square
value of the fluctuations when the incoming feeds are mixed immediately
without a tank (V, = 0). Compute the damping factor as a function of Vp.
Assume 6, = 62, 0; = 0. = 10s and use the numerical values of Example 1.2
(Section 1.2.3). Sketch a graph of the damping factor as a function of Vo.
1.10. State of system driven by Gaussian white noise as a Markov process
A stochastic process v(t) is a Markov process if
Pi{v(tn) me Vy v(t,), v(te), ey a V(tn_1)} = Pi{v(tn) < Vn | V(tn_1)} 1-585
118 Elements of Linear System Theory
forally, all 4,ts.°°:.!, WIN, 2 1 pe hae & fy, ane ally, OUOW
that the state ~(t) of the system
#(t) = A(t)e(t) + B(Aw(0), eg
x(t) = %,;
where w(t) is Gaussian white noise and x) a given stochastic variable, is a
Markov process, provided x, is independent of w(t), t > fp.
1.11. Modeling of second-order stochastic processes
Consider the system ("or () i) ea x(t) + a(t). 1-587
—Xpo — Oy 1
For convenience we have chosen the system to be in phase canonical form,
but this is not essential. Let w(t) be white noise with intensity I. The output
of the system is given by
v(t) = (71, Y2)@ (2). 1-588
(a) Show that if 1-587 is asymptotically stable the power spectral density
function of v(t) is given by
GAT eee 7 1-589
p (jo) + a(jo) + %
(b) Suppose that a stationary stochastic scalar process is given which has
one of two following types of covariance functions:
R,(r) = Bye!" | + Boe all, 1-590
or
R,(r) = Bye~70!?! cos (wot) + Bge~70!7! cos (wor), 1-591
where 7 = tf, — fg. Show that 1-587 and 1-588 can be used to model such a
process. Express the constants occurring in 1-587 and 1-588 in terms of the
constants occurring in 1-590 or 1-591. :
(c) Atmospheric turbulence manifests itself in the form of stochastically
varying air speeds. The speed fluctuations in a direction perpendicular to
the main flow can be represented as a scalar stochastic process with covari-
ance function
L
|r
R(r) = ore = F). 2
1-592
where 7 = ft, — t,. Model this process.
2 ANALYSIS OF LINEAR
CONTROL SYSTEMS
2.1 INTRODUCTION
In this introduction we give a brief description of control problems and of the
contents of this chapter.
A control system is a dynamic system which as time evolves behaves in a
certain prescribed way, generally without human interference. Control
theory deals with the analysis and synthesis of control systems.
The essential components of a control system (Fig. 2.1) are: (1) the plant,
which is the system to be controlled; (2) one or more sensors, which give
information about the plant; and (3) the controller, the “‘heart’’ of the control
system, which compares the measured values to their desired values and
adjusts the input variables to the plant.
An example of a control system is a self-regulating home heating system,
which maintains at all times a fairly constant temperature inside the home
even though the outside temperature may vary considerably. The system
operates without human intervention, except that the desired temperature
must be set. In this control system the plant is the home and the heating
equipment. The sensor generally consists of a temperature transducer inside
the home, sometimes complemented by an outside temperature transducer.
The controller is usually combined with the inside temperature sensor in the
thermostat, which switches the heating equipment on and off as necessary.
Another example of a control system is a tracking antenna, which without
human aid points at all times at a moving object, for example, a satellite.
Here the plant is the antenna and the motor that drives it. The sensor con-
sists of a potentiometer or other transducer which measures the antenna
displacement, possibly augmented with a tachometer for measuring the
angular velocity of the antenna shaft. The controller consists of electronic
equipment which supplies the appropriate input voltage to the driving motor.
Although at first glance these two control problems seem different, upon
further study they have much in common. First, in both cases the plant and
the controller are described by differential equations. Consequently, the
mathematical tool needed to analyze the behavior of the control system in
119
120 Analysis of Linear Control Systems
desired
value output
controller
sensor
Fig. 2.1. Schematic representation of a control system.
both cases consists of the collection of methods usually referred to as system
theory. Second, both control systems exhibit the feature of feedback, that is,
the actual operation of the control system is compared to the desired opera-
tion and the input to the plant is adjusted on the basis of this comparison.
Feedback has several attractive properties. Since the actual operation is
continuously compared to the desired operation, feedback control systems
are able to operate satisfactorily despite adverse conditions, such as dis-
turbances that act upon the system, or variations in plant properties. In a
home heating system, disturbances are caused by fluctuations in the outside
temperature and wind speed, and variations in plant properties may occur
because the heating equipment in parts of the home may be connected or
disconnected. In a tracking antenna disturbances in the form of wind gusts
act upon the system, and plant variations occur because of different friction
coefficients at different temperatures.
In this chapter we introduce control problems, describe possible solutions
to these problems, analyze those solutions, and present basic design objec-
tives. In the chapters that follow, we formulate control problems as mathe-
matical optimization problems and use the results to synthesize control
systems.
The basic design objectives discussed are stated mainly for time-invariant
linear control systems. Usually, they are developed in terms of frequency
domain characteristics, since in this domain the most acute insight can be
gained. We also extensively discuss the time domain description of control
systems via state equations, however, since numerical computations are
often more conveniently performed in the time domain.
This chapter is organized as follows. In Section 2.2 a general description is
given of tracking problems, regulator problems, and terminal control
problems. In Section 2.3 closed-loop controllers are introduced. In the re-
maining sections various properties of control systems are discussed, such
2.2 The Formulation of Control Problems 121
as stability, steady-state tracking properties, transient tracking properties,
effects of disturbances and observation noise, and the influence of plant
variations. Both single-input single-output and multivariable control systems
are considered.
2.2 THE FORMULATION OF CONTROL PROBLEMS
2.2.1 Introduction
In this section the following two types of control problems are introduced:
(1) tracking problems and, as special cases, regulator problems; and (2)
terminal control problems.
In later sections we give detailed descriptions of possible control schemes
and discuss at length how to analyze these schemes. In particular, the
following topics are emphasized: root mean square (rms) tracking error, rms
input, stability, transmission, transient behavior, disturbance suppression,
observation noise suppression, and plant parameter variation compensation.
2.2.2 The Formulation of Tracking and Regulator Problems
We now describe in general terms an important class of control problems—
tracking problems. Given is a system, usually called the plant, which cannot
be altered by the designer, with the following variables associated with it
(see Fig. 2.2),
disturbance voriable
We)
controlled variable z
input variable
u sensors
observed variable y
reference variable observation noise
fi ————————— Ym
Fig. 2.2. The plant.
1. An input variable u(t) which influences the plant and which can be
manipulated ;
2. A disturbance variable v,(t) which influences the plant but which cannot
be manipulated ;
122 Analysis of Linear Control Systems
3. An observed variable y(t) which is measured by means of sensors and
which is used to obtain information about the state of the plant; this observed
variable is usually contaminated with observation noise v,,(t);
4. A controlled variable z(t) which is the variable we wish to control;
5. A reference variable r(t) which represents the prescribed value of the
controlled variable z(f).
The tracking problem roughly is the following. For a given reference
variable, find an appropriate input so that the controlled variable tracks the
reference variable, that is,
2(t) = r(t), be aly: 2-1
where f, is the time at which control starts. Typically, the reference variable
is not known in advance. A practical constraint is that the range of values
over which the input u(t) is allowed to vary is limited. Increasing this range
usually involves replacement of the plant by a larger and thus more expen-
sive one. As will be seen, this constraint is of major importance and prevents
us from obtaining systems that track perfectly.
In designing tracking systems so as to satisfy the basic requirement 2-1,
the following aspects must be taken into account.
1. The disturbance influences the plant in an unpredictable way.
2. The plant parameters may not be known precisely and may vary.
3. The initial state of the plant may not be known.
4. The observed variable may not directly give information about the
state of the plant and moreover may be contaminated with observation noise.
The input to the plant is to be generated by a piece of equipment that will
be called the controller. We distinguish between two types of controllers:
open-loop and closed-loop controllers. Open-loop controllers generate u(t) on
the basis of past and present values of the reference variable only (see
Fig. 2.3), that is,
u(t) = forir(a), to = & = de t = 9. 2-2
disturbance voriable
Yp
reference input controlled
variable variable variable
controller
Fig. 2.3. An open-loop control system.
2.2 The Formulation of Control Problems 123
disturbonce variable
“A9)
controlled
reference
input
variable z
variable
variable sensors observed
controller
voriable y
observation noise
vm
Fig. 2.4. A closed-loop control system.
Closed-loop controllers take advantage of the information about the plant
that comes with the observed variable; this operation can be represented by
(see Fig. 2.4)
u(t) = feclr@), to <7 Stsy¥@),o<S7 <7), Lots. 2-3
Note that neither in 2-2 nor in 2-3 are future values of the reference variable
or the observed variable used in generating the input variable since they are
unknown. The plant and the controller will be referred to as the control
system,
Already at this stage we note that closed-loop controllers are much more
powerful than open-loop controllers. Closed-loop controllers can accumulate
information about the plant during operation and thus are able to collect
information about the initial state of the plant, reduce the effects of the dis-
turbance, and compensate for plant parameter uncertainty and variations.
Open-loop controllers obviously have no access to any information about the
plant except for what is available before control starts. The fact that open-loop
controllers are not afflicted by observation noise since they do not use the
observed variable does not make up for this.
An important class of tracking problems consists of those problems where
the reference variable is constant over long periods of time. In such cases it is
customary to refer to the reference variable as the set point of the system and
to speak of regulator problems. Here the main problem usually is to maintain
the controlled variable at the set point in spite of disturbances that act upon
the system. In this chapter tracking and regulator problems are dealt with
simultaneously.
This section is concluded with two examples.
124 Analysis of Linear Control Systems
Example 2.1. A position servo system
In this example we describe a control problem that is analyzed exten ively
later. Imagine an object moving in a plane. At the origin of the plare is a
rotating antenna which is supposed to point in the direction of the object at
all times. The antenna is driven by an electric motor. The control problem is
to command the motor such that
Cis COs Liat, 2-4
where 6(t) denotes the angular position of the antenna and 6,(t) the angular
position of the object. We assume that 6,(¢) is made available as a mechanical
angle by manually pointing binoculars in the direction of the object.
The plant consists of the antenna and the motor. The disturbance is the
torque exerted by wind on the antenna. The observed variable is the output
of a potentiometer or other transducer mounted on the shaft of the antenna,
given by
n(t) = A(t) + v(t), 2-5
where v(t) is the measurement noise. In this example the angle 4(t) is to be
controlled and therefore is the controlled variable. The reference variable is
the direction of the object 6,(¢). The input to the plant is the input voltage
to the motor ym.
A possible method of forcing the antenna to point toward the object is as
follows. Both the angle of the antenna 6(t) and the angle of the object 6,(t)
are converted to electrical variables using potentiometers or other trans-
ducers mounted on the shafts of the antenna and the binoculars. Then 6(t) is
subtracted from 0,(t); the difference is amplified and serves as the input
voltage to the motor. As a result, when 6,(t) — 0(t) is positive, a positive
input voltage is produced that makes the antenna rotate in a positive direc-
tion so that the difference between 6,(t) and 6(t) is reduced. Figure 2.5 gives
a representation of this control scheme.
This scheme obviously represents a closed-loop controller. An open-loop
controller would generate the driving voltage s(t) on the basis of the reference
angle 0,(t) alone. Intuitively, we immediately see that such a controller has
no way to compensate for external disturbances such as wind torques, or
plant parameter variations such as different friction coefficients at different
temperatures. As we shall see, the closed-loop controller does offer pro-
tection against such phenomena.
This problem is a typical tracking problem.
Example 2.2. A stirred tank regulator system
The preceding example is relatively simple since the plant has only a single
input and a single controlled variable. Multivariable control problems, where
the plant has several inputs and several controlled variables, are usually
pUuIM
dDUOgINSIp
1p)nBup
jo
aU}
JO puo
©
84}
J
uolziSOod
SJO}NIOUIG
1oa[qo
J2}]]04}U09
441P
108
ate
JOUDIS }095911}993)98
Jaiyiduio
J3}9WO0!}uUaj0d
5
puo
Jamod
Jaijdwo
0}
}ndui
3602]0A
JOJOW
juo}d
Joiow
puo
UD
DUUa
JO
Jo}nHhuo
3y}
9
uo13iSod
JOJOW
ee
JOSUSS
}O9!s}99a}09
joubis
Ja}9WO!jUajod
UOI}zOAJaSgO
asiou
“BI
‘*s"z
W
OAIOs UOTISOd
‘wia}sXs
125
f Pea}
Josuas
UOI}OJ}UBIUOD
‘wi9}SA$ JOIJUOD YUL}-porIys OUT, *9°T “BI
Ja}]041}U09
uo!}DJ}JUaDUOD
JO4
aoUuaJa jal
JOSU9S
WO9I YS MO) 4
Huro6jno
M015
JO4
gIUIIIIJ—4
c l
BAJDA BA]OA
pa | | paay
Z l
KJ 1070n 390 J0}0N}20 TF
BA|DA QAJOA | BA]DA
Z AOA
Hu130n}90 joubIs
Hulj}0n}90 jouBbis
126
2.2 The Formulation of Control Problems 127
much more difficult to deal with. As an example of a multivariable problem,
we consider the stirred tank of Example 1.2 (Section 1.2.3). The tank has two
feeds; their flows can be adjusted by valves. The concentration of the material
dissolved in each of the feeds is fixed and cannot be manipulated. The tank
has one outlet and the control problem is to design equipment that auto-
matically adjusts the feed valves so as to maintain both the outgoing flow and
the concentration of the outgoing stream constant at given reference values
(see Fig. 2.6).
This is a typical regulator problem. The components of the input variable
are the flows of the incoming feeds. The components of the controlled
variable are the outgoing flow and the concentration of the outgoing stream.
The set point also has two components: the desired outgoing flow and the
desired outgoing concentration. The following disturbances may occur:
fluctuations in the incoming concentrations, fluctuations in the incoming
flows resulting from pressure fluctuations before the valves, loss of fluid
because of leaks and evaporation, and so on. In order to control the system
well, both the outgoing flow and concentration should be measured; these
then are the components of the observed variable. A closed-loop controller
uses these measurements as well as the set points to produce a pneumatic
or electric signal which adjusts the valves.
2.2.3 The Formulation of Terminal Control Problems
The framework of terminal control problems is similar to that of tracking
and regulator problems, but a somewhat different goal is set. Given is a
plant with input variable w, disturbance variable v,, observed variable y,
and controlled variable z, as in the preceding section. Then a typical terminal
control problem is roughly the following. Find u(t), tf) << t<t, so that
z(t,) ~ r, where r is a given vector and where the terminal time ft, may or
may not be specified. A practical restriction is that the range of possible
input amplitudes is limited. The input is to be produced by a controller, which
again can be of the closed-loop or the open-loop type.
In this book we do not elaborate on these problems, and we confine
ourselves to giving the following example.
Example 2.3. Position control as a terminal control problem
Consider the antenna positioning problem of Example 2.1. Suppose that
at a certain time f, the antenna is at rest at an angle 6). Then the problem of
repositioning the antenna at an angle 0,, where it is to be at rest, in as short
a time as possible without overloading the motor is an example of a terminal
control problem.
128 Analysis of Linear Control Systems
2.3 CLOSED-LOOP CONTROLLERS; THE BASIC
DESIGN OBJECTIVE
In this section we present detailed descriptions of the plant and of closed-loop
controllers. These descriptions constitute the framework for the discussion
of the remainder of this chapter. Furthermore, we define the mean square
tracking error and the mean square input and show how these quantities can
be computed.
Throughout this chapter and, indeed, throughout most of this book, it
is assumed that the plant can be described as a linear differential system
with some of its inputs stochastic processes. The state differential equation of
the system is &(t) = A(t)x(t) + B(t)u(t) + v, (0),
LE ae: 2-6
Here a(t) is the state of the plant and u(t) the input variable. The initial state
2% is a stochastic variable, and the disturbance variable v,(t) is assumed to be
a stochastic process. The observed variable y(t) is given by
y(t) = C(t)x(t) + Um(t), where the observation noise v,,(t) is also assumed to be a stochastic process.
The controlled variable is 2(t) = D(t)x(t). 2-7
ES
Finally, the reference variable r(t) is assumed to be a stochastic process of the
same dimension as the controlled variable z(r).
The general closed-loop controller will also be taken to be a linear differen-
tial system, with the reference variable r(t) and the observed variable y(t) as
inputs, and the plant input u(t) as output. The state differential equation of
the closed-loop controller will have the form
q(t) = LOq) + K,.Or(t) — Kyo),
q(to) SS Jo> id
while the output equation of the controller is of the form
u(t) = F(t)q(t) + A(t)r(t) — Ay (ty(t). 2-10
Here the index r refers to the reference variable and the index f to feedback.
The quantity q(t) is the state of the controller. The initial state gy is either a
given vector or a stochastic variable. Figure 2.7 clarifies the interconnection
of plant and controller, which is referred to as the control system. If K,(t) =
0 and H,(t) = 0, the closed-loop controller reduces to an open-loop con-
troller (see Fig. 2.8). We refer to a control system with a closed-loop
129
49]}04}U09 doo}-pasojo
‘Sy
*z°z
wy
[o.1.U09 dooj-pasop
"ua}sKs
|
juojd
juo}d
Ja}joJjU09 doo)-uado
|
|
|
|
|
|
|
|
|
|
|
‘wia}sks josyuos dooj-uedo uy °8°Z “Shy
130
2.3 Closed-Loop Controllers 131
controller as a closed-loop control system, and to a control system with an
open-loop controller as an open-loop control system.
We now define two measures of control system performance that will
serve as our main tools in eyaluating how well a control system performs its
task:
Definition 2.1. The mean square tracking error C,(t) and the mean square
input C,,(t) are defined as:
Ch) Ser Owoeo}. tS %, 2-11
Ci(t) = Ef{u*()W,()u(t)}, t > to.
Here the tracking error e(t) is given by
e(t) = 2(t) — r(t), Oa he 2-12
and W(t) and W,(t), t >t), are given nonnegative-definite symmetric
weighting matrices.
When W,(t) is diagonal, as it usually is, C,(t) is the weighted sum of the
mean square tracking errors of each of the components of the controlled
variable. When the error e(t) is a scalar variable, and W, = 1, then C0)
is the rms tracking error. Similarly, when the input u(t) is scalar, and W, =1,
then -alean (3) is the rms input.
Our aim in designing a control system is to reduce the mean square tracking
error C,(t) as much as possible. Decreasing C,(t) usually implies increasing
the mean square input C,(t). Since the maximally permissible value of the
mean square input is determined by the capacity of the plant, a compromise
must be found between the requirement of a small mean square tracking
error and the need to keep the mean square input down to a reasonable
level. We are thus led to the following statement.
Basic Design Objective. Jn the design of control systems, the lowest possible
mean square tracking error should be achieved without letting the mean square
input exceed its maximally permissible value.
In later sections we derive from the basic design objective more specific
design rules, in particular for time-invariant control systems.
We now describe how the mean square tracking error C,(t) and the mean
square input C,,(t) can be computed. First, we use the state augmentation
technique of Section !.5.4 to obtain the state differential equation of the
132 Analysis of Linear Control Systems
control system. Combining the various state and output equations we find
kal a bee — B(t)H,(t)C(t) | (""
q(t) —K,O)CO L(t) / \q(), 553
B(t)H, (t) I —B(t)H,(t)\ (v(t) ‘
+ n0 PO* lo eo Devo) K,(t) 0 —K,(®) Um(t)
For the tracking error and the input we write
e(t) = [D(0, 0} ie =r
ty Ngo) 2-14
(t)
u(t) = [—H,(t)C(), roi | + H,(t)r(t) — Hy(t)n(t).
The computation of C,(t) and C,(t) is performed in two stages. First, we
determine the mean or deterministic part of e(t) and u(t), denoted by
a(t) = Efe(t)}, a(t) = Efu()},_ st > tp. 2-15
These means are computed by using the augmented state equation 2-13 and
the output relations 2-14 where the stochastic processes r(t), v,(t), and
V,,(t) are replaced with their means, and the initial state is taken as the mean
of col [a(to), q(to)].
Next we denote by %(t), g(t), and so on, the variables 2(t), q(t), and so on,
with their means %(t), g(t), and so on, subtracted:
BCE y=) CE) anh) q(t) = q(t) — q(t), and so on, t> tt. 2-16
With this notation we write for the mean square tracking error and the
mean square input
C(t) = Efe™(t)W,(te(t)} = e*(w(net) + E{e"()W,(e(n},
2-17C,(t) = EfuT()W,()u(t)} = a (QW, (Hat) + Efa7 (QW, (Han.
The terms E{é"(t)W,(t)é(t)} and E{a" (t)W,,(t)a(t)} can easily be found when
the variance matrix of col [%(¢), g(t)] is known. In order to determine this
variance matrix, we must model the zero mean parts of r(t), v,(t), and
V,,(t) as Output variables of linear differential systems driven by white noise
(see Section 1.11.4). Then col [%(t), G(t)] is augmented with the state of the
models generating the various stochastic processes, and the variance matrix
of the resulting augmented state can be computed using the differential
equation for the variance matrix of Section 1.11.2. The entire procedure is
illustrated in the examples.
2.3 Closed-Loop Controllers 133
Example 2.4. The position servo with three different controllers
We continue Example 2.1 (Section 2.2.2). The motion of the antenna can
be described by the differential equation
J6(t) + BO(t) = r(t) + 7,(t). 2-18
Here J is the moment of inertia of all the rotating parts, including the antenna.
Furthermore, B is the coefficient of viscous friction, 7(t) is the torque applied
by the motor, and 7,(t) is the disturbing torque caused by the wind. The
motor torque is assumed to be proportional to u(t), the input voltage to the
motor, so that
T(t) = ku(t).
Defining the state variables &,(t) = 0(t) and &,(t) = 6(t), the state differential
equation of the system is
Or 4 0 0
#(1) = w(t) +{ Ju(t)+{ }r(0), 2-19
ae K y
where
B k 1
H(t) = col |e.(0), cat), l= 5 : a a y= re 2-20
The controlled variable ¢(t) is the angular position of the antenna:
C(t) = G1, 0a): 2-21
When appropriate, the following numerical values are used:
= 465.
k = 0.787 rad/(V s*), J = 10 kg m’.
2-22
Design I. Position feedback via a zero-order controller
In a first attempt to design a control system, we consider the control
scheme outlined in Example 2.1. The only variable measured is the angular
position 6(¢), so that we write for the observed variable
n(t) = (1, O)x(t) + (2), 2-23
where »(t) is the measurement noise. The controller proposed can be de-
scribed by the relation
w(t) = A[8,(t) — n(@)], 2-24
where 6,(t) is the reference angle and / a gain constant. Figure 2.9 gives a
simplified block diagram of the control scheme. Here it is seen how an input
voltage to the motor is generated that is proportional to the difference
between the reference angle 0,(t) and the observed angular position 7(t).
134 Analysis of Linear Control Systems
disturbing torque
reference
driving
voltage
observation
noise
Vv
observed
voriable
q
Fig. 2.9. Simplified block diagram of a position feedback control system via a zero-order
controller.
The signs are so chosen that a positive value of 6,(t) — (t) results in a
positive torque upon the shaft of the antenna. The question what to choose for
A is left open for the time being; we return to it in the examples of later
sections.
The state differential equation of the closed-loop system is obtained from
2-19, 2-23, and 2-24:
Oe Arm Camry XC ele Cate yO: 6 T
om (2 “)x0+ (Joos (peo ( ho a
We note that the controller 2-24 does not increase the dimension of the
closed-loop system as compared to the plant, since it does not contain any
dynamics. We refer to controllers of this type as zero-order controllers.
In later examples it is seen how the mean square tracking error and the
mean square input can be computed when specific models are assumed for
the stochastic processes 6,(t), Ta(t), and »(t) entering into the closed-loop
system equation.
Design If. Position and velocity feedback via a zero-order controller
As we shall see in considerable detail in later chapters, the more informa-
tion the control system has about the state of the system the better it can be
made to perform. Let us therefore introduce, in addition to the potentiometer
that measures the angular position, a tachometer, mounted on the shaft of
the antenna, which measures the angular velocity. Thus we observe the
complete state, although contaminated with observation noise, of course.
We write for the observed variable
ro y(t) = ee 2-26
2.3 Closed-Loop Controllers 135
disturbing torque
reference driving
ongle + + voltage
6,
ongulor position
tachometer
+ F observation
=< noise
v1 (t)
observation noise
Vo (t)
y(t)
gain
Fig. 2.10. Simplified block diagram of a position and velocity feedback control system via
a zero-order controller.
where y(t) = col [7,(t), 42(t)] and where v(t) = col [»,(t), »2(t)] is the
observation noise.
We now suggest the following simple control scheme (see Fig. 2.10):
M(t) = A[6,) — mi) — Apre(t). 2-27
This time the motor receives as input a voltage that is not only proportional
to the tracking error 0,(t) — @(t) but which also contains a contribution pro-
portional to the angular velocity 6(t). This serves the following purpose.
Let us assume that at a given instant 0,(t) — 6(t) is positive, and that 6(f) is
positive and large. This means that the antenna moves in the right direction
but with great speed. Therefore it is probably advisable not to continue
driving the antenna but to start decelerating and thus avoid “‘overshooting”’
the desired position. When p is correctly chosen, the scheme 2-27 can
accomplish this, in contrast to the scheme 2-24. We see later that the present
scheme can achieve much better performance than that of Design I.
Design HI. Position feedback via a first-order controller
In this design approach it is assumed, as in Design I, that only the angular
position 9(t) is measured. If the observation did not contain any noise, we
could use a differentiator to obtain 6(t) from 6(¢) and continue as in Design
II. Since observation noise is always present, however, we cannot differen-
tiate since this greatly increases the noise level. We therefore attempt to
use an approximate differentiator (see Fig. 2.11), which has the property of
“filtering”? the noise to some extent. Such an approximate differentiator can
be realized as a system with transfer function
ee Ea 2-28
T,s + 1
136 Analysis of Linear Control Systems
disturbing torque
Tq
ceference
angle +
driving ;
voltage movon ongulor position
H 8
Or observation
noise
v(t)
opproximote
ongulor velocity
opproximote
differentiotor
observed
vorioble
H(t)
Fig. 2.11. Simplified block diagram of a position feedback control system using a first-order
controller.
where 7,, is a (small) positive time constant. The larger 7, is the less accurate
the differentiator is, but the less the noise is amplified.
The input to the plant can now be represented as
w(t) = 2{0,(t) — n(t)] — 2p8(t), 2-29
where 7(t) is the observed angular position as in 2-23 and where 0(f) is the
“approximate derivative,”’ that is, 0(t) satisfies the differential equation
T,0(t) + O(t) = 7(t). 2-30
This time the controller is dynamic, of order one. Again, we defer to later
sections the detailed analysis of the performance of this control system;
this leads to a proper choice of the time constant 7, and the gains / and p.
As we shall see, the performance of this design is in between those of Design
I and Design II; better performance can be achieved than with Design I,
although not as good as with Design II.
2.4 THE STABILITY OF CONTROL SYSTEMS
In the preceding section we introduced the control system performance
measures C,(t) and C,,(t). Since generally we expect that the control system
will operate over long periods of time, the least we require is that both
C,(t) and C,,(t) remain bounded as ¢ increases. This leads us directly to an
investigation of the stability of the control system.
If the control system is not stable, sooner or later some variables will
start to grow indefinitely, which is of course unacceptable in any control
system that operates for some length of time (i.e., during a period larger
than the time constant of the growing exponential). If the control system is
2.4 The Stability of Control Systems 137
unstable, usually C,(¢) or C,,(t), or both, will also grow indefinitely. We thus
arrive at the following design objective.
Design Objective 2.1. The control system should be asymptotically stable.
Under the assumption that the control system is time-invariant, Design
Objective 2.1 is equivalent to the requirement that all characteristic values of
the augmented system 2-13, that is, the characteristic values of the matrix
A—BH,C BF
=).0( copay 6 2-31
have strictly negative real parts. By referring back to Section 1.5.4, Theorem
1.21, the characteristic polynomial of 2-31 can be written as
det (sJ — A) det (sJ — L) det [J + H(s)G(s)], 2-32
where we have denoted by
H(s) = C(sI — A)“*B 2-33
the transfer matrix of the plant from the input u to be the observed variable
y, and by
G(S) = Fst — 1) *K, +H, 2-34
the transfer matrix of the controller from y to —u.
One of the functions of the controller is to move the poles of the plant
to better locations in the left-hand complex plane so as to achieve an im-
proved system performance. If the plant by itself is unstable, stabilizing the
system by moving the closed-loop poles to proper locations in the left-half
complex plane is the main function of the controller (see Example 2.6).
Example 2.5. Position servo
Let us analyze the stability of the zero-order position feedback control
system proposed for the antenna drive system of Example 2.4, Design I.
The plant transfer function (the transfer function from the driving voltage
to the antenna position) is given by
K
AGCh= : 2-35
s(s + «)
The controller transfer function is
GAS) i==eA0 2-36
Thus by 2-32 the closed-loop poles are the roots of
1+ weir = s? + as + KA. ie | s(s + «)
2-37
138 Analysis of Linear Control Systems
Fig. 2.12. Root loci for position servo. Solid lines, loci for second-order system; dashed
lines, modifications of loci due to the presence of the pole at —10s7?.
Figure 2.12 shows the loci of the closed-loop poles with 4 as a parameter for
the numerical values 2-22. :
It is seen that ideally the control system is stable for all positive values of
A. In practice, however, the system becomes unstable for large 2. The reason
is that, among other things, we have neglected the electrical time constant
T, of the motor. Taking this into account, the transfer function of motor
plus antenna is
H(s) = —————_. 2-38
s(s + «)(sT, + 1)
As a result, the closed-loop characteristic polynomial is
it ool A
s(s + 2(5 “a <) HS T; T,
Figure 2.12 shows the modification of the root loci that results for
2-39
T, = 0.1 s. 2-40
For A > 4d,,, where a 1
hn = “(a + “) ; 2-41
K ti é
the closed-loop system is unstable. In the present case /,, = 85.3 V/rad.
2.4 The Stability of Control Systems 139
Example 2.6. The stabilization of the inverted pendulum
As an example of an unstable plant, we consider the inverted pendulum of
Example 1.1 (Section 1.2.3). In Example 1.16 (Section 1.5.4), we saw that by
feeding back the angle ¢(¢) via a zero-order controller of the form
w(t) = Ad(t) 2-42
it is not possible to stabilize the system for any value of the gain 2. It is
possible, however, to stabilize the system by feeding back the complete
state x(t) as follows
w(t) = —kex(t). 2-43
Here k is a constant row vector to be determined. We note that implementa-
tion of this controller requires measurement of all four state variables.
In Example 1.1 we gave the linearized state differential equation of the
system, which is of the form
#(t) = Ax(t) + bu(t), where b is a column vector. Substitution of 2-43 yields
at) == Aah) —= bKe) 2-44
2-45
or
&(t) = (A — bk)x(t). 2-46
The stability of this system is determined by the characteristic values of the
matrix A — bk. In Chapter 3 we discuss methods for determining optimal
controllers of the form 2-43 that stabilize the system. By using those methods,
and using the numerical values of Example 1.1, it can be found, for example,
that k = (86.81, 12.21, —118.4, —33.44) 2-47
stabilizes the linearized system. With this value for k, the closed-loop
characteristic values are —4.706 + j1.382 and —1.902 + /3.420.
To determine the stability of the actual (nonlinear) closed-loop system, we
consider the nonlinear state differential equation
E(t) = &(2),
: il F
&(t) = cle = M E(t),
(0) = (0), a
zim esa (2 sa)
: e = zd eel 0),
M Li
140 Analysis of Linear Control Systems
where the definitions of the components £,, &, &3, and &, are the same as
for the linearized equations. Substitution of the expression 2-43 for H(t) into
2-48 yields the closed-loop state differential equation. Figure 2.13 gives the
closed-loop response of the angle ¢(¢) for different initial values (0) while
all other initial conditions are zero. For ¢(0) = 10° the motion is indistin-
guishable from the motion that would be found for the linearized system.
For (0) = 20° some deviations occur, while for (0) = 30° the system is no
longer stabilized by 2-47.
| 0
(degrees)
-40
Fig. 2.13. The behavior of the angle ¢(t) for the stabilized inverted pendulum: (a) ¢(0) =
10°; (6) $(0) = 20°; (c) (0) = 30°.
This example also illustrates Theorem 1.16 (Section 1.4.4), where it is
stated that when a linearized system is asymptotically stable the nonlinear
system from which it is derived is also asymptotically stable. We see that in
the present case the range over which linearization gives useful results is
quite large.
2.5 THE STEADY-STATE ANALYSIS OF THE
TRACKING PROPERTIES
2.5.1 The Steady-State Mean Square Tracking Error and Input
In Section 2.3 we introduced the mean square tracking error C, and the mean
square input C,,. From the control system equations 2-13 and 2-14, it can be
seen that all three processes r(t), v,(t), and v,,(t), that is, the reference
2.5 Steady-State Tracking Properties 141
variable, the disturbance variable, and the observation noise, have an effect
on C, and C,. From now until the end of the chapter, we assume that r(t),
v,(t), and v,,(t) are statistically uncorrelated stochastic processes so that their
contributions to C, and C,, can be investigated separately. In the present
and the following section, we consider the contribution of the reference
variable r(t) to C,(t) and C,(t) alone. The effect of the disturbance and the
observation noise are investigated in later sections.
We divide the duration of a control process into two periods: the transient
and the steady-state period. These two periods can be characterized as
follows. The transient period starts at the beginning of the process and ter-
minates when the quantities we are interested in (usually the mean square
tracking error and input) approximately reach their steady-state values. From
that time on we say that the process is in its steady-state period. We assume,
of course, that the quantities of interest converge to a certain limit as time
increases. The duration of the transient period will be referred to as the
settling time.
In the design of control systems, we must take into account the perfor-
mance of the system during both the transient period and the steady-state
period. The present section is devoted to the analysis of the steady-state
properties of tracking systems. In the next section the transient analysis is
discussed. In this section and the next, the following assumptions are made.
1. Design Objective 2.1 is satisfied, that is, the control system is asymp-
totically stable,
2. The control system is time-invariant and the weighting matrices W, and
W,, are constant;
3. The disturbance v,(t) and the observation noise v,,(t) are identical to zero;
4. The reference variable r(t) can be represented as
rt) =ro + 1,1), 2-49
where ry is a stochastic vector and r,(t) is a zero-mean wide-sense stationary
vector stochastic process, uncorrelated with ry.
Here the stochastic vector rg is the constant part of the reference variable
and is in fact the set point for the controlled variable. The zero-mean process
r,(t) is the variable part of the reference variable. We assume that the second-
order moment matrix of ry is given by
Elrora 3 — Re. 2-50
while the variable part r,(t) will be assumed to have the power spectral
density matrix &,(@).
Under the assumptions stated the mean square tracking error and the
mean square input converge to constant values as ¢ increases. We thus define
142 Analysis of Linear Control Systems
the steady-state mean square tracking error
C,~ = lim C2), 2-51
t> 0
and the steady-state mean square input
Cus = lim C,(1). 2-52
t7 0
In order to compute C,,, and C,,,,, let us denote by 7(s) the transmission of
the closed-loop control system, that is, the transfer matrix from the reference
variable r to the controlled variable z. We furthermore denote by N(s) the
transfer matrix of the closed-loop system from the reference variable r to
the input variable uw.
In order to derive expressions for the steady-state mean square tracking
error and input, we consider the contributions of the constant part ry and
the variable part r,(t) of the reference variable separately. The constant part
of the reference variable yields a steady-state response of the controlled
variable and input as follows
lim 2(t) = T(0)ro 2-53
t> 0
and
lim u(t) = N(0)ro, 2-54
t— 0
respectively. The-corresponding contributions to the steady-state square
tracking error and input are
[T(O)ro — rol” W.[TO)ro — ro] = tr {ror [T(O) — I]*W,[T(0) — I]} 2-55
and
[N(O)ro]” WuLN(O)ro] = tr [roro” N7(0)W.N(O)]. 2-56
It follows that the contributions of the constant part of the reference variable
to the steady-state mean square tracking error and input, respectively, are
tr {Ro[T(O) — I]7 W,[T(O) — 1] and = tr [R)N7(0)W,,N(O)]. —-2-57
The contributions of the variable part of the reference variable to the steady-
state mean square tracking error and input are easily found by using the
results of Section 1.10.4 and Section 1.10.3. The steady-state mean square
tracking error turns out to be
Ca = tt [RelT) ~ 1 W{T(0) — 1)
+ kk "Eo [T(—jo) — NT W,ITGe)y — 1 af\, 2-58
2.5 Steady-State Tracking Properties 143
while the steady-state mean square input is
co.)
Cue = tt l,N7(0)W,,N(0) + | L,(w)N7(—jo)W,N(jo) af 2-59
\ :
These formulas are the starting point for deriving specific design objectives.
In the next subsection we confine ourselves to the single-input single-output
case, where both the input u and the controlled variable z are scalar and
where the interpretation of the formulas 2-58 and 2-59 is straightforward. In
Section 2.5.3 we turn to the more general multiinput multioutput case.
In conclusion we obtain expressions for 7(s) and N(s) in terms of the
various transfer matrices of the plant and the controller. Let us denote the
transfer matrix of the plant 2-6-2-8 (now assumed to be time-invariant)
from the input u to the controlled variable z by K(s) and that from the input
u to the observed variable y by H(s). Also, let us denote the transfer matrix
of the controller 2-9, 2-10 (also time-invariant) from the reference variable
r to u by P(s), and from the plant observed variable y to —u by G(s). Thus
we have:
K(s) = D(sI — A)B, H(s) = C(sI — AB, Pg) = Fl —"L) +k a. G(s) = F(sl — L)*K, + H,.
2-60
The block diagram of Fig. 2.14 gives the relations between the several system
variables in terms of transfer matrices. From this diagram we see that, if
closed-loop controller
Fig. 2.14. The transfer matrix block diagram of a linear time-invariant closed-loop control
system.
144 Analysis of Linear Control Systems
r(t) has a Laplace transform R(s), in terms of Laplace transforms the several
variables are related by
U(s) = P(s)R(s) — G(s)¥(s),
VG) = AG)UG); 2-61
Z(s) = K(s)U(s).
Elimination of the appropriate variables yields
Z(s) = T(s)R(s), 2-62
U(s) = N(s)R(S),
where
T(s) = K(s)[I + G(s)H(s)}>P(s), N(s) = U + G(s)H(s)}*P(s).
T(s) and N(s) are of course related by
5-63
TG) = KG)N(Gs). 2-64
2.5.2 The Single-Input Single-Output Case
In this section it is assumed that both the input u and the controlled variable
z, and therefore also the reference variable r, are scalar variables. Without
loss of generality we take both W, = 1 and W,, = 1. Asa result, the steady-
state mean square tracking error and the steady-state mean square input can
be expressed as
C.. = RF, \TO)—1/ +| x,(w) |T(jw) — 1]? df, 2-65a
Cie R, |N(O)? + | ¥,(w) |N(jo) |? df. 2-65b
From the first of these expressions, we see that since we wish to design
tracking systems with a small steady-state mean square tracking error the
following advice must be given.
Design Objective 2.2. Jn order to obtain a small steady-state mean square
tracking error, the transmission T(s) of a time-invariant linear control system
should be designed such that
x ,(w) |Tjw) — 1]? 2-66
is small for all real w. In particular, when nonzero set points are likely to occur,
T(0) should be made close to |.
The remark about 7(0) can be clarified as follows. In certain applications
it is important that the set point of the control system be maintained very
accurately. In particular, this is the case in regulator problems, where the
2.5 Steady-State Tracking Properties 145
variable part of the reference variable is altogether absent. In such a case
it may be necessary that 7(0) very precisely equal 1.
We now examine the contributions to the integral in 2-65a from various
frequency regions. Typically, as @ increases, &,(@) decreases to zero. It
thus follows from 2-65a that it is sufficient to make |7(jw) — 1| small for
those frequencies where &,(m) assumes significant values.
In order to emphasize these remarks, we introduce two notions: the
frequency band of the control system and the frequency band of the reference
variable. The frequency band of the control system is roughly the range of
frequencies over which 7( ja) is “‘close”’ to 1:
Definition 2.2. Let T(s) be the scalar transmission of an asymptotically stable
time-invariant linear control system with scalar input and scalar controlled
variable. Then the frequency band of the control system is defined as the set
of frequencies w, w > 0, for which
ITG@) = 1 <<, 2-67
where e is a given number that is small with respect to |. If the frequency band
is an interval [w,, W2], we call w. — w, the bandwidth of the control system. If
the frequency band is an interval [0, w,], we refer to w, as the cutoff frequency
of the system.
Figure 2.15 illustrates the notions of frequency band, bandwidth, and cutoff
frequency.
|T(jw)-1|
We 0 ae
cut-off frequenc
frequency band q i
i bandwidth of =
the control system
Fig. 2.15. Illustration of the definition of the frequency band, bandwidth, and cutoff
frequency of a single-input single-output time-invariant control system. It is assumed that
T(jo) > 0as@— o.
146 Analysis of Linear Control Systems
In this book we usually deal with /ow-pass transmissions where the fre-
quency band is the interval from the zero frequency to the cutoff frequency
w,. The precise value of the cutoff frequency is of course very much dependent
upon the number e. When « = 0.01, we refer to w, as the 1 % cutoff frequency.
We use a similar terminology for different values of e. Frequently, however,
we find it convenient to speak of the break frequency of the control system,
which we define as that corner frequency where the asymptotic Bode plot of
|T(jw)| breaks away from unity. Thus the break frequency of the first-order
transmission
T(s) = 2-68
oO =
is «, while the break frequency of the second-order transmission
Wy
T(s) = 2-69
cus Laos + we?
is Wo. Note, however, that in both cases the cutoff frequency is considerably
smaller than the break frequency, dependent upon «, and, in the second-order
case, dependent upon the relative damping ¢. Table 2.1 lists the 1% and
10% cut-off frequencies for various cases.
Table 2.1 Relation between Break Frequency and Cutoff Frequency for First- and
Second-Order Scalar Transmissions
Second-order system
with break frequency
First-order system
with break frequency « C= 1084 E— On ele)
1% cutoff freq. 0.01« 0.012a, 0.0071 a, 0.0033 a5
10% cutoff freq. O.1a 0.12 0.07 1a, 0.03309
Next we define the frequency band of the reference variable, which is
the range of frequencies over which &,(q) is significantly different from zero:
Definition 2.3. Let r be a scalar wide-sense stationary stochastic process with
power spectral density function X,(@). The frequency band Q of r(t) is defined
as the set of frequencies w, w > 0, for which
2, (CD) Oe 2-70
2.5 Steady-State Tracking Properties 147
Here « is so chosen that the frequency band contains a given fraction | — ¢€
where e is small with respect to 1, of half of the power of the process, that is
[ 240) df = (l=) | _ 2A) df. 2-71
If the frequency band is an interval [w,, 2], we define w, — w, as the band-
width of the process. If the frequency band is an interval [0, w,], we refer to w,
as the cutoff frequency of the process.
Figure 2.16 illustrates the notions of frequency band, bandwidth, and cutoff
frequency of a stochastic process.
E(w)
We WY
= at be
eutane abond cut-off frequency
bandwidth of the
stochastic process
Fig. 2.16. Illustration of the definition of the frequency band, bandwidth, and cutoff
frequency of a scalar stochastic process r.
Usually we deal with low-pass-type stochastic processes that have an
interval of the form [0, w,] as a frequency band. The precise value of the
cutoff frequency is of course very much dependent upon the value of «.
When « = 0.01, we speak of the 1% cutoff frequency, which means that the
interval [0, w,] contains 99% of half the power of the process. A similar
terminology is used for other values of e. Often, however, we find it convenient
to speak of the break frequency of the process, which we define as the corner
frequency where the asymptotic Bode plot of &,(w) breaks away from its
low-frequency asymptote, that is, from %,(0). Let us take as an example
exponentially correlated noise with rms value o and time constant 6. This
148 Analysis of Linear Control Systems
process has the power spectral density function
20°60
2-72
foo
so that its break frequency is 1/0. Since this power spectral density function
decreases very slowly with w, the 1 and 10% cutoff frequencies are much
larger than 1/0; in fact, they are 63.66/6 and 6.314/6, respectively. |
Let us now reconsider the integral in 2-65a. Using the notions just intro-
duced, we see that the main contribution to this integral comes from those
frequencies which are in the frequency band of the reference variable but
not in the frequency band of the system (see Fig. 2.17). We thus rephrase
Design Objective 2.2 as follows.
frequency band of
control system
frequency band of
reference
—
t i
frequency range that is responsible for the
greater port of the mean squore tracking error
Fig. 2.17. Illustration of Design Objective 2.2.A.
Design Objective 2.2A. Jn order to obtain a small steady-state mean square
tracking error, the frequency band of the control system should contain as much
as possible of the frequency band of the variable part of the reference variable.
If nonzero set points are likely to occur, T(0) should be made close to 1.
An important aspect of this design rule is that it is also useful when very
little is known about the reference variable except for a rough idea of its
frequency band.
2.5 Steady-State Tracking Properties 149
Let us now consider the second aspect of the design—the steady-state
mean square input. A consideration of 2-65b leads us to formulate our next
design objective.
Design Objective 2.3. Jn order to obtain a small steady-state mean square
input in an asymptotically stable single-input single-output time-invariant
linear control system,
=x,(w) |N(jo)|? 2-73
should be made small for all real w. This can be achieved by making |N(jo)|
sufficiently small over the frequency band of the reference variable.
It should be noted that this objective does not contain the advice to keep
N(O) small, such as would follow from considering the first term of 2-65b.
This term represents the contribution of the constant part of the reference
variable, that is, the set point, to the input. The set point determines the
desired level of the controlled variable and therefore also that of the input.
It must be assumed that the plant is so designed that it is capable of sustaining
this level. The second term in 2-65b is important for the dynamic range of the
input, that is, the variations in the input about the set point that are per-
missible. Since this dynamic range is restricted, the magnitude of the second
term in 2-65b must be limited.
It is not difficult to design a control system so that one of the Design
Objectives 2.2A or 2.3 is completely satisfied. Since 7(s) and N(s) are related
by
T(s) = K(s)N(s), 2-74
however, the design of 7(s) affects N(s), and vice-versa. We elaborate a little
on this point and show how Objectives 2.2 and 2.3 may conflict. The plant
frequency response function |K(jm)| usually decreases beyond a certain
frequency, say w,. If |7(j@)| is to stay close to 1 beyond this frequency, it
is seen from 2-74 that |N(jw)| must increase beyond w,. The fact that
|7(jm)| is not allowed to decrease beyond w, implies that the reference
variable frequency band extends beyond w,. As a result, |N(j@)| will be
large over a frequency range where &,(w) is not small, which may mean an
important contribution to the mean square input. If this results in over-
loading the plant, either the bandwidth of the control system must be reduced
(at the expense of a larger tracking error), or the plant must be replaced by a
more powerful one.
The designer must find a technically sound compromise between the
requirements of a small mean square tracking error and a mean square input
that matches the dynamic range of the plant. This compromise should be
based on the specifications of the control system such as the maximal
150 Analysis of Linear Control Systems
allowable rms tracking error or the maximal power of the plant. In later
chapters, where we are concerned with the synthesis problem, optimal
compromises to this dilemma are found.
At this point a brief comment on computational aspects is in order. In
Section 2.3 we outlined how time domain methods can be used to calculate
the mean square tracking error and mean square input. In the time-invariant
case, the integral expressions 2-65a and 2-65b offer an alternative computa-
tional approach. Explicit solutions of the resulting integrals have been
tabulated for low-order cases (see, e.g., Newton, Gould, and Kaiser (1957),
Appendix E; Seifert and Steeg (1960), Appendix). For numerical computa-
tions we usually prefer the time-domain approach, however, since this is
better suited for digital computation. Nevertheless, the frequency domain
expressions as given are extremely important since they allow us to formulate
design objectives that cannot be easily seen, if at all, from the time domain
approach.
Example 2.7. The tracking properties of the position servo
Let us consider the position servo problem of Examples 2.1 (Section 2.2.2)
and 2.4 (Section 2.3), and let us assume that the reference variable is ade-
quately represented as zero-mean exponentially correlated noise with rms
value o and time constant T,. We use the numerical values
Greta.
T, = 10s. axi8
It follows from the value of the time constant and from 2-72 that the reference
variable break frequency is 0.1 rad/s, its 10% cutoff frequency 0.63 rad/s,
and its 1% cutoff frequency 6.4 rad/s.
Design I. Let us first consider Design I of Example 2.4, where zero-order
feedback of the position has been assumed. It is easily found that the trans-
mission 7(s) and the transfer function N(s) are given by
T(s) = ea ara:
n — Fi ;
od K 2-76
NO se + «)
s tas + ka
We rewrite the transmission as
T(s) where
ie
Ss? + 2Laos + wo"
Oy = [KA 2-78
2-77 [OR a = 4
2.5 Steady-State Tracking Properties 151
is the undamped natural frequency, and
ed
4 2 Sel 2-79
the relative damping. In Fig. 2.18 we plot |T(jo)| as a function of w for various
values of the gain A. Following Design Objective 2.2A the gain 2 should
probably not be chosen less than about 15 V/rad, since otherwise the cutoff
frequency of the control system would be too small as compared to the 1%
cutoff frequency of the reference variable of 6.4 rad/s. However, the cutoff
WwW OO
(rad/s)
0.01
0.001
A= 800
A= 400
A= 200
d= 100
A= 50
A=25
A=15
A=5
0.0001
Fig. 2.18. Bode plots of the transmission of the position control system, Design I, for
various values of the gain A.
frequency does not seem to increase further with the gain, due to the
peaking effect which becomes more and more pronounced. The value of
15 V/rad for the gain corresponds to the case where the relative damping ¢
is about 0.7.
It remains to be seen whether or not this gain leads to acceptable values of
the rms tracking error and the rms input voltage. To this end we compute
both. The reference variable can be modeled as follows
0,(t) = — = 80 + w(t), 2-80
r
where w(t) is white noise with intensity 207/7,. The combined state equations
152 Analysis of Linear Control Systems
of the control system and the reference variable are from 2-19, 2-24, and
2-80:
Eo) 0 1 0 £,(t) 0
E(t) = | —KA —a Ka E(t) | + | 0 w(t). 2-81
; 1 |
6,(t) 0 0 T. (t)
a AN 1
With this equation as a starting point, it is easy to set up and solve the
Lyapunov equation for the steady-state variance matrix Q of the augmented
state col [£,(t), &(t), 8,(t)] (Theorem 1.53, Section 1.11.3). The result is
Sess 0
®% -- a + «AT,
T,
(«Ay
gee 0 a o 2-82
a+ — + KAT,
KAT, 2 KA 5
i 5 1 .
+ — + KAT, c T,
a + — + KAT,
As a result, we obtain for the steady-state mean square tracking error:
Coo = lim E{[0(t) — 0,0} = fir — 2s + Ass
too
Cts = ot ae
6 ee are
ha al he 2-83
a+ — + KAT,
a r
where the g;, are the entries of Q. A plot of the steady-state rms tracking error
is given in Fig. 2.19. We note that increasing A beyond 15-25 V/rad decreases
the rms tracking error only very little. The fact that C,,, does not decrease to
zero as A» co is attributable to the peaking effect in the transmission which
becomes more and more pronounced as A becomes larger.
The steady-state rms input voltage can be found to be given by
Cys, = Ele} = EV2(0(t) — 8,()P} = 2C geo: 2-84
2.5 Steady-State Tracking Properties 153
rms
tracking
error
(rod)
0 zl n a Se eS
0 7g 50 75 100
goin A—» (V/rad)
rms 20
input
voltage
(V)
0 Se == =at J
0 25 50 75 100
goin’ —=(V/rad)
Fig. 2.19. Rms tracking error and rms input voltage as functions of the gain A for the
position servo, Design I.
Figure 2.19 shows that, according to what one would intuitively feel, the rms
input keeps increasing with the gain 2. Comparing the behavior of the rms
tracking error and the rms input voltage confirms the opinion that there is
very little point in increasing the gain beyond 15-25 V/rad, since the increase
in rms input voltage does not result in any appreciable reduction in the rms
tracking error. We observe, however, that the resulting design is not very
good, since the rms tracking error achieved is about 0.2 rad, which is not
very small as compared to the rms value of the reference variable of | rad.
Design II. The second design suggested in Example 2.4 gives better results,
since in this case the tachometer feedback gain factor p can be so chosen that
the closed-loop system is well-damped for each desired bandwidth, which
eliminates the peaking effect. In this design we find for the transmission
Ts) == ie 2-85
s* + (a + KdAp)s + KA
which is similar to 2-76 except that « is replaced with « + «Ap. As a result,
154 Analysis of Linear Control Systems
the undamped natural frequency of the system is
Wy = ved 2-86
and the relative damping
f a+ Kip
2-87
(a ee
The break frequency of the system is @», which can be made arbitrarily large
by choosing A large enough. By choosing p such that the relative damping
is in the neighborhood of 0.7, the cutoff frequency of the control system can
be made correspondingly large. The steady-state rms tracking error is
1
(a + KAp)? + (% + KAp) 7 + Kh
i 2
Coo = Ci, 2-88
(a + Kip)( + Kdp + e + «AT,)
while the steady-state mean square input voltage is given by
a? 4 a + = + KA
Gi ee ee 2-89
(« + KAp + = + KAT.) (4 + Kip)
C,.. can be made arbitrarily small by choosing 4 and p large enough. For a
given rms input voltage, it is possible to achieve an rms tracking error that
is less than for Design I. The problem of how to choose the gains A and p
such that for a given rms input a minimal rms tracking error is obtained
is a mathematical optimization problem.
In Chapter 3 we see how this optimization problem can be solved. At
present we confine ourselves to an intuitive argument as follows. Let us sup-
pose that for each value of / the tachometer gain p is so chosen that the rel-
ative damping ¢ is 0.7. Let us furthermore suppose that it is given that
the steady-state rms input voltage should not exceed 30 V. Then by trial
and error it can be found, using the formulas 2-88 and 2-89, that for
4 =500V/rad, p=0.06s, 2-90
the steady-state rms tracking error is 0.1031 rad, while the steady-state rms
input voltage is 30.64 V. These values of the gain yield a near-minimal rms
tracking error for the given rms input. We observe that this design is better
than Design I, where we achieved an rms tracking error of about 0.2 rad.
Still Design II is not very good, since the rms tracking error of 0.1 rad is not
very small as compared to the rms value of the reference variable of 1 rad.
2.5 Steady-State Tracking Properties 155
This situation can be remedied by either replacing the motor by a more
powerful one, or by lowering the bandwidth of the reference variable. The
10% cutoff frequency of the present closed-loop design is 0.071w) =
0.071V KA ~ 1.41 rad/s, where w, is the break frequency of the system (see
Table 2.1). This cutoff frequency is not large enough compared to the 1%
cutoff frequency of 6.4 rad/s of the reference variable.
Design III. The third design proposed in Example 2.4 is an intermediate
design: for 7, = 0 it reduces to Design II and for T;, = © to Design I. For
a given value of 7,, we expect its performance to lie in between that of the
two other designs, which means that for a given rms input voltage an rms
tracking error may be achieved that is less than that for Design I but larger
than that for Design II.
From the point of view of tracking performance, T, should of course be
chosen as small as possible. A too small value of T7,, however, will unduly
enhance the effect of the observation noise. In Example 2.11 (Section 2.8),
which concludes the section on the effect of observation noise in the control
system, we determine the most suitable value of 7;.
2.5.3 The Multiinput Multioutput Case
In this section we return to the case where the plant input, the controlled
variable, and the reference variable are multidimensional variables, for which
we rephrase the design objectives of Section 2.5.2.
When we first consider the steady-state mean square tracking error as
given by 2-58, we see that Design Objective 2.2 should be modified in the
sense that
tr {,(w)[T( — jo) — I} W,[T jo) — 1} 2-91
is to be made small for all real w > 0, and that when nonzero set points are
likely to occur,
tr {Ro[T(0) — I] W,[T() — 1]} 2-92
must be made small. Obviously, this objective is achieved when 7( jw) equals
the unit matrix for all frequencies. It clearly is sufficient, however, that
T( jw) be close to the unit matrix for all frequencies for which & ,(w) is
significantly different from zero. In order to make this statement more
precise, the following assumptions are made.
1. The variable part of the reference variable is a stochastic process with
uncorrelated components, so that its power spectral density matrix can be
expressed as
U(w) = diag [Z,1(), 200), * ++» Upm()]- 2-93
156 Analysis of Linear Control Systems
2. The constant part of the reference variable is a stochastic variable with
uncorrelated components, so that its second-order moment matrix can be
expressed as
Roses Gag (Ro a Rota 224g) 2-94
From a practical point of view, these assumptions are not very restrictive.
By using 2-93 and 2-94, it is easily found that the steady-state mean square
tracking error can be expressed as
Co S Ry, {(T(0) — TI W,[T) — Tex
+3 [= Coo((-jo) = I WATo) = Dudf, 2-95
where a
{[T(—jo) = 1]* W,[T(jo) = bee 2-96
denotes the i-th diagonal element of the matrix [J7(—jm) — I W,[T jo) — I].
Let us now consider one of the terms on the right-hand side of 2-95:
owen = I] W,[T(jo) = Nhs df. 2-97
This expression describes the contribution of the i-th component of the
reference variable to the tracking error as transmitted through the system.
It is therefore appropriate to introduce the following notion.
Definition 2.4. Let T(s) be the m X m transmission of an asymptotically
stable time-invariant linear control system. Then we define the frequency band
of the i-th link of the control system as the set of frequencies w, w > 0, for
which
{[T(—jo) — 1}? W.[Tjo) — Nha < 2°W 2-98
Here « is a given number which is small with respect to 1, W, is the weighting
matrix for the mean square tracking error, and W, ;; denotes the i-th diagonal
element of W,.
Once the frequency band of the i-th link is established, we can of course
define the bandwidth and the cutoff frequency of the i-th link, if they exist, as
in Definition 2.2. It is noted that Definition 2.4 also holds for nondiagonal
weighting matrices W,. The reason that the magnitude of
{[T(—jo) — IP W,[T(jo) — Di
is compared to W, ;, is that it is reasonable to compare the contribution
2-97 of the i-th component of the reference variable to the mean square
tracking error to its contribution when no control is present, that is, when
T(s) = 0. This latter contribution is given by
2.5 Steady-State Tracking Properties 157
owen 2.99
We refer to the normalized function {[7(—jw) — I]7W,[T( jw) — I}};5|W. 4:
as the difference function of the i-th link. In the single-input single-output
case, this function is |7(jw) — 1|?.
We are now in a position to extend Design Objective 2.2A as follows.
Design Objective 2.2B. Let T(s) be the m x m transmission of an asymp-
totically stable time-invariant linear control system for which both the constant
part and the variable part of the reference variable have uncorrelated com-
ponents. Then in order to obtain a small steady-state mean square tracking
error, the frequency band of each of the m links should contain as much as
possible of the frequency band of the corresponding component of the reference
variable. If the i-th component, i = 1,2,°-+,m, of the reference variable is
likely to have a nonzero set point, {{T(0) — I!" W,[T(O) — I}};,; should be made
small as compared to W, j;.
As an amendment to this rule, we observe that if the contribution to C,,, of
one particular term in the expression 2-95 is much larger than those of the
remaining terms, then the advice of the objective should be applied more
severely to the corresponding link than to the other links.
In view of the assumptions | and 2, it is not unreasonable to suppose that
the weighting matrix W, is diagonal, that is,
Wo == Cine OV, a, gas? bo a ea: 2-100
Then we can write
Uiejo) = Wie) =
= SI{7Ge) — Dil? Wea P= dh ne aol
i=
where {7( jw) — J},, denotes the (/,i)-th element of 7(jw) — J. This shows
that the frequency band of the i-th link is determined by the i-th column of
the transmission 7(s).
It is easy to see, especially in the case where W, is diagonal, that the design
objective forces the diagonal elements of the transmission T(ja) to be close
to 1 over suitable frequency bands, while the off-diagonal elements are to be
small in an appropriate sense. If all off-diagonal elements of T( jo) are zero,
that is, 7(jm) is diagonal, we say that the control system is completely de-
coupled. A control system that is not completely decoupled is said to exhibit
interaction. A well-designed control system shows little interaction. A control
system for which 7(0) is diagonal will be called statically decoupled.
We consider finally the steady-state mean square input. If the components
158 write
Analysis of Linear Control Systems
of the reference variable are uncorrelated (assumptions | and 2), we can
Cu = & Ro{N7OWNO}a+ X | ULM N(—Jo)WNGO) jie Af,
i=1 t=1 J—@ 2-102
where {N7(—jw)W,,N(jo)},, is the i-th diagonal element of N7(—jo) -
W,,N(jw). This immediately leads to the following design objective.
Design Objective 2.3A. Jn order to obtain a small steady-state mean square
input in an asymptotically stable time-invariant linear control system with an
m-dimensional reference variable with uncorrelated components,
{N7(—jo)W,N(jo)} 1 2-103
should be made small over the frequency band of the i-th component of the
reference variable, for i = 1,2,°**,m.
Again, as in Objective 2.3, we impose no special restrictions on
{N7(0)W,,N(0)};, even if the i-th component of the reference variable is
likely to have a nonzero set point, since only the fluctuations about the set
point of the input need be restricted.
Example 2.8. The control of a stirred tank
Let us take up the problem of controlling a stirred tank, as described in
Example 2.2 (Section 2.2.2). The linearized state differential equation is
given in Example 1.2 (Section 1.2.3); it is
=O0le 0 1
a(t) = | Ju ee ( Juco 2-104
Ol pa 002 AIL iG
As the components of the controlled variable z(t) we choose the outgoing
flow and the outgoing concentration so that we write
w(t) 0.01 0
2(t) = ( = ( Jet 2-105
C(t) 0 I
The reference variable r(t) thus has as its components p(t) and p,(t), the
desired outgoing flow and the desired outgoing concentration, respectively.
We now propose the following simple controller. If the outgoing flow is too
small, we adjust the flow of feed 1 proportionally to the difference between
the actual flow and the desired flow; thus we let
My(t) = ky[pi(t) — €(0)). 2-106
However, if the outgoing concentration differs from the desired value, the
flow of feed 2 is adjusted as follows:
Holt) = ke[pa(t) — So(0)). 2-107
Figure 2.20 gives a block diagram of this control scheme. The reason that
JO} SduUatJayas
MO}}
(3) 'g
JO} adUaJayas
(1) ?2g
UO!}0J}USIUOD
{MO} Buiwosus
(4) bn
Z MO} Buiwosul
MO}$ BHutoBbino
= (9) bu
(4) 65
HuloHino
U0}}0J}Ua5U0
Ja }}03}U095
‘Su
y *9z°z
JoUOS dooy-pasops
JOJ owayos
ay}
“YUL} Poss
159
160 Analysis of Linear Control Systems
this simple scheme is expected to work is that feed 2 has a higher concentra-
tion than feed 1; thus the concentration is more sensitive to adjustments of
the second flow. As a result, the first flow is more suitable for regulating the
outgoing flow. However, since the second flow also affects the outgoing flow,
and the first flow the concentration, a certain amount of interaction seems
unavoidable in this scheme.
For this control system the various transfer matrices occurring in Fig.
2.14 can be expressed as follows:
=O. Oles > 2 00les
s+0.01 s-+0.01
BOP Ie Nee esiamaiee. t:
s+ 0.02 s+ 0.02 2-108
P(s) = G(s) = ;
OP Bike
In Example 1.17 (Section 1.5.4), we found that the characteristic polynomial
of the closed-loop system is given by
$,(s) = s? + s(0.01k, + 0.75k, + 0.03)
+ (0,0002k, + 0.0075k, + 0.01k,k, + 0.0002), 2-109
from which we see that the closed-loop system is asymptotically stable for
all positive values of the gains A, and ky.
It can be found that the transmission of the system is given by
T(s) = K(s)[I + G(s)H(s)}"P(s)
1 [0.01k,(s + ky + 0.02) 0.01k(s + 0.02)
os | 2-110
$(8)\ —0.25k,(s +. 0.01) _ky(0.75s + 0.01k, + 0.0075)
As a result, we find that
T(s) —I = [54 5(0.75k, ++ 0.03) ;
=a + 0.0075ky + 0.0002] oc ata
dO) a —[s? + s(0.01k, + 0.03)
¢ S056 0.01 1
KCB SL) + 0.0002k, + 0.0002]
2-111
It is easy to see that if k, and k, simultaneously approach infinity then
[7(s) — I] + 0 so that perfect tracking is obtained.
2.5 Steady-State Tracking Properties 161
The transfer matrix N(s) can be found to be
N(s) = [I + G(s)H(s)] *P(s)
k,[s? + s(0.75k, + 0.03)
1 + 0.0075k, + 0.0002]
$.(s) 0.25k,ko(s + 0.01)
—0.01k,ko(s + 0.02)
ko[s? + s(0.01k, + 0.03)
+ 0.0002k, + 0.0002]
2-112
When &, and k, simultaneously approach infinity,
75(s + 0.01) —(s + 0.02)
N(s) > ( : 2-113
25(s + 0.01) s + 0.02
which means that the steady-state mean square input C,,,, will be infinite
unless the entries of X,(w) decrease fast enough with w.
In order to find suitable values for the gains k, and k,, we now apply
Design Objective 2.2B and determine k, and k, so that the frequency bands
of the two links of the system contain the frequency bands of the components
of the reference variable. This is a complicated problem, however, and there-
fore we prefer to use a trial-and-error approach that is quite typical of the
way multivariable control problems are commonly solved. This approach is
as follows. To determine k, we assume that the second feedback link has not
yet been connected. Similarly, in order to determine kj, we assume that the
first feedback link is disconnected. Thus we obtain two single-input single-
output problems which are much easier to solve. Finally, the control system
with both feedback links connected is analyzed and if necessary the
design is revised.
When the second feedback link is disconnected, the transfer function
from the first input to the first controlled variable is
H,,(s) — aaa . 2-114
Proportional feedback according to 2-106 results in the following closed-
loop transfer function from p,(t) to ¢,(t):
0.01k,
2-115
x 01k, 0.010
We immediately observe that the zero-frequency transmission is different
from |; this can be remedied by inserting an extra gain f; into the connection
from the first component of the reference variable as follows:
f(t) = kyl fp) — &()). 2-116
162 Analysis of Linear Control Systems
With this 2-115 is modified to
0.01k,f, a 2-117
s+ 0.01k, + 0.01
For each value of k,, it is possible to choose f, so that the zero-frequency
transmission is |. Now the value of k, depends upon the cutoff frequency
desired. For k, = 10 the 10% cutoff frequency is 0.011 rad/s (see Table 2.1).
Let us assume that this is sufficient for the purpose of the control system.
The corresponding value that should be chosen for f, is 1.1.
When studying the second link in a similar manner, it can be found that
the feedback scheme
M(t) = kel fepo(t) — 6(2)] 2-118
results in the following closed-loop transfer function from p,(t) to ¢,(t)
(assuming that the first feedback link is disconnected):
0.75k»f> een as en 2-119
s + 0.75k, + 0.02
For k, = 0.1 and f, = 1.267, the zero-frequency transmission is | and the
10% cutoff frequency 0.0095 rad/s.
Let us now investigate how the multivariable control system with
kee 00 10 0
G(s) = a 2-120
0 k, 0 0.1
and
kif, 0 L} 0
P(s) = ( a = 2-121
0 kofs 0 0.1267
performs. It can be found that the control system transmission is given by
a 1 | O.11s + 0.0132 0.001267s + pial)
\==—- SS >
s* + 0.205s + 0.01295 \ 2.755 — 0.0275 0.09502s + 0.01362
2-122
hence that
1
T(s) -—I= s” + 0.205s + 0.01295
jw — 0.095s + 0.00025 0.001267s + ee
: . 2-123
—2.75s — 0.0275 —s* — 0.1100s + 0.00067
2.5 Steady-State Tracking Properties 163
Now in order to determine the frequency bands of the two links of the control
system, we must first choose the weighting matrix W,. The two controlled
variables are the outgoing flow and the outgoing concentration. The flow
has the constant nominal value 0.02 m3/s, while the concentration has the
constant nominal value 1.25 kmol/m*. A 10% change in the flow therefore
corresponds to 0.002 m*/s, while a 10% change in the concentration is about
0.1 kmol/m*. Now let us suppose that we make the weighting matrix W,
diagonal, with diagonal entries W, , and W, 5. Let us also assume that 10%
changes in either the flow or the concentration make equal contributions
to the mean square tracking error. Then we have
(0.002)°W, = (0.1)°W, », 2-124
or
W, 1 = = VITO. e,2
2-125
Let us therefore choose W, = diag (50, 0.02). 2-126
Since W, is diagonal, we can use 2-101 to determine the frequency band of
the i-th link. The frequency band of the first link (the flow link) thus follows
from considering the inequality
(jo) + 0.095(jw) — 0.00025
(jw)? + 0.205(jw) + 0.01295
2
2.75(jw) + 0.0275 ‘
(jw)? + 0.205(jw) + 0.01295
< 507 22127
Dividing by 50 and rearranging, we obtain
\(ja)* + 0.095( jw) — 0.00025|* + 0.0004 |2.75( ja) + 0.0275]? ce
2-128
\(jw)? + 0.205( ja) + 0.01295]? as
Figure 2.21 shows a Bode plot of the left-hand side of this inequality, which
is precisely the difference function of the first link. It is seen that ¢ cannot be
0.00) 0.01 0) 1
1 1)
difference (rad/s)
function
01
0.01
0.001
Fig. 2.21. Difference functions of the first and the second link of the stirred-tank control
system.
164 Analysis of Linear Control Systems
chosen arbitrarily small since the left-hand side of 2-128 is bounded from
below. For ¢ = 0.1 the cutoff frequency is about 0.01 rad/s. The horizontal
part of the curve at low frequencies is mainly attributable to the second term
in the numerator of 2-128, which originates from the off-diagonal entry in
the first column of 7(jw) — J. This entry represents part of the interaction
present in the system.
We now consider the second link (the concentration link). Its frequency
band follows from the inequality
0.001267( jw) + 0.00002534 ‘ 0.0 (jo)* + 0.1100(ja) — 0.00067 7
(ja)? + 0.205( jw) + 0.01295 : (jo) + 0.205( jw) + 0.01295
<0.02«". 2-129
By dividing by 0.02 and rearranging, it follows for this inequality,
\(jw)? + 0.205(jw) + 0.01295? ie
2-130
The Bode plot of the left-hand side of this inequality, which is the difference
function of the second link, is also shown in Fig. 2.21. In this case as well,
the horizontal part of the curve at low frequencies is caused by the interaction
in the system. If the requirements on «¢ are not too severe, the cutoff frequency
of the second link is somewhere near 0.01 rad/s.
The cutoff frequencies obtained are reasonably close to the 10% cutoff
frequencies of 0.011 rad/s and 0.0095 rad/s of the single-loop designs.
Moreover, the interaction in the system seems to be limited. In conclusion,
Fig. 2.22 pictures the step response matrix of the control system. The plots
confirm that the control system exhibits moderate interaction (both dynamic
and static). Each link has the step response of a first-order system with a
time constant of approximately 10 s.
A rough idea of the resulting input amplitudes can be obtained as follows.
From 2-116 we see that a step of 0.002 m/s in the flow (assuming that this is
a typical value) results in an initial flow change in feed 1 of k,f,0.002 =
0.022 m/s. Similarly, a step of 0.1 kmol/m® in the concentration results in
an initial flow change in feed 2 of k, f,0.1 = 0.01267 m/s. Compared to the
nominal values of the incoming flows (0.015 m3/s and 0.005 m3/s, respec-
tively), these values are far too large, which means that either smaller step
input amplitudes must be chosen or the desired transition must be made
more gradually. The latter can be achieved by redesigning the control system
with smaller bandwidths.
In Problem 2.2 a more sophisticated design of a controller for the stirred
tank is considered.
2.6 Transient Tracking Properties 165
0.002 0,002
outgoing outgoing
flow n, (t) flow 1 (t)
(m3/s) Via ee
0
0 50
——P (s)
0.)
concentration oe re
Na(t) ai
(kmot/m3) Yao,
0
5
+ —~ (s) t —e(s)
Fig. 2.22. Step response matrix of the stirred-tank control system. Left column: Responses
of the outgoing flow and concentration to a step of 0.002 m/s in the set point of the flow.
Right column: Responses of the outgoing flow and concentration to a step of 0.1 kmol/m*
in the set point of the concentration.
2.6 THE TRANSIENT ANALYSIS OF THE
TRACKING PROPERTIES
In the previous section we quite extensively discussed the steady-state
properties of tracking systems. This section is devoted to the transient
behavior of tracking systems, in particular that of the mean square tracking
error and the mean square input. We define the seftling time of a certain
quantity (be it the mean square tracking error, the mean square input, or any
other variable) as the time it takes the variable to reach its A -state value
to within a specified accuracy. When this accuracy is, say, 1 % of the maximal
deviation from the steady-state value, we speak of the 1% oe time. For
other percentages similar terminology is used.
Usually, when a control system is started the initial tracking error, and as
a result the initial input also, is large. Obviously, it is desirable that the mean
square tracking error settles down to its steady-state value as quickly as
possible after starting up or after upsets. We thus formulate the following
directive.
166 Analysis of Linear Control Systems
Design Objective 2.4. A control system should be so designed that the settling
time of the mean square tracking error is as short as possible.
As we have seen in Section 2.5.1, the mean square tracking error attributable
to the reference variable consists of two contributions. One originates from
the constant part of the reference variable and the other from the variable
part. The transient behavior of the contribution of the variable part must be
found by solving the matrix differential equation for the variance matrix of
the state of the control system, which is fairly laborious. The transient
behavior of the contribution of the constant part of the reference variable to
the mean square tracking error is much simpler to find; this can be done
simply by evaluating the response of the control system to nonzero initial con-
ditions and to steps in the reference variable. As a rule, computing these
responses gives a very good impression of the transient behavior of the
control system, and this is what we usually do.
For asymptotically stable time-invariant linear control systems, some
information concerning settling times can often be derived from the locations
of the closed-loop poles. This follows by noting that a// responses are exponen-
tially damped motions with time constants that are the negative reciprocals
of the real parts of the closed-loop characteristic values of the system. Since
the 1% settling time of
Pi satehy FS Za th is 4.60, a bound for the 1 % settling time ¢, of any variable is
2-131
t, < 4.6 max | ; 2-132
i \[Re(A,)|
where 4,, i= 1,2,°++,m, are the closed-loop characteristic values. Note
that for squared variables such as the mean square tracking error and the
mean square input, the settling time is half that of the variable itself.
The bound 2-132 sometimes gives misleading results, since it may easily
happen that the response of a given variable does not depend upon certain
characteristic values. Later (Section 3.8) we meet instances, for example,
where the settling time of the rms tracking error is determined by the closed-
loop poles furthest from the origin and not by the nearby poles, while the
settling time of the rms input derives from the nearby closed-loop poles.
Example 2.9. The settling time of the tracking error of the position servo
Let us consider Design I of Example 2.4 (Section 2.3) for the position servo.
From the steady-state analysis in Example 2.7 (Section 2.5.2), we learned
that as the gain 4 increases the rms steady-state tracking error keeps de-
creasing, although beyond a certain value (15-25 V/rad) very little improve-
ment in the rms tracking error is obtained, while the rms input voltage
2.7 Effects of Disturbances 167
becomes larger and larger. We now consider the settling time of the tracking
error. To this end, in Fig. 2.23 the response of the controlled variable to a
step in the reference variable is plotted for various values of 2, from zero
initial conditions. As can be seen, the settling time of the step response
(hence also that of the tracking error) first decreases rapidly as A increases,
but beyond a value of 4 of about 15 V/rad the settling time fails to improve
because of the increasingly oscillatory behavior of the response. In this case
angulor
position
e(t)
(rad) Fig. 2.23. Response of Design I of the
position servo to a step of 0.1 rad in the
reference variable for various values of
the gain A.
t —»(s)
as well, the most favorable value of A seems to be about 15 V/rad, which
corresponds to a relative damping ¢ (see Example 2.7) of about 0.7. From the
plots of |7(jw)| of Fig. 2.18, we see that for this value of the gain the largest
bandwidth is achieved without undesirable peaking of the transmission.
2.7 THE EFFECTS OF DISTURBANCES IN THE
SINGLE-INPUT SINGLE-OUTPUT CASE
In Section 2.3 we saw that very often disturbances act upon a control system,
adversely affecting its tracking or regulating performance. In this section we
derive expressions for the increases in the steady-state mean square tracking
error and the steady-state mean square input attributable to disturbances,
and formulate design objectives which may serve as a guide in designing
control systems capable of counteracting disturbances.
Throughout this section the following assumptions are made.
1. The disturbance variable v,(t) is a stochastic process that is uncorrelated
with the reference variable r(t) and the observation noise v,,(t).
As a result, we can obtain the increase in the mean square tracking error and
the mean square input simply by setting r(t) and v,,(¢) identical to zero.
2. The controlled variable is also the observed variable, that is, C = D.
168 Analysis of Linear Control Systems
This means that we can write
y(t) = a(t) + v,(t), 2-133
and that in the time-invariant case
H(s) = K(s). 2-134
The assumption that the controlled variable is also the observed variable is
quite reasonable, since it is intuitively clear that feedback is most effective
when the controlled variable itself is directly fed back.
3. The control system is asymptotically stable and time-invariant.
4, The input variable and the controlled variable, hence also the reference
variable, are scalars. W, and W,, are both |.
The analysis of this section can be extended to multivariable systems but
doing so adds very little to the conclusions of this and the following sections.
5. The disturbance variable v,(t) can be written as
v(t) = Vpo + Vp,(t), 2-135
where the constant part Vy» of the disturbance variable is a stochastic vector
with given second-order moment matrix, and where the variable part v,,,(t) of
the disturbance variable is a wide-sense stationary zero mean stochastic process
with power spectral density matrix &,,(@), uncorrelated with Vy».
The transfer matrix from the disturbance variable v,(t) to the controlled
variable z(t) can be found from the relation (see Fig. 2.24)
Z(s) = —H(s)G(s)Z(s) + D(sI — A)"V,(s), 2-136
where Z(s) and V,(s) denote the Laplace transforms of z(t) and »v,(t),
Vip
Fig. 2.24. Transfer matrix block diagram of a closed-loop control system with plant
disturbance v,.
2.7 Effects of Disturbances 169
respectively, so that
1
LS ae eee he A) Va ( 8), (s) 1+ HOG® ( y~V,(s)
2-137
Here we have used the fact that the controlled variable is a scalar so that
1 + H(s)G(s) is also a scalar function. We now introduce the function
1
S(s) 2-138
1 + H(s)G(s)’
which we call the sensitivity function of the control system for reasons to be
explained later.
We compute the contribution of the disturbance variable to the steady-
state mean square tracking error as the sum of two terms, one originating
from the constant part and one from the variable part of the disturbance.
Since
Z(s) = S(s)D(sI — A)“V,(s), 2-139
the steady-state response of the controlled variable to the constant part of
the disturbance is given by
lim z(t) = S(0)D(—A)‘vy9 = S(O)v 0. 2-140
t> oo
Here we have assumed that the matrix A is nonsingular—the case where A
is singular is treated in Problem 2.4, Furthermore, we have abbreviated
Vo0 => D(—A) 1045. 2-141
As a result of 2-140, the contribution of the constant part of the disturbance
to the steady-state mean square tracking error is
EX|S(O)vool?} = |S(O)? Vo, 2-142
where V, is the second-order moment of vp), that is, Vy = E{vpo}. Further-
more it follows from 2-139 with the methods of Sections 1.10.4 and 1.10.3
that the contribution of the variable part of the disturbance to the steady-
state mean square tracking error can be expressed as
co)
| |[S(jw)|? D(jal — AY'E,,(@)(—jol — AT)*D*? df
= i |S(jo)|2Z,o(@) df. 2-143
—— OO
Here we have abbreviated
Do) = D(jol — A)y"d,,(@)\(—jol — ATY*D*. 2-144
Consequently, the increase in the steady-state mean square tracking error
170 Analysis of Linear Control Systems
attributable to the disturbance is given by
C,., (with disturbance) — C,,, (without disturbance)
= SOP Vy +] [So Zl) df 2-145
Before discussing how to make this expression small, we give an interpreta-
tion. Consider the situation of Fig. 2.25 where a variable v(t) acts upon the
closed-loop system. This variable is added to the controlled variable. It is
Fig. 2.25. Transfer matrix block diagram of a closed-loop control system with the
equivalent disturbance v, at the controlled variable.
easily found that in terms of Laplace transforms with the reference variable
and the initial conditions identical to zero the controlled variable is given by
AAs) = S(S)¥ p65) 2-146
where V,(s) denotes the Laplace transform of v9(t). We immediately see that
if vo(t) is a stochastic process with as constant part a stochastic variable
with second-order moment V, and as variable part a zero-mean wide-sense
stationary stochastic process with power spectral density X ,9(@), the increase
in the steady-state mean square tracking error is exactly given by 2-145. We
therefore call the process vy(t) with these properties the equivalent disturbance
at the controlled variable.
An examination of 2-145 leads to the following design rule.
Design Objective 2.5. Jn order to reduce the increase of the steady-state mean
square tracking error attributable to disturbances in an asymptotically stable
linear time-invariant control system with a scalar controlled variable, which is
also the observed variable, the absolute value of the sensitivity function S(jw)
should be made small over the frequency band of the equivalent disturbance at
2.7 Effects of Disturbances 171
the controlled variable. If constant errors are of special concern, S(O) should
be made small, preferably zero.
The last sentence of this design rule is not valid without further qualification
for control systems where the matrix A of the plant is singular; this case is
discussed in Problem 2.4. It is noted that since S(jw) is given by
S(jo) = —? 2-147
1 + H(jw)G(jo)
a small S( jw) generally must be achieved by making the loop gain H(jw)G(jw)
of the control system large over a suitable frequency range. This easily
conflicts with Design Objective 2:1 (Section 2.4) concerning the stability of
the control system (see Example 2.5, Section 2.4), and with Objective 2.3
(Section 2.5.2) concerning the mean square input. A compromise must be
found.
Reduction of constant errors is of special importance for regulator and
tracking systems where the set point of the controlled variable must be
maintained with great precision. Constant disturbances occur very easily in
control systems, especially because of errors made in establishing the nominal
input. Constant errors can often be completely eliminated by making S(0) =
0, which is usually achieved by introducing integrating action, that is, by
letting the controller transfer function G(s) have a pole at the origin (see
Problem 2.3).
Let us now turn to a consideration of the steady-state mean square input.
It is easily found that in terms of Laplace transforms we can write (see
Fig. 2.24) = G(s)
U(s) = D(sI — A)’Y,(s), 2-148
1 + H(s)G(s)
where U(s) is the Laplace transform of u(t). It follows for the increase in the
steady-state mean square input, using the notation introduced earlier in this
section,
C,,.. (with disturbance) — C,,,, (without disturbance)
a. | G(0) 2 fo.@)
ro +|
Se Sa eae. e140
1 + H(0)G(0)
1 + H(jo)G(jo)
This expression results in the following directive.
Design Objective 2.6. In order to obtain a small increase in the steady-state
mean square input attributable to the disturbance in an asymptotically stable
linear time-invariant control system with a scalar controlled variable that is
172 Analysis of Linear Control Systems
also the observed variable and a scalar input,
G(jo)
2-150
1 + H(jw)Gjo)
should be made small over the frequency band of the equivalent disturbance at
the controlled variable.
In this directive no attention is paid to the constant part of the input since,
as assumed in the discussion of Objective 2.3, the plant must be able to
sustain these constant deviations.
Design Objective 2.6 conflicts with Objective 2.5. Making the loop gain
H(ja)G(j) large, as required by Objective 2.5, usually does not result in
small values of 2-150. Again a compromise must be found.
Example 2.10. The effect of disturbances on the position servo
In this example we study the effect of disturbances on Design I of the
position servo of Example 2.4 (Section 2.3). It is easily found that the sen-
sitivity function of the control system as proposed is given by
s(s + «)
Ss) == é
(s) s? + as + Ka 2-151
In Fig. 2.26 Bode plots of |S(jw)| are given for several values of the gain A.
It is seen that by choosing 4 larger the frequency band over which disturbance
suppression is obtained also becomes larger. If the equivalent disturbance at
the controlled variable, however, has much power near the frequency where
|S(jw)| has its peak, then perhaps a smaller gain is advisable.
—s WW)
(rad/s) ewere
0.001
Fig. 2.26. Bode plots of the sensitivity function of the position control system, Design I, as
a function of the gain A.
2.7 Effects of Disturbances 173
In Example 2.4 we assumed that the disturbance enters as a disturbing
torque 7,(¢) acting on the shaft of the motor. If the variable part of this
disturbing torque has the power spectral density function D,,(@), the variable
part of the equivalent disturbance at the controlled variable has the power
spectral density function
pie ie
SUn: 2-152
jojo + «)
The power spectral density of the contribution of the disturbing torque to the
controlled variable is found by multiplying 2-152 by |S(ja)|? and thus is
given by
Sere ele i Pas
2 Yo). 2-153
rE + af jo) + KA
Let us suppose that the variable part of the disturbing torque can be repre-
sented as exponentially correlated noise with rms value o,, and time constant
T,4 So that
20%4T a
ao) 2-154
1 + Or,
The increase in the steady-state mean square tracking error attributable
to the disturbing torque can be computed by integrating 2-153, or by modeling
the disturbance, augmenting the state differential equation, and solving for
the steady-state variance matrix of the augmented state. Either way we find
C,.. (with disturbing torque) — C,,, (without disturbing torque)
2
2 es ees 2-155
1+ aT., + KAT2, and
From this we see that the addition to C,,, monotonically decreases to zero
with increasing A. Thus the larger / the less the disturbing torque affects the
tracking properties.
In the absence of the reference variable, we have u(t) = —An(t) so that
the increase in the mean square input voltage attributable to the disturbing
torque is 4? times the increase in the mean square tracking error:
C,,.. (with disturbing torque) — C,,,, (without disturbing torque)
2
ee ee eee A 2-156
1+ 0T,g t+ KAT 34 xx
For A> o, C,,,, monotonically increases to
(i aT aly” o
aT. aK 2-1579 Td°
174 Analysis of Linear Control Systems
It is easily found from 2-25 that a constant disturbing torque 7) results in a
steady-state displacement of the controlled variable of
aS; 2-158
KA
Clearly, this displacement can also be made arbitrarily small by making
the gain A sufficiently large.
2.8 THE EFFECTS OF OBSERVATION NOISE IN THE
SINGLE-INPUT SINGLE-OUTPUT CASE
In any closed-loop scheme, the effect of observation noise is to some extent
felt. In this section the contribution of the observation noise to the mean
square tracking error and the mean square input is analyzed. To this end,
the following assumptions are made.
1. The observation noise v,,(t) is a stochastic process which is uncorrelated
with the reference variable r(t) and the plant disturbance v,(t).
As a result, the increase in the mean square tracking error and the mean
square input attributable to the observation noise may be computed simply
by setting r(¢) and v,(t) identical to zero.
2. The controller variable is also the observed variable, that is, C = D,
so that y(t) = 2(t) + d_(t), 2-159
and, in the time-invariant case,
Aris) 2-160
3. The control system is asymptotically stable and time-invariant.
4. The input variable and the controlled variable, hence also the reference
variable, are scalars. W, and W,, are both 1.
Here also the analysis can be extended to multivariable systems but again
very little additional insight is gained.
5. The observation noise is a zero-mean wide-sense stationary stochastic
process with power spectral density function &,,,,(@).
Figure 2.27 gives a transfer function block diagram of the situation that
results from these assumptions. It is seen that in terms of Laplace transforms
Z(s) = —H(s)G(s)[V,,(s) + Z(s)], 2-161
so that
aaa __H(s)G(s) | he
Ls) = ; GH VG): 2-162
2.8 Effects of Observation Noise 175
Fig. 2.27. Transfer matrix block diagram of a closed-loop control system with observation
noise.
Consequently, the increase in the steady-state mean square tracking error
attributable to the observation noise can be written as
C... (with observation noise) — C,,, (without observation noise)
H(j@)G(jw) |?
-[" 1 + H(jw)G(jo)
Dina Oval. 2-163
Our next design objective can thus be formulated as follows.
Design Objective 2.7. Jn order to reduce the increase in the steady-state mean
square tracking error attributable to observation noise in an asymptotically
stable linear time-invariant control system with a scalar controlled variable
that is also the observed variable, the system should be designed so that
H(jo)G(jo)
2-164
1 + H(jo)G(jo)
is small over the frequency band of the observation noise.
Obviously, this objective is in conflict with Objective 2.5, since making the
loop gain H(jw)G(jw) large, as required by Objective 2.5, results in a value
of 2-164 that is near 1, which means that the observation noise appears
unattenuated in the tracking error. This is a result of the fact that if a large
loop gain H(jm@)G(jw) is used the system is so controlled that z(t) + v,,(t)
instead of z(t) tracks the reference variable.
A simple computation shows that the transfer function from the observa-
tion noise to the plant input is given by
G(s)
ON eee all a:
U(s) 1+ G@)HO VAS) 165
which results in the following increase in the steady-state mean square input
176 Analysis of Linear Control Systems
attributable to observation noise:
C,,.. (with observation noise) — C,,,, (without observation noise)
G(jo)
PSeviayae 2-166
=|" 1 + G(jo)H(jo)
This yields the design rule that to make the increase in the steady-state mean
square input attributable to the observation noise small,
| Gj)
2-167
1 + G(jo)H(jo)
should be made small over the frequency band of the observation noise.
Clearly, this rule is also in conflict with Objective 2.5.
Example 2.11. The position servo with position feedback only
Let us once again consider the position servo of Example 2.4 (Section 2.3)
with the three different designs proposed. In Examples 2.7 (Section 2.5.2) and
2.9 (Section 2.6), we analyzed Design I and chose A = 15 V/rad as the best
value of the gain. In Example 2.7 it was found that Design II gives better
performance because of the additional feedback link from the angular
velocity. Let us now suppose, however, that for some reason (financial or
technical) a tachometer cannot be installed. We then resort to Design III,
which attempts to approximate Design II by using an approximate differenti-
ator with time constant 7,. If no observation noise were present, we could
choose T, = 0 and Design HI would reduce to Design II. Let us suppose that
observation noise is present, however, and that is can be represented as
exponentially correlated noise with time constant
Poe O02 S 2-168
and rms value
oye 0.00 rad, 2-169
The presence of the observation noise forces us to choose T, > 0. In order
to determine a suitable value of T,, we first assume that 7, will turn out to be
small enough so that the gains p and / can be chosen as in Design II. Then
we see how large 7, can be made without spoiling the performance of Design
II, while at the same time sufficiently reducing the effect of the observation
noise.
It is easily found that the transmission of the control system according to
Design III is given by
KA(T,s + 1)
T(s) = 2-170
Tys® + («Ty + 1s? + (a + KAT, + pd)s + Ak
2.8 Effects of Observation Noise 177
To determine a suitably small value of T,, we argue as follows. The closed-
loop system according to Design II, with the numerical values obtained in
Example 2.7 for A and p, has an undamped natural frequency w, of about
20 rad/s with a relative damping of 0.707. Now in order not to impede the
behavior of the system, the time constant 7, of the differentiator should be
chosen small with respect to the inverse natural frequency, that is, small with
respect to 0.05 s. In Fig. 2.28 we have plotted the transmission 2-170 for
w —s{rad/s)
1 10 100 1000
Fig. 2.28. The effect of T, on the transmission of Design III of the position servo.
various values of T,. It is seen that for 7, = 0.01 s the transmission is hardly
affected by the approximate derivative operation, but that for 7, = 0.1s
discrepancies occur.
Let us now consider the effect of the observation noise. Modeling v,,(t)
in the usual way, the additions to the steady-state mean square tracking error
and input attributable to the observation noise can be computed from the
variance matrix of the augmented state. The numerical results are plotted in
Fig. 2.29. These plots show that for small 7, the steady-state mean square
input is greatly increased. An acceptable value of 7, seems to be about 0.01 s.
For this value the square root of the increase in the steady-state mean square
input is only about 2 V, the square root of the increase in the steady-state
mean square tracking error of about 0.0008 rad is very small, and the trans-
mission of the control system is hardly affected.
178 Analysis of Linear Control Systems
0.0012
rms 0.0010
trocking
error 0.0008 8
rms
0.0006 input 6
d voltage
(rod) o.0004 i
0.0002 (V)
0 0
0.00) 0.01 0.7 0.001 0.01 0.1
Tq —~(s) Tg —=(s)
Fig. 2.29. The square roots of the additions to the steady-state mean square tracking error
and input voltage due to observation noise as a function of T, for Design III of the position
Servo.
2.9 THE EFFECT OF PLANT PARAMETER
UNCERTAINTY IN THE SINGLE-INPUT
SINGLE-OUTPUT CASE
Quite often a control system must be designed for a plant whose parameters
are not exactly known to the designer. Also, it may happen in practice that
changes of plant parameters frequently occur and that it is too laborious to
measure the plant parameters each time and adjust the controller.
We shall see that closed-loop controllers can be designed so that the per-
formance of the control system deteriorates very little even though there may
be quite a large discrepancy between the actual plant parameters and the
nominal plant parameters, that is, the parameter values that have been used
while designing the controller. To this end we investigate the addition to the
steady-state mean square tracking error attributable to parameter deviations.
In this section we work with the following assumptions.
1. The control system is time-invariant and asymptotically stable.
2. The controlled variable is also the observed variable, that is, C = D,
hence K(s) = H(s).
3. The input variable and the controlled variable, hence also the reference
variable, are scalar. W, and W,, are both 1.
Extension to the multivariable case is possible, but does not give much
additional insight.
4. Only the effect of parameter changes on the tracking properties is con-
sidered and not that on the disturbance suppression or noise reduction properties.
5. The reference variable has a constant part ro, which is a stochastic vector,
2.9 The Effect of Plant Parameter Uncertainty 179
with second-order moment Ro and as variable part a zero-mean wide-sense
stationary stochastic process with power spectral density function X,(w).
We denote by H,(s) the nominal transfer function of the plant, and by
H;,(s) the actual transfer function. Similarly, we write 7)(s) for the trans-
mission of the control system with the nominal plant transfer function and
T,(s) for the transmission with the actual plant transfer function. We assume
that the transfer function G(s) in the feedback link and the transfer function
P(s) in the link from the reference variable (see the block diagram of Fig.
2.14, Section 2.5.1) are precisely known and not subject to change.
Using 2-63, we obtain for the nominal transmission
A,(s)P.
TAGs eels} 2-171
1 + G(s)H)(s)
and for the actual transmission
H,(s)P
T(s) i(s) P(s) 2-172
1+ GAs)’
For the actual control system, the steady-state mean square tracking error
is given by
Coo = |T,(0) — 1]? Ro +| |T,(jw) — 1|* 2,(@) df. 2-173
We now make an estimate of the increase in the mean square tracking error
attributable to a change in the transmission. Let us denote
AT(s) = T,(s) — To(s). Inserting 7,(s) = T)(s) + AT(s) into 2-173, we obtain
2-174
Can = ITO) = IP Ry +f (To) — 11° B40) df
+ 2{T 0) — ATOR, + 2Re| [tie — NaT(—J08,0) af
+ |AT(O)? Ry + i * AT(jo)[2E,(c) df. 2175
We now proceed by assuming that the nominal control system is well-
designed so that the transmission 7)( jc) is very close to | over the frequency
band of the reference variable. In this case we can neglect the first four terms
of 2-175 and we approximate
Comp ~ |AT (0)? Ry + i |AT(jow)|® &,(w) df. 2-176
180 Analysis of Linear Control Systems
This approximation amounts to the assumption that
|To(jo) — 1] « |AT(jo)| for all w in the frequency band of the reference variable.
Our next step is to express A7(s) in terms of AH(s), where
2ATT
AH(s) = H,(s) — H,(s). 2-178
We obtain: _ _HiS)P(s)__ Hols) PCs) _
ST Te Giang oO se)
= AH(s)P(s)
TL + AY(s)G(s)]1 + G(s)H,(s)]
= S,(s) AH(s)N,(s), 2-179
where
Ci (iS) ae 2-180
1 + H,(s)G(s)
is the sensitivity function of the actual control system, and where
a ase
N,(s) 2-181
1 + G(s)H)(s)
is the transfer function of the nominal control system from the reference
variable r to the input variable uv. Now with the further approximation
S,(jw) ~ So(jo), 2-182
where
1
So(s) 2-183
1 + H)(s)G(s)
is the sensitivity function of the nominal control system (which is known),
we write for the steady-state mean square tracking error
Coa = |So(O)[? AH(O)No(O)I° Ro +{ |So( jo) |" |AH( jo) No(jo) |? 2,(@) df.
2-184
We immediately conclude the following design objective.
Design Objective 2.8. Consider a time-invariant asymptotically stable linear
closed-loop control system with a scalar controlled variable that is also the
observed variable. Then in order to reduce the steady-state mean square
tracking error attributable to a variation AH(s) in the plant transfer function
H(s), the control system sensitivity function So( jm) should be made small over
2.9 The Effect of Plant Parameter Uncertainty 181
the frequency band of |AH(jw)N,(jo)|? X,(@). If constant errors are of special
concern, S,(0) should be made small, preferably zero, when AH(0)N,(0) is
different from zero.
This objective should be understood as follows. Usually the plant trans-
mission 7 (s) is determined by finding a compromise between the require-
ments upon the mean square tracking error and the mean square input.
Once 7)(s) has been chosen, the transfer function N,(s) from the reference
variable to the plant input is fixed. The given 7)(s) and N,(s) can be realized
in many different ways, for example, by first choosing the transfer function
G(s) in the feedback link and then adjusting the transfer function P(s) in the
link from the reference variable so that the desired 7,(s) is achieved. Now
Design Objective 2.8 states that this realization should be chosen so that
Soe Se 2-185
1 + Ho(jo)G(jo)
is small over the frequency band of |AH(jw)N,(jm)|? X,(w). The latter
function is known when some idea about AH(j) is available and 7)( ja)
has been decided upon. We note that making the sensitivity function S)( jw)
small is a requirement that is also necessary to reduce the effect of disturbances
in the control system, as we found in Section 2.7. As noted in Section 2.7,
S(O) can be made zero by introducing integrating action (Problem 2.3).
We conclude this section with an interpretation of the function S)(s).
From 2-179 and 2-171 it follows that
AT(s) _ AH(s)
S,(s) 2-186
Tyme H,(s)
Thus S,(s) relates the relative change in the plant transfer function H(s)
to the resulting relative change in the control system transmission 7(s).
When the changes in the plant transfer function are restricted in magnitude,
we can approximate S,(jw) ~ S,(jw). This interpretation of the function
S(s) is a classical concept due to Bode (see, e.g., Horowitz, 1963). So(s) is
called the sensitivity function of the closed-loop system, since it gives infor-
mation about the sensitivity of the control system transmission to changes
in the plant transfer function.
Example 2.12. The effect of parameter variations on the position servo
Let us analyze the sensitivity to parameter changes in Design I of the
position servo (Example 2.4, Section 2.3). The sensitivity function for this
design is given by
Cea: 2-187
> = :
ols) se +as + KA
182 Analysis of Linear Control Systems
Plots of |S(jw)| for various values of the gain 4 have been given in Fig. 2.26.
It is seen that for A = 15 V/rad, which is the most favorable value of the
gain, protection against the effect of parameter variations is achieved up to
about 3 rad/s. To be more specific, let us assume that the parameter variations
are caused by variations in the moment of inertia J. Since the plant parameters
a and « are given by (Example 2.4)
c= z [ ‘ 2-188
J
2
J
it is easily found that for small variations AJ in J we can write
AH(s) | 8 AJ
ie Sy, 2-189
H(s) sta J
where
H(s) = —— 2-190
s(s + a)
is the plant transfer function. We note the following.
1. For zero frequency we have
aul) = 0, 2-191
H(0)
no matter what value AJ has. Since 7(0) = 1, and consequently A7(0) = 0,
this means that the response to changes in the set point of the tracking system
is always correct, independent of the inertial load of the servo.
2. We see from 2-189 that as a function of w the effect of a variation in
the moment of inertia upon the plant transfer function increases up to
the break frequency « = 4.6 rad/s and stays constant from there onward.
From the behavior of the sensitivity function, it follows that for low fre-
quencies (up to about 3 rad/s) the effect of a variation in the moment of
inertia upon the transmission is attenuated and that especially for low fre-
quencies a great reduction results.
To illustrate the control system sensitivity, in Fig. 2.30 the response of the
closed-loop system to a step in the reference variable is given for the cases
= = 0, —0.3, and +0.3. 2-192
Taking into account that a step does not have a particularly small frequency
band, the control system compensates the parameter variation quite satis-
factorily.
2.10 Open-Loop Steady-State Equivalence 183
(c)
ongulor (0)
position gy
8 (b)
(rad)
Fig. 2.30. The effect of parameter variations
on the response of the position servo, Design I,
A to a step of 0.1 rad in the reference variable:
0 ‘ 4 (a) Nominal inertial load; (6) inertial load 1.3
t—2(s) > of nominal; (¢) inertial load 0.7 of nominal.
2.10* THE OPEN-LOOP STEADY-STATE
EQUIVALENT CONTROL SCHEME
The potential advantages of closed-loop control may be very clearly brought
to light by comparing closed-loop control systems to their so-called open-
loop steady-state equivalents. This section is devoted to a discussion of such
open-loop equivalent control systems, where we limit ourselves to the time-
invariant case.
Consider a time-invariant closed-loop control system and denote the
transfer matrix from the reference variable r to the plant input u by N(s).
Then we can always construct an open-loop control system (see Fig. 2.31)
that has the same transfer matrix N(s) from the reference variable r to the
plant input uw. As a result, the transmission of both the closed-loop system
and the newly constructed open-loop control system is given by
TS) K(S\N (5): 2-193
where K(s) is the transfer matrix of the plant from the plant input w to the
controlled variable z. For reasons explained below, we call the open-loop
system steady-state equivalent to the given closed-loop system.
In most respects the open-loop steady-state equivalent proves to be in-
ferior to the closed-loop control system. Often, however, it is illuminating to
open-loop controller plont
2 N(s) “ K(s)
Fig. 2.31. The open-loop steady-state equivalent control system.
184 Analysis of Linear Control Systems
study the open-loop equivalent of a given closed-loop system since it provides
a reference situation with a performance that should be improved upon. We
successively compare closed-loop control systems and their open-loop
equivalents according to the following aspects of control system performance:
stability; steady-state tracking properties; transient behavior; effect of plant
disturbances; effect of observation noise; sensitivity to plant variations.
We first consider stability. We immediately see that the characteristic
values of the equivalent open-loop control system consist of the characteristic
values of the plant, together with those of the controller (compare Section
1.5.4). This means, among other things, that an unstable plant cannot be
stabilized by an open-loop controller. Since stability is a basic design objective,
there is little point in considering open-loop equivalents when the plant is not
asymptotically stable.
Let us assume that the plant and the open-loop equivalent are asymp-
totically stable. We now consider the steady-state tracking properties of both
control systems. Since the systems have equal transmissions and equal
transfer matrices from the reference variable to the plant input, their steady-
state mean square tracking errors and mean square input are also equal.
This explains the name steady-state equivalent. This also means that from
the point of view of tracking performance there is no need to resort to closed-
loop control.
We proceed to the transient properties. Since among the characteristic
values of the open-loop equivalent control system the characteristic values
of the plant appear unchanged, obviously no improvement in the transient
properties can be obtained by open-loop control, in contrast to closed-loop
control. By transient properties we mean the response of the control system
to nonzero initial conditions of the plant.
Next we consider the effect of disturbances. As in Section 2.7, we assume
that the disturbance variable can be written as the sum of a constant and a
variable part. Since in the multivariable case we can write for the contri-
bution of the disturbance variable to the controlled variable in the closed-loop
system
Z(s) = [I + H(s)G(s)]“ D(sI — AV, (s), 2-194
it follows that the contribution of the disturbance variable to the mean
square tracking error of the closed-loop system can be expressed as
C,. (with disturbance) — C,,, (without disturbance)
= tr /S7(0)%S(0)W, + | ” S(jo)Z,q(o)S7(—jo)W, df\, 2-195
2.10 Open-Loop Steady-State Equivalence 185
where we have used the results of Sections 1.10.3 and 1.10.4, and where
S(s) = [ + H(s)G(s)T",
Xi o(@) = D(jol — AY"D,,(w)(—jol — AT)'D?, 2-196
Vo = D(—A)E{v,.05\(—A7)*D*.
In analogy with the single-input single-output case, S(s) is called the
sensitivity matrix of the system. The matrix A is assumed to be nonsingular.
Let us now consider the equivalent open-loop system. Here the contri-
bution of the disturbance to the controlled variable is given by
Z(s) = D(sI — A)>V,(s). 2-197
Assuming that the open-loop equivalent control system is asymptotically
stable, it is easily seen that the increase in the steady-state mean square
tracking error due to the disturbance in the open-loop system can be expressed
as
C,.. (with disturbance) — C,,, (without disturbance)
a [Wer +] X,9(@) W, if}. 2-198
We see from 2-198 that the increase in the mean square tracking error is
completely independent of the controller, hence is not affected by the open-
loop control system design. Clearly, in an open-loop control system disturbance
reduction is impossible.
Since the power spectral density matrix &,,(@) may be ill-known, it is of
some interest to establish whether or not there exists a condition that
guarantees that in a closed-loop control system the disturbance is reduced as
compared to the open-loop equivalent irrespective of &,,. Let us rewrite the
increase 2-195 in the mean square tracking error of a closed-loop system as
follows:
C,., (with disturbance) — C,,, (without disturbance)
= tr {S7(0)W,S(0)Vo +| S7(—jw)W,S(jo)Z,(@) df}, 2-199
where S(s) is the sensitivity matrix of the system. A comparison with 2-198
leads to the following statement.
Theorem 2.1. Consider a time-invariant asymptotically stable closed-loop
control system where the controlled variable is also the observed variable and
where the plant is asymptotically stable. Then the increase in the steady-state
mean square tracking error due to the plant disturbance is less than or
186 Analysis of Linear Control Systems
at least equal to that for the open-loop steady-state equivalent, regardless of
the properties of the plant disturbance, if and only if
S7T(—jo)W,S(jo) < W, for all real w. 2-200
The proof of this theorem follows from the fact that, given any two non-
negative-definite Hermitian matrices M, and Mg, then M, > M, implies
and is implied by tr (M,N) > tr (M,N) for any nonnegative-definite Her-
mitian matrix N.
The condition 2-200 is especially convenient for single-input single-output
systems, where S(s) is a scalar function so that 2-200 reduces to
|S(jo)| < 1 for all real w. 2-201
Usually, it is simpler to verify this condition in terms of the return difference
function
1
DS) =a es G(s): 2-202
(s) 5 (s)G(s)
With this we can rewrite 2-201 as
|[J(jo)| > 1 for all real w. 2-203
Also, for multiinput multioutput systems it is often more convenient to
verify 2-200 in terms of the return difference matrix
J(s) = S1(s) = 1+ HA(s)G(s). 2-204
In this connection the following result is useful.
Theorem 2.2. Let J(s) = S~\(s). Then the three following statements are
equivalent:
(a) S™(—jo)W.S(jo) < W.,
(b) J7(—jw)W,J(jw) > W., 2-205
(c) J(jo)WOI"(—jo) > Wo.
The proof is left as an exercise.
Thus we have seen that open-loop systems are inferior to closed-loop
control systems from the point of view of disturbance reduction. In all
fairness it should be pointed out, however, that in open-loop control systems
the plant disturbance causes no increase in the mean square input.
The next item of consideration is the effect of observation noise. Obviously,
in open-loop control systems observation noise does not affect either the
mean square tracking error or the mean square input, since there is no feed-
back link that introduces the observation noise into the system. In this
respect the open-loop equivalent is superior to the closed-loop system.
2.10 Open-Loop Steady-State Equivalence 187
Our final point of consideration is the sensitivity to plant variations. Let
us first consider the single-input single-output case, and let us derive the
mean square tracking error attributable to a plant variation for an open-loop
control system. Since an open-loop control system has a unity sensitivity
function, it follows from 2-184 that under the assumptions of Section 2.9
the mean square tracking error resulting from a plant variation is given by
C,. (open-loop) ~ |AH(0)N;(0)|? Ry + | ” |AH(jo)No(joo)[? E,(c) df.
2-206
Granting that N,(s) is decided upon from considerations involving the
nominal mean square tracking error and input, we conclude from this
expression that the sensitivity to a plant transfer function variation of an
open-loop control system is not influenced by the control system design.
Apparently, protection against plant variations cannot be achieved through
open-loop control.
For the closed-loop case, the mean square tracking error attributable to
plant variations is given by 2-184:
C,.. (closed-loop) ~ |S (0)|? |AH(0)N,(0)|? Ro
+ [Isso AMUN oP Eo) af. 2-207
A comparison of 2-206 and 2-207 shows that the closed-loop system is
always less sensitive to plant variations than the equivalent open-loop system,
no matter what the nature of the plant variations and the properties of the
reference variable are, if the sensitivity function satisfies the inequality
ISo(j@)| < 1 for all w. 2-208
Thus we see that the condition that guarantees that the closed-loop system is
less sensitive than the open-loop system to disturbances also makes the
system less sensitive to plant variations.
In the case of disturbance attenuation, the condition 2-208 generalizes to
So7(—jo)W,S(jo) << W., for all a, 2-209
for the multivariable case. It can be proved (Cruz and Perkins, 1964;
Kreindler, 1968a) that the condition 2-209 guarantees that the increase in the
steady-state mean square tracking error due to (small) plant variations
in a closed-loop system is always less than or equal to that for the open-loop
steady-state equivalent, regardless of the nature of the plant variation and the
properties of the reference variable.
188 Analysis of Linear Control Systems
We conclude this section with Table 2.2, which summarizes the points of
agreement and difference between closed-loop control schemes and their
open-loop steady-state equivalents.
Table 2.2 Comparison of Closed-Loop and Open-Loop Designs
Feature Closed-loop design
Stability
Unstable plant can be
stabilized
Open-loop steady-state
equivalent
Unstable plant cannot
be stabilized
Steady-state mean square
tracking error and
input attributable to
reference variable
Transient behavior
Identical performance if the
plant is asymptotically stable.
Effect of disturbances
Effect of observation
noise
Effect of plant
variations
Great improvement in
response to initial
conditions is possible
Effect on mean square
tracking error can be
greatly reduced; mean
square input is
increased
Both mean square
tracking error and
mean square input are
increased
Effect on mean square
tracking error can be
greatly reduced
No improvement in
response to initial
conditions is possible
Full effect on mean
square tracking error;
mean square input is
not affected
No effect on mean square
tracking error or mean
square input
Full effect on mean
square tracking error
2.11 CONCLUSIONS
In this chapter we have given a description of control problems and of the
various aspects of the performance of a control system. It has been shown
that closed-loop control schemes can give very attractive performances.
Various rules have been developed which can be applied when designing
a control system.
Very little advice has been offered, however, on the question how to
select the precise form of the controller. This problem is considered in the
2.12 Problems 189
following chapters. We formulate the problem of finding a suitable com-
promise for the requirement of a small mean square tracking error without
an overly large mean square input as a mathematical optimization problem.
This optimization problem will be developed and solved in stages in Chapters
3-5. Its solution enables us to determine, explicitly and quantitatively, suitable
control schemes.
2.12 PROBLEMS
2.1. The control of the angular velocity of a motor
Consider a dc motor described by the differential equation
dc(t
J a + Be(t) = m(t), 2-210
where c(t) is the angular velocity of the motor, m(t) the torque applied to the
shaft of the motor, J the moment of inertia, and B the friction coefficient.
Suppose that
m(t) = ku(t), 2-211
where u(t) is the electric voltage applied to the motor and k the torque
coefficient. Inserting 2-211 into 2-210, we write the system differential
equation as
HD + ac(t) = xu(t). 2-212
dt
The following numerical values are used:
a =0.5s1, K = 150 rad/(Vs*), J=0.01 kgm’. 2-213
It is assumed that the angular velocity is both the observed and the controlled
variable. We study the simple proportional control scheme where the input
voltage is given by
u(t) = —Ac(t) + pr(t). 2-214
Here r(t) is the reference variable and / and p are gains to be determined.
The system is to be made into a tracking system.
(a) Determine the values of the feedback gain A for which the closed-loop
system is asymptotically stable.
(b) For each value of the feedback gain A, determine the gain p such that
the tracking system exhibits a zero steady-state error response to a step in
the reference variable. In the remainder of the problem, the gain p is always
chosen so that this condition is satisfied.
(c) Suppose that the reference variable is exponentially correlated noise
with an rms value of 30 rad/s and a break frequency of | rad/s. Determine the
190 Analysis of Linear Control Systems
feedback gain such that the rms input voltage to the de motor is 2 V. What is
the rms tracking error for this gain? Sketch a Bode plot of the transmission
of the control system for this gain. What is the 10% cutoff frequency?
Compare this to the 10% cutoff frequency of the reference variable and
comment on the magnitude of the rms tracking error as compared to the
rms value of the reference variable. What is the 10% settling time of the
response of the system to a step in the reference variable?
(d) Suppose that the system is disturbed by a stochastically varying torque
on the shaft of the dc motor, which can be described as exponentially
correlated noise with an rms value of 0.1732 N m and a break frequency of
1 rad/s. Compute the increases in the steady-state mean square tracking
error and mean square input attributable to the disturbance for the values of
A and p selected under (c). Does the disturbance significantly affect the per-
formance of the system?
(e) Suppose that the measurement of the angular velocity is afflicted by
additive measurement noise which can be represented as exponentially
correlated noise with an rms value of 0.1 rad/s and a break frequency of
100 rad/s. Does the measurement noise seriously impede the performance of
the system?
(f) Suppose that the dc motor exhibits variations in the form of changes
in the moment of inertia J, attributable to load variations. Consider the off-
nominal values 0.005 kg m? and 0.02 kg m? for the moment of inertia. How
do these extreme variations affect the response of the system to steps in the
reference variable when the gains A and p are chosen as selected under (c)?
2.2. A decoupled control system design for the stirred tank
Consider the stirred tank control problem as described in Examples 2.2
(Section 2.2.2) and 2.8 (Section 2.5.3). The state differential equation of the
plant is given by
—0.01 0 1 1
a(t) ( no + ( Ju 2-215
0 —0.02 —0.25 0.75
and the controlled variable by
0.01 0
at) = ( }a0. 2-216
0 1
(a) Show that the plant can be completely decoupled by choosing
u(t) = Qu'(t), 2-217
where Q is a suitable 2 x 2 matrix and where u’(t) = col [u;(0), 43()] is a
new input to the plant.
2.12 Problems 191
(b) Using (a), design a closed-loop control system, analogous to that
designed in Example 2.8, which is completely decoupled, where 7(0) = J,
and where each link has a 10% cutoff frequency of 0.01 rad/s.
2.3. Integrating action
Consider a time-invariant single-input single-output plant where the
controlled variable is also the observed variable, that is, C = D, and which
has a nonsingular A-matrix. For the suppression of constant disturbances,
the sensitivity function S(jw) should be made small, preferably zero, at
w = 0. S(s) is given by ;
S(s) 2-218
1+ H(s)G(s)’
where H(s) is the plant transfer function and G(s) the controller transfer
function (see Fig. 2.25). Suppose that it is possible to find a rational function
Q(s) such that the controller with transfer function
G(s) = 265) 2-219
makes the closed-loop system asymptotically stable. We say that this con-
troller introduces integrating action. Show that for this control system
S(0) = 0, provided H(0)Q(0) is nonzero. Consequently, controllers with
integrating action can completely suppress constant disturbances.
2.4*. Constant disturbances in plants with a singular A-matrix
Consider the effect of constant disturbances in a control system satisfying
the assumptions 1 through 5 of Section 2.7, but where the matrix A of the
plant is singular, that is, the plant contains integration.
(a) Show that the contribution of the constant part of the disturbance to
the steady-state mean square tracking error can be expressed as
lim E{v4(—sI — AT) D*®S(—s)S(s)D(sI — A), 9}. 2-220
s>0
We distinguish between the two cases (b) and (c).
(b) Assume that the disturbances enter the system in such a way that
lim D(sI — A)~v59 2-221
s70
is always finite. This means that constant disturbances always result in
finite, constant equivalent errors at the controlled variable despite the
integrating nature of the plant. Show that in this case
(i) Design Objective 2.5 applies without modification, and
Thy SO) Oy ided
eS ee DABreH lim sH(s)G(s) 2-222
s70
is nonzero.
192 Analysis of Linear Control Systems
Here H(s) is the plant transfer function and G(s) the transfer function in the
feedback link (see Fig. 2.25). This result shows that in a plant with integration
where constant disturbances always result in finite, constant equivalent errors
at the controlled variable, constant disturbances are completely suppressed
(provided 2-222 is satisfied, which implies that neither the plant nor the
controller transfer function has a zero at the origin).
(c) We now consider the case where 2-221 is not finite. Suppose that
lim s*D(sI — A)~‘v,o 2-223
s70
is finite, where k is the least positive integer for which this is true. Show that
in this case
2-224
should be made small, preferably zero, to achieve a small constant error at
the controlled variable. Show that 2-224 can be made equal to zero by letting
i
G(s) == Q(s), 2-225
sk mo+
— 1
where Q(s) is a rational function of s such that Q(0) # 0 and Q(0) ¥ &,
and where my is the least integer m such that
lim s”H(s) 2-226
s70
is finite.
3 OPTIMAL LINEAR STATE
FEEDBACK CONTROL SYSTEMS
3.1 INTRODUCTION
In Chapter 2 we gave an exposition of the problems of linear control theory.
In this chapter we begin to build a theory that can be used to solve the prob-
lems outlined in Chapter 2. The main restriction of this chapter is that we
assume that the complete state x(t) of the plant can be accurately measured
at all times and is available for feedback. Although this is an unrealistic
assumption for many practical control systems, the theory of this chapter will
prove to be an important foundation for the more general case where we do
not assume that x(t) is completely accessible.
Much attention of this chapter is focused upon regulator problems, that
is, problems where the goal is to maintain the state of the system at a desired
value. We shall see that linear control theory provides powerful tools for
solving such problems. Both the deterministic and the stochastic versions of
the. optimal linear regulator problem are studied in detail. Important ex-
tensions of the regulator problem—the nonzero set point regulator and the
optimal linear tracking problem—also receive considerable attention.
Other topics dealt with are the numerical solution of Riccati equations,
asymptotic properties of optimal control laws, and the sensitivity of linear
optimal state feedback systems.
3.2 STABILITY IMPROVEMENT OF LINEAR
SYSTEMS BY STATE FEEDBACK
3.2.1 Linear State Feedback Control
In Chapter 2 we saw that an important aspect of feedback system design is
the stability of the control system. Whatever we want to achieve with the
control system, its stability must be assured. Sometimes the main goal of a
feedback design is actually to stabilize a system if it is initially unstable, or
to improve its stability if transient phenomena do not die out sufficiently fast.
193
194 Optimal Linear State Feedback Control Systems
The purpose of this section is to investigate how the stability properties of
linear systems can be improved by state feedback.
Consider the linear time-varying system with state differential equation
é(t) = A(t)u(t) + B(t)u(t). 3-1
If we suppose that the complete state can be accurately measured at all times,
it is possible to implement a linear control law of the form
u(t) = —F(t)a(t) + u'(t), 3-2
where F(t) is a time-varying feedback gain matrix and u'(t) a new input. If
this control law is connected to the system 3-1, the closed-loop system is
described by the state differential equation
&(t) = [A(t) — BO FO) + BO)u'(2). 3-3
The stability of this system depends of course on the behavior of A(t) and
B(t) but also on that of the gain matrix F(t). It is convenient to introduce
the following terminology.
Definition 3.1. The linear control law
u(t) = —F(t)x(t) + u(t) 3-4
is called an asymptotically stable control law for the system
a(t) = A(t)x(t) + B(t)u(t) 3-5
if the closed-loop system
is asymptotically stable.
&(t) = [AW) — BO) FO (1) + BO)u'() 3-6
If the system 3-5 is time-invariant, and we choose a constant matrix F, the
stability of the control law 3-4 is determined by the characteristic values of
the matrix A — BF. In the next section we find that under a mildly re-
strictive condition (namely, the system must be completely controllable), all
closed-loop characteristic values can be arbitrarily located in the complex
plane by choosing F suitably (with the restriction of course that complex
poles occur in complex conjugate pairs). If all the closed-loop poles are placed
in the left-half plane, the system is of course asymptotically stable.
We also see in the next section that for single-input systems, that is,
systems with a scalar input uw, usually a unique gain matrix F is found for a
given set of closed-loop poles. Melsa (1970) lists a FORTRAN computer
program to determine this matrix. In the multiinput case, however, a given
set of poles can usually be achieved with many different choices of F.
3.2 Stability Improvement by State Feedback 195
Example 3.1. Stabilization of the inverted pendulum
The state differential equation of the inverted pendulum positioning system
of Example 1.1 (Section 1.2.3) is given by
0 1 0 O 0
Gone - 0 0
oh). 0 0 01 x(t) + 0 M(t). 3-7
St sie 2 26 0
Tg, IE
Let us consider the time-invariant control law
w(t) = —(¢,, po, 3, fa) x(t). It follows that for the system 3-7 and control law 3-8 we have
3-8
0 1 0 0
th _Ftds _$ _ de
M M M M
A — BF = 0 0 0 1 ; 3-9
Be ‘ con Te
1; ie
The characteristic polynomial of this matrix is
4 3F + $2 o(fi 8 F + ¢2+ $48 gi + $5 8
SS Mee ee eee a ee ee
M M UL M L M UL
Now suppose that we wish to assign all closed-loop poles to the location —«.
Then the closed-loop characteristic polynomial should be given by
(s + a)* = st + 4as® + 607s* + 4a3s + a4. 3-11
Equating the coefficients of 3-10 and 3-11, we find the following equations
in 1; ho, Ps, and pa: P +o yg
M
a ee
eee 3-12
Fe Gat Oak 4a’
SS SS ee = ES
M L
bi + $38 4
ee ae Os
M UL
196 Optimal Linear State Feedback Control Systems
With the numerical values of Example 1.1 and with « = 3 s~+, we find from
these linear equations the following control law:
u(t) = —(65.65, 11.00, —72.60, —21.27)x(2). 3-13
Example 3.2. Stirred tank
The stirred tank of Example 1.2 (Section 1.2.3) is an example of a multi-
input system. With the numerical values of Example 1.2, the linearized state
differential equation of the system is
—0.01 0 ( l 1 W) at
Owes a(t) + u(t). -
) 0 —0.02 —0.25 0.75
Let us consider the time-invariant control law
iGy= = ie 5 et. 3-15
for Poo
It follows from 3-14 and 3-15 that the closed-loop characteristic polynomial
is given by
det (sl ae A aa BF) = se + s(0.03 + dir aa 0.25¢15 + doy os 0.7522)
al (0.0002 ob 0.0241, = 0.002545 + 0.02¢.; + 0.0075¢55 + P1192 is i201).
3-16
We can see at a glance that a given closed-loop characteristic polynomial
can be achieved for many different values of the gain factors ¢,;. For example,
the three following feedback gain matrices
ilesll! Bier 0 0 0.1 O
Fi= ’ Ff, = and Fi=
0 0 1.1 —1.2333 0 0.1
3-17
all yield the closed-loop characteristic polynomial s? + 0.2050s + 0.01295,
so that the closed-loop characteristic values are —0.1025 + j0.04944. We
note that in the control law corresponding to the first gain matrix the second
component of the input is not used, the second feedback matrix leaves the
first component untouched, while in the third control law both inputs con-
trol the system.
In Fig. 3.1 are sketched the responses of the three corresponding closed-
loop systems to the initial conditions
&(0) = 0 m°, &,(0) = 0.1 kmol/m*, 3-18
Note that even though the closed-loop poles are the same the differences in
the three responses are very marked.
197
(3) 43 BWN}IOA JOJUaWaJOU!
SO
(gw)
(3) 43
‘0
(gw)
'3
(3)
(gw)
4S
uF
}
S‘0-
S02
@)
©)
——— 0s
(S)
0S
0
——"
6-4
AS
jOJUaWAaJOU!
(3) 23 UO!}D4}UaIUOD
(3) 23
ot
0
©
ane
0
0
oe, (2
0
Te ‘31
94}
Jo sasuodsoyx dooy-pasoa
0} YURI pedis
DY}
ules yorqpssy
(0) sooljeur
2°7
(q)
(2) $7
“A
(3) °§
@
ee
10
2
ny Om
0
yRIWTUL
= (0)'F SUONIpUOS
‘wo
= (0)*>
©
2
[Od
lame
Gg (Ol
Joy ,u/jouy
94}
198 Optimal Linear State Feedback Control Systems
3.2.2* Conditions for Pole Assignment and Stabilization
In this section we state precisely (1) under what conditions the closed-loop
poles of a time-invariant linear system can be arbitrarily assigned to any
location in the complex plane by linear state feedback, and (2) under what
conditions the system can be stabilized. First, we have the following result.
Theorem 3.1. Consider the linear time-invariant system
z(t) = Ax(t) + Bu(t) with the time-invariant control law
u(t) = —Fa(t) + u'(t). 3-19
3-20
Then the closed-loop characteristic values, that is, the characteristic values of
A — BF, can be arbitrarily located in the complex plane (with the restriction
that complex characteristic values occur in complex conjugate pairs) by
choosing F suitably if and only if the system 3-19 is completely controllable.
A complete proof of this theorem is given by Wonham (1967a), Davison
(1968b), Chen (1968b), and Heymann (1968). Wolovich (1968) considers
the time-varying case. We restrict our proof to single-input systems. Suppose
that the system with the state differential equation
x(t) = Ax(t) + bu(t), 3-21
where y(t) is a scalar input, is completely controllable. Then we know from
Section 1.9 that there exists a state transformation 2’(t) = T—1a(t), where T
is a nonsingular transformation matrix, which transforms the system 3-19
into its phase-variable canonical form:
0) ] 0) a Kenai stale @) @)
0 0. . Te Os veer 0 0
Ae a’ (t) + “++ u(t).
Oi 9 aie Siac ae 0 1 0
— Xp =, oes —On_1 1
3-22
Here the numbers «,, 7 = 0,1,--:,n— 1 are the coefficients of the char-
acteristic polynomial of the system 3-21, that is, det (sJ — A) = s” + a, ys"
"++ + 045 + %. Let us write 3-22 more compactly as
&(t) = A’x'(t) + b’u(t). 3-23
Consider now the linear control law
w(t) = —f'a'(t) + p’(d), 3-24
3.2 Stability Improvement by State Feedback 199
where f’ is the row vector
i cae (fy, Po, tg ees Pn). 3-25
If this control law is connected to the system, the closed-loop system is
described by the state differential equation
&'(t) = (A’ — b’f’)x'(t) + b’p'(t). 3-26
It is easily seen that the matrix A’ — b’f is given by
0 1 (hee a Rigen ee ves 0
0 0 Dia eee eee 0
7 ee ee (COC en
(0 (@) il
i i er eee Eon
3-27
This clearly shows that the characteristic polynomial of the matrix A’ — b’f’
has: the coefficients (a, — ,,5), 1 = 0, 1,.°-* .n — 1. Since the ¢,, 7= 1,
2,°**,M, are arbitrarily chosen real numbers, the coefficients of the closed-
loop characteristic polynomial can be given any desired values, which means
that the closed-loop poles can be assigned to arbitrary locations in the com-
plex plane (provided complex poles occur in complex conjugate pairs).
Once the feedback law in terms of the transformed state variable has been
chosen, it can immediately be expressed in terms of the original state variable
x(t) as follows:
w(t) = —f'2"(t)h + wD) = —f'TO2(t) + w(t) = —fx(t) + w(t). 3-28
This proves that if 3-19 is completely controllable, the closed-loop charac-
teristic values may be arbitrarily assigned. For the proof of the converse of
this statement, see the end of the proof of Theorem 3.2. Since the proof
for multiinput systems is somewhat more involved we omit it. As we have
seen in Example 3.2, for multiinput systems there usually are many solutions
for the feedback gain matrix F for a given set of closed-loop characteristic
values.
Through Theorem 3.1 it is always possible to stabilize a completely con-
trollable system by state feedback, or to improve its stability, by assigning
the closed-loop poles to locations in the left-half complex plane. The theorem
gives no guidance, however, as to where in the left-half complex plane the
closed-loop poles should be located. Even more uncertainty occurs in the
multiinput case where the same closed-loop pole configuration can be
achieved by various control laws. This uncertainty is removed by optimal
linear regulator theory, which is discussed in the remainder of this chapter.
200 Optimal Linear State Feedback Control Systems
Theorem 3.1 implies that it is always possible to stabilize a completely
controllable linear system. Suppose, however, that we are confronted with
a time-invariant system that is not completely controllable. From the dis-
cussion of stabilizability in Section 1.6.4, it can be shown that stabilizability,
as the name expresses, is precisely the condition that allows us to stabilize
a not completely controllable time-invariant system by a time-invariant
linear control law (Wonham, 1967a):
Theorem 3.2. Consider the linear time-invariant system
a(t) = Ax(t) + Bu(t) 3-29
with the time-invariant control law
u(t) = —Fa(t) + u(t). 3-30
Then it is possible to find a constant matrix F such that the closed-loop system
is asymptotically stable if and only if the system 3-29 is stabilizable.
The proof of this theorem is quite simple. From Theorem 1.26 (Section
1.6.3), we know that the system can be transformed into the controllability
canonical form
Aw PAM B!
a(t) = | o Je Ep ( ‘ue 3-31
0 Abs 0
where the pair {Aj,, By} is completely controllable. Consider the linear con-
trol law
u(t) = —(Fy, F5)a'(t) + u(t). For the closed-loop system we find
3-32
x = x —_ : 9) x u(t
i(t) as | (t) WG Fi)a'(t) + Gy (t)
vane te i ae 0
Ai, — BUF; Aly — BiF3\ Bi
= x(t) + u'(t). 3-33
0 Ai 0
The characteristic values of the compound matrix in this expression are the
characteristic values of Aj, — BF, together with those of Aj.. Now if the
system 3-29 is stabilizable, A}. is asymptotically stable, and since the pair
{Aj,, Bj} is completely controllable, it is always possible to find an Fj such
that Ai, — BiF; is stable. This proves that if 3-29 is stabilizable it is always
possible to find a feedback law that stabilizes the system. Conversely, if one
can find a feedback law that stabilizes the system, 45. must be asymptotically
stable, hence the system is stabilizable. This proves the other direction of the
theorem.
3.3. The Deterministic Linear Optimal Regulator 201
The proof of the theorem shows that, if the system is stabilizable but not
completely controllable, only some of the closed-loop poles can be arbitrarily
located since the characteristic values of Aj, are not affected by the control
law. This proves one direction of Theorem 3.1.
3.3 THE DETERMINISTIC LINEAR OPTIMAL
REGULATOR PROBLEM
3.3.1 Introduction
In Section 3.2 we saw that under a certain condition (complete control-
lability) a time-invariant linear system can always be stabilized by a linear
feedback law. In fact, more can be done. Because the closed-loop poles can
be located anywhere in the complex plane, the system can be stabilized;
but, moreover, by choosing the closed-loop poles far to the left in the com-
plex plane, the convergence to the zero state can be made arbitrarily fast.
To make the system move fast, however, large input amplitudes are required.
In any practical problem the input amplitudes must be bounded; this imposes
a limit on the distance over which the closed-loop poles can be moved to the
left. These considerations lead quite naturally to the formulation of an
optimization problem, where we take into account both the speed of con-
vergence of the state to zero and the magnitude of the input amplitudes.
To introduce this optimization problem, we temporarily divert our atten-
tion from the question of the pole locations, to return to it in Section 3.8.
Consider the linear time-varying system with state differential equation
a&(t) = A(t)x(t) + B(t)u(t), 3-34
and let us study the problem of bringing this system from an arbitrary initial
state to the zero state as quickly as possible (in Section 3.7 we consider the
case where the desired state is not the zero state). There are many criteria
that express how fast an initial state is reduced to the zero state; a very useful
one is the quadratic integral criterion
1 i a (t)R,(t)x(t) dt. 3-35
to
Here R,(t) is a nonnegative-definite symmetric matrix. The quantity
a? (t)R,(t)a(t) is a measure of the extent to which the state at time ¢ deviates
from the zero state; the weighting matrix R,(t) determines how much weight
is attached to each of the components of the state. The integral 3-35 is a
criterion for the cumulative deviation of x(t) from the zero state during the
interval [f,, ¢,].
202 Optimal Linear State Feedback Control Systems
As we saw in Chapter 2, in many control problems it is possible to identify
a controlled variable z(t). In the linear models we employ, we usually have
2(t) = D(t)x(t). 3-36
If the actual problem is to reduce the controlled variable z(t) to zero as
fast as possible, the criterion 3-35 can be modified to
( "2 (t)Re(talt) dt, 3.37
to
where R;(t) is a positive-definite symmetric weighting matrix. It is easily seen
that 3-37 is equivalent to 3-35, since with 3-36 we can write
I "T()R,(t)e(1) dt = { * ePQ)R,(1)x(2) dt, 0 to
3-38
where
R(t) = D7(t)R,(t) D(t). 3-39
If we now attempt to find an optimal input to the system by minimizing
the quantity 3-35 or 3-37, we gererally run into the difficulty that indefinitely
large input amplitudes result. To prevent this we include the input in the
criterion; we thus consider
[crore + u7(t)R,(t)u(t)] dt, 3-40
where R,(t) is a positive-definite symmetric weighting matrix. The inclusion
of the second term in the criterion reduces the input amplitudes if we attempt
to make the total value of 3-40 as small as possible. The relative importance
of the two terms in the criterion is determined by the matrices Rg and R,.
If it is very important that the terminal state x(t,) is as close as possible to
the zero state, it is sometimes useful to extend 3-40 with a third term as follows
[er@rsox + u*(t)R,(t)u(t)] dt + 27 (t))P,2(t,), 3-41
where P, is a nonnegative-definite symmetric matrix.
We are now in a position to introduce the deterministic linear optimal
regulator problem:
Definition 3.2. Consider the linear time-varying system
a(t) = A(t)x(t) + B(t)u(t), 3-42
where
(to) = Xo, 3-43
with the controlled variable
a(t) = D(t)a(t). 3-44
3.3. The Deterministic Linear Optimal Regulator 203
Consider also the criterion
[erorso-@ + u¥(t)R,(t)u(t)] dt + «7 (t,)P,2(t,), 3-45
where P, is a nonnegative-definite symmetric matrix and R,(t) and R,(t) are
positive-definite symmetric matrices for ty) <<t<t,. Then the problem of
determining an input u(t), ty <t<t,, for which the criterion is minimal
is called the deterministic linear optimal regulator problem.
Throughout this chapter, and indeed throughout this book, it is understood
that A(t) is a continuous function of t and that B(t), D(t), R3(t), and R,(t)
are piecewise continuous functions of ¢, and that all these matrix functions
are bounded.
A special case of the regulator problem is the time-invariant regulator
problem:
Definition 3.3. If all matrices occurring in the formulation of the deterministic
linear optimal regulator problem are constant, we refer to it as the time-
invariant deterministic linear optimal regulator problem.
We continue this section with a further discussion of the formulation of
the regulator problem. First, we note that in the regulator problem, as it
stands in Definition 3.2, we consider only the transient situation where an
arbitrary initial state must be reduced to the zero state. The problem formula-
tion does not include disturbances or a reference variable that should be
tracked; these more complicated situations are discussed in Section 3.6.
A difficulty of considerable interest is how to choose the weighting matrices
R;, R,, and P, in the criterion 3-45. This must be done in the following
manner. Usually it is possible to define three quantities, the integrated square
regulating error, the integrated square input, and the weighted square ter-
minal error. The integrated square regulating error is given by
i “FP ()W(de(1) dt, 3-46
0
where W,(t), tp <t<1t,, is a weighting matrix such that 2" (t)W,(t)z(t)
is properly dimensioned and has physical significance. We discussed the
selection of such weighting matrices in Chapter 2. Furthermore, the integrated
square input is given by
ty | u? (t)W,(t)u(t) dt, 3-47
t 0
where the weighting matrix W,,(t), tg < t < 1,, is similarly selected. Finally,
the weighted square terminal error is given by
a? (t,)W,2(t,), 3-48
204 Optimal Linear State Feedback Control Systems
where also W, is a suitable weighting matrix. We now consider various prob-
lems, such as:
1. Minimize the integrated square regulating error with the integrated
square input and the weighted square terminal error constrained to certain
maximal values.
7 2. Minimize the weighted square terminal error with the integrated square
_) input and the integrated square regulating error constrained to certain
” | maximal values.
3. Minimize the integrated square input with the integrated square
regulating error and the weighted square terminal error constrained to
certain maximal values.
All these versions of the problem can be studied by considering the mini-
mization of the criterion
: at ty
(pi | OM) at + ps | WPM (OULD at + pyeTa Welt), 3-49
to to
where the constants p,, p:, and ps are suitably chosen. The expression 3-45
is exactly of this form. Let us, for example, consider the important case where
the terminal error is unimportant and where we wish to minimize the inte-
grated square regulating error with the integrated square input constrained
to a certain maximal value. Since the terminal error is of no concern, we set
p3 = 0. Since we are minimizing the integrated square regulating error, we
take p; = 1. We thus consider the minimization of the quantity
I “EMOWADE) + pau (QW,(Ou(t) at 3-50
The scalar p. now plays the role of a Lagrange multiplier. To determine the
appropriate value of p., we solve the problem for many different values of py.
This provides us with a graph as indicated in Fig. 3.2, where the integrated
square regulating error is plotted versus the integrated square input with
Pz aS a parameter. As p, decreases, the integrated square regulating error
decreases but the integrated square input increases. From this plot we can
determine the value of p, that gives a sufficiently small regulating error with-
out excessively large inputs.
From the same plot we can solve the problem where we must minimize the
integrated square input with a constrained integrated square regulating error.
Other versions of the problem formulation can be solved in a similar manner.
We thus see that the regulator problem, as formulated in Definition 3.2, is
quite versatile and can be adapted to various purposes.
3.3. The Deterministic Linear Optimal Regulator 205
integrated
square
regulating error
See?
P2
integrated squore input ——»
Fig. 3.2. Integrated square regulating error versus integrated square input, with p,; = 1
and p= 0.
We see in later sections that the solution of the regulator problem can be
given in the form of a linear control law which has several useful prop-
erties. This makes the study of the regulator problem an interesting and
practical proposition.
Example 3.3. Angular velocity stabilization problem
As a first example, we consider an angular velocity stabilization problem.
The plant consists of a dc motor the shaft of which has the angular velocity
&(t) and which is driven by the input voltage u(t). The system is described by
the scalar state differential equation
E(t) = —a&(t) + Ku(t), 3-51
where « and « are given constants. We consider the problem of stabilizing
the angular velocity &(t) at a desired value wo. In the formulation of the
general regulator problem we have chosen the origin of state space as the
equilibrium point. Since in the present problem the desired equilibrium
position is &(t) = wo, we shift the origin. Let wy be the constant input voltage
to which w, corresponds as the steady-state angular velocity. Then mw» and
Wo are related by
= —AWy + Ko. 3-52
Introduce now the new state variable
E(t) = €(0) — wp. 3-53
Then with the aid of 3-52, it follows from 3-51 that &'(t) satisfies the state
differential equation E(t) = —ad"(t) + xu’ (0), 3-54
206 Optimal Linear State Feedback Control Systems
where
p(t) = w(t) — Mo. 3-55
This shows that the problem of bringing the system 3-51 from an arbitrary
initial state &(t)) = w, to the state € = w, is equivalent to bringing the system
3-51 from the initial state &(t,) = w, — mz, to the equilibrium state & = 0.
Thus, without restricting the generality of the example, we consider the
problem of regulating the system 3-51 about the zero state. The controlled
variable ¢ in this problem obviously is the state ¢:
C(t) = E(t). 3-56
As the optimization criterion, we choose
} “TCU + pur(t)] dt + mE%(ty), 3-57
with p > 0, 7, > 0. This criterion ensures that the deviations of &(t) from
zero are restricted [or, equivalently, that E(t) stays close to wo], that u(t)
does not assume too large values [or, equivalently, u(t) does not deviate too
much from po], and that the terminal state ¢(t,) will be close to zero [or,
equivalently, that &(t,) will be close to w,]. The values of p and 7, must be
determined by trial and error. For « and « we use the following numerical
values: ;
g = 0554,
x = 150 rad/(V s*), 3-58
Example 3.4. Position control
In Example 2.4 (Section 2.3), we discussed position control by a de motor.
The system is described by the state differential equation
oe a 0
a(t) = i Ja re ( J 3-59
where x(t) has as components the angular position &,(¢) and the angular
velocity &(¢) and where the input variable y(t) is the input voltage to the dc
amplifier that drives the motor. We suppose that it is desired to bring the
angular position to a constant value &,). As in the preceding example, we make
a shift in the origin of the state space to obtain a standard regulator problem.
Let us define the new state variable x’(t) with components
Ex(t) = €,(t) — &40,
E(t) = &(t). Saou
3.3 The Deterministic Linear Optimal Regulator 207
A simple substitution shows that 2’(t) satisfies the state differential equation
0 1 0
att) = | eo - | Jno 3-61
0 -« K
Note that in contrast to the preceding example we need not define a new
input variable. This results from the fact that the angular position can be
maintained at any constant value with a zero input. Since the system 3-61
is identical to 3-59, we omit the primes and consider the problem of regulating
3-59 about the zero state.
For the controlled variable we choose the angular position:
C(t) = €,(¢) = (1, 0)x(?). 3-62
An appropriate optimization criterion is
[eo + pu?(t)] dt. 3-63
The positive scalar weighting coefficient p determines the relative importance
of each term of the integrand. The following numerical values are used for
«and x:
o= 4.654,
Ro OLS) tad) (V/s). 3-64
3.3.2 Solution of the Regulator Problem
In this section we solve the deterministic optimal regulator problem using
elementary methods of the calculus of variations. It is convenient to rewrite
the criterion 3-45 in the form
ty
i [w7(t)R,(t)a(t) + u7(t)R,(t)u(t)] dt + x7(t,)P, a(t), to
3-65
where R,(t) is the nonnegative-definite symmetric matrix
R(t) = DT@)R,()) D(d). 3-66
Suppose that the input that minimizes this criterion exists and let it be de-
noted by u°(t), fy) < t < 4. Consider now the input
u(t) = u(t) + eii(t), Lal li, 3-67
where f(t) is an arbitrary function of time and « is an arbitrary number.
We shall check how this change in the input affects the criterion 3-65. Owing
to the change in the input, the state will change, say from 2°(f) (the optimal
behavior) to
x(t) = w(t) + eX(t), Giese Peet: 3-68
208 Optimal Linear State Feedback Control Systems
This defines #(t), which we now determine. The solution x(t) as given by
3-68 must satisfy the state differential equation 3-42 with u(t) chosen accord-
ing to 3-67. This yields
60(t) + e&(t) = A(t)x(t) + eA(D)E(1) + B(t)Uv(t) + eB(DA(1). 3-69
Since the optimal solution must also satisfy the state differential equation,
we have
4 #°(t) = A(t)x°(t) + B(t)u(t). 3-70
Subtraction of 3-69 and 3-70 and cancellation of « yields
&(t) = A(t)#(t) + BA A(t). 3-71
Since the initial state does not change if the input changes from u(t) to
u(t) + efi(t), th) <t<t,, we have Z(t,) = 0, and the solution of 3-71
using 1-61 can be written as
a(t) = i ‘O(t, 7)B(n)a(r) dr, 3-72
where (tf, fy) is the transition matrix of the system 3-71. We note that %(t)
does not depend upon «. We now consider the criterion 3-65. With 3-67
and 3-68 we can write
1 | [e*()Ri)a(t) + u?()Ra(t)u(t)] dt + x7(t)P,x(t)
to
t1
= | [eP*(OR( a(t) + uP (t)Ra(tu(t)] dt + 2°? (t)Py2"(t)
to
t1
+ 2 { [27 (t)Ry(t)a(t) + @()R(t)u(t)] dt + #7 (nyP.2%(e)]
to
1 .
+ e| i [@7(t)R, (a(t) + A(R (1) aA(1)] dt + mma Pra)} 3-73
to
Since u°(t) is the optimal input, changing the input from u(t) to the input
3-67 can only increase the value of the criterion. This implies that, as a func-
tion of ¢, 3-73 must have a minimum at e = 0. Since 3-73 is a quadratic ex-
pression in ¢, it can assume a minimum for ¢ = 0 only if its first derivative
with respect to « is zero at ¢ = 0. Thus we must have
i “a? (t)Ry(t)2°(t) + a7 (t)R(t)u%(1)] dt + €7(t,)P,x(t,) = 0. 3-74
Substitution of 3-72 into 3-74 yields after an interchange of the order of
3.3. The Deterministic Linear Optimal Regulator 209
integration and a change of variables
ti ti
i (|B [ O7 (7, t)R,(1)2°(r) dr + R,(t)u(t)
0 to
+ B7(t)®7(t,, t)P,x(t;)( dt = 0. 3-75
Let us now abbreviate,
ty
p(t) =| O? (7, t)R,(7)2°(7) dr + OF (t,, t)P,2°(ty). t
3-76
With this abbreviation 3-75 can be written more compactly as
to (| i" (t){B7(t)p(t) + Ro(t)u(t)} dt = 0. 3-77
to
This can be true for every a(t), t) < t < ty, only if
B?(t)p(t) + R,(t)u(t) = 0, tee Rat: 3-78
By the assumption that R,(t) is nonsingular for ty < t < t,, we can write
u(t) = —Rz(t)B7(t)p(t), tp <t<h. 3-79
If p(t) were known, this relation would give us the optimal input at time ¢.
We convert the relation 3-76 for p(t) into a differential equation. First,
we see by setting ¢ = ¢, that
P(ty) = Pyx*(t,). 3-80
By differentiating 3-76 with respect to t, we find
P(t) = —R,(t)x°(t) — A*(t)p(t), where we have employed the relationship [Theorem 1.2(d), Section 1.3.1]
3-81
£ ON, t) = —A*(1)®7(t,, t). 3-82
t
We are now in a position to state the variational equations. Substitution
of 3-79 into the state differential equation yields
2°(t) = A(t)a°(t) — B(t)R2(t)B"(1)p(t). 3-83
Together with 3-81 this forms a set of 2n simultaneous linear differential
equations in the m components of «°(t) and the n components of p(t). We
term p(t) the adjoint variable. The 2n boundary conditions for the differential
equations are
To) 8 3-84
and
p(t) = P,x'(t,). 3-85
210 Optimal Linear State Feedback Control Systems
We see that the boundary conditions hold at opposite ends of the interval
[t,t], which means that we are faced with a two-point boundary value
problem. To solve this boundary value problem, let us write the simultaneous
differential equations 3-83 and 3-81 in the form
BS | A(t) Bp a) Bo a
P(t) —R,(t) —A7(t) p(t)
Consider this the state differential equation of an 2n-dimensional linear
system with the transition matrix O(t, f)). We partition this transition matrix
corresponding to 3-86 as
©1(t, to.) O,2(t, t
ult, to) Ora a Pigs
HE) = |
On(t, to) Ozol(t, to)
With this partitioning we can express the state at an intermediate time ¢ in
terms of the state and adjoint variable at the terminal time ¢, as follows:
x(t) = On (t, t)2°(t) + O2(t, ty)p(ty). With the terminal condition 3-85, it follows
3-88
x(t) = [Ox (t, 4) + Oro(t, t1)Pi}x°(t). Similarly, we can write for the adjoint variable
3-89
P(t) = Ooi (t, 4)2%(t1) + Ooolt, ty )p(ty)
= [Oni(t, 4) + Ono(t, t:)Pi}2°(4). Elimination of x°(t,) from 3-89 and 3-90 yields
3-90
P(t) = [Oar(t, 4) + Ooe(t, H)Pil[Ou(t, 4) + Or(t, 4)Pid12°(t). 3-91
The expression 3-91 shows that there exists a linear relation between p(t)
and x(t) as follows
p(t) = P(t)2°(0), 3-92
where
P(t) = [Oar(t, 1) + Ooo(t, 4) Pi[Ou(t, 4) + Or2(t, Pil. With 3-79 we obtain for the optimal input to the system
3-93
w(t) = —F(t)x(t), 3-94
where
F(t) = Rz'(t)B7(t)P(1). 3-95
This is the solution of the regulator problem, which has been derived under
the assumption that an optimal solution exists. We summarize our findings as
follows.
3.3 The Deterministic Linear Optimal Regulator 211
Theorem 3.3. Consider the deterministic linear optimal regulator problem.
Then the optimal input can be generated through a linear control law of the
form
u(t) = —F(t)x°(0), 3-96
where
F(t) = Rz"(t)B*(t)P(t). 3-97
The matrix P(t) is given by
P(t) = [On(t, 4) + Oroo(t, H)Pi/On(t, 4) + Ont, 4)PiJ7, 3-98
where Ox,(t, to), Qr9(t, to), Ooi(t, to), and Oo0(t, to) are obtained by partitioning
the transition matrix O(t, to) of the state differential equation
a seep pitti elles) ae
PO Ry) —AT(t) p(t)”
where
R,(t) = D7(t)R,(t) D(2). 3-100
This theorem gives us the solution of the regulator problem in the form of a
linear control law. The control law automatically generates the optimal input
for any initial state. A block diagram interpretation is given in Fig. 3.3 which
very Clearly illustrates the closed-loop nature of the solution.
system
feedback
gain
motrix
F(t)
Fig. 3.3. The feedback structure of the optimal linear regulator.
The formulation of the regulator problem as given in Definition 3.2 of
course does not impose this closed-loop form of the solution. We can just as
easily derive an open-loop representation of the solution. At time f) the
expression 3-89 reduces to
%y = [Ou(to, 4) + Oio(to, t,)P,|2°(t). 3-101
212 Optimal Linear State Feedback Control Systems
Solving 3-101 for x°(t,) and substituting the result into 3-90, we obtain
p(t) == [On(t, ty) ar Or(t, t,)P,] [Oi1(to, ty) ots Or2(to, t) Py] x». 3-102
This gives us from 3-79
u(t) = — Rz*(t)B7(t)[Oalt, ty) =: Ooo(t, ty) Py [Oi(to, ty) oh Oro(to, SE ieee:
ists. 3-103
For a given 2, this yields the prescribed behavior of the input. The corre-
sponding behavior of the state follows by substituting x(t,) as obtained from
3-101 into 3-89:
2°(t) = [On(t, tr) + Or(t, tr)Pi]Or(to, 41) + Ore(to, tr)Pil'%- 3-104
In view of what we learned in Chapter 2 about the many advantages of
closed-loop control, for practical implementation we prefer of course the
closed-loop form of the solution 3-96 to the open-loop form 3-103. In Section
3.6, where we deal with the stochastic regulator problem, it is seen that state
feedback is not only preferable but in fact imperative.
Example 3.5. Angular velocity stabilization
The angular velocity stabilization problem of Example 3.3 (Section 3.3.1) is
the simplest possible nontrivial application of the theory of this section. The
combined state and adjoint variable equations 3-99 are now given by
ie —o == ae
Mii) ene ubeg 3-105
The transition matrix corresponding to this system of differential equations
can be found to be
5 oe? (tte) as ee Pte — a lee _ ee
O(t, to) = ? Y py
= = fete = aaa Fuataak ei (t—to) ve Nees ony tt)
an 2y 2y
3-106
where
2
y -/ ier 3-107
p
To simplify the notation we write the transition matrix as
Ont) = (A(t, to) O10(t, * 3-108
O1(t, to) Doo(t, to)
3.3. The Deterministic Linear Optimal Regulator 213
— It follows from 3-103 and 3-104 that in open-loop form the optimal input
and state are given by
« Ooy(t, ty) + Boot, th)
we) = — E,, 3-109
P A1x(to, t1) + Pr2(to, th)
Oii(t, tr) + Or0(t, tym
eG) = 3-110
0:
Dii(to, ty) + Ayo(to, ti)71
Figure 3.4 shows the optimal trajectories and the behavior of the optimal
input for different values of the weighting factor p. The following numerical
values have been used:
cuss,
k = 150 rad/(V s?), 3-111
to = 0 S, ty => 1 Ss.
The weighting coefficient zr, has in this case been set to zero. The figure clearly
shows that as p decreases the input amplitude grows, whereas the settling
time becomes smaller.
Figure 3.5 depicts the influence of the weighting coefficient 7,; the factor
p is kept constant. It is seen that as 77, increases the terminal state tends to be
closer to the zero state at the expense of a slightly larger input amplitude
toward the end of the interval.
Suppose now that it is known that the deviations in the initial state are
usualiy not larger than +100 rad/s and that the input amplitudes should be
limited to +3 V. Then we see from the figures that a suitable choice for p
is about 1000. The value of 7, affects the behavior only near the terminal
time.
Let us now consider the feedback form of the solution. It follows from
Theorem 3.3 that the optimal trajectories of Figs. 3.4 and 3.5 can be generated
by the control law p(t) = —F(DE(), 3-112
where the time-varying scalar gain F(t) is given by
K Oex(t, ty) + O0(t, tym
F(t) = 3-113p A(t, ty) + Oyo(t, tm
Figure 3.6 shows the behavior of the gain F(t) corresponding to the various
numerical values used in Figs. 3.4 and 3.5. Figure 3.6 exhibits quite clearly
that in most cases the gain factor F(t) is constant during almost the whole
interval [f), t,]. Only near the end do deviations occur. We also see that
a, = 0.19 gives a constant gain factor over the entire interval. Such a gain
factor would be very desirable from a practical point of view since the im-
plementation of a time-varying gain is complicated and costly. Comparison
100
ongulor
velocity
E
| T, =0
(pie) p= 10000
50
0 0 0.5 t —= (s) 1
input
voltage
(V)
Fig. 3.4. The behavior of state and input for the angular velocity stabilization problem
for different values of p.
214
ongulor
velocity
4
(rad/s)
input
voltage
Fig. 3.5. The behavior of state and input for the angular velocity stabilization problem
for different values of z,. Note the changes in the vertical scales near the end of the interval
p=100, % =0
P=10000, 1,=0
Fig. 3.6. The behavior of the optimal feedback gain factor for the angular velocity
stabilization problem for various values of p and 7.
215
216 Optimal Linear State Feedback Control Systems
of the curves for 7, = 0.19 in Fig. 3.5 with the other curves shows that there
is little point in letting F vary with time unless the terminal state is very heavily
weighted.
3.3.3 Derivation of the Riccati Equation
We proceed with establishing a few more facts about the matrix P(t)
as given by 3-98. In our further analysis, P(t) plays a crucial role. It is possible
to derive a differential equation for P(t). To achieve this we differentiate
P(t) as given by 3-98 with respect to ¢. Using the rule for differentiating the
inverse of a time-dependent matrix M(t),
<M) = —M-\1)M(t)M~\(0), 3-114
which can be proved by differentiating the identity M(t)M+(t) = J, we
obtain
PO) = [Oor(t, Uae Oso(t, ty) Pi[Ou(t, tr) + Or2(¢, 4) Pil
=a [Oar(t, i a 2 Ooo(t, t)POu(t, 4) + Or(t, 4) Pil+
*[On(t, 4) + Ont, HPO, 1) + Ort, 4)PiJ +, 3-115
where a dot denotes differentiation with respect to ¢. Since @(f, fo) is the
transition matrix of 3-99, we have
O,,(t, ty) a A(t)@4,(t, ty) i. B(t)Rz'()B" (Ox, ty),
Oia) = A(t)O,9(t, th) — B(t)Rz"(t)B7(1)O20(t, ty),
3-116
On) = —R,(t)O(t, ty) — A* (Oot, ty),
On2(t, t) = —R,(t)O,.(t, ty) as A*(1)Oo9(t, t,).
Substituting all this into 3-115, we find after rearrangement the following
differential equation for P(t):
— P(t) = R,(t) — P(t)B(t)Rz(t)B7(t)P(t) + P(t)A(t) + AZ(t)P(t). 3-117
The boundary condition for this differential equation is found by setting
t = ¢, in 3-98. It follows that
P(t,) = Py. 3-118
The matrix differential equation thus derived resembles the well-known
scalar differential equation
a + a(x)y + B(a)y? = y(2), 3-119
where x is the independent and y the dependent variable, and «(x), B(x),
3.3. The Deterministic Linear Optimal Regulator 217
and (x) are known functions of «. This equation is known as the Riccati
equation (Davis, 1962). Consequently, we refer to 3-117 as a matrix Riccati
equation (Kalman, 1960).
We note that since the matrix P, that occurs in the terminal condition for
P(t) is symmetric, and since the matrix differential equation for P(t) is also
symmetric, the solution P(t) must be symmetric for all t) < t < t,. This
symmetry will often be used, especially when computing P.
We now find an interpretation for the matrix P(t). The optimal closed-
loop system is described by the state differential equation
a(t) = [A(t) — B(t)F(t)|x(2). 3-120
Let us consider the optimization criterion 3-65 computed over the interval
[t, t,]. We write
i [x2(r)Ri(r)a(7) + u?(r)Ro(r)u(r)] dr + 27 (t))Pyx(ty)
=_ i “o8(n)[Ry(7) + F4(r)Ro(7)F(r) a(t) dt + x7 (t,)Py2(t,), 3-121
since
u(r) = —F(r)x(7). 3-122
From the results of Section 1.11.5 (Theorem 1.54), we know that 3-121 can
be written as
PEEP ote), 3-123
where P(t) is the solution of the matrix differential equation
— P(t) = R(t) + F7()RAHF()
i + P(t)[A(t) — BY)F()] + [A() — BOF P(), 3-124
wit
P(t,) = P.
Substituting F(t) = Rz"(t)B" (t)P(t) into 3-124 yields
— P(t) = R,(t) + P()B()Rs (NBT()P(t) + P(NA(1)
— P(t)B(t)Ry\()BT() P(t) + AT(1)P(1)
— P(t)B(t)Rz'(t)B7(t)P(t). 3-125
We claim that the solution of this matrix differential equation is precisely
Oats 3-126
218 Optimal Linear State Feedback Control Systems
This is easily seen since substitution of P(t) for P(t) reduces the differential
equation 3-125 to
—P(t) = R,(t) — P(t)B(t)Rz(t)B7(t)P(t) + P(t)A(t) + AT()P(t). 3-127
This is the matrix Riccati equation 3-117 which is indeed satisfied by P(¢);
also, the terminal condition is correct. This derivation also shows that P(t)
must be nonnegative-definite since 3-121 is a nonnegative expression because
R,, R,, and P, are nonnegative-definite.
We summarize our conclusions as follows.
Theorem 3.4. The optimal input for the deterministic optimal linear regulator
is generated by the linear control law
u(t) = —F%(t)x*(t), 3-128
where
F(t) = Rz'(t)B7(t)P(t). 3-129
Here the symmetric nonnegative-definite matrix P(t) satisfies the matrix
Riccati equation
—P(t) = R,(t) — P(t)B()Rz ()B7()P(t) + P(DA(t) + ATP), 3-130
with the terminal condition
and where
Plt =P, 3-131
R,(t) a D* (t)R3(t)D(t).
For the optimal solution we have
| eM) Ry(r)2%r) + u%(2)Ry(rwa)] dr + 2° (4)P, 2%)
= xT (1)P()x(t), t<t,. 3-132
We see that the matrix P(t) not only gives us the optimal feedback law but
also allows us to evaluate the value of the criterion for any given initial state
and initial time.
From the derivation of this section, we extract the following result
(Wonham, 1968a), which will be useful when we consider the stochastic
linear optimal regulator problem and the optimal observer problem.
Lemma 3.1. Consider the matrix differential equation
—P(t) = R,(t) + F™()RAt)F(t) + PLA) — BOF (2)]
+ [A(t) — BIDFO)* PM, 3-133
3.3. The Deterministic Linear Optimal Regulator 219
with the terminal condition
P(t,) = P,, 3-134
where R,(t), Ro(t), A(t) and B(t) are given time-varying matrices of appropriate
dimensions, with R,(t) nonnegative-definite and R,(t) positive-definite for
to St < ty, and P, nonnegative-definite. Let F(t) be an arbitrary continuous
matrix function for ty < t < t,. Then forty <t<t,
POS PO), 3-135
where P(t) is the solution of the matrix Riccati equation
— P(t) = R,(t) — P(t)B(t)Rz'(t)B7(t)P(t) + P(t)A(t) + A7(t1)P(1), 3-136
PG;) = Pj. 3-137
The inequality 3-135 converts into an equality if
F(r) = Ry"(r)B7(1)P(z) ION) < T 3-138
The lemma asserts that P(t) is ““minimized”’ in the sense stated in 3-135 by
choosing F as indicated in 3-138. The proof is simple. The quantity
a? (t)P(t)ax(t) 3-139
is the value of the criterion 3-121 if the system is controlled with the arbitrary
linear control law
u(t) = —F(z)a(r), Sa So 3-140
The optimal control law, which happens to be linear and is therefore also
the best linear control law, yields «”(t)P(t)x(t) for the criterion (Theorem
3.4), so that
a" (t)P(t)a(t) > a7()P(t)x(t) —_—for all x(t). 3-141
This proves 3-135.
We conclude this section with a remark about the existence of the solution
of the regulator problem. It can be proved that under the conditions formu-
lated in Definition 3.2 the deterministic linear optimal regulator problem
always has a unique solution. The existence of the solution of the regulator
problem also guarantees (1) the existence of the inverse matrix in 3-98, and
(2) the fact that the matrix Riccati equation 3-130 with the terminal condition
3-131 has the unique solution 3-98. Some references on the existence of the
solutions of the regulator problem and Riccati equations are Kalman
(1960), Athans and Falb (1966), Kalman and Englar (1966), Wonham
(1968a), Bucy (1967a, b), Moore and Anderson (1968), Bucy and Joseph
(1968), and Schumitzky (1968).
220 Optimal Linear State Feedback Control Systems
Example 3.6. Angular velocity stabilization
Let us continue Example 3.5. P(t) is in this case a scalar function and
satisfies the scalar Riccati equation
2
—P(t) = 1 — — P%(t) — 2aP(t), pP
3-142
with the terminal condition
P(t;) = ™. 3-143
In this scalar situation the Riccati equation 3-142 can be solved directly.
In view of the results obtained in Example 3.5, however, we prefer to use
3-98, and we write
P(t) = Boi(t, ty) + Ooo(t, ty)7 ;
bath: 3-144
O1x(t, ty) + Ar2(t, tr)
with the 6,; defined as in Example 3.5. Figure 3.7 shows the behavior of P(t)
for some of the cases previously considered. We note that P(t), just as the
gain factor F(t), has the property that it is constant during almost the entire
interval except near the end. (This is not surprising since P(t) and F(t) differ
by a constant factor.)
p=10000, T,=0
04
2
(rad 13) 54
0.2
0.1
0 0.5 }
t ——(s)
Fig. 3.7.. The behavior of P(t) for the angular velocity stabilization problem for various
values of p and 7.
3.4 STEADY-STATE SOLUTION OF THE
DETERMINISTIC LINEAR OPTIMAL
REGULATOR PROBLEM
3.4.1 Introduction and Summary of Main Results
In the preceding section we considered the problem of minimizing the criterion
i EZ()R,(t)2(t) + u7(t)R,(t)u(t)] dt + x7 (t,)P,2(t,) 3-145
3.4 Steady-State Solution of the Regulator Problem 221
for the system f
i #(1) = A(Nea(t) + B(tu(t),
z(t) = D(t)a(t), ae
where the terminal time 7, is finite. From a practical point of view, it is often
natural to consider very long control periods [tf , t,]. In this section we there-
fore extensively study the asymptotic behavior of the solution of the deter-
ministic regulator problem as t, — ©.
The main results of this section can be summarized as follows.
1. As the terminal time t, approaches infinity, the solution P(t) of the
matrix Riccati equation
—P(t) = D*(1)R,(t) D(t) — P(t)B()R2"()B7(1)P(t) + AT()P() + P(A),
; P . ae
3-147
with the terminal condition P(t;) = Pr, 3-148
generally approaches a steady-state solution P(t) that is independent of P,.
The conditions under which this result holds are precisely stated in Section
3.4.2. We shall also see that in the time-invariant case, that is, when the
matrices A, B, D, R3, and R, are constant, the steady-state solution P, not
surprisingly, is also constant and is a solution of the algebraic Riccati equa-
tion
0 = D?tR,D — PBR; B*P + A*P + PA. 3-149
It is easily recognized that P is nonnegative-definite. We prove that in general
(the precise conditions are given) the steady-state solution P is the only solu-
tion of the algebraic Riccati equation that is nonnegative-definite, so that it
can be uniquely determined.
Corresponding to the steady-state solution of the Riccati equation, we
obtain of course the steady-state control law
u(t) = —F(t)a(t), 3-150
where
F(t) = Rz()BT(O)P(0). 3-151
It will be proved that this steady-state control law minimizes the criterion
3-145 with t, replaced with oo. Of great importance is the following:
2. The steady-state control law is in general asymptotically stable.
Again, precise conditions will be given. Intuitively, it is not difficult to
understand this fact. Since
| “EZ()Ra(D2t) + ut (1)Re(tu(t)] dt 3-152
0
222 Optimal Linear State Feedback Control Systems
exists for the steady-state control law, it follows that in the closed-loop
system u(t) > 0 and z(t) + 0 as t-> o., In general, this can be true only if
a(t) 0, which means that the closed-loop system is asymptotically stable.
Fact 2 is very important since we now have the means to devise linear
feedback systems that are asymptotically stable and at the same time possess
optimal transient properties in the sense that any nonzero initial state is
reduced to the zero state in an optimal fashion. For time-invariant systems
this is a welcome addition to the theory of stabilization outlined in Section
3.2. There we saw that any time-invariant system in general can be stabilized
by a linear feedback law, and that the closed-loop poles can be arbitrarily
assigned. The solution of the regulator problem gives us a prescription to
assign these poles in a rational manner. We return to the question of the
optimal closed-loop pole distribution in Section 3.8. /
Example 3.7. Angular velocity stabilization
For the angular velocity stabilization problem of Examples 3.3, 3.5, and
3.6, the solution of the Riccati equation is given by 3-144. It is easily found
with the aid of 3-106 that as ft, — o,
py P= 2(-a4 [t+ ©), 3-153
K p
P can also be found by solving the algebraic equation 3-149 which in this case
reduces to :
ey
C= 1=—— fP*—2P. 3-154
p
This equation has the solutions
2
P(—a fo +*). 3-155
K p
Since P must be nonnegative, it follows immediately that 3-153 is the correct
solution.
The corresponding steady-state gain is given by
“| es Ke
a I ire” Ain Ue AY es eal J
id Pp
—*
3-156
By substituting
w(t) = — E(t) 3-157
into the system state differential equation, it follows that the closed-loop
system is described by the state differential equation
eG) = a a” ; &(t). 3-158
3.4 Steady-State Solution of the Regulator Problem 223
Obviously, this system is asymptotically stable.
Example 3.8. Position control
As a more complicated éxample, we consider the position control problem
of Example 3.4 (Section 3.3.1). The steady-state solution P of the Riccati
equation 3-147 must now satisfy the equation
1 _({0\4 A 0 Ove if) 1
0= (14,0) — P| J-O,«)P+ P+P . 3-159
0) k/ p 1 -« 0 -—«
Let P;;, i, 7 = 1, 2, denote the elements of P. Then using the fact that P,. =
P.,, the following algebraic equations are obtained from 3-159
O=1— — 4,
2
P
lin — ~ —
0 = — — PyyPo + Puy — «Pip, 3-160
p
O= = — P+ OP. — FP...
p
These equations have several solutions, but it is easy to verify that the only
nonnegative-definite solution is given by
Py =P = vP 3-161
Fa & i(-«+ + +2s)), p \ Pp
3-162
Thus the input is given by
u(t) = — Fx(t). 3-163
It is easily found that the optimal closed-loop system is described by the
state differential equation
0 i
M=( i | ee De | 200): 3-164
/p /p
224 Optimal Linear State Feedback Control Systems
The closed-loop characteristic polynomial can be computed to be
esate eae. 3-165
The closed-loop characteristic values are
(-Je+ a jas 74), 3-166
2 vp Vo vp
Figure 3.8 gives the loci of the closed-loop characteristic values as p varies.
It is interesting to see that as p decreases the closed-loop poles go to infinity
along two straight lines that make an angle of 7/4 with the negative real axis.
Asymptotically, the closed-loop poles are given by
We aWu-1+/) as p> 0. 3-167
p
Figure 3.9 shows the response of the steady-state optimal closed-loop system
Fig. 3.8. Loci of the closed-loop roots of the position control system as a function of p.
3.4 Steady-State Solution of the Regulator Problem 225
ongulor 0.1
position
C(t)
(rad)
0 05 input °
voltage
u(t)
Sls)
Fig. 3.9. Response of the optimal position control system to the initial state £,(0) =
0.1 rad, €.(0) = O rad/s.
corresponding to the following numerical values:
K= 0.787 rad/(V S),
«= 4,6 5-1, ae
p = 0.00002 rad?/V?.
The corresponding gain matrix is
Pi ==(223,0, 18-09), 3-169
while the closed-loop poles can be computed to be —9.658 + j9.094. We
observe that the present design is equivalent to the position and velocity
feedback design of Example 2.4 (Section 2.3). The gain matrix 3-169 is
optimal from the point of view of transient response. It is interesting to note
that the present design method results in a second-order system with relative
damping of nearly 1/2, which is exactly what we found in Example 2.7
(Section 2.5.2) to be the most favorable design.
To conclude the discussion we remark that it follows from Example 3.4
that if x(t) is actually the deviation of the state from a certain equilibrium
state v which is not the zero state, x(t) in the control law 3-163 should be re-
placed with 2’(t), where
ee = ia
a(t) = ; 3-170
54(t)
226
aduUajajas
+ Olg uoizisod
‘wiasXs [o1}U0D uoNIsod Jeumjdo oy} Jo WeIseIp ~Oo[g ‘OLE “BI
(3) 3603)]0A
}ndul
'§ uoiqisod joyn6uo
9-Pp (3)
Jatyi7dwo
(223 Azi007
a0 Jo,n6uo
-OtjUa}od
Jaj}auw
3.4 Steady-State Solution of the Regulator Problem 227
Here ¢4o is the desired angular position. This results in the control law
L(t) = —F,[é,(t) — E19) — Fe&(t), 3-171
where F = (F,, F,). The block diagram corresponding to this control law
is given in Fig. 3.10.
Example 3.9. Stirred tank
As another example, we consider the stirred tank of Example 1.2 (Section
1.2.3). Suppose that it is desired to stabilize the outgoing flow F(t) and the
outgoing concentration c(t). We therefore choose as the controlled variable
0.01 0
at) = y(t) = ( 4 at 3-172
where we use the numerical values of Example 1.2. To determine the weight-
ing matrix R3, we follow the same argument as in Example 2.8 (Section
2.5.3). The nominal value of the outgoing flow is 0.02 m3/s. A 10% change
corresponds to 0.002 m?/s. The nominal value of the outgoing concentration
is 1.25 kmol/m’. Here a 10% change corresponds to about 0.1 kmol/m%.
Suppose that we choose R, diagonal with diagonal elements o, and oy.
Then
27 (t)Rae(t) = 0,0,°(t) + o2£2"(t), 3-173
where z(t) = col (¢,(t), ¢,(t)). Then if a 10% change in the outgoing flow is
to make about the same contribution to the criterion as a 10% change in the
outgoing concentration, we must have
o,(0.002)? ~ o,(0.1)?, 3-174
or
71 ~ 2500. 3-175
O2
Let us therefore select
o, = 50, oo = $0 3-176
or
50. 6 |0(O
R= , 3-177
Om Or02)
To choose R, we follow a similar approach. A 10% change in the feed F,
corresponds to 0.0015 m3/s, while a 10% change in the feed F, corresponds to
0.0005 m3/s. Let us choose R, = diag (p;, py). Then the 10% changes in F,
and F, contribute an amount of
p,(0.0015)? + p.(0.0005)? 3-178
228
a) (3 @WN}OA
(¢ Ww)
oo =d
0
0S
Oot
(Seat
(923
u01305}2UaDU09
(Sad
ool os 0
aWN}OA
(3)'3
‘0
(¢UW)
U0!}0J}UaDU09
au (3)23
gw
(S)
ool
ool
(3) 8)
[OU paay
(9)
700
LOU peaaj
(3) '11
700
em
700
1 700
(9)
paay
2x1
0 |
Ss zu)
Zou
=
(3) 211 ZOU pea
Ol=xd
S Ca
229
“3
“EEE
jo sasuodsar dooj-pasojg
oy}
JOJ YUR} poLINs poyefnFor
JO SAN[LA SNOLIA
oY}
“4d 1O}ORy SUNYSIOM
yoy
JO
‘aUNJOA [e}UOWIEIOUI
‘*] ‘OU pad} ‘UONBIJUBOUOD
pue
Z “OU padj
01
ay}
938}8 [eNIUI
= (0)
‘(0 ‘T'0)[09
3ysry
‘AUINIOA [e}USUUAIOUI
‘T ‘OU pad} ‘UOT}eI}UBDUOD
puv
Z ‘OU pad}
0}
9Y}
9381S [eI}TUI
= (Q0)#
0) [09
‘(1'0
:uumnyoo
sosuodsay
:uumnyjos
Jo sosuodsoy
230 Optimal Linear State Feedback Control Systems
to the criterion. Both terms contribute equally if
3-179
We therefore select
1 0
Res 3-180
where p is a scalar constant to be determined.
Figure 3.11 depicts the behavior of the optimal steady-state closed-loop
system for p = 00, 10, 1, and 0.1. The case p = 00 corresponds to the open-
loop system (no control at all). We see that as p decreases a faster and faster
response is obtained at the cost of larger and larger input amplitudes. Table
3.1 gives the closed-loop characteristic values as a function of p. We see that
in all cases a system is obtained with closed-loop poles that are well inside the
left-half complex plane.
Table 3.1 Locations of the Steady-State
Optimal Closed-Loop Poles as a Function
of e for the Regulated Stirred Tank
Optimal closed-loop poles
p (s)
roa) —0.01 —0.02
10 —0.02952, —0.04523
1 —0.07517, —0.1379
0.1 —0.2310, —0.4345
We do not list here the gain matrices F found for each value of p, but it
turns out that they are not diagonal, as opposed to what we considered in
Example 2.8. The feedback schemes obtained in the present example are
optimal in the sense that they are the best compromises between the require-
ment of maximal speed of response and the limitations on the input ampli-
tudes.
Finally, we observe from the plots of Fig. 3.11 that the closed-loop system
shows relatively little interaction, that is, the response to an initial disturb-
ance in the concentration hardly affects the tank volume, and vice versa.
3.4.2* Steady-State Properties of Optimal Regulators
In this subsection and the next we give precise results concerning the steady-
state properties of optimal regulators. This section is devoted to the general,
3.4 Steady-State Solution of the Regulator Problem 231
time-varying case; in the next section the time-invariant case is investigated
in much more detail. Most of the results in the present section are due
to Kalman (1960). We more or less follow his exposition.
We first state the following result.
Theorem 3.5. Consider the matrix Riccati equation
— P(t) = D7(t)R,(t) D(t) — P()BO)Rs(NB"()PO) + AT(t)P(t) + P(A)A(D).
3-181
Suppose that A(t) is continuous and bounded, that B(t), D(t), R;(t), and R,(t)
are piecewise continuous and bounded on [t,, ©), and furthermore that
R,(t)> of, R,(t)> Bl, forall t, 3-182
where « and f are positive constants.
(i) Then if the system
#(t) = A(a(t) + BO)u(d),
a(t) = D(t)x(t), 3-183
is either
(a) completely controllable, or
(b) exponentially stable,
the solution P(t) of the Riccati equation 3-181 with the terminal condition
P(t,) = 0 converges to a nonnegative-definite matrix function P(t) as t, > ©.
P(t) is a solution of the Riccati equation 3-181.
(ii) Moreover, if the system 3-183 is either
(c) both uniformly completely controllable and uniformly completely re-
constructible, or
(d) exponentially stable,
the solution P(t) of the Riccati equation 3-181 with the terminal condition
P(t,) = P, converges to P(t) as t; > © for any P, > 0.
The proof of the first part of this theorem is not very difficult. From Theorem
3.4 (Section 3.3.3), we know that for finite 7,
t
a*()P()x() = min {{ e7@)Rk) 2) + u?(r)R2(r)u(r)] dr}. 3-184
ae
Of course this expression is a function of the terminal time ¢,. We first
establish that as a function of ¢, this expression has an upper bound. If the
system is completely controllable [assumption (a)], there exists an input that
transfers the state x(t) to the zero state at some time f¢;. For this input we can
compute the criterion
{ j [27(r)R3(7)2(7) + u7(7)Ro(7)u(z)] dr. 3-185
232 Optimal Linear State Feedback Control Systems
This number is an upper bound for 3-184, since obviously we can take u(t) =
0 for t > ty.
If the system is exponentially stable (Section 1.4.1), x(t) converges ex-
ponentially to zero if we let u(t) = 0. Then
i es (r)R,(r)2(7) + u7(7)R2(7)u(z)] dr = AOR) dr 3-186
converges to a finite number as t, — 00, since D(t) and R;(t) are assumed to
be bounded. This number is an upper bound for 3-184.
Thus we have shown that as a function of ¢, the expression 3-184 has an
upper bound under either assumption (a) or (b). Furthermore, it is reasonably
obvious that as a function of f, this expression is monotonically nonde-
creasing. Suppose that this were not true. Then there must exist a ¢; and ft;
with t{ > t, such that for t, = tj the criterion is smaller than for t, = tj.
Now apply the input that is optimal for ¢7 over the interval [fo, t;]. Since the
integrand of the criterion is nonnegative, the criterion for this smaller interval
must give a value that is less than or equal to the criterion for the larger
interval [f9, t{]. This is a contradiction, hence 3-184 must be a monotonically
nondecreasing function of f,.
Since as a function of t, the expression 3-184 is bounded from above and
monotonically nondecreasing, it must have a limit as t; — oo. Since x(t)
is arbitrary, each of the elements of P(t) has a limit, hence P(t) has a limit
that we denote as P(t). That P(t) is nonnegative-definite and symmetric is
obvious. That P(t) is a solution of the matrix Riccati equation follows by the
continuity of the solutions of the Riccati equation with respect to initial
conditions. Following Kalman (1960), let II(t; P,, t,) denote the solution of
the matrix Riccati equation with the terminal condition P,(t,) = P,. Then
Pt) = lim 1; 0, 4,) = lim EE es Oty ty
te 0 tg 0
== Tifestim 11-07%), 3)
tz 00
== Hire )at 3-187
which shows that P,(t) is indeed a solution of the Riccati equation. The
proof of the remainder of Theorem 3.5 will be deferred for a moment.
We refer to P(t) as the steady-state solution of the Riccati equation. To
this steady-state solution corresponds the steady-state optimal control law
u(t) = — F(t)2(t), 3-188
where
F(t) = Ry\(t)B7(t)P(t). 3-189
3.4 Steady-State Solution of the Regulator Problem 233
Concerning the stability of the steady-state control law, we have the following
result.
Theorem 3.6. Consider the deterministic linear optimal regulator problem
and suppose that the assumptions of Theorem 3.5 concerning A, B, D, R, and
R, are satisfied. Then if the system
a(t) = A(t)x(t) + B(t)u(t), Ce
x(t) = D(t)x(0),
is either
constructible, or
(b) exponentially stable,
the following facts hold:
(i) The steady-state optimal control law
(a) both uniformly completely controllable and uniformly completely re-
u(t) = —Ryz'(t)B7(t)P(t)x(t) 3-191
is exponentially stable.
(li) The steady-state control law 3-191 minimizes
lim | i “EeT)Ra(12(1) + ut (t)R(t)u(t)] dt + Ta Pyxtt) 3-192
ti 0
for all P, > 0. The minimal value of the criterion 3-192, which is achieved by the
steady-state control law, is given by
x"(t))P(to)st( to). 3-193
A rigorous proof of these results is given by Kalman (1960). We only make
the theorem plausible. If condition (a) or (b) of Theorem 3.6 is satisfied, also
condition (a) or (b) of Theorem 3.5 holds. It follows that the solution of the
Riccati equation 3-181 with P(t,) = 0 converges to P(t) as t, > 0. For the
corresponding steady-state control law, we have
| “Ee ()Ra(12(t) + u*()Ro(tu(t)] dt = x7(to)P(to)a(to). 3-194
Since the integral converges and R,(t) and R,(f) satisfy the conditions
3-182, both z(t) and u(t) must converge to zero as tf > 00. Suppose now that
the closed-loop system is not asymptotically stable. Then there exists an
initial state such that x(t) does not approach zero while z(t) + 0 and u(t) > 0.
This is clearly in conflict with the complete reconstructibility of the system if
(a) holds, or with the assumption of exponential stability of the system if
(b) holds. Hence the closed-loop system must be asymptotically stable. That
it moreover is exponentially stable follows from the uniformity properties.
This settles part (i) of the theorem. Part (ii) can be shown as follows. Sup-
pose that there exists another control law that yields a smaller value for
234 Optimal Linear State Feedback Control] Systems
3-192. Because the criterion 3-192 yields a finite value when the steady-state
optimal control law is used, this other control law must also yield a finite
value. Then, by the same argument as for the steady-state control law,
this other control law must be asymptotically stable. This means that for
this control law
lim { “eXOR a(t) + u™(ORAdu(t)) dt + M1 Pret)
t17 © l
= | “EeZ(R,(t)2(1) + u?(t)R,(t)u(t)] dt. 3-195
But since the right-hand side of this expression is minimized by the steady-
state control law, there cannot be another control law that yields a smaller
value for the left-hand side. This proves part (ii) of Theorem 3.6. This more-
over proves the second part of Theorem 3.5, since under assumptions (c)
or (d) of this theorem the steady-state feedback law minimizes the criterion
3-192 for all P,; > 0, which implies that the Riccati equation converges to
P(t) for all P, > 0:
We illustrate the results of this section as follows.
Example 3.10. Reel-winding mechanism
As an example of a simple time-varying system, consider the reel-winding
mechanism of Fig. 3.12. A de motor drives a reel on which a wire is being
ongular
velocity w(t) radius R(t)
axis driven
by d-c motor
wire
speed (C(t)
Fig. 3.12. Schematic representation of a reel-winding mechanism.
wound. The speed at which the wire runs on to the reel is to be kept constant.
Because of the increasing diameter of the reel, the moment of inertia in-
creases; moreover, to keep the wire speed constant, the angular velocity must
decrease. Let w(t) be the angular velocity of the reel, J(t) the moment of
inertia of reel and motor armature, and u(t) the input voltage to the power
amplifier that drives the dc motor. Then we have
“Woo = ku(t) — do(t), 3-196
3.4 Steady-State Solution of the Regulator Problem 235
where « is a constant which expresses the proportionality of the torque of
the motor and the input voltage, and where ¢ is a friction coefficient. Further-
more, let R(t) denote the radius of the reel; then the speed ¢(t) at which the
wire is wound is given by
C(t) = R(t)w(t). 3-197
Let us introduce the state variable
E(t) = J(t)w(t). 3-198
The system is then described by the equations
ees woe
g(t) = — ~~ ot) + Kult),
J(t) Re 3-199
C(t) = 1) E(t).
We assume that the reel speed is so controlled that the wire speed is kept
constant at the value ¢,. The time dependence of J and R can then be esta-
blished as follows. Suppose that during a short time df the radius increases
from R to R + dR. The increase in the volume of wire wound upon the reel
is proportional to R dR. The volume is also proportional to dt, since the wire
is wound with a supposedly constant speed. Thus we have
RdR= c dt, 3-200
where c is a constant. This yields after integration
R(t) = V R20) + At, 3-201
where /: is another constant. However, if the radius increases from R to
R + dR, the moment of inertia increases with an amount that is proportional
to RdR R? = R® dR. Thus we have
dJ = c'R® dR, 3-202
where c’ is a constant. This yields after integration
J(t) = J(0) + A'[RXt) — R*(0)], 3-203
where /’ is another constant.
Let us now consider the problem of regulating the system such that the
wire speed is kept at the constant value ¢). The nominal solution ¢)(¢),
[4o(t) that corresponds to this situation can be found as follows. If ¢)(t) = ¢,
we have
J(t) an 3-204
E,(t) R(t) bo 0
236 Optimal Linear State Feedback Control Systems
The nominal input is found from the state differential equation:
Olerireiecel t ty) + —é ae ue 3-205
L(t) = “| sa ) I(t) o(t) dt\ R(t) R(t)
Let us now define the shifted state, input, and controlled variables:
E(t) = E(t) — S0(t),
b(t) = w(t) — bolt), C(t) = C(t) — Oot).
These variables satisfy the equations
3-206
a os
SG) = E(t) + cu(t
(t) 6 (t) + Ku'(t),
RY) , 3-207
C@) = t
Y= H(i) E"(1).
Let us choose the criterion
[ 120 + pu] dt. 3-208
Then the Riccati equation takes the form
; R*(t) 2 Kk ee
—P(t)= — P(t P(t 3-209
J*(t) oj J(t) 2
with the terminal condition
Bits) 20; 3-210
P(t) is in this case a scalar function. The scalar feedback gain factor is given
by
FQ) =~ PQ), ant
p
We choose the following numerical values:
J(t) = 0.02 + 66.67[R4(t) — R4(0)] kg m?,
R(t) = V0.01 + 0.00051 m,
¢ = 0.01 kg m?/s, k = 0.1 kg m? rad/(V s?),
p = 0.06 m?/(V?s?).
3-212
Figure 3.13 shows the behavior of the optimal gain factor F(t) for the terminal
3.4 Steady-State Solution of the Regulator Problem 237
steady-state portion
of curves
15
gain
F
10
V
pears!
5
0
0 5 10 15 20
+ — (s)
Fig. 3.13. Behavior of the optimal gain factor for the reel-winding problem for various
values of the terminal time ¢}.
times 4; = 10, 15, and 20s. We note that for each value of ¢, the gain ex-
hibits an identical steady-state behavior; only near the terminal time do
deviations occur. It is clearly shown that the steady-state gain is time-
varying. It is not convenient to implement such a time-varying gain. In
the present case a practically adequate performance might probably just as
well be obtained through a time-invariant feedback gain.
3.4.3* Steady-State Properties of the Time-Invariant Optimal
Regulator
In this section we study the steady-state properties of the time-
invariant optimal linear regulator. We are able to state sufficient and neces-
sary conditions under which the Riccati equation has a steady-state solution
and under which the steady-state optimal closed-loop system is stable. Most
of these facts have been given by Wonham (1968a), Lukes (1968), and
Martensson (1971).
Our results can be summarized as follows.
Theorem 3.7. Consider the time-invariant regulator problem for the system
a(t) = Ax(t) + Bu(t),
Aga — Tee A. 3-213
and the criterion
| "EMORAU) + uP(ORau(d)] dt + 27)Pyett,), 3-214
238 Optimal Linear State Feedback Control Systems
with Rz > 0, R, > 0, P; > 0. The associated Riccati equation is given by
— P(t) = D?R,D — P(t)BRz'B*P(t) + A*P(t) + P(t)A, —- 3-215
with the terminal condition
P(t,) = Py. 3-216
(a) Assume that P, = 0. Then as t, > © the solution of the Riccati equation
approaches a constant steady-state value P if and only if the system possesses
no poles that are at the same time unstable, uncontrollable, and reconstructible.
(b) If the system 3-213 is both stabilizable and detectable, the solution of the
Riccati equation 3-215 approaches the unique value P as t;—> © for every
Pe 0,
(c) If P exists, it is a nonnegative-definite symmetric solution of the algebraic
Riccati equation
0 = D7™R,D — PBR;BTP + ATP + PA. S287
If the system 3-213 is stabilizable and detectable, P is the unique nonnegative-
definite symmetric solution of the algebraic Riccati equation 3-217.
(d) If P exists, it is strictly positive-definite if and only if the system 3-213
is completely reconstructible.
(e) If P exists, the steady-state control law
u(t) = — Fx(t), 3-218
where
fis ROB, 3-219
is asymptotically stable if and only if the system 3-213 is stabilizable and
detectable.
law minimizes
(f) If the system 3-213 is stabilizable and detectable, the steady-state control
lim | i ‘e7()Rez(t) + u(t)Rou(t)] dt + Ma Pyx(t)| 3-220
ti a
for all P, > 0. For the steady-state control law, the criterion 3-220 takes the
value
ii w(t Pw ty). 3-221
We first prove part (a) of this theorem. Suppose that the system is not com-
pletely reconstructible. Then it can be transformed into reconstructibility
canonical form as follows.
Ay 'O B,
{ «= ( Ja + | Ju 3-222
Ay Ags B,
| A =(D, — Opals, ‘ee
3.4 Steady-State Solution of the Regulator Problem 239
where the pair {A;,, D,} is completely reconstructible. Partitioning the solu-
tion P(t) of the Riccati equation 3-215 according to the partitioning in 3-222
as Prt) P(t)
sal
e , 3-223
Pyx(t) P2o(t)
it is easily found that the Riccati equation 3-215 reduces to the following three
matrix equations
—P,,(t) = D,*R,D, am [Pii(t)B, cu P;.(t)Bo|Ro”
‘ [By7 P,,(2) a By PEGI + AfP,,(t)
+ AZPZ(t) + Pull Ay + Pilt) Ao, 3-224
—P,(t) = —[Py(t)By + Pyo(t)By]R2"[B,"Py2(t) + By” P29(t)]
+ AZP,(t) + Af Po(t) + Pro(t)Age, 3-225
—P,,(t) = —[Ph(t)B, + Poo(t)Bo]Ro [By Pis(t) + By” Po9(t)]
+ AzpPoo(t) + Poo(t)Are. 3-226
It is easily seen that with the terminal conditions P,,(t,) = 0, Py.(t,) = 0,
and P..(t,) = 0 Eqs. 3-225 and 3-226 are satisfied by
Pat) — 0, Poth) = 0, t < ty. 3-227
With these identities 3-224 reduces to
—P,(t) = D7 R,D, — Py(t)B,R2' By P(t) + AnPu(t) + Pult)Au,
P,,(t,) = 0. 3-228
It follows from this that the unreconstructible poles of the system, that is,
the characteristic values of A,., do not affect the convergence of P,,(t) as
t, > 00, hence that the convergence of P(t) is also not affected by the un-
reconstructible poles. To investigate the convergence of P(t), we can therefore
as well assume for the time being that the system 3-213 is completely re-
constructible.
Let us now transform the system 3-213 into controllability canonical
form and thus represent it as follows:
( As oo (°
ag) = a(t) + u(t), 3-229
On nee 0
At) =(D,, Dz) x(t),
where the pair {A,,, B,} is completely controllable. Suppose now that the
system is not stabilizable so that A,, is not asymptotically stable. Then
240 Optimal Linear State Feedback Control Systems
obviously there exist initial states of the form col (0, 29) such that #(t) > o
no matter how u(t) is chosen. By the assumed complete reconstructibility,
for such initial states
i ie (t)R32(t) + u7(t)Rau(t)] dt 3-230
will never converge to a finite number as t, + 00. This proves that P(t) also
will not converge to a finite value as ¢,; + 00 if the system 3-213 is not stabiliz-
able. However, if 3-213 is stabilizable, we can always find a feedback law '
that makes the closed-loop system stable. For this feedback law 3-230 con-
verges to a finite number as t, + 00; this number is an upper bound for the
minimal value of the criterion. As in Section 3.4.2, we can argue that the
minimal value of 3-230 is a monotonically nondecreasing function of 4.
This proves that the minimal value of 3-230 has a limit as t; — 00, hence that
P(t) as solved from 3-215 with P(t,) = 0 has a limit P as t,-> 00. This
terminates the proof of part (a) of the theorem.
We defer the proof of parts (b) and (c) for a moment. Part (d) is easily
recognized to be valid. Suppose that the system is not completely recon-
structible. Then, as we have seen in the beginning of the proof of (a), when
the system is represented in reconstructibility canonical form, and P, = 0,
P(t) can be represented in the form
P(t) 0
“Pr ! 3-231
Oe 20
which very clearly shows that P, if it exists, is singular. This proves that if
P is strictly positive-definite the system must be completely reconstructible.
To prove the converse assume that the system is completely reconstructible
and that P is singular. Then there exists a nonzero initial state such that
| [27(t)Rg2(t) + u?(t)Reu(t)] dt = 0. 3-232
to
Since R; > 0 and R, > 0, this implies that
u(t) = 0 and a(t) == 0 For. tiih 3-233
‘| But this would mean that there is a nonzero initial state that causes a zero
| input response of z(t) that is zero for all ¢. This is in contradiction to the
|, assumption of complete reconstructibility, and therefore the assumption
\4 that P is singular is false. This terminates the proof of part (d).
We now consider the proof of part (e). We assume that P exists. This means
that the system has no unstable, uncontrollable poles that are reconstructible.
3.4 Steady-State Solution of the Regulator Problem 241
We saw in the proof of (a) that in the reconstructibility canonical representa-
tion of the system P is given in the form
: 3-234
070
This shows that the steady-state feedback gain matrix is of the form
= Py 0 os
P= Rea(By B.( Sita ee RE 3-235
0 0
This in turn means that the steady-state feedback gain matrix leaves the un-
reconstructible part of the system completely untouched, which implies that
if the steady-state control law is to make the closed-loop system asymptotic-
ally stable, the unreconstructible part of the system must be asymptotically
stable, that is, the open-loop system must be detectable. Moreover, if the
closed-loop system is to be asymptotically stable, the open-loop system
must be stabilizable, otherwise no control law, hence not the steady-state
control law either, can make the closed-loop system stable. Thus we see
that stabilizability and detectability are necessary conditions for the steady-
state control law to be asymptotically stable.
Stabilizability and detectability are also sufficient to guarantee asymptotic
stability. We have already seen that the steady-state control law does not
affect and is not affected by the unreconstructible part of the system; there-
fore, if the system is detectable, we may as well omit the unreconstructible
part and assume that the system is completely reconstructible. Let us repre-
sent the system in controllability canonical form as in 3-229. Partitioning the
matrix P(t) according to the partitioning of 3-229, we write:
Prt) Pas
P(t) = ( ay oy 3-236
P;,(t) P.(t)
It is not difficult to find from the Riccati equation 3-215 that Pj,(t) is the
solution of
—P,,(t) = Di Rady aa PuDBiRe Br Pat) si ALP G® + Py,(t)Aq,
P,,(t,) = 9. 3-237
We see that this is the usual Riccati-type equation. Now since the pair
{A,,, By} is completely controllable, we know from Theorem 3.5 that P,;(t)
has an asymptotic solution P,, as t,—> 0 such that A,, — B,F,, where
F, = R,B,"P,,, is asymptotically stable. The control law for the whole
242 Optimal Linear State Feedback Control Systems
system 3-229 is given by
at a 7 P Pi» 2 aft ee
F= (Ff, fy) = Rz(B,", 0( = £ = (Rz'By* Py, Ry" B,* Py»).
12 22 3-238
With this control law the closed-loop system is described by
Ay, — BF, Ay. — BF,
a(t) = ( = eer : ‘ot. 3-239
0 Ag»
Clearly, if the open-loop system is stabilizable, the closed-loop system is
asymptotically stable since both A,, — B,F, and A, are asymptotically
stable. This proves that detectability and stabilizability are sufficient con-
ditions to guarantee that the closed-loop steady-state control law will be
asymptotically stable. This terminates the proof of (e).
Consider now part (f) of the theorem. Obviously, the steady-state control
law minimizes
3-240
| “EeMRea(t) + u™(OReult)) at, to
and the minimal value of this criterion is given by a" (ty) Px(ty). Let us now
consider the criterion
ty
lim | [z7(t)Ra2(t) + u7(t)Rou(t)] dt + M1) Pyx()) 3-241
tia aoldto
with P, > 0. If the system is stabilizable and detectable, for the steady-state
control law the criterion 3-241 is equal to
( [27(t)Rs2(t) + a7 (t)Rzii(t)] dt = x7 (ty) P2(to), 3-242
to
where Z and dare the controlled variable and input generated by the steady-
state control law. We claim that the steady-state control law not only
minimizes 3-240, but also 3-241. Suppose that there exists another control
law that gives a smaller value of 3-241, so that for this control law
| “TZ (t)Ree(t) + u*(t)Rou(t)] dt + lim w7(t,)P,2(t,) < x7(t))Px(to). 3-243
to t 17-0
Because P, > 0 this would imply that for this feedback law
i “2% (DRee(t) + uT()Ryu(t)] dt < 291 (ty) Px( to). 3-244
But since we know that the left-hand side of this expression is minimized by
the steady-state control law, and no value of the criterion less than
3.4 Steady-State Solution of the Regulator Problem 243
a” (to) Px(to) can be achieved, this is a contradiction, which means that
3-241 is also minimized by the steady-state control law. This terminates the
proof of part (f).
We now return to part (b) of the theorem. The fact stated in (b) immedi-
ately follows from (f). Consider now part (c). In general, the algebraic
Riccati equation has many solutions (see Problem 3.8). If P exists, it is a
nonnegative-definite solution of the algebraic Riccati equation because
P must be a solution of the Riccati differential equation 3-215. Suppose
that the system 3-213 is stabilizable and detectable, and let P’ be any non-
negative-definite solution of the algebraic Riccati equation. Consider the
Riccati differential equation 3-215 with the terminal condition P, = P’.
Obviously, the solution of the Riccati equation is P(t) = P’, t < t. Then the
steady-state solution P must also be given by P’. This proves that any
nonnegative-definite solution P’ of the algebraic Riccati equation is the steady-
state solution P, hence that the steady-state value P is the unique nonnegative-
definite solution of the algebraic Riccati equation. This terminates the proof
of (c), and also the proof of the whole theorem.
Comments. We conclude this section with the following comments. Parts
(b) and (c) state that stabilizability and detectability are sufficient conditions
for the Riccati equation to converge to a unique P for all P, > 0 and for the
algebraic Riccati equation to have a unique nonnegative-definite solution.
That these conditions are not necessary can be seen from simple examples.
Furthermore, it may very well happen that although P does not exist,
F = lim Rz'B* P(t) 3-245
does exist. pl
It is not difficult to conclude that the steady-state control law u(t) =
—Fx(t), if it exists, changes only the locations of those open-loop poles
that are both controllable and reconstructible. Therefore an unfavorable
situation may arise when a system possesses uncontrollable or unrecon-
structible poles, in particular if these poles are unstable. Unfortunately,
it is usually impossible to change the structure of the system so as to make un-
controllable poles controllable. If a system possesses unreconstructible
poles with undesirable locations, it is often possible, however, to redefine
the controlled variable such that the system no longer has unreconstructible
poles.
3.4.4* Solution of the Time-Invariant Regulator Problem by
Diagonalization
In this section we further investigate the steady-state solution of the time-
invariant regulator problem. This first of all provides us with a method for
244 Optimal Linear State Feedback Control Systems
computing the steady-state solution P of the Riccati equation, and moreover
puts us into a position to derive information about the closed-loop regulator
poles and the closed-loop behavior of the regulator. Throughout the section
we assume that the open-loop system is both stabilizable and detectable.
In Section 3.3.2 we saw that the regulator problem can be solved by con-
sidering the linear differential equation
x(t) x(t)
(e = z\ ) 3-246
P(t) P(t)
where Z is the constant matrix
A —BR;'B*
Vigra ; 3-247
—R, ey
Here R,; = D7 R,D. Correspondingly, we have the boundary conditions
X(to) = Xo, 3-248a
P(ty) = Pyx(t). 3-248b
From Sections 3.3.2 and 3.3.3 (Eq. 3-92), we know that p(t) and x(t) are
related by
p(t) = P(t)a(t), 3-249
where P(t) is the solution of the matrix Riccati equation with the terminal
condition P(t,) = P,. Suppose now that we choose
P, =P, 3-250
where P is the steady-state solution of the Riccati equation. Then the Riccati
equation obviously has the solution
P(t)=P, eg CE 3-251
This shows that the steady-state solution can be obtained by replacing the
terminal condition 3-248b with the initial condition
pt) = Pr). 3-252
Solving the differential equation 3-246 with the initial conditions 3-248a and
3-252 gives us the steady-state behavior of the state and adjoint variable.
We study the solution of this initial value problem by diagonalization
of the matrix Z. It can be shown by elementary determinant manipulations
that
det (—sI — Z) = det (sJ — Z). 3-253
Consequently, det (sJ — Z) is a polynomial in s? which shows that, if A is a
3.4 Steady-State Solution of the Regulator Problem 245
characteristic value of Z, —/ is also a characteristic value. Let us for simplic-
ity assume that the characteristic values of Z are all distinct (for the more
general case, see Problem 3.9). This allows us to diagonalize Z as follows:
A 60
Z=W wt, 3-254
0 —A
Here A is a diagonal matrix which is constructed as follows. If a characteristic
value 4 of Z has a strictly positive real part, it is a diagonal element of A;
—A is automatically placed in — A. If 4 has zero real part, one of the pair A,
—A is arbitrarily assigned to A and the other to —A. The matrix W is com-
posed of the characteristic vectors of Z; the ith column vector of W is the
characteristic vector of Z corresponding to the characteristic value in the
ith diagonal position of diag (A, —A).
Let us now consider the differential equation
i i 0 (0°)
= : 3-255
2,(t) 0 —A/} \z,(t)
where
24(t x(t)
( , w( } 3-256
z(t) p(t)
We partition W~ as follows: _ ieee
Wt=V= ; 3-257
Vo, Vos
Then we can write
z(t) = Vi, x(t) + Viop(t)
= (Yj, + Vagrant): 3-258
We know that the steady-state solution is stable, that is, x(t) > 0 as t— oo.
This also implies that z,(t) + 0 as t > oo. From 3-255, however, we see that
a(t) = ez (4). 3-259
Since the characteristic values of A all have zero or positive real parts,
z,(t) can converge to zero only if 2;(t)) = 0. According to 3-258, this can be
the case for all x, if and only if P satisfies the relation
Vix ot Vice. = 0. 3-260
If V,, is nonsingular, we can solve for P as follows:
Pe Veal a 3-261
In any case P must satisfy 3-260. Let us suppose that 3-260 does not have a
246 Optimal Linear State Feedback Control Systems
unique nonnegative-definite solution for P and let P’ be any nonnegative-
definite solution. Consider now the differential equation 3-246 with the
terminal condition
DG) = Pat), 3-262
We can write the solution in the form
be = be S| ae : ; ie | ee 3.263
p(t) Wo, Woe 0 eV \Var Veo! \p(t)
where W has also been partitioned. Substitution of 3-262 gives
se te | ee 0 ee of cr a 3.264
p(t) Wo, Woe 0 alee (Var + VoeP’)x(ty)
By using the fact that P’ is a solution of 3-260, this can be further worked
out; we obtain
a(t) ae Wee Va 45 Viel ath), 3-265a
PO = Wie S Usn— Vek WAG) 3-265b
For t = 1, the first of these equations reduces to
ty = Wie A \(Vay + VaoP’) x(t). 3-266
Since the two-point boundary value problem must have a solution for all
%, the matrix that relates x, and 2(t,) must be nonsingular (otherwise this
equation would not have a solution if x is not in the range of this matrix).
In fact, since any t < ¢, can be considered as the initial time for the interval
[t, t,], the matrix
Wise (Ven Veal) 3-267
must be nonsingular for all ¢ < t,. Solving 3-265a for x(t,) and substituting
this into 3-265b yields
P(t) = Ware (Vay + VagP Ver + Vag eNO Wige(t), 3-268
or (O’Donnell, 1966)
p(t) = WoW io x(t). 3-269
Apparently, solving the two-point boundary value problem with the ter-
minal condition P(t,) = P’ yields a solution of the form
p(t) = Pa(t), 3-270
where P is constant. Since this solution is independent of the terminal time f,,
P is also the steady-state solution P of the Riccati equation as t, > oo.
Since, as we know from Theorem 3.7, this steady-state solution is unique, we
3.4 Steady-State Solution of the Regulator Problem 247
cannot but conclude that
P = Wye a 3-271
This argument shows that W,, is nonsingular and that P can be represented
in the form 3-271. Since the partitioned blocks of V and W have a special
relationship, it can also be shown that Vj, is nonsingular, hence also that
3-261 is a valid expression (Problem 3.12).
In addition to these results, we can obtain the following interesting con-
clusion. By solving 3-266 for x(t,) and substituting the result into 3-265a, we
find
a(t) = We A" wie. 3-272
This shows very explicitly that the characteristic values of the steady-state
closed-loop system are precisely the diagonal elements of —A (O’Donnell,
1966). Since the closed-loop system is known to be asymptotically stable, it
follows that the diagonal elements of —A have strictly negative real parts.
Since these characteristic values are obtained from the characteristic values
of Z, this means that Z cannot have any characteristic values with zero real
parts, and that the steady-state closed-loop characteristic values are precisely
those characteristic values of Z that have negative real parts (Letov, 1960).
We summarize these conclusions as follows.
Theorem 3.8. Consider the time-invariant deterministic linear optimal
regulator problem and suppose that the pair {A, B} is stabilizable and the pair
{A, D} detectable. Define the 2n X 2n matrix
A — BR; Bt
a : 3-273
— DTR,D —At
and assume that Z has 2n distinct characteristic values. Then
(a) Ifdis a characteristic value of Z, —A also is a characteristic value. Z has no
characteristic values with zero real parts.
(b) The characteristic values of the steady-state closed-loop optimal regulator
are those characteristic values of Z that have negative real parts.
(c) If Z is diagonalized in the form
kK 8
Z=W wo, 3-274
0 —A
where the diagonal matrix A has as diagonal elements the characteristic values
of Z with positive real parts, the steady-state solution of the Riccati equation
3-215 can be written as
P = WooWio == —ViVia 3-275
248 Optimal Linear State Feedback Control Systems
where the W,; and V,;, i, j = 1, 2, are obtained by partitioning W and V=
W-, respectively. The inverse matrix in both expressions exists.
(d) The response of the steady-state closed-loop optimal regulator can be
written as
a(t) = Wier Ware. 3-276
The diagonalization approach discussed in this section is further pursued in
Problems 3.8 through 3.12.
3.5 NUMERICAL SOLUTION OF THE RICCATI
EQUATION
3.5.1 Direct Integration
In this section we discuss various methods for the numerical solution of the
Riccati equation, which is of fundamental importance for the regulator
problem and, as we see in Chapter 4, also for state reconstruction problems.
The matrix Riccati equation is given by
— P(t) = R,(t) — P(t)B(t)Rz'(t)B7(t)P(t) + A7(t)P(t) + P(t)A(t), 3-277
with the terminal condition
Pie Pi:
A direct approach results from considering 3-277 a set of n® simultaneous
nonlinear first-order differential equations (assuming that P(t) is ann Xn
matrix) and using any standard numerical technique to integrate these
equations backward from t,. The most elementary method is Euler’s method,
where we write
P(t — At) ~ P(t) — P(t) At, 3-278
and compute P(t) for t= 4, — At, t, — 2At,---. If the solution converges
to a constant value, such as usually occurs in the time-invariant case, some
stopping rule is needed. A disadvantage of this approach is that for sufficient
accuracy usually a quite small value of Ar is required, which results in a large
number of steps. Also, the symmetry of P(t) tends to be destroyed because of
numerical errors. This can be remedied by symmetrizing after each step, that
is, replacing P(t) with 3[P(t) + P7(t)]. Alternatively, the symmetry of P(t)
can be exploited by reducing 3-277 to a set of 4n(m + 1) simultaneous first-
order differential equations, which results in an appreciable saving of com-
puter time. A further discussion of the method of direct integration may be
found in Bucy and Joseph (1968).
The method of direct integration is applicable to both the time-varying
and the time-invariant case. If only steady-state solutions for time-invariant
3.5 Numerical Solution of the Riccati Equation 249
problems are required, the methods presented in Sections 3.5.3 and 3.5.4 are
more effective.
We finally point out the following. In order to realize a time-varying con-
trol law, the entire behavior of F(t) for tj < t < t, must be stored. It seems
attractive to circumvent this as follows. By off-line integration P(t,) can be
computed. Then the Riccati equation 3-277 is integrated on-line, with the
correct initial value P(t)), and the feedback gain matrix is obtained, on-line,
from F(t) = Ry'(t)B7(t)P(t). This method usually leads to unsatisfactory
results, however, since in the forward direction the Riccati equation 3-277 is
unstable, which causes computational inaccuracies that increase with 1
(Kalman, 1960).
3.5.2 The Kalman-Englar Method
When a complete solution is required of the time-invariant Riccati equation, a
convenient approach (Kalman and Englar, 1966) is based upon the following
expression, which derives from 3-98:
P(t,41) = [Ooi (ti1, t;) tg Ooo(tip1, t,)P(t;)] [On (tiu, t;) aa Oro(ti1, t,) P(t)",
3-279
where ae ay 3.280
The matrices ©,,(t, fo) are obtained by partitioning the transition matrix
@(t, fo) of the system
(#0) _ (9) a
xt x(t)
P(t) P(t)
where
A —BR; Bt
Le : 3-282
— D*R,D —At
We can compute @(f;,,, ¢;) once and for all as
Oltis, ty) = 7, 3-283
which can be evaluated according to the power series method of Section
1.3.2. The solution of the Riccati equation is then found by repeated appli-
cation of 3-279. It is advantageous to symmetrize after each step.
Numerical difficulties occur when At is chosen too large. Vaughan (1969)
discusses these difficulties in some detail. They manifest themselves in near-
singularity of the matrix to be inverted in 3-279. It has been shown by Vaughan
that a very small Ar is required when the real parts of the characteristic
values of Z have a large spread. For most problems there exists a At small
enough to obtain accurate results. Long computing times may result, how-
ever, especially when the main interest is in the steady-state solution.
250 Optimal Linear State Feedback Control Systems
3.5.3* Solution by Diagonalization
In order to obtain the steady-state solution of the time-invariant Riccati
equation, the results derived in Section 3.4.4 by diagonalizing the 2n x 2n
matrix Z are useful. Here the asymptotic solution is expressed as
P = Wye Wr, 3-284
where W,. and W,, are obtained by partitioning a matrix W as follows:
Wi, W.
W= ( _ i} 3-285
Woy Woe
The matrix W consists of the characteristic vectors of the matrix Z so arranged
that the first n columns of W correspond to the characteristic values of Z
with positive real parts, and the last n columns of W to the characteristic
values of Z with negative real parts.
Generally, some or all of the characteristic vectors of Z may be complex
so that W,. and W,, may be complex matrices. Complex arithmetic can be
avoided as follows. Since if e is a characteristic vector of Z corresponding to a
characteristic value / with negative real part, its complex conjugate é is also
a characteristic vector corresponding to a characteristic value 2 with a
negative real part, the last n columns of W will contain besides real column
vectors only complex conjugate pairs of column vectors. Then it is always
possible to perform a nonsingular linear transformation
Wie Wi»
es U, 3-286
Woe Woe
such that every pair of complex conjugate column vectors e and é in
col (Wis, Woz) is replaced with two real vectors Re(e) and Im (e) in
col (Wi2, Wo.). Then
Wo2Wi2" =e (We2U)(Wi2U) * a Wo2Wis, 3-287
which shows that W2, and W;, can be used to compute P instead of W2. and
Wyo.
Let us summarize this method of obtaining P:
(a) Form the matrix Z and use any standard numerical technique to com-
pute those characteristic vectors that correspond to characteristic values with
negative real parts.
(b) Form from these n characteristic vectors a 2n x n matrix
Wie oH 3-288
We
3.5 Numerical Solution of the Riccati Equation 251
where W,, and W2, aren x n submatrices, as follows. If e is a real character-
istic vector, let e be one of the columns of 3-288. If e and é form a complex
conjugate pair, let Re (e) be one column of 3-288 and Im (e) another.
(c) Compute P as
Pea Wie Wee. 3-289
The efficiency of this method depends upon the efficiency of the subprogram
that computes the characteristic vectors of Z. Van Ness (1969) has suggested
a characteristic vector algorithm that is especially suitable for problems of
this type. The algorithm as outlined above has been successfully applied for
solving high-order Riccati equations (Freestedt, Webber, and Bass, 1968;
Blackburn and Bidwell, 1968; Hendricks and Haynes, 1968). Fath (1969)
presents a useful modification of the method.
The diagonalization approach can also be employed to obtain not only
the asymptotic solution of the Riccati equation but the complete behavior of
P(t) by the formulas of Problem 3.11.
A different method for computing the asymptotic solution P is to use the
identity (see Problem 3.10)
if wa| ] = 0, i
3-290
where ¢(s) is obtained by factoring
det (sJ — Z) = $(s)¢(—5), 3-291
such that the roots of $(s) are precisely the characteristic values of Z with
negative real parts. Clearly, £(s) is the characteristic polynomial of the steady-
state closed-loop optimal system. Here det (sJ — Z) can be obtained by the
Leverrier algorithm of Section 1.5.1, or by any standard technique for
obtaining characteristic values of matrices. Both favorable (Freestedt,
Webber, and Bass, 1968) and unfavorable (Blackburn and Bidwell, 1968;
Hendricks and Haynes, 1968) experiences with this method have been
reported.
3.5.4* Solution by the Newton—Raphson Method
In this subsection a method is discussed for computing the steady-state
solution of the time-invariant Riccati equation, which is quite different from
the previous methods. It is based upon repeated solution of a linear matrix
equation of the type
0= A?P+ PAR, 3-292
which has been discussed in Section 1.11.3.
252 Optimal Linear State Feedback Control Systems
The steady-state solution P of the Riccati equation must satisfy the algebraic
Riccati equation
0 = R, — PSP + A*P + PA, 2-293
where
SBR, Bi: 3-294
Consider the matrix function
F(P) = R, — PSP + ATP + PA. 3-295
The problem is to find the nonnegative-definite symmetric matrix P that
satisfies
FC) =, 3-296
We derive an iterative procedure. Suppose that at the k-th stage a solution
P,, has been obtained, which is not much different from the desired solution P,
and let us write
P=P,4+P. 3-297
If P is small we can approximate F(P) by omitting quadratic terms in P and
we obtain
F(P) ~ R, — P,SP, — P,SP — PSP, — AT(P, + P)+(P. + PA. 3-298
The basic idea of the Newton-Raphson method is to estimate P by setting
the right-hand side of 3-298 equal to zero. If the estimate of P so obtained is
denoted as P,, and we let
Pri = Py + Ps then we find by setting the right-hand side of 3-298 equal to zero:
3-299
Oe Ry + PySPyet Pay Ay at Pa, 3-300
where
A, = A— SP,. 3-301
Equation 3-300 is of the type 3-292, for which efficient methods of solution
exist (see Section 1.11.3). We have thus obtained the following algorithm.
(a) Choose a suitable P, and set the iteration index k equal to 0.
(b) Solve P,,, from 3-300.
(c) If convergence is obtained, stop; otherwise, increase k by one and
return to (b).
Kleinman (1968) and McClamroch (1969) have shown that if the algebraic
Riccati equation has a unique nonnegative-definite solution, P, and P,,,
satisfy
Piper. “PSO oe 3-302
3.6 Stochastic Regulator and Tracking Problems 253
and
inves ear 3-303
k~> 00
provided Py is so chosen that
A, = A— SP, 3-304
is asymptotically stable. This means that the convergence of the scheme is
assured if the initial estimate is suitably chosen. If the initial estimate is
incorrectly selected, however, convergence to a different solution of the
algebraic Riccati equation may occur, or no convergence at all may result.
If A is asymptotically stable, a safe choice is P) = 0. If A is not asymptotically
stable, the initial choice may present difficulties. Wonham and Cashman
(1968), Man and Smith (1969), and Kleinman (1970b) give methods for
selecting Py when A is not asymptotically stable.
The main problem with this approach is 3-292, which must be solved
many times over. Although it is linear, the numerical effort may still be
rather formidable, since the number of linear equations that must be solved
at each iteration increases rapidly with the dimension of the problem (for
n = 15 this number is 120). In Section 1.11.3 several numerical approaches
to solving 3-292 are referenced. In the literature favorable experiences
using the Newton—Raphson method to solve Riccati equations has been
reported with up to 15-dimensional problems (Blackburn, 1968; Kleinman,
1968, 1970a).
3.6 STOCHASTIC LINEAR OPTIMAL REGULATOR
AND TRACKING PROBLEMS
3.6.1 Regulator Problems with Disturbances—The Stochastic Regulator
Probiem
In the preceding sections we discussed the deterministic linear optimal
regulator problem. The solution of this problem allows us to tackle purely
transient problems where a linear system has a disturbed initial state, and it is
required to return the system to the zero state as quickly as possible while
limiting the input amplitude. There exist practical problems that can be
formulated in this manner, but much more common are problems where
there are disturbances that act uninterruptedly upon the system, and that
tend to drive the state away from the zero state. The problem is then to design
a feedback configuration through which initial offsets are reduced as quickly
as possible, but which also counteracts the effects of disturbances as much as
possible in the steady-state situation. The solution of this problem will bring
us into a position to synthesize the controllers that have been asked for in
254 Optimal Linear State Feedback Control Systems
Chapter 2. For the time being we maintain the assumption that the complete
state of the system can be accurately observed at each instant of time.
The effect of the disturbances can be accounted for by suitably extending
the system description. We consider systems described by
&(t) = A(t)a(t) + B(thu(t) + v(t),
3-305
a(t) = D(t)x(t),
where u(t) is the input variable, z(t) is the controlled variable, and v(t)
represents disturbances that act upon the system. We mathematically repre-
sent the disturbances as a stochastic process, which we model as the output
of a linear system driven by white noise. Thus we assume that v(t) is given by
v(t) = D,(t)x,(t). 3-306
Here x,(t) is the solution of
a(t) = A,(t)x,(t) + w(t), 3-307
where w(t) is white noise. We furthermore assume that both 2(f)) and 24(to)
are stochastic variables.
We combine the description of the system and the disturbances by defining
an augmented state vector #(t) = col [x(t), x,(t)], which from 3-305, 3-306,
and 3-307 can be seen to satisfy
A(t) D,(t) Bit) 0
= ( Jao + ( Juco + ( ). 3-308
0 A,(t) 0 w(t)
In terms of the augmented state, the controlled variable is given by
ai) =3(D (2), O28). 3-309
We note in passing that 3-308 represents a system that is not completely
controllable (from uw).
We now turn our attention to the optimization criterion. In the determi-
nistic regulator problem, we considered the quadratic integral criterion
{ EZ (OR¢(Hz(t) + u?(t)R,(t)u(t)] dt + x7 (t,)P,2x(t,). 3-310
For a given input u(t), 9 < t < t,, and a given realization of the disturbances
v(t), t) <t < ht, this criterion is a measure for the deviations z(t) and u(t)
from zero. A priori, however, this criterion cannot be evaluated because of
the stochastic nature of the disturbances. We therefore average over all
possible realizations of the disturbances and consider the criterion
B| | Ee" ()R,(t)z(t) + u™(t)R,(t)u(t)] dt + a) Pyxtt)} 3-311
3.6 Stochastic Regulator and Tracking Problems 255
In terms of the augmented state #(t) = col [z(t), x,(t)], this criterion can be
expressed as
al ‘e“()R,(t)2(1) + u*(t)R,(t)u(t)] dt + #7(t,)P,2(1)5, 3-312
where
Ph phn
(een ) 3-313
0 0
It is obvious that the problem of minimizing 3-312 for the system 3-308 is
nothing but a special case of the general problem of minimizing
|| ‘27 (t)R,(t)2(1) + u7(t)R,(t)u(t)] dt + x7 (t,)Pya(t,) 3-314
for the system
&(t) = A(t)a(t) + B(t)u(t) + w(t), 3-315
where w(t) is white noise and where x(f,) is a stochastic variable. We refer to
this problem as the stochastic linear optimal regulator problem:
Definition 3.4. Consider the system described by the state differential equa-
tion
a(t) = A(t)a(t) + B(t)u(t) + w(t) 3-316
with initial state
C(t) = ty 3-317
and controlled variable
z(t) = D(t)x(t). 3-318
In 3-316 w(t) is white noise with intensity V(t). The initial state x, is a stochastic
variable, independent of the white noise w, with
E{axo%"} = Qp. 3-319
Consider the criterion
el |e" OROx0 + u*(t)Ro(t)u(t)] dt + x7(t))Pi2(t)}, 3-320
where R;(t) and R,(t) are positive-definite symmetric matrices for th <t<h
and P, is nonnegative-definite symmetric. Then the problem of determining for
each t, ty < t < ty, the input u(t) as a function of all information from the past
such that the criterion is minimized is called the stochastic linear optimal
regulator problem. If all matrices in the problem formulation are constant,
we refer to it as the time-invariant stochastic linear optimal regulator problem.
The solution of this problem is discussed in Section 3.6.3.
256 Optimal Linear State Feedback Control Systems
Example 3.11. Stirred tank
In Example 1.37 (Section 1.11.4), we considered an extension of the model
of the stirred tank where disturbances in the form of fluctuations in the
concentrations of the feeds are incorporated. The extended system model is
given by
= i 0 0 0 1 1
20
0 7 Fro Fao Ci9 — Co Cop — Co
6 V, V. V, V,
a(t) = : eo Or : nn EO)
0 0 — — 0 0 0
0,
1
0 0 0 —— 0 0
0,
iO) « 16)
OmEO
a w(t), 3-321
1 0O
Oil
where w(t) is white noise with intensity
0
0,
V= en, 3-322
Q 28
0,
Here the components of the state are, respectively, the incremental volume of
fluid, the incremental concentration in the tank, the incremental concentra-
tion of the feed F,, and the incremental concentration of the feed F,. Let us
consider as previously the incremental outgoing flow and the incremental
outgoing concentration as the components of the controlled variable. Thus
we have
pe oO 0)
a(t) = | 26 a(t). 3-323
OP AOL
The stochastic optimal regulator problem now consists in determining the
input u(t) such that a criterion of the form
FL E™OR + u%(t)Reu(t)] dt + 27 (ty)Py2(ty) 3-324 0
3.6 Stochastic Regulator and Tracking Problems 257
is minimized. We select the weighting matrices R, and R, in exactly the same
manner as in Example 3.9 (Section 3.4.1), while we choose P, to be the zero
matrix.
3.6.2 Stochastic Tracking Problems
We have introduced the stochastic optimal regulator problem by considering
regulator problems with disturbances. Stochastic regulator problems also
arise when we formulate stochastic optimal tracking problems. Consider the
linear system
a(t) = A(t)x(t) + B(t)u(t), 3-325
with the controlled variable
Ai) Dah): 3-326
Suppose we wish the controlled variable to follow as closely as possible a
reference variable z,(t) which we model as the output of a linear differential
system driven by white noise:
z(t) = D,(O)2,(0), 3-327
with
z,(t) = A,(t)x,(t) + w(t). 3-328
Here w(t) is white noise with given intensity V(t). The system equations and
the reference model equations can be combined by defining the augmented
state £(t) = col [x(t), x,(t)], which satisfies
Atty 0 Bit) 0
7g (9 | ho oh | Juco + ( } 3-329
0 A,(t) 0 w(t)
In passing, we note that this system (just as that of 3-308) is not completely
controllable from uw.
To obtain an optimal tracking system, we consider the criterion
E| i “te — 2,() PRO (z(t) — 2,(t)] + uZ(OR()u(} ai), 3-330
where R,(t) and R,(t) are suitable weighting matrices. This criterion expresses
that the controlled variable should be close to the reference variable, while .
the input amplitudes should be restricted. In fact, for R3(t) = W,(t) and
R,(t) = pW,,(t), the criterion reduces to
i “ICA + pCO) dt, 3-331
to
where C,(t) and C,,(t) denote the mean square tracking error and the mean
258 Optimal Linear State Feedback Control Systems
square input, respectively, as defined in Chapter 2 (Section 2.3):
ae T
C(t) aes Efe (t)W.(the(t)}, 3-332
C(t) = EfuT(W,(u(t)}.
Here e(t) is the tracking error
e(t) = 2(t) — z,{t). 3-333
The weighting coefficient p must be adjusted so as to obtain the smallest
possible mean square tracking error for a given value of the mean square
input.
The criterion 3-330 can be expressed in terms of the augmented state x(t)
as follows:
ty zl | [27(t)R, (121) + u7(t)R(t)u(t)] dt), 3-334
where i
A(t) = (D(t), —D,(t)) x(t). 3-335
Obviously, the problem of minimizing the criterion 3-334 for the system
3-329 is a special case of the stochastic linear optimal regulator problem of
Definition 3.4.
Without going into detail we point out that tracking problems with disturb-
ances also can be converted into stochastic regulator problems by the state
augmentation technique.
In conclusion, we note that the approach of this subsection is entirely
in line with the approach of Chapter 2, where we represented reference
variables as having a variable part and a constant part. In the present section
we have set the constant part equal to zero; in Section 3.7.1 we deal with
nonzero constant references.
Example 3.12. Angular velocity tracking system
Consider the angular velocity control system of Example 3.3 (Section 3.3.1).
Suppose we wish that the angular velocity, which is the controlled variable
C(t), follows as accurately as possible a reference variable ¢,(t), which may be
described as exponentially correlated noise with time constant 6 and rms
value o. Then we can model the reference process as (see Example 1.36,
Section 1.11.4)
C(t) = (4), 3-336
where &,(t) is the solution of
: 1
f(t) = — E(t) + w(t). 3-337
The white noise w(t) has intensity 20?/@. Since the system state differential
equation is F
E(t) = —a€(t) + «u(t, 3-338
3.6 Stochastic Regulator and Tracking Problems 259
the augmented state differential equation is given by
—a 0 K 0
a(t) = ro! #(t) + ' u(t) + ; w(t), 3-339
6
with X(t) = col [&(¢), &,(t)]. For the optimization criterion we choose
ty
B| | [[S(t) — CP + pu?(t)] ai), 3-340
where p is a suitable weighting factor. This criterion can be rewritten as
te B| { [o°(t) + pur(t)] ai), 3-341
to
where
C(t) = (1, —1) #0). 3-342
The problem of minimizing 3-341 for the system described by 3-339 and 3-342
constitutes a stochastic optimal regulator problem.
3.6.3 Solution of the Stochastic Linear Optimal Regulator Problem
In Section 3.6.1 we formulated the stochastic linear optimal regulator prob-
lem. This problem (Definition 3.4) exhibits an essential difference from the
deterministic regulator problem because the white noise makes it impossible
to predict exactly how the system is going to behave. Because of this, the best
policy is obviously not to determine the input u(t) over the control period
[to, t:] @ priori, but to reconsider the situation at each intermediate instant f
on the basis of all available information.
At the instant ¢ the further behavior of the system is entirely determined by
the present state x(r), the input u(r) for + > ¢, and the white noise w(r) for
7 >t. All the information from the past that is relevant for the future is
contained in the state x(t). Therefore we consider control laws of the form
u(t) = g[x(¢), ¢], 3-343
which prescribe an input corresponding to each possible value of the state at
time ¢.
The use of such control laws presupposes that each component of the state
can be accurately measured at all times. As we have pointed out before, this
is an unrealistic assumption. This is even more so in the stochastic case
where the state in general includes components that describe the disturbances
or the reference variable; it is very unlikely that these components can be
easily measured. We postpone the solution of this difficulty until after
260 Optimal Linear State Feedback Control Systems
Chapter 4, however, where the reconstruction of the state from incomplete
and inaccurate measurements is discussed.
In preceding sections we have obtained the solution of the deterministic
regulator problem in the feedback form 3-343. For the stochastic version of
the problem, we have the surprising result that the presence of the white
noise term w(t) in the system equation 3-316 does not alter the solution
except to increase the minimal value of the criterion. We first state this fact
and then discuss its proof:
Theorem 3.9. The optimal linear solution of the stochastic linear optimal
regulator problem is to choose the input according to the linear control law
u(t) = —F%(t)x(t), 3-344
where
F(t) = Rz*(t)B7(t)P(t). 3-345
Here P(t) is the solution of the matrix Riccati equation
— P(t) = R,(t) — P(t)B(t)Rz"(t)B7(t)P(t) + AT(t)P(t) + P(t)A(t) 3-346
with the terminal condition
PG awe 3-347
Here we abbreviate as usual
R,(t) = D7(t)R,(t) D(t). 3-348
The minimal value of the criterion is given by
tr | P(t) Qe + i “POKO ar]. 3-349
It is observed that this theorem gives only the best /inear solution of the
stochastic regulator problem. Since we limit ourselves to linear systems, this
is quite satisfactory. It can be proved, however, that the linear feedback law
is optimal (without qualification) when the white noise w(t) is Gaussian
(Kushner, 1967, 1971; Astrém, 1970).
To prove the theorem let us suppose that the system is controlled through
the linear control law
u(t) = —F(t)x(t). 3-350
Then the closed-loop system is described by the differential equation
&(t) = [A(t) — B(t)F(t)Ja(t) + w(t) 3-351
and we can write for the criterion 3-320
B| { ‘oT (QR) + FT)R()F()|x(0) dt + M1) Pro(t)]. 3.352
to
3.6 Stochastic Regulator and Tracking Problems 261
We know from Theorem 1.54 (Section 1.11.5) that the criterion can be ex-
pressed as
. | P1Qo a | “BU)V (A) ar| 3-353
where P(t) is the solution of the matrix differential equation
— P(t) = (A) — BEF(Q PO)
+ P()[A(t) — BO) FQ] + Ri(t) + F7(QRADF(), 3-354
with the terminal condition
P(t,) = Py. 3-355
Now Lemma 3.1 (Section 3.3.3) states that P(t) satisfies the inequality
P(t) 2h () 3-356
for all tf) < t < 4,, where P(t) is the solution of the Riccati equation 3-346
with the terminal condition 3-347. The inequality 3-356 converts into an
equality if F is chosen as
Fr) = Rz'(7r)B*(r)P(r), to 7% t 3-357
The inequality 3-356 implies that
tr [PT] > tr [POT] 3-358
for any nonnegative-definite matrix I’. This shows very clearly that 3-353 is
minimized by choosing F according to 3-357. For this choice of F, the criterion
3-353 is given by 3-349. This terminates the proof that the control law 3-345
is the optimal linear control law.
Theorem 3.9 puts us into a position to solve various types of problems.
In Sections 3.6.1 and 3.6.2, we showed that the stochastic linear optimal
regulator problem may originate from regulator problems for disturbed
systems, or from optimal tracking problems. In both cases the problem has a
special structure. We now briefly discuss the properties of the solutions that
result from these special structures.
In the case of a regulator with disturbances, the system state differential
and output equations take the partitioned form 3-308, 3-309. Suppose that
we partition the solution P(t) of the Riccati equation 3-346 according to
the partitioning #(t) = col [x(t), x4(t)] as
Py,(1) Ee
P(t) = ( 3-359
Pix(t) Ps9(t)
If, accordingly, the optimal feedback gain matrix is partitioned as
F°(t) a (F,(t), F,(t)), 3-360
262 Optimal Linear State Feedback Control Systems
it is not difficult to see that
F,(t) a Rz'(t)B7(t)Pui(t),
3-361
F(t) = Rz*()B"(t)P,,(t).
Furthermore, it can be found by partitioning the Riccati equation that P,,,
P45, and Py. are the solutions of the matrix differential equations
E ad) a D*(t)R;(t) D(t) a P,,(t)B(t)Rz (t)B7(t)P3,(t)
+ AT(t)P,,(t) + Py, (t)A(t), 3-362
P,,(t) = P,,
—P,,(t) = Py(t)D,(t) + [A() — BO)F,(t))"Pio(t) + Pra(t) A(t), Pere
P,,(t) = 0,
=P) = —PAOBORs OB OPRLD + De OPA) + PaO)
+ Aq"(t)Poo(t) + P22(t)A,(t), 3-364
Po(t) = 0.
We observe that P,,, and therefore also F,, is completely independent of the
properties of the disturbances, and is in fact obtained by solving the determi-
nistic regulator problem with the disturbances omitted. Once P,, and F, have
been found, 3-363 can be solved to determine P,, and from this F,. The
control system structure is given in Fig. 3.14. Apparently, the feedback link,
white noise
Ww
disturbance
feedforward cy Bamics
Link
feedback Link
Fig. 3.14. Structure of the optimal state feedback regulator with disturbances.
3.6 Stochastic Regulator and Tracking Problems 263
that is, the link from the state x to the input u is completely independent of the
properties of the disturbances. The feedforward link, that is, the link from the
state of the disturbances x, to the input wu, is of course dependent upon
the properties of the disturbances.
A similar conclusion can be reached for optimal tracking problems. Here
it turns out that with the structures 3-329 and 3-335 of the state differential
and output equations the feedback gain matrix can be partitioned as
F°(t) = (F\(t), —F,(t)) 3-365
(note the minus sign that has been introduced), where
F\(t) = Rz*(t)B*(t)Px(0),
3-366
F(t) = —Rz*(t)B7(t)P,2(t).
Here the matrices P,,, P,,, and P,, are obtained by partitioning the matrix P
according to the partitioning %(t) = col [x(t), x,(t)]; they satisfy the matrix
differential equations
— P,(t) = D*(t)R,(t) D(t) — Py (t)B(t)Rz'(t)B7 (t)P y(t)
+ A*(t)Pu(t) + Pu(A(t), 3-367
P(t) = 0,
—P,x(t) = — D7(t)R3(t)D,(t) + [A() — BOF :(D)]* Pra(t)
a P,.(t)A,(t), 3-368
P,,(ty) = 0,
— P(t) = D,7(t)R3(t)D,(t) — P(t)B(t)Rz (t)B" (t)Pio(t)
+ A,"(t)Poo(t) + Poo(t)A(t), 3-369
P(t) = 0.
We conclude that for the optimal tracking system as well the feedback link
is independent of the properties of the reference variable, while the feedforward
link is of course influenced by the properties of the reference variable. A
schematic representation of the optimal tracking system is given in Fig. 3.15.
Let us now return to the general stochastic optimal regulator problem.
In practice we are usually confronted with control periods that are very
long, which means that we are interested in the case where t, — oo. In the
deterministic regulator problem, we saw that normally the Riccati equation
3-346 has a steady-state solution P(t) as t, > oo, and that the corresponding
steady-state control law F(t) is optimal for half-infinite control periods. It is
not difficult to conjecture (Kushner, 1971) that the steady-state control law
264 Optimal Linear State Feedback Control Systems
feedforward
Link
reference
vorioble
dynamics
feedback Link
Fig. 3.15. Structure of the optimal state feedback tracking system.
is optimal for the stochastic regulator in the sense that it minimizes
; 1
lim
; B| { “Teh (DRe(D2(1) + u*(t)R,(t)u(t)] ai), 3-370
t1— 00 ty ae
if this expression exists for the steady-state control law, with respect to all
other control laws for which 3-370 exists. For the steady-state optimal
control law, the criterion 3-370 is given by
lim
ty i tr [P(t)V(1)] dt, 3-371
ty> 0 ty ee 0
to
if it exists (compare 3-349). Moreover, it is recognized that for a time-
invariant stochastic regulator problem and an asymptotically stable time-
invariant control law the expression 3-370 is equal to
lim Efz7(t)R,2(t) + u7(t)Rou(t)}. 3-372
t>o
From this it immediately follows that the steady-state optimal control law
minimizes 3-372 with respect to all other time-invariant control laws. We see
from 3-371 that the minimal value of 3-372 is given by
tr (PV). 3-373
We observe that if R; = W, and R, = pW,,, where W, and W,, are the
weighting matrices in the mean square tracking error and the mean square
input (as introduced in Section 2.5.1), the expression 3-372 is precisely
C, ioe) ap pC. fools 3-374
Here C,,, is the steady-state mean square tracking error and C,,,, the steady-
state mean square input. To compute C,,, and C,,, separately, as usually is
required, it is necessary to set up the complete closed-loop system equations
and derive from these the differential equation for the variance matrix of the
3.6 Stochastic Regulator and Tracking Problems 265
state. From this variance matrix all mean square quantities of interest can be
obtained.
Example 3.13. Stirred tank regulator
In Example 3.11 we described a stochastic regulator problem arising from
the stirred tank problem. Let us, in addition to the numerical values of
Example 1.2 (Section 1.2.3), assume the following values:
CG; = A0's,
G50 5,
3-375
o, = 0.1 kmol/m?,
0, = 0.2 kmol/m?.
Just as in Example 3.9 (Section 3.4.1), we choose the weighting matrices R
and R, as follows.
50 0 L 0
Ros , Ro=p 3-376
0 0.02 ae)
where p is to be selected. The optimal control law has been computed for
p = 10, 1, and 0.1, as in Example 3.9, but the results are not listed here. It
turns out, of course, that the feedback gains from the plant state variables
are not affected by the inclusion of the disturbances in the system model.
This means that the closed-loop poles are precisely those listed in Table 3.1.
In order to evaluate the detailed performance of the system, the steady-
state variance matrix
O = lim E{a(t)x7(1)} 3-377
t— 00
has been computed from the matrix equation
0 = (A — BF)O + O(A — BF)? + V. The steady-state variance matrix of the input can be found as follows:
3-378
lim E{u(t)u7(t)} = lim E{Fa(t)2"(1)FT} = FOF’. 3-379
to to
From these variance matrices the rms values of the components of the con-
trolled variable and the input variable are easily obtained. Table 3.2 lists the
results. The table shows very clearly that as p decreases the fluctuations in
the outgoing concentration become more and more reduced. The fluctuations
in the outgoing flow caused by the control mechanism also eventually
decrease with p. All this happens of course at the expense of an increase in the
fluctuations in the incoming feeds. Practical considerations must decide which
value of p is most suitable.
266 Optimal Linear State Feedback Control Systems
Table 3.2 Rms Values for Stirred-Tank Regulator
Steady-state rms values of
Incremental Incremental feed
outgoing Incremental
flow concentration No. 1 No. 2
p (m*/s) (kmol/m?*) (m*/s) (m*/s)
oO 0 0.06124 0 0
10 0.0001038 0.03347 0.0008957 0.0006980
1 0.00003303 0.008238 0.001567 0.001487
0.1 0.000004967 0.001127 0.001769 0.001754
Example 3.14. Angular velocity tracking system
Let us consider the angular velocity tracking problem as outlined in Example
3.12. To solve this problem we exploit the special structure of the tracking
problem. It follows from 3-365 that the optimal tracking law is given by
M(t) = —Fy(tye) + Fo@é,(2). 3-380
The feedback gain F,(t) is independent of the properties of the reference
variable and in fact has already been computed in previous examples where
we considered the angular velocity regulation problem. From Example 3.7
(Section 3.4.1), it follows that the steady-state value of the feedback gain is
given by
7 1 eas
f=—(—a+,/a +—}, 3-381
K p
while the steady-state value of P,, is
2'
Pi, = 2(-n+ Jet +), 3-382
K p
By using 3-368, it follows that the steady-state value of P,, can be solved from
12° 3-383
Solution yields
Le 3-384
1 Ke
pt yee
3.6 Stochastic Regulator and Tracking Problems 267
so that
us
ae £ = 3-385
gt e+e p
Finally, solution of 3-369 for P., gives
2
ot 6 af ge 2 Io 4+ —
Ay 6 OG) p
22 = 5 are 3-386
i is J oe 4 P
Let us choose the following numerical values:
G = 05S,
K = 150 rad/(V s*),
() = Ils, 3-387
o = 30 rad/s,
p= 1000 madAi(y 52);
This yields the following numerical results:
F, = 0.02846, F, = 0.02600, 3-388
» 0.1897 —0.1733
P= 5 3-389
=(11733 0.1621
From 3-373 it follows that
lim [E{Z°(t)} + pE{w(t)}] = tr (PV), t> oo
where f(t) = &(t) — &,(t). Since in the present problem
3-390
2) 0 0
V= 42) = : 3-391
zs 0 1800
60
we find that
lim [E{27(t)} + pE{u?(t)}] = 291.8 rad?/s?. 3-392
t+
We can use 3-392 to obtain rough estimates of the rms tracking error and rms
input voltage as follows. First, we have from 3-392
lim E{Z?(t)} < 291.8 rad?/s?. 3-393
t> 0
268 Optimal Linear State Feedback Control Systems
It follows that
steady-state rms tracking error < 17.08 rad/s. 3-394
Similarly, it follows from 3-392
291.8
linet) 0.2918 Vx 3-395
t+ P
We conclude that
steady-state rms input voltage < 0.5402 V. 3-396
Exact values for the rms tracking error and rms input voltage can be found by
computing the steady-state variance matrix of the state Z(t) of the closed-
loop augmented system. This system is described by the equation
—% 0
a(t) = 1 &(t) + (“\i-n F a(t) + (;) w(t), 3-397
0 —- 0
6
or
—x—k«F, «KF, 0
Ps 1 &(t) + ( Juco 3-398
0 ee 1
6
As a result, the steady-state variance matrix O of Z(t), is the solution of the
matrix equation
—a—«F, «fF, —a— KF, 0 0 0
0= O0+0 = =f 2
0 = «F, _i 0 20"
6 6 6
3-399
Numerical solution yields
n 497.5 608.4
= : 3-400
~ \608.4 900.0
The steady-state mean square tracking error can be expressed as
E{[&(t) at E(t)P} = On; ear 20s aie Qos
= (80; iad 1s. 3-401
where the Q,, are the entries of O. Similarly, the mean square input is given
by
lim E{(— Fe) + FE (OP} = AYO — 2F.AOn + Fr'On
== ORO Ve 3-402
3.6 Stochastic Regulator and Tracking Problems 269
In Table 3.3 the estimated and actual rms values are compared. Also given are
the open-loop rms values, that is, the rms values without any control at all.
It is seen that the estimated rms tracking error and input voltage are a little
on the large side, but that they give a very good indication of the orders of
magnitude. We moreover see that the control is not very good since the rms
tracking error of 13.44 rad/s is not small as compared to the rms value of the
Table 3.3. Numerical Results for the Angular Velocity
Tracking System
Steady-state Steady-state
rms rms
tracking error input voltage
(rad/s) (V)
Open-loop 30 0
Estimated closed-loop <17.08 <0.5402
Actual closed-loop 13.44 0.3333
reference variable of 30 rad/s. Since the rms input is quite small, however,
there seems to be room for considerable improvement. This can be achieved
by choosing the weighting coefficient p much smaller (see Problem 3.5).
Let us check the reference variable and closed-loop system bandwidths
for the present example. The reference variable break frequency is 1/0 =
1 rad/s. Substituting the control law into the system equation, we find for the
closed-loop system equation
2
oie = ae ee) FE). 3-403
P
This is a first-order system with break frequency
2
i a + © = 4.769 rad/s. p
3-404
Since the power spectral density of the reference variable, which is exponen-
tially correlated noise, decreases relatively slowly with increasing frequency,
the difference in break frequencies of the reference variable and the closed-
loop system is not large enough to obtain a sufficiently small tracking error.
270 Optimal Linear State Feedback Control Systems
3.7 REGULATORS AND TRACKING SYSTEMS WITH
NONZERO SET POINTS AND CONSTANT
DISTURBANCES
3.7.1 Nonzero Set Points
In our discussion of regulator and tracking problems, we have assumed up
to this point that the zero state is always the desired equilibrium state of the
system. In practice, it is nearly always true, however, that the desired
equilibrium state, which we call the set point of the state, is a constant point
in state space, different from the origin. This kind of discrepancy can be
removed by shifting the origin of the state space to this point, and this is
what we have always done in our examples. This section, however, is devoted
to the case where the set point may be variable; that is, we assume that the
set point is constant over long periods of time but that from time to time it is
shifted. This is a common situation in practice.
We limit our discussion to the time-invariant case. Consider the linear
time-invariant system with state differential equation
x(t) = Ax(t) + Bu(t), 3-405
where the controlled variable is given by
Z(t jia= Dag). 3-406
Let us suppose that the set point of the controlled variable is given by 2p.
Then in order to maintain the system at this set point, a constant input up
must be found (diCaprio and Wang, 1969) that holds the state at a point x
such that
a) => Day. 3-407
It follows from the state differential equation that x) and uw» must be related
by
0 = Axy + Buy. 3-408
Whether or not the system can be maintained at the given set point depends on
whether 3-407 and 3-408 can be solved for uv for the given value of 2p.
We return to this question, but let us suppose for the moment that a solution
exists. Then we define the shifted input, the shifted state, and the shifted
controlled variable, respectively, as
u(t) = u(t) — up,
a(t) = v(t) — to, a(t) 20) Sac
3-409
3.7 Nonzero Set Points and Constant Disturbances 271
It is not difficult to find, by solving these equations for w, x, and z, substituting
the result into the state differential equation 3-405 and the output equation
3-406, and using 3-407 and 3-408, that the shifted variables satisfy the
equations
a!(t) = AXt) + Bu'(t),
z(t) = Dzx'(t). aw,
Suppose now that at a given time the set point is suddenly shifted from one
value to another. Then in terms of the shifted system equations 3-410, the
system suddenly acquires a nonzero initial state. In order to let the system
achieve the new set point in an orderly fashion we propose to effect the trans-
ition such that an optimization criterion of the form
i “EZO)Re(t) + u'()Reu'(1)] dt + a7.) Py2'(ty) 3-411
to
is minimized. Let us assume that this shifted regulator problem possesses a
steady-state solution in the form of the time-invariant asymptotically stable
steady-state control law
u(t) = —F2'(t). 3-412
Application of this control law ensures that, in terms of the original system
variables, the system is transferred to the new set point as quickly as possible
without excessively large transient input amplitudes.
Let us see what form the control law takes in terms of the original system
variables. We write from 3-412 and 3-409:
u(t) = —Fx(t) + uy + Fr. 3-413
This shows that the control law is of the form
u(t) = —Fa(t) + uy, 3-414
where the constant vector up is to be determined such that in the steady-
state situation the controlled variable z(t) assumes the given value z). We now
study the question under what conditions ug can be found.
Substitution of 3-414 into the system state differential equation yields
a(t) = (A — BF)x(t) + Bui, 3-415
Since the closed-loop system is asymptotically stable, as t— oo the state
reaches a steady-state values 2, that satisfies
0 = Am + Buy. 3-416
Here we have abbreviated
A=A-— BF. 3-417
272 Optimal Linear State Feedback Control Systems
Since the closed-loop system is asymptotically stable, A has all of its character-
istic values in the left-half complex plane and is therefore nonsingular;
consequently, we can solve 3-416 for 2»:
ine (Ale Buy. 3-418
If the set point z, of the controlled variable is to be achieved, we must there-
fore have
Zy = D(—A) "Bug. 3-419
When considering the problem of solving this equation for uy for a given value
of z), three cases must be distinguished :
(a) The dimension of z is greater than that of u: Then 3-419 has a solution
for special values of 2) only; in general, no solution exists. In this case we
attempt to control the variable z(t) with an input u(t) of smaller dimension;
since we have too few degrees of freedom, it is not surprising that no solution
can generally be found.
(b) The dimensions of u and z are the same, that is, a sufficient number of
degrees of freedom is available to control the system. In this case 3-419 can
be solved for uj provided D(— A)~1B is nonsingular; assuming this to be the
case (we shall return to this), we find
uy = [D(—A) BY 2, 3-420
which yields for the optimal input to the tracking system
u(t) = —Fx(t) + [D(—A)“B} 2). 3-421
(c) The dimension of z is less than that of u: In this case there are too many
degrees of freedom and 3-419 has many solutions. We can choose one of
these solutions, but it is more advisable to reformulate the tracking problem
by adding components to the controlled variable.
On the basis of these considerations, we henceforth assume that
dim (z) = dim (w), 3-422
so that case (b) applies. We see that
D(—4)“B = H,(0), 3-423
where
H,(s) = D(sI — A)“B. 3-424
We call H,(s) the closed-loop transfer matrix, since it is the transfer matrix
from u'(t) to 2(t) for the system
&(t) = Ax(t) + Bu(t),
2(t) = D2(t), 3-425
u(t) = —Fer(t) + u'(t).
3.7 Nonzero Set Points and Constant Disturbances 273
In terms of H,(0) the optimal control law 3-421 can be written as
u(t) = — Fe(t) + Hz"(0)zo. 3-426
As we have seen, this control law has the property that after a step change in
the set point z) the system is transferred to the new set point as quickly as
possible without excessively large transient input amplitudes. Moreover, this
control law of course makes the system return to the set point from any
initial state in an optimal manner. We call 3-426 the nonzero set point
optimal control law. It has the property that it statically decouples the control
system, that is, the transmission 7(s) of the control system (the transfer
matrix from the set point z) to the controlled variable z) has the property
that 7(0) = J.
We now study the question under what conditions 7,(0) has an inverse.
It will be proved that this property can be directly ascertained from the open-
loop system equations
a(t) = Aa(t) + Bu(t),
2(t) = Dx(t). Eee
Consider the following string of equalities
det [H(s)] = det [D(sI — A + BF) "B]
= det [D(sI] — A) {I + BF(sI — A)1}“B]
= det [D(sI — A)-4{I — BFL + (sI — A) BF-(sI — A) }B)
= det [D(s] — A)~'B] det [I — F(s] — A + BF) 'B]
= det [D(s! — A) 'B] det [I — (sI — A + BF)'BF]
= det [D(sI — A)~'B] det [(s! — A + BF)"] det (sl ~— A)
_ det [D(sI — A)‘B] det (sI — A)
det (sf = A+ BF)
See $.(s)
3-428
Here we have used Lemma 1.1 (Section 1.5.3) twice. The polynomial y(s) is
defined by
YG)
det [H(s)] = 3-429
d(s)
where H(s) is the open-loop transfer matrix
His) = DG = A)“ B; 3-430
274 Optimal Linear State Feedback Control Systems
and ¢(s) the open-loop characteristic polynomial
f(s) = det (sf — A). 3-431
Finally, ¢,(s) is the closed-loop characteristic polynomial
b,(s) = det (sJ — A + BF). 3-432
We see from 3-428 that the zeroes of the closed-loop transfer matrix are the
same as those of the open-loop transfer matrix. We also see that
det [D(— A) ‘B] = det [H,(0)] = yO)
3-433
$.(0)
is zero if and only if y(0) = 0. Thus the condition y(0) ¥ O guarantees that
D(—A)“B is nonsingular, hence that the nonzero set point control law
exists. These results can be summarized as follows.
Theorem 3.10. Consider the time-invariant system
#(t) = Ax(t) + Bu(t),
2(t) = D2(t), aae
where z and u have the same dimensions. Consider any asymptotically stable
time-invariant control law
u(t) = —Fe(t) + u(t). 3-435
Let H(s) be the open-loop transfer matrix
H(s) = D(sI — A)“B, 3-436
and H,(s) the closed-loop transfer matrix
H,(s) = D(sI — A + BF)"B. 3-437
Then H,(0) is nonsingular and the controlled variable z(t) can under steady-
state conditions be maintained at any constant value z) by choosing
u'(t) = Hz*(0)z, 3-438
if and only if H(s) has a nonzero numerator polynomial that has no zeroes
at the origin.
It is noted that the theorem is stated for any asymptotically stable control
law and not only for the steady-state optimal control law.
The discussion of this section has been confined to deterministic regulators.
Of course stochastic regulators (including tracking problems) can also have
nonzero set points. The theory of this section applies to stochastic regulators
3.7 Nonzero Set Points and Constant Disturbances 275
without modification; the nonzero set point optimal control law for the
stochastic regulator is also given by
u(t) = — Fx(t) + Hy(0)zp. 3-439
Example 3.15. Position control system
Let us consider the position control system of Example 3.4 (Section 3.3.1).
In Example 3.8 (Section 3.4.1), we found the optimal steady-state control law.
It is not difficult to find from the results of Example 3.8 that the closed-loop
transfer function is given by
Hs) = ———————__. 3-440
se+s (i a” aie +
Je Vp
If follows from 3-435 and 3-438 that the nonzero set point optimal control
law is given by
a 1
ff) Ht) (t) H,(0) Co
1 1 2 1
=— = (1) — he + Je oh = Sa = Gos 3-441
vp K ve ve
where ¢, is the set point for the angular position. This is precisely the control
law 3-171 that we found in Example 3.8 from elementary considerations.
Example 3.16. Stirred tank
As an example of a multivariable system, we consider the stirred-tank
regulator problem of Example 3.9 (Section 3.4.1). For p = 1 (where p is
defined as in Example 3.9), the regulator problem yields the steady-state
feedback gain matrix
fe ie basta Ae
0.01681 0.05475
It is easily found that the corresponding closed-loop transfer matrix is given
by
H(s) = D(sI — A+ BF)"B
1
52 4 0.21315 + 0.01037
0.01s + 0.0007475 0.01s + ae
—0.25s — 0.01931 0.758 + 0.1084 / 3-443
276 Optimal Linear State Feedback Control Systems
From this the nonzero set point optimal control law can be found to be
es 10.84 —0.1171
u(t) = —Fa(t) + ( Je
3-444
1.931 0.07475
Figure 3.16 gives the response of the closed-loop system to step changes in
the components of the set point 2). Here the set point of the outgoing flow is
incrementol
outgoing
flow 9902 0.002
£4 (t) Cy (t)
(m¥s) (m/s)
0 =i SS es 0
50 50
t ——(s) t——_»—(‘s)
incrementol
outgoing
concentration
Coit) 03 rity
(kmol/m3) (kmol/m3)
0 0
50 50
t —— (s) t —— (s)
Fig. 3.16. The responses of the stirred tank as a nonzero set point regulating system. Left
column: Responses of the incremental outgoing flow and concentration to a step of
0.002 m*/s in the set point of the flow. Right column: Responses of the incremental
outgoing flow and concentration to a step of 0.1 kmol/m* in the set point of the
concentration.
changed by 0.002 m?/s, which amounts to 10% of the nominal value, while the
set point of the outgoing concentration is changed by 0.1 kmol/m?, which is
8% of the nominal value. We note that the control system exhibits a certain
amount of dynamic coupling or interaction, that is, a change in the set point
of one of the components of the controlled variable transiently affects the
other component. The effect is small, however.
3.7 Nonzero Set Points and Constant Disturbances 277
3.7.2* Constant Disturbances
In this subsection we discuss a method for counteracting the effect of constant
disturbances in time-invariant regulator systems. As we saw in Chapter 2,
in regulators and tracking systems where high precision is required, it is
important to eliminate the effect of constant disturbances completely.
This can be done by the application of integrating action. We introduce
integrating action in the context of state feedback control by first extending
the usual regulator problem, and then consider the effect of constant disturb-
ances in the corresponding modified closed-loop control system configuration.
Consider the time-invariant system with state differential equation
a(t) = Ax(t) + Bu(t), 3-445
with x(f)) given and with the controlled variable
et) = Dz). 3-446
We add to the system variables the “integral state’’ q(t) (Newell and Fisher,
1971; Shih, 1970; Porter, 1971), defined by
q(t) = 2(t), 3-447
with q(t) given. One can now consider the problem of minimizing a criterion
of the form
[ eroRco + gq? (t)Rig(t) + u7(t)Rou(t)] dt, 3-448
where R;, R3, and R, are suitably chosen weighting matrices. The first term
of the integrand forces the controlled variable to zero, while the second term
forces the integral state, that is, the total area under the response of the
controlled variable, to go to zero. The third term serves, as usual, to restrict the
input amplitudes.
Let us assume that by minimizing an expression of the form 3-448, or by
any other method, a time-invariant control law
u(t) = —F,2x(t) — Feq(t) 3-449
is determined that stabilizes the augmented system described by 3-445,
3-446, and 3-447. (We defer for a moment the question under which con-
ditions such an asymptotically stable control law exists.) Suppose now that a
constant disturbance occurs in the system, so that we must replace the state
differential equation 3-445 with
a(t) = Ax(t) + Bu(t) + vp, 3-450
where v, is a constant vector. Since the presence of the constant disturbance
278 Optimal Linear State Feedback Control Systems
does not affect the asymptotic stability of the system, we have
De 3-451
or, from 3-447,
We ACh 3.452
This means that the control system with the asymptotically stable control law
3-449 has the property that the effect of constant disturbances on the controlled
variable eventually vanishes. Since this is achieved by the introduction of the
integral state g, this control scheme is a form of integral control. Figure 3.17
depicts the integral control scheme.
Fig. 3.17. State feedback integral control.
Let us now consider the mechanism that effects the suppression of the
constant disturbance. The purpose of the multivariable integration of 3-447
is to generate a constant contribution uv» to the input that counteracts the
effect of the constant disturbance on the controlled variable. Thus let us
consider the response of the system 3-450 to the input
u(t) = —Fyx(t) + up. Substitution of this expression into the state differential equation 3-450 yields
a(t) = (A — BF,)x(t) + Buy + vp. 3-453
3-454
In equilibrium conditions the state assumes a constant value x that must
satisfy the relation
0 = Az, + Buy + v%, 3-455
where
A = A — BF,. 3-456
Solution for x yields
ty = (—A)“Buy + (—A) 0p, 3-457
provided 4 is nonsingular. The corresponding equilibrium value z,) of the
3.7 Nonzero Set Points and Constant Disturbances 279
controlled variable is given by
%y = Dx = D(—A)"Bu, + D(—A)“ 2. 3-458
When we now consider the question whether or not a value of uy exists that
makes z) = 0, we obviously obtain the same conditions as in Section 3.7.1,
broken down to the three following cases.
(a) The dimension of z is greater than that of u: In this case the equation
0 = D(—A)"Buy + D(—A) 2 3-459
represents more equations than variables, which means that in general no
solution exists. The number of degrees of freedom is too small, and the
steady-state error in z cannot be eliminated.
(b) The dimension of z equals that of u: In this case a solution exists if and
only if
D(—A)“B = H,(0) 3-460
is nonsingular, where
H,(s) = D(sI — A)1B 3-461
is the closed-loop transfer matrix. As we saw in Theorem 3.10, H,(0) is
nonsingular if and only if the open-loop transfer matrix H(s) = D(sJ — A)1B
has no zeroes at the origin.
(c) The dimension of z is less than that of u: In this case there are too many
degrees of freedom and the dimension of z can be increased by adding
components to the controlled variable.
On the basis of these considerations, we from now on restrict ourselves to
the case where dim (z) = dim (u). Then the present analysis shows that a
necessary condition for the successful operation of the integral scheme under
consideration is that the open-loop transfer matrix H(s) = D(sJ — A)1B
have no zeroes at the origin. In fact, it can be shown, by a slight extension of
the argument of Power and Porter (1970) involving the controllability canoni-
cal form of the system 3-445, that necessary and sufficient conditions for the
existence of an asymptotically stable control law of the form 3-449 are that
(i) the system 3-445 is stabilizable; and
(ii) the open-loop transfer matrix H(s) = D(sI — A)*B has no zeroes at
the origin.
Power and Porter (1970) and Davison and Smith (1971) prove that necessary
and sufficient conditions for arbitrary placement of the closed-loop system
poles are that the system 3-445 be completely controllable and that the open-
loop transfer matrix have no zeroes at the origin. Davison and Smith (1971)
state the latter condition in an alternative form.
280 Optimal Linear State Feedback Control Systems
In the literature alternative approaches to determining integral control
schemes can be found (see, e.g., Anderson and Moore, 1971, Chapter 10;
Johnson, 1971b).
Example 3.17. Integral control of the positioning system
Let us consider the positioning system of previous examples and assume
that a constant disturbance can enter into the system in the form of a con-
stant torque 7, on the shaft of the motor. We thus modify the state differential
equation 3-59 to
eG ( po n ("jue i (°)-» 3-462
0 —« K y
where y = 1/J, with J the moment of inertia of all the rotating parts. As
before, the controlled variable is given by
C(t) = 4h, Oz(?). 3-463
We add to the system the scalar integral state q(t), defined by
g(t) = C(¢). 3-464
From Example 3.15 we know that the open-loop transfer function has no
zeroes at the origin; moreover, the system is completely controllable so that
we expect no difficulties in finding an integral control system. Let us consider
the optimization criterion
I [P(t) + Ag*(t) + pu()] dt. 3-465
to
As in previous examples, we choose
p = 0.00002 rad?/V?. 3-466
Inspection of Fig. 3.9 shows that in the absence of integral control q(t) will
reach a steady-state value of roughly 0.01 rad s for the given initial condition.
Choosing
A=10s? 3-467
can therefore be expected to affect the control scheme significantly.
Numerical solution of the corresponding regulator problem with the
numerical values of Example 3.4 (Section 3.3.1) and y = 0.1 kg m- yields
the steady-state control law
u(t) = —F,x(t) — Foq(t), 3-468
with
F, = (299.8, 22.37),
Fy = 707.1. 3-469
3.8 Asymptotic Properties 281
The corresponding closed-loop characteristic values are —9.519 + /9.222 s+
and —3.168s"*. Upon comparison with the purely proportional scheme of
Example 3.8 (Section 3.4,1), we note that the proportional part of the feed-
back, represented by F,, has hardly changed (compare 3-169), and that the
corresponding closed-loop poles, which are —9.658 + /9.094 s-! in Example
3.8 also have moved very little. Figure 3.18 gives the response of the integral
angular 0.004
position
C
0,002
(rad)
0
0 1 2
input
_——— (s)
voltage 0 1 2
(V) =2
Fig. 3.18. Response of the integral position control system to a constant torque of 10 N m
on the shaft of the motor.
control system from zero initial conditions to a constant torque 7, of 10 Nm
on the shaft of the motor. The maximum deviation of the angular displace-
ment caused by this constant torque is about 0.004 rad.
3.8* ASYMPTOTIC PROPERTIES OF
TIME-INVARIANT OPTIMAL CONTROL LAWS
3.8.1* Asymptotic Behavior of the Optimal Closed-Loop Poles
In Section 3.2 we saw that the stability of time-invariant linear state feedback
control systems can be achieved or improved by assigning the closed-loop
poles to suitable locations in the left-half complex plane. We were not able
to determine which pole patterns are most desirable, however. In Sections 3.3
and 3.4, the theory of linear optimal state feedback control systems was
developed. For time-invariant optimal systems, a question of obvious
interest concerns the closed-loop pole patterns that result. This section is
devoted to a study of these patterns. This will supply valuable information
about the response that can be expected from optimal regulators.
282 Optimal Linear State Feedback Control Systems
Suppose that in the time-invariant regulator problem we let
R, = pN, 3-470
where N is a positive-definite symmetric matrix and p a positive scalar. With
this choice of R,, the optimization criterion is given by
[eroReo + pu?(t)Nu(t)] dt. 3-471
The parameter p determines how much weight is attributed to the input; a
large value of p results in small input amplitudes, while a small value of p
permits large input amplitudes. We study in this subsection how the locations
of the optimal closed-loop regulator poles vary as a function of p. For this
investigation we employ root locus methods.
In Section 3.4.4 we saw that the optimal closed-loop poles are the left-
half plane characteristic values of the matrix Z, where
A. TBR Bo A —1py—B?
3-472
vb — = Pp
—R, =A — DTR,D —At
Using Lemma 1.2 (Section 1.5.4) and Lemma 1.1 (Section 1.5.3), we expand
det (sI — Z) as follows:
‘pi BNeBe
det (sf! — Z) = det e
D7 RID she At
= det (sI — A)
- det (1 + A?) — D?R,D(sI — A) ; BN 8" |
= det (sJ — A) det (sI + A”)
- det [ = D*R.DGI = A) ; BN B{(sI + any |
= det (sI — A)(—1)" det (—sI — A)
- det E + 2 N“*B*(—sI — AT)*D7R,D(sI — Avs
Pp
= (—1)"4(s)¢(—s) det E ue NAH —S)RyHC) | 3-473
Pp
3.8 Asymptotic Properties 283
where n is the dimension of the state x, and
(s) = det (sJ — A),
(8) ( ) 3-474
H(s) = D(sI — A)“B.
For simplicity, we first study the case where both the input wu and the con-
trolled variable z are scalars, while
R, = 1, N=1. 3-475
We return to the multiinput multioutput case at the end of this section. It
follows from 3-473 that in the single-input single-output case the closed-loop
poles are the left-half plane zeroes of
1
D'6eM—9] 1 +2 HHH), 3.476
p
where H(s) is now a scalar transfer function. Let us represent H(s) in the form
H(s) = ws) : 3-477
(5s)
where y(s) is the numerator polynomial of H(s). It follows that the closed-
loop poles are the left-half plane roots of
P(s)p(—s) + ; w(s)y(—s) = 0. 3-478
We can apply two techniques in determining the loci of the closed-loop poles.
The first method is to recognize that 3-478 is a function of s, to substitute
s? = 5’, and to find the root loci in the s’-plane. The closed-loop poles are
then obtained as the left-half plane square roots of the roots in the s’-plane.
This is the root-square locus method (Chang, 1961).
For our purposes it is more convenient to trace the loci in the s-plane. Let
us write
Dp
ys) = a] ] (s — »),
ae 3-479
$(s) =e inl (s aa 7;)s
where the v,, i= 1,2,-+--,p, are the zeroes of H(s), and the z,, 7= 1,
2,°°:,n, the poles of H(s). To bring 3-478 in standard form, we rewrite it
with 3-479 as
aCe eee opel (s—»)(s+»)=0. 3-480
284 Optimal Linear State Feedback Control Systems
Applying the rules of Section 1.5.5, we conclude the following.
(a) As p — 0, of the 2n roots of 3-480 a total number of 2p asymptotically
approach the p zeroes »;, i= 1,2,°°-, p, and their negatives —v,, i= 1,
Dec p-
(b) As p—>0, the other 2(n — p) roots of 3-480 asymptotically approach
straight lines which intersect in the origin and make angles with the positive
real axis of
BR Se EA ren) 4 ap a de
Dien 3 3-481
al Ll ao ee ee eee
HD.
(c) As p> 0, the 2(n — p) faraway roots of 3-480 are asymptotically at a
distance
oe 1/[2(n—p)] i 3-482
p
from the origin.
(d) As p—> 00, the 2n roots of 3-480 approach the n poles 7;, i= 1,
2,:°*,m, and their negatives —7,, i = 1, 2,---, 7.
Since the optimal closed-loop poles are the left-half plane roots of 3-480 we
easily conclude the following (Kalman, 1964).
Theorem 3.11. Consider the steady-state solution of the single-input single-
output regulator problem with R,; = 1 and R, = p. Assume that the open-
loop system is stabilizable and detectable and let its transfer function be given by
cA i (s — »,)
HO) = er AO, 3-483
II (s — 7;)
t=]
where the 7;, i= 1,2,°*++,n, are the characteristic values of the system.
Then we have the following.
(a) As p | 0, p of the n optimal closed-loop characteristic values asymptotically
approach the numbers #,, i = 1,2,+-++, p, where
; if R
ane I, v; if e (v;) << 0, 3-484
—?, if Re(y;) > 0.
(b) As p | 0, the remaining n — p optimal closed-loop characteristic values
asymptotically approach straight lines which intersect in the origin and make
3.8 Asymptotic Properties 285
angles with the negative real axis of
ae i ea fea ade
Sar 3-485
heciat =
bette) a =n ee bee a n — p even.
n—'p 2
These faraway closed-loop characteristic values are asymptotically at a distance
2\1/[2(n—p) J
Wy = («) 3-486
P
from the origin.
(c) As p— ©, the n closed-loop characteristic values approach the numbers
Gent = 1,2, °* *, i; where
x =| a, if Re(m) <0,
3-487
—T; if Re (ar,) > 0:
The configuration of poles indicated by (b) is known as a Butterworth
configuration of order n — p with radius w, (Weinberg, 1962). In Fig. 3.19
Re
Fig. 3.19. Butterworth pole configurations of orders one through five and unit radii.
286 Optimal Linear State Feedback Control Systems
some low-order Butterworth configurations are indicated. In the next section
we investigate what responses correspond to such configurations.
Figure 3.20 gives an example of the behavior of the closed-loop poles for a
fictitious open-loop pole-zero configuration. Crosses mark the open-loop
poles, circles the open-loop zeroes. Since the excess of poles over zeroes is
two, a second-order Butterworth configuration results as p | 0. The remaining
pto
x open-loop poles SS
© open-loop zeroes
Fig. 3.20. Root loci of the characteristic values of the matrix Z (dashed and solid lines)
and of the closed-loop poles (solid lines only) for a single-input single-output system with a
fictitious open-loop pole-zero configuration.
closed-loop pole approaches the open-loop zero as p | 0. For p— oo the
closed-loop poles approach the single left-half plane open-loop pole and the
mirror images of the two right-half plane open-loop poles.
We now return to the multiinput case. Here we must investigate the roots of
$(s)¢(—s) det 1 ao NAH —S)RH)| = 0. 3-488
p
The problem of determining the root loci for this expression is not as simple
3.8 Asymptotic Properties 287
as in the single-input case. Evaluation of the determinant leads to an expres-
sion of the form
2% (l/p)s = 3-489
where the functions «,(1/p), i=0,1,2,--+,m are polynomials in 1/p.
Rosenau (1968) has given rules that are helpful in obtaining root loci for
such an expression. We are only interested in the asymptotic behavior of the
roots as p—> 0 and p-—» o. The roots of 3-488 are also the roots of
d(s)¢(—s) det [pI + N“H7(—s)R,H(s)] = 0. 3-490
As p ~ 0 some of the roots go to infinity; those that stay finite approach the
zeroes of
$(s)¢(—s) det [NH 7(—s)R,H(s)], 3-491
provided this expression is not identically zero. Let us suppose that H(s) is a
square transfer matrix (in Section 3.7 we saw that this is a natural assump-
tion). Then we know from Section 1.5.3 that
Aen@e 3-492
p(s)’
where p(s) is a polynomial at most of degree n — k, with n the dimension of
the system and k& the dimension of u and z. As a result, we can write for 3-491
det (Rs)
det (N) w(—s)y(s). 3-493
Thus it follows that as p | 0 those roots of 3-490 that stay finite approach the
zeroes of the transfer matrix H(s) and their negatives. This means that those
optimal closed-loop poles of the regulator that stay finite approach those
zeroes of H(s) that have negative real parts and the negatives of the zeroes
that have nonnegative real parts.
It turns out (Rosenau, 1968) that as p | 0 the far-off closed-loop regulator
poles, that is, those poles that go to infinity, generally do not form a single
Butterworth configuration, such as in the single-input case, but that they
group into several Butterworth configurations of different orders and different
radii (see Examples 3.19 and 3.21). A rough estimate of the distance of the
faraway poles from the origin can be obtained as follows. Let ¢,(s) denote
the closed-loop characteristic polynomial. Then we have
$As)b—s) = $(s)4(—s) det E a : N“H 7(—S)RsH() |. 3-494
288 Optimal Linear State Feedback Control Systems
For small p we can approximate the right-hand side of this expression by
d(s)p(—s) det E N*H™—s)RsHG)| = det (Rs) y(s)y(—s) 3-495
p p* det (N)
where k is the dimension of the input wu. Let us write
v(s) = J] (s — »). i=1
Then the leading term in 3-491 is given by
a? et (Rs) (_ 19,2 p* det (N)
This shows that the polynomial ¢,(s)¢,(—s) contains the following terms
3-496
3-497
$A)b(—9) = (—'S Ho t(D)
det (Rs) 2
—s) = (—1)"s"" + +++ + a? ——*— (—1)?s°? +--+. 3-498
The terms given are the term with the highest power of s and the term with
the highest power of 1/p. An approximation of the faraway roots of this
polynomial (for small p) is obtained from
prdaet (K.)
(= 1) "57? bm (—1)’s°? = 0. 3-499
p* det (N)
It follows that the closed-loop poles are approximated by the left-half plane
solutions of
1/[2(n—p)
So ocala =e [2(n—p ;
3-500
p* det (N)
This first approximation indicates a Butterworth configuration of order
n — p. We use this expression to estimate the distance of the faraway poles
to the origin; this (crude) estimate is given by
, det (Rs) 1/[2(n—p)] reeccn) p* det (N)
3-501
We consider finally the behavior of the closed-loop poles for p — oo. In
this case we see from 3-494 that the characteristic values of the matrix Z
approach the roots of ¢(s)¢(—s). This means that the closed-loop poles
approach the numbers #;, i = 1,2,--+,n, as given by 3-487.
We summarize our results for the multiinput case as follows.
Theorem 3.12. Consider the steady-state solution of the multiinput time-
invariant regulator problem. Assume that the open-loop system is stabilizable
and detectable, that the input u and the controlled variable z have the same
3.8 Asymptotic Properties 289
dimension k, and that the state x has dimension n. Let H(s) be the k x k open-
loop transfer matrix
(Ss): =<D(sl —A)-+1B; 3-502
Suppose that $(s) is the open-loop characteristic polynomial and write
ws)
“TT (s — »)
det [H(s)] = 3-503
Ss n
Hs) IT (s — 7)
Assume that « 4 0 and take R, = pN with N > 0, p > 0.
(a) Then as p —>0, p of the optimal closed-loop regulator poles approach the
values ;,i = 1,2,°-+, p, where
| Y; if Re(y) <0
3-504
sar URE) 0,
The remaining closed-loop poles go to infinity and group into several Butter-
worth configurations of different orders and different radii. A rough estimate
of the distance of the faraway closed-loop poles to the origin is
G det (Rs) jo
3-505
p” det (N)
(b) As p—> ©, the n closed-loop regulator poles approach the numbers #,,
Lime a2 ie where
4 m if Re(m) <0
a, =
3-506—7; if Re (Gz) > 0.
We conclude this section with the following comments. When p is very
small, large input amplitudes are permitted. As a result, the system can move
fast, which is reflected in a great distance of the faraway poles from the origin.
Apparently, Butterworth pole patterns give good responses. Some of the
closed-loop poles, however, do not move away but shift to the locations of
open-loop zeroes. As is confirmed later in this section, in systems with left-
half plane zeroes only these nearby poles are “‘canceled”’ by the open-loop
zeroes, which means that their effect in the controlled variable response is not
noticeable.
The case p = © corresponds to a very heavy constraint on the input
amplitudes. It is interesting to note that the “cheapest” stabilizing control
law (“cheap”’ in terms of input amplitude) is a control law that relocates the
unstable system poles to their mirror images in the left-half plane.
Problem 3.14 gives some information concerning the asymptotic behavior of
the closed-loop poles for systems for which dim (uw) 4 dim (2).
290 Optimal Linear State Feedback Control Systems
Example 3.18. Position control system
In Example 3.8 (Section 3.4.1), we studied the locations of the closed-loop
poles of the optimal position control system as a function of the parameter p.
As we have seen, the closed-loop poles approach a Butterworth configuration
of order two. This is in agreement with the results of this section. Since the
open-loop transfer function
H(s) = S 3-507
s(s + a)
has no zeroes, both closed-loop poles go to infinity as p | 0.
Example 3.19. Stirred tank
As an example of a multiinput multioutput system consider the stirred tank
regulator problem of Example 3.9 (Section 3.4.1). From Example 1.15
(Section 1.5.3), we know that the open-loop transfer matrix is given by
0.01 0.01
s+0.01 s+0.01
H(s) = 3-508
O25) is
s+ 0.02 -s + 0.02
For this transfer matrix we have
0.01
det [H(s)] = 3-509
(s + 0.01)(s + 0.02) |
Apparently, the transfer matrix has no zeroes; all closed-loop poles are
therefore expected to go to «0 as p | 0. With the numerical values of Example
3.9 for R, and N, we find for the characteristic polynomial of the matrix Z
s+ (—05 x 10° — aa p
= (0.4 x 1077 + O7416 4 107r plOe
p
). 3-510
Figure 3.21 gives the behavior of the two closed-loop poles as p varies.
Apparently, each pole traces a first-order Butterworth pattern. The asymp-
totic behavior of the roots for p | 0 can be found by solving the equation
=A
gt — 0.02416 5, 107% _
7 = 9, 3-511
p p
which yields for the asymptotic closed-loop pole locations
0.1373 :
= and as : 3-512
Vp Jp
3.8 Asymptotic Properties 291
locus of first pole
locus of second pole
Re
(s—!)
Fig. 3.21. Loci of the closed-loop roots for the stirred tank regulator. The locus on top
originates from —0.02, the one below from —0.01.
The estimate 3-505 yields for the distance of the faraway poles to the origin
0.1
3-513
Jp
We see that this is precisely the geometric average of the values 3-512.
Example 3.20. Pitch control of an airplane
As an example of a more complicated system, we consider the longi-
tudinal motions of an airplane (see Fig. 3.22). These motions are character-
ized by the velocity u along the x-axis of the airplane, the velocity w along
the z-axis of the airplane, the pitch 0, and the pitch rate g = 6. The x- and
z-axes are rigidly connected to the airplane. The x-axis is chosen to coincide
with the horizontal axis when the airplane performs a horizontal stationary
flight.
horizontal
a
Z-OxIS vertical
Fig. 3.22. The longitudinal motions of an airplane.
292 Optimal Linear State Feedback Control Systems
The control variables for these motions are the engine thrust 7 and the
elevator deflection 6. The equations of motion can be linearized around a
nominal solution which consists of horizontal flight with constant speed.
It can be shown (Blakelock, 1965) that the linearized longitudinal equations
of motion are independent of the lateral motions of the plane.
We choose the components of the state as follows:
&(@) = ul), incremental speed along z-axis,
€,(t) = w(t), ana along z-axis, Esty OZ), pitch,
E(t) = 4), pitch rate.
ee
The input variable, this time denoted by c, we define as
we Ge incremental engine thrust, 3.515
a(t) elevator deflection.
With these definitions the state differential equations can be found from the
inertial and aerodynamical laws governing the motion of the airplane (Blake-
lock, 1965). For a particular medium-weight transport aircraft under cruising
conditions, the following linearized state differential equation results:
—0.01580 0.02633 —9.810 0
—0.1571 —1.030 0 120.5
a(t) = a(t)
0 0 0 1
0.0005274 —0.01652 0 — 1.466
0.0006056 0
0 —9.496
+ c(t). 3-516
0
0 = JeD05
Here the following physical units are employed: u and w in m/s, 6 in rad,
g in rad/s, Tin N, and 6 in rad.
In this example we assume that the thrust is constant, so that the elevator
deflection 6(t) is the only control variable. With this the system is described
3.8 Asymptotic Properties 293
by the state differential equation
—0.01580 0.02633 —9.810 0
—0.1571 — 1.030 0 120.5
(1) = x(t)
0 0 0 1
0.0005274 —0.01652 0 — 1.466
0
—9.496
+ O(t). 3-517
0
—5.565
As the controlled variable we choose the pitch 0(t):
G1) = (050; 1, Daw). 3-518
It can be found that the transfer function from the elevator deflection 6(t)
to the pitch (1) is given by —
—5.565s* — 5.6635 — 0.1112
; = : 3-519
Se 2.012s" =) 3,.5445~ + 0.064879 4- 0.05079
The poles of the transfer function are
—0.006123 + j0.09353, 3-520
1.200 ay 024,
while the zeroes are given by
—9.02004 and —0.9976. 3-521
The loci of the closed-loop poles can be found by machine computation.
They are given in Fig. 3.23. As expected, the faraway poles group into a
Butterworth pattern of order two and the nearby closed-loop poles approach
the open-loop zeroes. The system is further discussed in Example 3.22.
Example 3.21. The control of the longitudinal motions of an airplane
In Example 3.20 we considered the control of the pitch of an airplane
through the elevator deflection. In the present example we extend the system
by controlling, in addition to the pitch, the speed along the 2-axis. As an
additional control variable, we use the incremental engine thrust 7(¢). Thus
we choose for the input variable
Oe fee incremental engine thrust,
a(t) 3-522
elevator deflection,
294 Optimal Linear State Feedback Control Systems
p=0.1 ond lorger
b
Fig. 3.23. Loci of the closed-loop poles of the pitch stabilization system. (a) Faraway
poles; (b) nearby poles.
and for the controlled variable
ee (“) incremental speed along the z-axis, 3.523
6(t) pitch.
From the system state differential equation 3-516, it can be computed that
the system transfer matrix has the numerator polynomial
p(s) = —0.003370(s + 1.002), 3-524
3.8 Asymptotic Properties 295
which results in a single open-loop zero at — 1.002. The open-loop poles are
at —0.006123 + j0.09353 and —1.250 + 71.394.
Before analyzing the problem any further, we must establish the weighting
matrices R, and N. For both we adopt a diagonal form and to determine
their values we proceed in essentially the same manner as in Example 3.9
(Section 3.4.1) for the stirred tank. Suppose that R,; = diag (01, 02). Then
z7(1)R,2(t) = o,u°(t) + o,0°(t). 3-525
Now let us assume that a deviation of 10 m/s in the speed along the z-axis is
considered to be about as bad as a deviation of 0.2 rad (12°) in the pitch.
We therefore select o, and o, such that
o,(10)° = o,(0.2)°, 3-526
or
01 = = 0.0004. 3-527
ror
Thus we choose ‘
0.02 O
Rs = Py 3-528
0 50
where for convenience we have let det (R3;) = 1. Similarly, suppose that
N = diag (p;, pg) so that
c*(t)Nc(t) = p, T(t) + pz 6°(t). 3-529
To determine p, and pz, we assume that a deviation of 500 N in the engine
thrust is about as acceptable as a deviation of 0.2 rad (12°) in the elevator
deflection. This leads us to select
pi(500)? = p,(0.2)?, 3-530
which results in the following choice of N:
0.0004 0
N= : 3-531
0 2500
With these values of R, and N, the relation 3-505 gives us the following
estimate for the distance of the far-off poles:
a (22 det (R;) = 0.15
3-532
w pe det (N) pus ;
The closed-loop pole locations must be found by machine computation.
Table 3.4 lists the closed-loop poles for various values of p and also gives the
estimated radius wy). We note first that one of the closed-loop poles
approaches the open-loop zero at —1.002. Furthermore, we see that a, is
296 Optimal Linear State Feedback Control Systems
only a very crude estimate for the distance of the faraway poles from the
origin.
The complete closed-loop loci are sketched in Fig. 3.24. It is noted that the
appearance of these loci is quite different from those for single-input systems.
Two of the faraway poles assume a second-order Butterworth configuration,
while the third traces a first-order Butterworth pattern. The system is further
discussed in Example 3.24.
P=0.01
Fig. 3.24. Loci of the closed-loop poles for the longitudinal motion control system.
(a) Faraway poles; (6) nearby pole and one faraway pole. For clarity the coinciding
portions of the loci on the real axis are represented as distinct lines; in reality they coincide
with the real axis.
3.8 Asymptotic Properties 297
Table 3.4 Closed-Loop Poles for the Longitudinal Motion Stability Augmentation
System
Closed-loop poles Wo
p (ses) ()
00 —0.006123 + 0.09353 ==15250) 4/1394 0
1 —0.1734 + j0.1184 1203025 / 1415 0.15
LOS =0/5252 = 0.2166 p31 Or etal O 0.32
10 —0.8877 — 0.2062 1906 te] 2.479 0.70
lo —0.9745 — 0.2431 —3.484 + j3.609 15
19 —0.9814 — 0.4806 —6.241 + j6.312 a2
Oe? == 1,020 — 1.344 Liay ct hielo 7.0
10% = 1003 — 4.283 =19.83. 2. 719.85 15
10-* —1,002 —42.82 —O2, 32° yOn.t3 70
3.8.2* Asymptotic Properties of the Single-Input Single-Output
Nonzero Set Point Regulator
In this section we discuss the single-input single-output nonzero set point
optimal regulator in the light of the results of Section 3.8.1. Consider the
single-input system
a(t) = Ax(t) + bu(t) 3-533
with the scalar controlled variable
C(t) = dz(t): 3-534
Here 5 is a column vector and d a row vector. From Section 3.7 we know
that the nonzero set point optimal control law is given by
= — 3-535
p(t) = —fx(t) + ~~ a 0) Co,
where f is the row vector
ewes 3-536
with P the solution of the appropriate Riccati equation. Furthermore, H,(s)
is the closed-loop transfer function
H,(s) = d(sI — A + bf), 3-537
and ¢, is the set point for the controlled variable.
In order to study the response of the regulator to a step change in the set
point, let us replace ¢, with a time-dependent variable ¢,(¢). The inter-
connection of the open-loop system and the nonzero set point optimal
298 Optimal Linear State Feedback Control Systems
control law is then described by
H(t) = (A — bf a(t) + b—~ LA), we
Ae
L(t) (8):
Laplace transformation yields for the transfer function T(s) from the variable
set point C,(t) to the controlled variable C(t):
T(s) = d(sI — A+ bf)"b a 3-539
Let us consider the closed-loop transfer function d(sJ — A + bf)~b.
Obviously,
7 vs)
(I A+ bf) b= 3-540
$.(s)
where ¢,(s) = det (sJ — A+ bf) is the closed-loop characteristic poly-
nomial and y,(s) is another polynomial. Now we saw in Section 3.7 (Eq.
3-428) that the numerator of the determinant of a square transfer matrix
D(sI — A + BF)“ B is independent of the feedback gain matrix F and is
equal to the numerator polynomial of the open-loop transfer matrix
D(sI — A)*B. Since in the single-input single-output case the determinant
of the transfer function reduces to the transfer function itself, we can immedi-
ately conclude that p,(s) equals y(s), which is defined from
w(s)
H(s) = 3-541
f(s)
Here H(s) = d(sI — A)b is the open-loop transfer function and ¢(s) =
det (sJ — A) the open-loop characteristic polynomial.
As a result of these considerations, we conclude that
As) Pel)
T(s) = 3-542
$.(8) y(0)
Let us write
p
ys) = «[] (s — »), 3-543
i=1
where the y,, i = 1,2,--+,p, are the zeroes of H(s). Then it follows from
Theorem 3.11 that as p | 0 we can write for the closed-loop characteristic
polynomial
1) n—p
(8) = TI (s — #IT — 4.00), 3-544
i= i=l
where the #,, i= 1, 2,---,p, are defined by 3-484, the n,, i= 1, 2,---,
3.8 Asymptotic Properties 299
n — p, form a Butterworth configuration of order n — p and radius 1, and
where
a 1/[2(n—p)]
on iE) 3-545
p
Substitution of 3-544 into 3-542 yields the following approximation for T(s):
: » [-~+1
T(s) ~ 1G) bee
n—p = ~
ese 7 a) paca 3-546
c= Ni®o B;
This we rewrite as
—-+1
1 . Y;
1S eae Lh 3-547
Xn—p(S/@p) i=1 a Ss ae 1
where ¥,_,(S) is a Butterworth polynomial of order n — p, that is, 7,_,(s) is
defined by
ta-o(6) = TT (-* +1). 3-548
i=1
;
Table 3.5 lists some low-order Butterworth polynomials (Weinberg, 1962).
Table 3.5 Butterworth Polynomials of Orders One
through Five
Ws) =s +1
xs) = 5% + 1.4145 + 1
ys) = 5° + 25? + 2s + 1
xs) = s* + 2.61353 + 3.4145? + 2.6135 + 1
x,(S) = 5° + 3.236s* + 5.2365° + 5.2365? + 3.2365 + 1
The expression 3-547 shows that, if the open-loop transfer function has
zeroes in the left-half plane only, the control system transfer function 7(s)
approaches
1 oe 3-549
Xn—p(S]@o)
as p | 0. We call this a Butterworth transfer function of order n — p and
break frequency wp . In Figs. 3.25 and 3.26, plots are given of the step
responses and Bode diagrams of systems with Butterworth transfer functions
300 Optimal Linear State Feedback Control Systems
step
response
0 5 t—=(s) 10
Fig. 3.25. Step responses of systems with Butterworth transfer functions of orders one
through five with break frequencies 1 rad/s.
of various orders. The plots of Fig. 3.25 give an indication of the type of
response obtained to steps in the set point. This response is asymptotically
independent of the open-loop system poles and zeroes (provided the latter
are in the left-half complex plane). We also see that by choosing p small
enough the break frequency , can be made arbitrarily high, and corre-
spondingly the settling time of the step response can be made arbitrarily
small. An extremely fast response is of course obtained at the expense of
large input amplitudes.
This analysis shows that the response of the controlled variable to changes
in the set point is dominated by the far-off poles 7,9, = 1,2,°°:,n —p.
The nearby poles, which nearly coincide with the open-loop zeroes, have
little effect on the response of the controlled variable because they nearly
cancel against the zeroes. As we see in the next section, the far-off poles
dominate not only the response of the controlled variable to changes in the
set point but also the response to arbitrary initial conditions. As can easily
be seen, and as illustrated in the examples, the nearby poles do show up in
the input. The settling time of the tracking error is therefore determined by
the faraway poles, but that of the input by the nearby poles.
The situation is less favorable for systems with right-half plane zeroes.
Here the transmission 7(s) contains extra factors of the form
s+ %;
3-550
A Saas
2.
3.8 Asymptotic Properties 301
00! 0. as lO w—e (rad/s) 100
lone IN
10-8
leg?
0.01 oF 10 = w—e(rad/s) 100
Fig. 3.26. Modulus and phase of Butterworth transfer functions of orders one through
five with break frequencies 1 rad/s.
and the tracking error response is dominated by the nearby pole at #;. This
points to an inherent limitation in the speed of response of systems with
right-half plane zeroes. In the next subsection we further pursue this topic.
First, however, we summarize the results of this section:
Theorem 3.13. Consider the nonzero set point optimal control law 3-535 for
the time-invariant, single-input single-output, stabilizable and detectable
system
a(t) = Ax(t) + bu(t),
3-551C(t) = dx(t),
where R, = 1 and R, = p. Then as p|\ 0 the control system transmission
T(s) (i.e., the closed-loop transfer function from the variable set point C(t)
302 Optimal Linear State Feedback Control Systems
to the controlled variable ¢(t)) approaches
p v;
L(s) = 3-552
Xn—p eae, ij=1 os Ss
where %n_,(S) is a Butterworth polynomial of order n — p and radius 1, n is
the order of the system, p is the number of zeroes of the open-loop transfer
function of the system, wy is the asymptotic radius of the Butterworth con-
figuration of the faraway closed-loop poles as given by 3-486, ¥;,i = 1,2,°"°,
p, are the zeroes of the open-loop transfer function, and 9;,i = 1,2,°*-,p,
are the open-loop transfer function zeroes mirrored into the left-half complex
plane.
Example 3.22. Pitch control
Consider the pitch control problem of Example 3.20. For p = 0.01 the
steady-state feedback gain matrix can be computed to be
f = (—0.0001174, 0.002813, —10.00, —1.619). 3-556
The corresponding closed-loop characteristic polynomial is given by
f(s) = s* + 11.495? + 66.435? + 56.845 + 1.112. 3-557
The closed-loop poles are
—0.02004, —0.9953, and —0.5239 + j5.323. 3-558
We see that the first two poles are very close to the open-loop zeroes at
—0.2004 and —0.9976. The closed-loop transfer function is given by
Ys) _ —5,565s" — 5.663s — 0.1112
H{s) = : : , 3-559
d, ‘Gye S* + 11.49s° + 66.435 + 56.845 + 1.112
so that H,(0) = —0.1000. As a result, the nonzero set point control law is
given by
6(t) = —fx(t) — 10.000,(2), 3-560
where 0,(t) is the set point of the pitch.
Figure 3.27 depicts the response of the system to a step of 0.1 rad in the
set point 6,(f). It is seen that the pitch 6 quickly settles at the desired value;
its response is completely determined by the second-order Butterworth
configuration at —5.239 + 75.323. The pole at —0.9953 (corresponding to a
time constant of about | s) shows up most clearly in the response of the speed
along the z-axis w and can also be identified in the behavior of the elevator
deflection 6. The very slow motion with a time constant of 50s, which
3.8 Asymptotic Properties 303
inerementot 2% Ge) 5
speed
along
X-axis
u
(m/s) -4
10
speed
along
Z-axis
Ww
(m/s) IP 0
0 t—s(s) 5
0.1
pitch
6 =
(rad)
0) 0 t—e(s) 5
0 t—e(s) 5
elevator 9%
deflection
i)
(rad)
-1 Fig. 3.27. Response of the pitch control system
to a step of 0.1 rad in the pitch angle set point.
corresponds to the pole at —0.02004, is represented in the response of the
speed along the x-axis u, the speed along the z-axis w, and also in the elevator
deflection 0, although this is not visible in the plot. It takes about 2 min for
u and w to settle at the steady-state values —49.16 and 7.754 m/s.
Note that this control law yields an initial elevator deflection of —1 rad
which, practically speaking, is far too large.
304 Optimal Linear State Feedback Control Systems
Example 3.23. System with a right-half plane zero
As a second example consider the single-input system with state differ-
ential equation
0 1 0
eh x(t) + u(t). 3-561
0 —2 1
Let us choose for the controlled variable
CH=, —D«@). 3-562
This system has the open-loop transfer function
Hee 3-563
s(s + 2)
and therefore has a zero in the right-half plane. Consider for this system the
criterion
| “12 + pur(s)] dt. 3-564
It can be found that the corresponding Riccati equation has the steady-state
solution
(estes (me ara Vp
ip x —$_—_____= 3-565
Vp p(—2 + /44+- a 1 Vp
The corresponding steady-state feedback gain vector is
By yh ath
fet eis [4 ae a a= 3-566
VP Ty VP.
The closed-loop poles can be found to be
st Soo eae te wae
sleds ee ee 3-567
z p/p p/p
Figure 3.28 gives a sketch of the loci of the closed-loop poles. As expected,
one of the closed-loop poles approaches the mirror image of the right-half
plane zero, while the other pole goes to — oo along the real axis.
For p = 0.04 the closed-loop characteristic polynomial is given by
s? + 6245s + 5, 3-568
and the closed-loop poles are located at —0.943 and —5.302. The closed-loop
Im
open-loop
poles
| open-loop
(671) zero
Re —»(s7))
Fig. 3.28. Loci of the closed-loop poles for a system with a right-half plane zero.
0 1 2 3 4 5
t —s (s)
Fig. 3.29. Response of a closed-loop system with a right-half plane zero to a unit step in
the set point.
305
306 Optimal Linear State Feedback Control Systems
transfer function is
sy We ~ $2 ae ye sae
so that H,(0) = 0.2. The steady-state feedback gain vector is
f= G6, 4-245). 3-570
As a result, the nonzero set point control law is
w(t) = —(5, 4.245)a(t) + 52,(t). 3-571
Figure 3.29 gives the response of the closed-loop system to a step in the set
point ¢,(t). We see that in this case the response is dominated by the closed-
loop pole at —0.943. It is impossible to obtain a response that is faster and at
the same time has a smaller integrated square tracking error.
3.8.3* The Maximally Achievable Accuracy of Regulators and Tracking
Systems
In this section we study the steady-state solution of the Riccati equation as p
approaches zero in
R, = pN. 3-572
The reason for our interest in this asymptotic solution is that it will give us
insight into the maximally achievable accuracy of regulator and tracking
systems when no limitations are imposed upon the input amplitudes.
This section is organized as follows. First, the main results are stated in the
form of a theorem. The proof of this theorem (Kwakernaak and Sivan,
1972), which is long and technical, is omitted. The remainder of the section
is devoted to a discussion of the results and to examples.
We first state the main results:
Theorem 3.14. Consider the time-invariant stabilizable and detectable linear
system
a(t) = Ax(t) + Bu(t),
2(t) = Da(t), gat
where B and D are assumed to have full rank. Consider also the criterion
| “TE (t)Reel(t) + u?(t)Rau(t)] dt 3-574
where R, > 0, R, > 0. Let
R, = pN; 3-575
with N > 0 and p a positive scalar, and let P,, be the steady-state solution of
3.8 Asymptotic Properties 307
the Riccati equation
—P(t) = D?R,D — P,(t)BR;B™P (t) + A7P,(t) + P,(t)A,
-57
P,(t,) = 0. aan
Then the following facts hold.
(a) The limit
lim £ = Be 3-577
4 p+0
exists.
(b) Let z,(t), t > ty, denote the response of the controlled variable for the
regulator that is steady-state optimal for R, = pN. Then
ee i oO) Ree (ab a (ta lear ia) 3-578
pl0 Jto
(c) If dim (z) > dim (wu), then P, # 0.
(d) Jf dim (2) = dim (u) and the numerator polynomial y(s) of the open-loop
transfer matrix H(s) = D(sI — A)"B is nonzero, Py = 0 if and only if y(s)
has zeroes with nonpositive real parts only.
(e) If dim (z) < dim (wu), then a sufficient condition for Py to be 0 is that there
exists a rectangular matrix M such that the numerator polynomial w(s) of
the square transfer matrix D(sI — A)*BM is nonzero and has zeroes with
nonpositive real parts only.
A discussion of the significance of the various parts of the theorem now
follows. Item (a) states that, as we let the weighting coefficient of the input p
decrease, the criterion
[ [z,7(t)Rsz,(t) + pu," (t)Nu,(t)] dt = x7 (to)P,x(to) 3-579
ed to
approaches a limit x” (t))Pot(to). If we identify R; with W, and N with W,,, the
expression 3-579 can be rewritten as
{ Crop P| Coase 3-580
to to
where C, ,(t) = z(t) W,z,(t) is the weighted square regulating error and
C,,, p(t) = Teele) W_u,(t) the weighted square input. It follows from item (b)
of the theorem that as p | 0, of the two terms in 3-580 the first term, that is,
the integrated square regulating error, fully accounts for the two terms
together so that in the limit the integrated square regulating error is given by
lim i C,,,(t) dt = a7 (t,)Pyx(ty). 3-581
p\o
to
308 Optimal Linear State Feedback Control Systems
If the weighting coefficient p is zero, no costs are spared in the sense that
no limitations are imposed upon the input amplitudes. Clearly, under this
condition the greatest accuracy in regulation is achieved in the sense that the
integrated square regulation error is the least that can ever be obtained.
Parts (c), (d), and (e) of the theorem are concerned with the conditions
under which P, = 0, which means that ultimately perfect regulation is
approached since
(o 6)
lim { C,_,(t) dt = 0. 3-582
p10 Jto
Part (c) of the theorem states that, if the dimension of the controlled variable
is greater than that of the input, perfect regulation is impossible. This is
very reasonable, since in this case the number of degrees of freedom to control
the system is too small. In order to determine the maximal accuracy that can
be achieved, Py must be computed. Some remarks on how this can be done
are given in Section 4.4.4.
In part (d) the case is considered where the number of degrees of freedom
is sufficient, that is, the input and the controlled variable have the same dimen-
sions. Here the maximally achievable accuracy is dependent upon the
properties of the open-loop system transfer matrix H(s). Perfect regulation is
possible only when the numerator polynomial w(s) of the transfer matrix
has no right-half plane zeroes (assuming that y(s) is not identical to zero).
This can be made intuitively plausible as follows. Suppose that at time 0 the
system is in the initial state x). Then in terms of Laplace transforms the
response of the controlled variable can be expressed as
Z(s) = H(s)U(s) + D(sI — A)“, 3-583
where Z(s) and U(s) are the Laplace transforms of z and w, respectively.
Z(s) can be made identical to zero by choosing
U(s) = —A(s)D(sI — A)“ 2. 3-584
The input u(t) in general contains delta functions and derivatives of delta
functions at time 0. These delta functions instantaneously transfer the system
from the state x, at time 0 to a state 2(0*) that has the property that 2(0*+) =
Dzx(0*) = 0 and that z(t) can be maintained at 0 for t > 0 (Sivan, 1965).
Note that in general the state a(t) undergoes a delta function and derivative
of delta function type of trajectory at time 0 but that z(t) moves from 2(0) =
Dx, to 0 directly, without infinite excursions, as can be seen by inserting
3-584 into 3-583.
The expression 3-584 leads to a stable behavior of the input only if the
inverse transfer matrix H~*(s) is stable, that is if the numerator polynomial
p(s) of H(s) has no right-half plane zeroes. The reason that the input 3-584
3.8 Asymptotic Properties 309
cannot be used in the case that H~1(s) has unstable poles is that although the
input 3-584 drives the controlled variable z(t) to zero and maintains 2(t) at
zero, the input itself grows indefinitely (Levy and Sivan, 1966). By our
problem formulation such inputs are ruled out, so that in this case 3-584
is not the limiting input as p | 0 and, in fact, costless regulation cannot be
achieved.
Finally, in part (e) of the theorem, we see that if dim (z) < dim (uw), then
Py = 0 if the situation can be reduced to that of part (d) by replacing the
input uv with an input wv’ of the form
u(t) = Mu(t). 3-585
The existence of such a matrix M is not a necessary condition for P, to be
zero, however.
Theorem 3.14 extends some of the results of Section 3.8.2. There we found
that for single-input single-output systems without zeroes in the right-half
complex plane the response of the controlled variable to steps in the set
point is asymptotically completely determined by the faraway closed-loop
poles and not by the nearby poles. The reason is that the nearby poles are
canceled by the zeroes of the system. Theorem 3.14 leads to more general
conclusions. It states that for multiinput multioutput systems without zeroes
in the right-half complex plane the integrated square regulating error goes to
zero asymptotically. This means that for small values of p the closed-loop
response of the controlled variable to any initial condition of the system is
very fast, which means that this response is determined by the faraway
closed-loop poles only. Consequently, also in this case the effect of the nearby
poles is canceled by the zeroes. The slow motion corresponding to the nearby
poles of course shows up in the response of the input variable, so that in
general the input can be expected to have a much longer settling time than
the controlled variable. For illustrations we refer to the examples.
It follows from the theory that optimal regulator systems can have “hidden
modes’”’ which do not appear in the controlled variable but which do appear
in the state and the input. These modes may impair the operation of the
control system. Often this phenomenon can be remedied by redefining or
extending the controlled variable so that the requirements upon the system
are more faithfully reflected.
It also follows from the theory that systems with right-half plane zeroes are
fundamentally deficient in their capability to regulate since the mirror images
of the right-half plane zeroes appear as nearby closed-loop poles which are
not canceled by zeroes. If these right-half plane zeroes are far away from the
origin, however, their detrimental effect may be limited.
It should be mentioned that ultimate accuracy can of course never be
310 Optimal Linear State Feedback Control Systems
achieved since this would involve infinite feedback gains and infinite input
amplitudes. The results of this section, however, give an idea of the ideal
performance of which the system is capable. In practice, this limit may not
nearly be approximated because of the constraints on the input amplitudes.
So far the discussion has been confined to the deterministic regulator
problem. Let us now briefly consider the stochastic regulator problem, which
includes tracking problems. As we saw in Section 3.6, we have for the
stochastic regulator problem
C4 pC, = tt PV), 3-586
where C,,, and C,,,, indicate the steady-state mean square regulation error
and the steady-state mean square input, respectively. It immediately follows
that
Ti (Corcsup et Cnc uae Pel): 3-587
po
It is not difficult to argue [analogously to the proof of part (b) of Theorem
3.14] that of the two terms in 3-587 the first term fully accounts for the left-
hand side so that
me Ciasp = (Pov) 3-588
This means that perfect stochastic regulation (Py) = 0) can be achieved under
the same conditions for which perfect deterministic regulation is possible. It
furthermore is easily verified that, for the regulator with nonwhite disturb-
ances (Section 3.6.1) and for the stochastic tracking problem (Section 3.6.2),
perfect regulation or tracking, respectively, is achieved if and only if in both
cases the plant transfer matrix H(s) = D(sI — A)"B satisfies the con-
ditions outlined in Theorem 3.14. This shows that it is the plant alone that
determines the maximally achievable accuracy and not the properties of the
disturbances or the reference variable.
In conclusion, we note that Theorem 3.14 gives no results for the case in
which the numerator polynomial y(s) is identical to zero. This case rarely
seems to occur, however.
Example 3.24. Control of the longitudinal motions of an airplane
As an example of a multiinput system, we consider the regulation of the
longitudinal motions of an airplane as described in Example 3.21. For p =
10°° we found in Example 3.21 that the closed-loop poles are —1.003,
— 4,283, and —19.83 + 719.83. The first of these closed-loop poles practically
coincides with the open-loop zero at —1.002.
Figure 3.30 shows the response of the closed-loop system to an initial
deviation in the speed along the a-axis u, and to an initial deviation in the
pitch 6. It is seen that the response of the speed along the x-axis is determined
05
w
0
m (ce)
=i
0.01
0.01
pitch
8
8
(rad)
(rad)
0 05
t —— (s)
0.5
engine 6
thrust
T
0
if
(N)
(N)
-1000
-1000
elevator
deflection
6 ]
6 1
(rad)
Hiroe
0
0
05
05
t ——e— (5)
t ——e(s)
Fig. 3.30. Closed-loop responses of a longitudinal stability augmentation system for an
airplane. Left column: Responses to the initial state u(0)=1 m/s, while all other com-
ponents of the initial state are zero. Right column: Response to the initial state 0(0) =
0.01 rad, while all other components of the initial state are zero,
312 Optimal Linear State Feedback Control Systems
mainly by a time constant of about 0.24 s which corresponds to the pole at
—4,283. The response of the pitch is determined by the Butterworth con-
figuration at —19.83 + j19.83. The slow motion with a time constant of
about | s that corresponds to the pole at — 1.003 only affects the response of
the speed along the z-axis w.
We note that the controlled system exhibits very little interaction in the
sense that the restoration of the speed along the x-axis does not result in an
appreciable deviation of the pitch, and conversely.
Finally, it should be remarked that the value p = 10~° is not suitable from
a practical point of view. It causes far too large a change in the engine thrust
and the elevator angle. In addition, the engine is unable to follow the fast
thrust changes that this control law requires. Further investigation should
take into account the dynamics of the engine.
The example confirms, however, that since the plant has no right-half
plane zeroes an arbitrarily fast response can be obtained, and that the nearby
pole that corresponds to the open-loop zero does not affect the response of the
controlled variable.
Example 3.25. 4 system with a right-half plane zero
In Example 3.23 we saw that the system described by 3-561 and 3-562 with
the open-loop transfer function
ies 3-589
s(s + 2)
has the following steady-state solution of the Riccati equation
1+<V1 + 4p + 2VP vp
i 3-590
7 = Ve 8
Pp p(-24 f4+t 42)
p vp
As p approaches zero, P approaches P,, where
2 £0
Py = . 3-591
0 0
As we saw in Example 3.23, in the limit p | 0 the response is dominated by
the closed-loop pole at —1.
3.9* SENSITIVITY OF LINEAR STATE FEEDBACK
CONTROL SYSTEMS
In Chapter 2 we saw that a very important property of a feedback system is
its ability to suppress disturbances and to compensate for parameter changes.
3.9 Sensitivity 313
In this section we investigate to what extent optimal regulators and tracking
systems possess these properties. When we limit ourselves to time-invariant
problems and consider only the steady-state case, where the terminal time is
at infinity, the optimal regulator and tracking systems we have derived have
the structure of Fig. 3.31. The optimal control law can generally be represented
state of
reference varioble
setpoint
Zo
Fig. 3.31. The structure of a time-invariant linear state feedback control system.
in the form
u(t) = —Fae(t) + F,x,(t) + Fo, 3-592
where ~,(t) is the state of the reference variable, z) the set point, and Pe Abe.
and F, are constant matrices. The matrix F is given by
F = R;'B'P, 3-593
where P is the nonnegative-definite solution of the algebraic Riccati equation
0 = D*R,D — PBR;'B*P + AtP + PA. 3-594
In Chapter 2 (Section 2.10) we saw that the ability of the closed-loop system
to suppress disturbances or to compensate for parameter changes as compared
to an equivalent open-loop configuration is determined by the behavior of the
return difference matrix J(s). Let us derive J(s) in the present case. The
transfer matrix of the plant is given by (sJ — A) 1B, while that of the feed-
back link is simply F. Thus the return difference matrix is
J(s) = I+ (sI — A)“BF. 3-595
Note that we consider the complete state x(t) as the controlled variable (see
Section 2.10).
We now derive an expression for J(s) starting from the algebraic Riccati
equation 3-594, Addition and substraction of an extra term sP yields after
314 Optimal Linear State Feedback Control Systems
rearrangement
0 = D?R,D — PBR,'B* P — (—sI — A*)P — P(sI — A). 3-596
Premultiplication by B’(—sJ — A’) and postmultiplication by (sJ — A) 7B
gives
0 = BT(—sI — AT)"\(— PBRz'B* P + D™R,D*)(sI — A)'B
— BTP(sI — A) "1B — BT(—sI — A*)*PB. 3-597
This can be rearranged as follows:
[i + B?(—sI — A?)4PBRe IR. + Ry BPI — Ay B)
= R, + B?(—sI — AT)"D?R,D(sI — A)"B. 3-598
After substitution of R;'B? P = F, this can be rewritten as
{t + BT(—sI — At)“ F*]R,[I + F(sI — A) *B]
= R, + H7(—s)R;H(s), 3-599
where H(s) = D(sJ — A)“1B. Premultiplication of both sides of 3-599 by
F* and postmultiplication by F yields after a simple manipulation
it + FFB(—sl — At) "|F*R.FII + (sI — A) BF]
= F’R,F + FTH*7(—s)R3H(s)F, 3-600
or
J7(—s)F?R,FJ(s) = FTR,F + FTH™(—s)R3H(s)F. 3-601
If we now substitute s = jw, we see that the second term on the right-hand
side of this expression is nonnegative-definite Hermitian; this means that we
can write
J*(—jw)WJ(jo) > W for all real aw, 3-602
where
W = FTR,F. 3-603
We know from Section 2.10 that a condition of the form 3-602 guarantees
disturbance suppression and compensation of parameter changes as com-
pared to the equivalent open-loop system for all frequencies. This is a useful
result. We know already from Section 3.6 that the optimal regulator gives
optimal protection against white noise disturbances entering at the input side
of the plant. The present result shows, however, that protection against
disturbances is not restricted to this special type of disturbances only. By the
same token, compensation of parameter changes is achieved.
Thus we have obtained the following result (Kreindler, 1968b; Anderson
and Moore, 1971).
3.9 Sensitivity 315
Theorem 3.15. Consider the system configuration of Fig. 3.31, where the
“plant” is the detectable and stabilizable time-invariant system
a(t) = Ax(t) + Bu(t). 3-604
Let the feedback gain matrix be given by
Bk Bey 3-605
where P is the nonnegative-definite solution of the algebraic Riccati equation
0 = D?R,D — PBR, BtP + ATP + PA. 3-606
Then the return difference
satisfies the inequality
J(s) = 1+ (sl — A)" BF 3-607
J7(—jw)WJ(jo) > W for all real a, 3-608
where
Wes FORE. 3-609
For an extension of this result to time-varying systems, we refer the reader
to Kreindier (1969).
It is clear that with the configuration of Fig. 3.31 improved protection is
achieved only against disturbances and parameter variations inside the feed-
back loop. In particular, variations in D fully affect the controlled variable
z(t). It frequently happens, however, that D does not exhibit variations. This
is especially the case if the controlled variable is composed of components
of the state vector, which means that z(f) is actually inside the loop (see
Fig..3,02).
Fig. 3.32. Example of a situation in which the controlled variable is inside the feedback
loop.
316 Optimal Linear State Feedback Control Systems
Theorem 3.15 has the shortcoming that the weighting matrix F7R,F is
known only after the control law has been computed; this makes it difficult
to choose the design parameters R; and R, such as to achieve a given weighting
matrix. We shall now see that under certain conditions it is possible to deter-
mine an asymptotic expression for W. In Section 3.8.3 it was found that if
dim (z) = dim (u), and the open-loop transfer matrix H(s) = D(sJ — A)“*B
does not have any right-half plane zeroes, the solution P of the algebraic
Riccati equation approaches the zero matrix as the weighting matrix R,
approaches the zero matrix. A glance at the algebraic Riccati equation 3-594
shows that this implies that
PBR, BP — DARD 3-610
as R, — 0, or, since R,'B? P = F, that
FTR,F > D?R,D 3-611
as R, — 0. This proves that the weighting matrix W in the sensitivity criterion
3-608 approaches D7 R,D as R, — 0.
We have considered the entire state x(t) as the feedback variable. This
means that the weighted square tracking error is
x1 (1)W2x(t). 3-612
From the results we have just obtained, it follows that as R, — 0 this can be
replaced with
a7 (t)D?R,D2(t) = 27(t)Rg2(t). 3-613
This means (see Section 2.10) that in the limit R, — 0 the controlled variable
receives all the protection against disturbances and parameter variations,
and that the components of the controlled variable are weighted by Ry. This
is a useful result because it is the controlled variable we are most interested in.
The property derived does not hold, however, for plants with zeroes in the
right-half plane, or with too few inputs, because here P does not approach
the zero matrix.
We summarize our conclusions:
Theorem 3.16. Consider the weighting matrix
W = F*R,F, 3-614
where
P= RioB UP, 3-615
with P the nonnegative-definite symmetric solution of
= D?R,D — PBR;'BTP + ATP + PA. 3-616
3.9 Sensitivity 317
If the conditions are satisfied (Theorem 3.14) under which P 0 as R, 0,
then
W — DtR,D 3-617
as R, +0.
The results of this section indicate in a general way that state feedback
systems offer protection against disturbances and parameter variations. Since
sensitivity matrices are not very convenient to work with, indications as to
what to do for specific parameter variations are not easily found. The follow-
ing general conclusions are valid, however.
1. As the weighting matrix R, is decreased the protection against disturb-
ances and parameter variations improves, since the feedback gains increase.
For plants with zeroes in the left-half complex plane only, the break fre-
quency up to which protection is obtained is determined by the faraway
closed-loop poles, which move away from the origin as R, decreases.
2. For plants with zeroes in the left-half plane only, most of the protection
extends to the controlled variable. The weight attributed to the various
components of the controlled variable is determined by the weighting
matrix Rs.
3. For plants with zeroes in the right-half plane, the break frequency up to
which protection is obtained is limited by those nearby closed-loop poles
that are not canceled by zeroes.
Example 3.26. Position control system
As an illustration of the theory of this section, let us perform a brief
sensitivity analysis of the position control system of Example 3.8 (Section
3.4.1). With the numerical values given, it is easily found that the weighting
matrix in the sensitivity criterion is given by
a ~ 1 0.08364
W = FTR,F = : 3-618
0.08364 0.006994
This is quite close to the limiting value
il ©
Do R.D = 3-619
0 0
To study the sensitivity of the closed-loop system to parameter variations,
in Fig. 3.33 the response of the closed-loop system is depicted for nominal
and off-nominal conditions. Here the off-nominal conditions are caused by
a change in the inertia of the load driven by the position control system.
The curves a correspond to the nominal case, while in the case of curves 5
and c the combined inertia of load and armature of the motor is § of nominal
318 Optimal Linear State Feedback Control Systems
0.)
position
‘+
(rad)
input a
Fig. 3.33. The effect of parameter variations on the response of the position control
system: (a) Nominal load; (6) inertial load S of nominal; (c) inertial load 3 of nominal.
and 3 of nominal, respectively. A change in the total moment of inertia by a
certain factor corresponds to division of the constants « and « by the same
factor. Thus 3 of the nominal moment of inertia yields 6.9 and 1.18 for «
and x, respectively, while 3 of the nominal moment of inertia results in the
values 3.07 and 0.525 for « and «, respectively. Figure 3.33 vividly illustrates
the limited effect of relatively large parameter variations.
3.10 CONCLUSIONS
This chapter has dealt with state feedback control systems where all the
components of the state can be accurately measured at all times. We have
discussed quite extensively how linear state feedback control systems can
be designed that are optimal in the sense of a quadratic integral criterion.
Such systems possess many useful properties. They can be made to exhibit a
satisfactory transient response to nonzero initial conditions, to an external
reference variable, and to a change in the set point. Moreover, they have
excellent stability characteristics and are insensitive to disturbances and
parameter variations.
3.11 Problems 319
All these properties can be achieved in the desired measure by appropri-
ately choosing the controlled variable of the system and properly adjusting
the weighting matrices R; and R,. The results of Sections 3.8 and 3.9, which
concern the asymptotic properties and the sensitivity properties of steady-
state control laws, give considerable insight into the influence of the weighting
matrices.
A major objection to the theory of this section, however, is that very often
it is either too costly or impossible to measure all components of the state.
To overcome this difficulty, we study in Chapter 4 the problem of recon-
structing the state of the system from incomplete and inaccurate measure-
ments. Following this in Chapter 5 it is shown how the theory of linear state
feedback control can be integrated with the theory of state reconstruction
to provide a general theory of optimal linear feedback control.
3.41 PROBLEMS
3.1. Stabilization of the position control system
Consider the position control system of Example 3.4 (Section 3.3.1).
Determine the set of all linear control laws that stabilize the position
control system.
3.2. Position control of a frictionless de motor
A simplification of the regulator problem of Example 3.4 (Section 3.3.1)
occurs when we neglect the friction in the motor; the state differential equation
then takes the form
0 1 0
2h r= a(t) + M(t), 3-620
0 O K
where x(t) = col [&,(t), &.(t)]. Take as the controlled variable
C(t) = (1, O)a(t), 3-621
and consider the criterion
ty [ eo + oor ae 3622
to
(a) Determine the steady-state solution P of the Riccati equation.
(b) Determine the steady-state control law.
(c) Compute the closed-loop poles. Sketch the loci of the closed-loop poles
as p varies.
(d) Use the numerical values x = 150 rad/(V s?) and p = 2.25 rad?/V?
and determine by computation or simulation the response of the closed-loop
system to the initial condition €,(0) = 0.1 rad, €,(0) = 0 rad/s.
320 Optimal Linear State Feedback Control Systems
3.3. Regulation of an amplidyne
Consider the amplidyne of Problem 1.2.
(a) Suppose that the output voltage is to be kept at a constant value e,5
Denote the nominal input voltage as eo, and represent the system in terms of a
shifted state variable with zero as nominal value.
(b) Choose as the controlled variable
C(t) = en(t) — ea0, 3-623
and consider the criterion
ty [eo + purer a to
3.624
where
L(t) = eo(t) — eoo- 3-625
Find the steady-state solution of the resulting regulator problem for the
following numerical values:
ALS i0 ae eee ae
L, 2
R, =5Q, R, = 10Q, 3-626
k, = 20V/A, ky = 50 V/A,
p = 0.025.
(c) Compute the closed-loop poles.
(d) Compute or simulate the response of the closed-loop system to the
initial conditions 7(0) = col (1, 0) and 7(0) = col (0, 1).
3.4. Stochastic position control system
Consider the position control problem of Example 3.4 (Section 3.3.1) but
assume that in addition to the input a stochastically varying torque operates
upon the system so that the state differential equation 3-59 must be extended
as follows:
FOS Oot eae 7
a a(t ay
Here »(t) represents the effect of the disturbing torque. We model »(t) as
exponentially correlated noise:
FON a: : v(t) + o(t), 3-628
where c(t) is white noise with intensity 207/06.
(a) Consider the controlled variable
t(t) = (1, 0)2'(0) 3-629
3.11 Problems 321
and the criterion
ty B| { [2'(t) + pu(t)] ai) 3-630
to
Find the steady-state solution of the corresponding stochastic regulator
problem.
(b) Use the numerical values
k = 0.787 rad/(V s?),
a = 4.6571, 3-631
ge = 51ad/s*,
Gs Ls.
Compute the steady-state rms values of the controlled variable ¢(t) and the
input u(t) for p = 0.2 x 10-* rad?/V?.
3.5. Angular velocity tracking system
Consider the angular velocity tracking problem of Examples 3.12 (Section
3.6.2) and 3.14 (Section 3.6.3). In Example 3.14 we found that the value of p
that was chosen (p = 1000) leaves considerable room for improvement.
(a) Vary p and select that value of p that results in a steady-state rms input
voltage of 3 V.
(b) Compute the corresponding steady-state rms tracking error.
(c) Compute the corresponding break frequency of the closed-loop system
and compare this to the break frequency of the reference variable.
3.6. Nonzero set point regulator for an amplidyne
Consider Problem 3.3 where a regulator has been derived for an amplidyne.
(a) Using the results of this problem, find the nonzero set point regulator.
(b) Simulate or calculate the response of the regulator to a step in the
output voltage set point of 10 V.
3.7. Extension of the regulator problem
Consider the linear time-varying system
a(t) = A(t)x(t) + B(t)u(t) 3-632
with the generalized quadratic criterion
ty { [eT()Ri(tha(t) + 2x7 (t)Ryo(thu(t) + u7(t)Ro(d)u(t)] dt + x*(h)P,x(h),
to 3-633
where R,(t), R,(t), and R,(t) are matrices of appropriate dimensions.
322 Optimal Linear State Feedback Control Systems
(a) Show that the problem of minimizing 3-633 for the system 3-632 can
be reformulated as minimizing the criterion
[ worn + u'7(t)R,(t)u'(t)] dt + #7(t))P12(t)
3-634
for the system
a(t) = A’(t)x(t) + B(t)u'(t),
3-635
where
Ryi(t) = R,(t) — Ryo(t)Ro"()Ria(t),
u'(t) = u(t) + Re (t)Ria(t)2(t),
A'(t) = A(t) — B(t)Ra*()Ria(t)
(Kalman, 1964; Anderson, 1966a; Anderson and Moore, 1971).
(b) Show that 3-633 is minimized for the system 3-632 by letting
3-636
u(t) = —F°(t)x(t),
3-637
where
F(t) = Ry (t)[B7()P() + Ra),
with P(t) the solution of the matrix Riccati equation
3-638
—P(t) = [A(t) — BIDRs*()RB(1))" PC)
+ P(t)[A(t) — B()Rs*()Ri5(1)]
+ R(t) — Ri(t)Re (NRa(t)
— P(t)B()Rz ()B7()P(), t<h,
3-639
P(t,) — tae
(c) For arbitrary F(t), t < t,, let P(t) be the solution of the matrix differential
equation
— P(t) = [A(t) — BO) F (|? Pt) + P(D[A(t) — BOF)
+ R(t) — Ri(f)F(t) — FT()RE()
+ FR ()FQ), t<h,
3-640
PG)" Pj.
Show that by choosing F(t) equal to F°(t), P(t) is minimized in the sense that
P(t) > P(t), t < 4, where P(t) is the solution of 3-639. Remark: The proof
of (c) follows from (b). One can also prove that 3-637 is the best linear
control law by rearranging 3-640 and applying Lemma 3.1 (Section 3.3.3) to it.
3.8*. Solutions of the algebraic Riccati equation (O’Donnell, 1966; Ander-
son, 1966b; Potter, 1964)
Consider the algebraic Riccati equation
0 = R, — PBR,;'B*P + PA + AP. 3-641
3.11 Problems 323
Let Z be the matrix
3-642
Z can always be represented as
L=Wiw=, 3-643
where J is the Jordan canonical form of Z. It is always possible to arrange
the columns of W such that J can be partitioned as
Noes ' 3-644
Joy Jo0
Here Jy,, Jz, and Jy. are n X n blocks. Partition W accordingly as
Wi, W,
W = ( = af : ; Wor Was
(a) Consider the equality
3-645
ZW = WI, 3-646
and show by considering the 12- and 22-blocks of this equality that if W,,
is nonsingular P = W,.W,,' is a solution of the algebraic Riccati equation.
Note that in this manner many solutions can be obtained by permuting the
order of the characteristic values in J.
(b) Show also that the characteristic values of the matrix A —
BR;'B" W,.W;, are precisely the characteristic values of J. and that the
(generalized) characteristic vectors of this matrix are the columns of W,,.
Hint: Evaluate the 12-block of the identity 3-646.
3.9*, Steady-state solution of the Riccati equation by diagonalization
Consider the 2m x 2n matrix Z as given by 3-247 and suppose that it
cannot be diagonalized. Then Z can be represented as
Z=Wwiy, 3-647
where J is the Jordan canonical form of Z, and W is composed of the charac-
teristic vectors and generalized characteristic vectors of Z. It is always
possible to arrange the columns of W such that J can be partitioned as
follows
J= ; 3-648
Jo1 J 50
where the n xX n matrix J;, has as diagonal elements those characteristic
values of Z that have positive real parts and half of those that have zero
324 Optimal Linear State Feedback Control Systems
real parts. Partition W and V = W~ accordingly as
W ee i oy V me ie e| 3-649
Wo Woe Vo, Voge
Assume that {A, B} is stabilizable and {A, D} detectable. Follow the argu-
ment of Section 3.4.4 closely and show that for the present case the following
conclusions hold.
(a) The steady-state solution P of the Riccati equation
—P(t) = R, — P(t)BRz‘B* P(t) + ATP(t) + P(t)A 3-650
satisfies
Vix + Bae = 0. 3-651
(b) W,, is nonsingular and
P = W,.Win- 3-652
(c) The steady-state optimal behavior of the state is given by
a(t) = Wy e772? Wr2(to). 3-653
Hence Z has no characteristic values with zero real parts, and the steady-
state closed-loop poles consist of those characterstic values of Z that have
negative real parts. Hint: Show that
et =
hee 3-654
Xx( t) ev aot] ”
where the precise form of X(t) is unimportant.
3.10*. Bass’ relation for P (Bass, 1967)
Consider the algebraic Riccati equation
0 = R, — PBR;'BTP + ATP + PA 3-655
and suppose that the conditions are satisfied under which it has a unique
nonnegative-definite symmetric solution. Let the matrix Z be given by
“Cr prea
i : 3-656
—R, Ae,
It follows from Theorem 3.8 (Section 3.4.4) that Z has no characteristic
values with zero real parts. Factor the characteristic polynomial of Z as
follows
det (sJ — Z) = $(s)¢(—s) 3-657
such that the roots of 4(s) have strictly negative real parts. Show that P
3.11 Problems 325
satisfies the relation:
I #2 | = (), 3-658
lg
Hint: Write $(Z) = 6(WJW~>) = W4(J)W+ = Wd4(J)V where V = Wo
and J = diag (A, —A) in the notation of Section 3.4.4.
3.11*. Negative exponential solution of the Riccati equation (Vaughan,
1969)
Using the notation of Section 3.4.4, show that the solution of the time-
invariant Riccati equation
—P(t) = R, — P(t)BRz/BT P(t) + ATP(t) + P(t)A,
3-659
P(t,) = Nhe
can be expressed as follows:
P(t) = [Woo a W,G(ty ars t)|[Wy» ts Wi G(t, am Dire 3-660
where
Gi) =e“'Sse™, 3-661
with
S = (Vi + VigP1)(Vor1 + VooPi)™- 3-662
Show with the aid of Problem 3.12 that S can also be written in terms of Was
S = —(Wo — PyWy2) "(Woy — Pi Wi). 3-663
3.12*. The relation between W and V
Consider the matrix Z as defined in Section 3.4.4.
(a) Show that if e = col (e’, e”), where e’ and e” both are n-dimensional
vectors, is a right characteristic vector of Z corresponding to the characteristic
value /, that is, Ze = Ae, then (e’”, —e’”) is a left characteristic vector of Z
corresponding to the characteristic value —A, that is,
(e"?, —e'T)Z = —A(e"?, —e'*). 3-664
(b) Assume for simplicity that all characteristic values 4;,i = 1, 2, ++: , 2n,
of Z are distinct and let the corresponding characteristic vectors be given by
e,, i= 1,2,-+:,2n. Scale the e; such that if the characteristic vector
e = col (e’, e”) corresponds to a characteristic value A, and f = col (f’, f")
corresponds to —A, then
frre = ee. 3-665
Show that if W is a matrix of which the columns are e,, i= 1,2,°-°-, 2n,
and we partition
Wy W.
W = ( 11 ‘i 3-666
Woy Woo
326 Optimal Linear State Feedback Control Systems
then (O’Donnell, 1966; Walter, 1970)
& Wh —Wi
Wm tie 2) 3-667
21 fal
Hint: Remember that left and right characteristic vectors for different
characteristic values are orthogonal.
3.13*. Frequency domain solution of regulator problems
For single-input time-invariant systems in phase-variable canonical form,
the regulator problem can be conveniently solved in the frequency domain.
Let
&(t) = Ax(t) + bu(t) 3-668
be given in phase-variable canonical form and consider the problem of
minimizing
| “TC + puc(a dt, 3-669
where ;
C(t) = az(t). 3-670
(a) Show that the closed-loop characteristic polynomial can be found by
factorization of the polynomial
bee He 8). 3-671
P
where H(s) is the open-loop transfer function H(s) = d(sI — A)~b.
(b) Fora given closed-loop characteristic polynomial, show how the corre-
sponding control law
w(t) = —fe(0) 3-672
can be found. Hint: Compare Section 3.2.
3.14*. The minimum number of faraway closed-loop poles
Consider the problem of minimizing
} [a7 (t)R,2(t) + pu? (t)Nu(t)] dt, 3-673
to
where R, > 0, N > 0, and p > 0, for the system
a(t) = Ax(t) + Bu(t). 3-674
(a) Show that as p | 0 some of the closed-loop poles go to infinity while
the others stay finite. Show that those poles that remain finite approach the
left-half plane zeroes of
det [B7(—sI — AT)7R,(sI — A)“1B]. 3-675
3.11 Problems 327
(b) Prove that at least k closed-loop poles approach infinity, where k is
the dimension of the input w. Hint: Let |s| — 00 to determine the maximum
number of zeroes of 3-675. Compare the proof of Theorem 1.19 (Section
15:3).
(c) Prove that as p-—> oo the closed-loop poles approach the numbers
w;,, i= 1,2,+-+*,n, which are the characteristic values of the matrix A
mirrored into the left-half complex plane.
3.15*. Estimation of the radius of the faraway closed-loop poles from the
Bode plot (Leake, 1965; Schultz and Melsa, 1967, Section 8.4)
Consider the problem of minimizing
[eo + euton at 3.616
to
for the single-input single-output system
#(t) = Aw(t) + bult),
C(t) = de(t).
3-677Suppose that a Bode plot is available of the open-loop frequency response
function H(jw) = d(jwI — A)b. Show that for small p the radius of the
faraway poles of the steady-state optimal closed-loop system can beestimated:
as the frequency w, for which |H(j,)| = Jp.
4 OPTIMAL LINEAR RECONSTRUCTION OFeTAEso LATE
4.1 INTRODUCTION
All the versions of the regulator and tracking problems solved in Chapter 3
have the following basic assumption in common: the complete state vector
can be measured accurately. This assumption is often unrealistic. The most
frequent situation is that for a given system
a(t) = A(t)x(t) + BY)u(t), (fo) = Xo 4-1
only certain linear combinations of the state, denoted by y, can be measured:
yt) = Cathy. 4-2
The quantity y, which is assumed to be an /-dimensional vector, with /
usually less than the dimension n of the state x, will be referred to as the
observed variable.
The purpose of this chapter is to present methods of reconstructing the
state vector, or finding approximations to the state vector, from the observed
variable. In particular, we wish to find a functional F,
e‘H=Fly(r),t<7T<t, m<t, 4-3
such that «’(t) ~ x(t), where x’(t) represents the reconstructed state. Here to
is the initial time of the observations. Note that F[y(7), to <7 < ft], the
reconstructed a(t), is a function of the past observations y(7), tp) <7 < t,
and does not depend upon future observations, y(r), 7 > ¢. Once the state
vector has been reconstructed, we shall be able to use the control laws of
Chapter 3, which assume knowledge of the complete state vector, by re-
placing the actual state with the reconstructed state.
In Section 4.2 we introduce the observer, which is a dynamic system whose
output approaches, as time increases, the state that must be reconstructed.
Although this approach does not explicitly take into account the difficulties
that arise because of the presence of noise, it seeks methods of recon-
structing the state that implicitly involve a certain degree of filtering of the
noise.
328
4.2 Observers 329
In Section 4.3 we introduce all the stochastic phenomena associated with
the problem explicitly and quantitatively and find the optimal observer,
also referred to as the Kalman—Bucy filter. The derivation of the optimal
observer is based upon the fact that the optimal observer problem is “‘dual’”’
to the optimal regulator problem presented in Chapter 3.
Finally, in Section 4.4 the steady-state and asymptotic properties of the
Kalman-Bucy filter are studied. These results are easily obtained from
optimal regulator theory using the duality of the optimal regulator and
observer problems.
4.2 OBSERVERS
4.2.1 Full-Order Observers
In order to reconstruct the state x of the system 4-1 from the observed
variable y as given by 4-2, we propose a linear differential system the output
of which is to be an approximation to the state x in a suitable sense. It will
be investigated what structure this system should have and how it should
behave. We first introduce the following terminology (Luenberger, 1966).
Definition 4.1. The system
is an observer for the system
q(t) = Fg) + GWy(t) + A(tu(t), 4-4
a(t) = K(t)g(t) + Ly) + M@u(t),
a(t) = A(t)a(t) + B(t)u(t), ie
y(t) = C(a(t),
if for every initial state x(t ) of the system 4-5 there exists an initial state qy for
the system 4-4 such that
q(to) = Yo 4-6
implies
z(t) = 2(¢), iat 4-7
for all u(t), t > to.
We note that the observer 4-4 has the system input u and the system observed
variable y as inputs, and as output the variable z. We are mainly interested in
observers of a special type where the state q(t) of the observer itself is to be
an approximation to the system state 2(f):
Definition 4.2. The n-dimensional system
A(t) = F(t)&(t) + G()y(t) + H(du(t) 4-8
330 Optimal Reconstruction of the State
is a full-order observer for the n-dimensional system
a(t) = A(t)a(t) + B(t)u(t), 4-9a
y(t) = C(t)x(t), 4-9b
if E(t) = 2(to) 4-10
at) 2); Me ap 4-11
implies
for all u(t), t > to.
The observer 4-8 is called a full-order observer since its state ¢ has the same
dimension as the state « of the system 4-9. In Section 4.2.3 we consider
observers of the type 4-4 whose dimension is less than that of the state x.
Such observers will be called reduced-order observers.
We now investigate what conditions the matrices F, G, and H must
satisfy so that 4-8 qualifies as an observer. We first state the result.
Theorem 4.1. The system 4-8 is an observer for the system 4-9 if, and only if,
F(t) = A(t) — K()C(),
G(t) = K(t), 4-12
H(t) = Bit),
where K(t) is an arbitrary time-varying matrix. As a result, full-order observers
have the following structure:
&(t) = A(t)a(t) + B(Du(t) + K()[y() — C(D&(1)). 4-13
This theorem can be proved as follows. By subtracting 4-8 from 4-9a and
using 4-9b, the following differential equation for x(t) — &(t) is obtained:
#(t) — &(t) = [AW — GHC kW — FAD + [BO — HW.
4-14
This immediately shows that x(t) = #(t) for t > to, for all u(t), t > ty.
implies 4-12. Conversely, if 4-12 is satisfied, it follows that
#(t) — &0) = [A(t) — K(NCOM2O — €@), 4-15
which shows that if x(t)) = £(t)) then x(t) = €(t) for all t >t, for all
u(t), t > to. This concludes the proof of the theorem.
The structure 4-13 follows by substituting 4-12 into 4-8. Therefore, a
full-order observer (see Fig. 4.1) consists simply of a model of the system
with as extra driving variable a term that is proportional to the difference
4.2 Observers 331
Fig. 4.1. Block diagram of a full-order observer.
y(t) — g(t), where
Y(t) = CWH#(t) 4-16
is the observed variable as reconstructed by the observer. We call the matrix
K(t) the gain matrix of the observer. Up to this point the choice of K(t) for
t > fy is still arbitrary.
From 4-13 we see that the observer can also be represented as
A(t) = [A() — KOC + BOu(t) + KOy(0. 4-17
This shows that the stability of the observer is determined by the behavior of
A(t) — K(t)C(t). Of course stability of the observer is a desirable property
in itself, but the following result shows that stability of the observer has
further implications,
Theorem 4.2. Consider the observer
E(t) = A(Ha(t) + B(u(t) + K()[y() — C40] 4-18
for the system
Then the reconstruction error
a(t) = A(t)a(t) + B(t)u(t),
y(t) = C(t)x(t).
e(t) = x(t) — “(t) 4-19
4-20
332 Optimal Reconstruction of the State
satisfies the differential equation
é(t) = [A(t) — K(HC(Mle(2). The reconstruction error has the property that
e(t) > 0 as t—> ©, for all e(to), if, and only if, the observer is asymptotically stable.
4-21
4-22
That the reconstruction error, as defined by 4-20, satisfies the differential
equation 4-21 immediately follows from 4-15. Comparing 4-21 and 4-17, we
see that the stability of the observer and the asymptotic behavior of the
reconstruction error are both determined by the behavior of the matrix
A(t) — K(t)C(t). This clearly shows that the reconstruction error e(t)
approaches zero, irrespective of its initial value, if and only if the observer is
asymptotically stable. This is a very desirable result.
Observer design thus revolves about determining the gain matrix K(f) for
t > t) such that the reconstruction error differential equation 4-21 is asymp-
totically stable. In the time-invariant case, where all matrices occurring in
the problem formulation are constant, including the gain K, the stability of
the observer follows from the locations of the characteristic values of the
matrix A — KC. We refer to the characteristic values of A — KC as the
observer poles. In the next section we prove that, under a mildly restrictive
condition (complete reconstructibility of the system), all observer poles can
be arbitrarily located in the complex plane by choosing K suitably (within
the restriction that complex poles occur in complex conjugate pairs).
At this point we can only offer some intuitive guidelines for a choice of
K to obtain satisfactory performance of the observer. To obtain fast con-
vergence of the reconstruction error to zero, K should be chosen so that the
observer poles are quite deep in the left-half complex plane. This, however,
generally must be achieved by making the gain matrix K large, which in
turn makes the observer very sensitive to any observation noise that may be
present, added to the observed variable y(t). A compromise must be found.
Section 4.3 is devoted to the problem of finding an optimal compromise,
taking into account all the statistical aspects of the problem.
Example 4.1. Positioning system
In Example 2.4 (Section 2.3), we considered a positioning system described
by the state differential equation
On 0
&(t) = | Jeo oh ( Jo 4-23
0 —« K
Here x(t) = col [€,(¢), &(¢)], where &,(¢) denotes the angular displacement
4.2 Observers 333
and €,(t) the angular velocity. Let us assume that the observed variable 7(t)
is the angular displacement, that is,
mt) = (1, O)a(t).
A time-invariant observer for this system is given by
et 0 ky
a(t) = (, “)0 af ( Jo ah (, lag —(1, 0)#@], 4-24
K
where the constant gains k, and k, are to be selected. The characteristic
polynomial of the observer is given by
det _ + (12 0))| =. det ( )
0 s 0 -—« ky Ky sta
=s*+ (a+k,)s+k,. 4-25
With the numerical values of Example 2.4, the characteristic values of the
system 4-23 are located at 0 and —« = —4.6s". In order to make the
observer fast as compared to the system itself, let us select the gains k, and k,
such that the observer poles are located at —50 + /50s"'. This yields for
the gains:
k, = 95.40 s+, k, = 4561 s~. 4-26
In Fig. 4.2 we compare the output of the observer to the actual response of
the system. The initial conditions of the positioning system are
£(0) = Ol rad, ) §2,(0) = 0.5 rad/s, 4-27
pe reconstructed
i NEO
/ N
ongular
position
E(t) 0.1
(rad)
Fig. 4.2. Actual response of a positioning system and the response as reconstructed by a
full-order observer,
334 Optimal Reconstruction of the State
while the input voltage is given by
u(t) = —10V, i 0; 4-28
The observer has zero initial conditions. Figure 4.2 clearly shows the excellent
convergence of the reconstructed angular position to its actual behavior.
4.2.2* Conditions for Pole Assignment and Stabilization of Observers
In this section we state necessary and sufficient conditions for pole assign-
ment and stabilization of time-invariant full-order observers. We first have
the following result, which is dual to Theorem 3.1 (Section 3.2.2).
Theorem 4.3. Consider the time-invariant full-order observer
&(t) = A&(t) + K[y(t) — C&(t)] + Bu(t) 4-29
for the time-invariant system
a(t) = Ax(t) + Bu(t),
4-30
y(t) = Cx(t).
Then the observer poles, that is, the characteristic values of A — KC, can be
arbitrarily located in the complex plane (within the restriction that complex
characteristic values occur in complex conjugate pairs), by choosing the constant
matrix K suitably, if and only if the system 4-30 is completely reconstructible.
To prove this theorem we note that
det Vi (A — KG) = dev — Aa — CR ik 4-31
so that the characteristic values of A — KC are identical to those of A? —
C?K*. However, by Theorem 3.1 the characteristic values of A7 — C7 KT
can be arbitrarily located by choosing K appropriately if and only if the pair
{A”, C"} is completely controllable. From Theorem 1.41 (Section 1.8), we
know that {4”, C7} is completely controllable if and only if {A, C} is
completely reconstructible. This completes the proof.
If {A, C} is not completely reconstructible, the following theorem, which
is dual to Theorem 3.2 (Section 3.2.2) gives conditions for the stability of the
observer.
Theorem 4.4. Consider the time-invariant observer
&(t) = A&(t) + K[y(t) — C&(t)] + Bu(t) for the time-invariant system
4-32
a(t) = Ax(t) + Bu(t),
y(t) = Cx(t). 1
4.2 Observers 335
Then a matrix K can be found such that the observer is asymptotically stable if
and only if the system 4-33 is detectable.
Detectability was defined in Section 1.7.4. The proof of this theorem follows
by duality from Theorem 3.2.
4.2.3* Reduced-Order Observers
In this section we show that it is possible to find observers of dimension Jess
than the dimension of the system to be observed. Such observers are called
reduced-order observers. For simplicity we discuss only the time-invariant
case. Let the system to be observed be described by
&(t) = Ax(t) + Bu(t),
y(t) = Cx(t),
4-34
where the dimension of the state x(t) is n and the dimension of the observed
variable y(t) is given by /. Since the observation equation y(t) = Czx(t)
provides us with / linear equations in the unknown state 2(f), it is necessary
to reconstruct only n — / linear combinations of the components of the state.
This approach was first considered by Luenberger (1964, 1966). We follow
the derivation of Cumming (1969).
Assuming that C has full rank, we introduce an (nm — /)-dimensional
vector p(t),
pt) = Ca), 4-35
such that
C
4-36
(ay
is nonsingular. By the relations
it follows that
iD) == (CEG):
y(t) “ ) tae
p(t) = C’x(t),
CN ye)
soe | ) ( } Cc p(t)
4.38
It is convenient to write
C —I)
Ge
== (fare), 4-39
so that
at) == Tay(t) + Lap). 4-40
Thus if we reconstruct p(t) and denote the reconstructed value by f(t), we
336 Optimal Reconstruction of the State
can write the reconstructed state as
E(t) = Lyy(t) + L2p(t). 4-41
An observer for p(t) can be found by noting that p(t) obeys the following
differential equation
p(t) = C’Ax(t) + C’Bu(t), 4-42
or
p(t) = C’ALpp(t) + CAL y(t) + C’Bu(t). 4-43
Note that in this differential equation y(t) serves as a forcing variable.
If we now try to determine an observer for p by replacing p with p in 4-43
and adding a term of the form K(t)[y(t) — C2#(t)], where K is a gain matrix,
this is unsuccessful since from 4-41 we have y — C# = y — CLyy — CL,p =
y — y =0; apparently, y does not carry any information about p. New
information must be laid bare by differentiating y(t):
y(t) = CAx(t) + CBu(t) aa
= CAL, p(t) + CAL,y(t) + CBu(t).
Equations 4-43 and 4-44 suggest the observer
B(t) = C'ALsp(t) + CAL y(t) + C'Bu(t)
+ K[y(t) — CAL,y(t) — CBu(t) — CAL, p(t)]. 4-45
We leave it as an exercise to show that, if the pair {A, C} is completely
reconstructible, also the pair {C’AL,, CAL,} is completely reconstructible,
so that by a suitable choice of K all the poles of 4-45 can be placed at arbitrary
positions (Wonham, 1970a).
In the realization of the observer, there is no need to take the derivative
of y(t). To show this, define
q(t) = p(t) — Ky(t). 4-46
It is easily seen that
q(t) = [C’AL, — KCAL, ]q(t)
+ [C’AL,K + C'AL, — KCAL, — KCAL,K]y(t)
+ [C’B — KCBlu(t). 4-47
This equation does not contain y(t). The reconstructed state follows from
&(t) = Lyg(t) + (Ly + Lok)y(t). 4-48
Together, 4-47 and 4-48 constitute an observer of the form 4-4.
Since the reduced-order observer has a direct link from the observed
variable y(t) to the reconstructed state #(t), the estimate £(t) will be more
sensitive to measurement errors in y(t) than the estimate generated by a
4.2 Observers 337
full-order observer. The question of the effects of measurement errors and
system disturbances upon the observer is discussed in Section 4.3.
Example 4.2 Positioning system
In this example we derive a one-dimensional observer for the positioning
system we considered in Example 4.1. For this system the observed variable
is given by
n(t) = (1, O)ax(t). 4-49
Understandably, we choose the variable p(t), which now is a scalar, as
p(t) = (0, 1)x(2), 4-50
so that p(t) is precisely the angular velocity. It is immediately seen that p(t)
satisfies the differential equation
p(t) = —ap(t) + Ku(t). 4-51
Our observation equation we obtain by differentiation of 7(t):
H(t) = E(t) = £2(0) = p(n). 4-52
An observer for p(t) is therefore given by
PI) = —aplt) + Ke) + ALI) — pO), 4-53
where the scalar observer gain / is to be selected. The characteristic value of
the observer is —(« + A). To make the present design comparable to the
full-order observer of Example 4.1, we choose the observer pole at the same
distance from the origin as the pair of poles of Example 4.1. Thus we let
a +2 = 50/2 = 70.71 s. With « = 4.6 s+ this yields for the gain
= (FHS | 4-54
The reconstructed state of the original system is given by
P n(t)
= : tae). 4-55
P(t)
To obtain a reduced-order observer without derivatives, we set
g(t) = pt) — An(t). 4-56
By using 4-53 it follows that q(t) satisfies the differential equation
q(t) = —(a + Alg(t) + Kut) — (a + A)An(d). 4-57
In terms of g(t) the reconstructed state of the original system is given by
/ )
a(t) = | } 4-58
q(t) + An(t)
338 Optimal Reconstruction of the State
01
ongulor
osition actual
ES (t) ~~ and
1 reconstructed
(rad)
0 0.3 tw (s)
|
Cia
angular |
velocity \
Eo(t) 2
reconstructed
(rad/s)
Fig. 4.3. Actual response of a positioning system and the response as reconstructed by a
reduced-order observer.
In Fig. 4.3 we compare the output of the reduced-order observer described by
4-57 and 4-58 to the actual behavior of the system. The initial conditions of
the system are, as in Example 4.1:
€,(0) = 0.1 rad, €s(0)'=: 0.5 rad/s; 4-59
while the input is given by
u(t) = —10V, ced, 4-60
The observer initial condition is
q(0) = O rad/s. 4-61
Figure 4.3 shows that the angular position is of course faithfully reproduced
and that the estimated angular velocity quickly converges to the correct
value, although the initial estimate is not very good.
4.3 The Optimal Observer 339
4.3 THE OPTIMAL OBSERVER
4.3.1 A Stochastic Approach to the Observer Problem
In Section 4.2 we introduced observers. It has been seen, however, that in
the selection of an observer for a given system a certain arbitrariness remains
in the choice of the gain matrix K. In this section we present methods of
finding the optimal gain matrix. To this end we must make specific assump-
tions concerning the disturbances and observation errors that occur in the
system that is to be observed. We shall then be able to define the sense in
which the observer is to be optimal.
It is assumed that the actual system equations are
&(t) = A(t)x(t) + B(t)u(t) + w,(2), y(t) = C(t)x(t) + we(t). 4-62a
4-62b
Here w(t) is termed the state excitation noise, while w.(t) is the observation
or measurement noise. It is assumed that the joint process col [w,(t), w2(t)]
can be described as white noise with intensity
Vi(t) =“ Viet)
V)= A 4-63
Vit) ‘V~(t)
that is,
W1(t1)
E [w,7(te), We" (ts)] = V(t) 0(t, — ty). 4-64
W(t,
If V,.(t) = 0, the state excitation noise and the observation noise are un-
correlated. Later (in Section 4.3.5) we consider the possibility that w,(t)
and w,(t) can not be represented as white noise processes. A case of special
interest occurs when
eX ( ape 0 maa ras 4-65
This assumption means in essence that all components of the observed
variable are corrupted by white noise and that it is impossible to extract from
y(t) information that does not contain white noise. If this condition is satisfied,
we call the problem of reconstructing the state of the system 4-62 non-
singular.
Finally, we denote
E{x(to)} = %, E{[x(to) — %][x(to) — Xo)" } = Qo. Suppose now that a full-order observer of the form
4-66
A(t) = A(t)A(t) + B(t)u(t) + KY) — CH#O] 4-67
340 Optimal Reconstruction of the State
is connected to the system 4-62. Then the reconstruction error is given by
e(t) = a(t) — 2h). 4-68
The mean square reconstruction error
Ele"()W(He()}, 4-69
with W(t) a given positive-definite symmetric weighting matrix, is a measure
of how well the observer reconstructs the state of the system at time ¢. The
mean square reconstruction error is determined by the choice of #(t)) and of
K(zt), t) < 7 < t. The problem of how to choose these quantities optimally
is termed the optimal observer problem.
Definition 4.3. Consider the system
&(t) = A(t)x(t) + Bit)u(t) + wy (4),
y(t) = Cat) + welt),
t > to. 4-70
Here col [w,(t), w.(t)] is a white noise process with intensity
( V(t) ped
St 4-71
Vict) Ve(t)/
Furthermore, the initial state x(t)) is uncorrelated with w, and Woe,
E{x(t)} = X, E{[x(to) — Xq][x(to) — Za)" } = Qo, 4-72
and u(t), t > to, is a given input to the system. Consider the observer
#1) = A(DE(D) + Wu) + KOLO — CHE). 4-73
Then the problem of finding the matrix function K(r), ty <7 < t, and the
initial condition £(t)), so as to minimize
E{e"(t)W(the(t)}, 4-74
where
e(t) = x(t) — £(1), 4-75
and where W(t) is a positive-definite symmetric weighting matrix, is termed
the optimal observer problem. If
V(t) > 0, t > to, 4-76
the optimal observer problem is called nonsingular.
In Section 4.3.2 we study the nonsingular optimal observer problem where
the state excitation noise and the observation noise are assumed moreover
to be uncorrelated. In Section 4.3.3 we relax the condition of uncorrelated-
ness, while in Section 4.3.4 the singular problem is considered.
4.3. The Optimal Observer 341
4.3.2 The Nonsingular Optimal Observer Problem with Uncorrelated
State Excitation and Observation Noises
In this section we consider the nonsingular optimal observer problem where
it is assumed that the state excitation noise and the observation noise are
uncorrelated. This very important problem was first solved by Kalman and
Bucy (Kalman and Bucy, 1961), and its solution has had a tremendous
impact on optimal filtering theory. A historical account of the derivation of
the so-called Kalman-Bucy filter is given by Sorenson (1970).
Somewhat surprisingly the derivation of the optimal observer can be
based on Lemma 3.1 (Section 3.3.3). Before proceeding to this derivation,
however, we introduce the following lemma, which shows how time can be
reversed in any differential equation.
Lemma 4.1. Consider the differential equations
a “VAG me sae
d 4-77
X(t) —= Xo,
and
eee) =/flt —t4@)], t<h,
dt 4-78
y (ty) = Y1>
where ty < t,, and
[ee ie oe 4-79
Then if oe 4-80
the solutions of 4-77 and 4-78 are related as follows:
a(t) =y(t*—), 12 t ee
—_ x =
y(t) = x(t* — 2), t<h.
This lemma is easily proved by a change in variable from ¢ to t* — ¢.
We now proceed with our derivation of the optimal observer. Subtracting
4-67 from 4-62a and using 4-62b, we obtain the following differential equation
for the reconstruction error e(t) = x(t) — &(t):
x(t
é(t) = [A(t) — K(HNC(HJe(t) + CT, =x" )) w(t) 4-82
(ty) = &o>
where
Cy = U(to) — F(t), 4-83
342 Optimal Reconstruction of the State
and where, as yet, K(t), ¢ > to, is an arbitrary matrix function. Let us
denote by Q(t) the variance matrix of e(t), and by é(t) the mean of e(t):
EXe(t)} = e(t), 4-84
E{fe(t) — &()][e(t) — e(t)}"} = O(0).
Then we write
Efe(t)e(t)} = e(t)é7(t) + O(). 4-85
With this, using 1-469, the mean square reconstruction error can be expressed
as
Efe™()W(te(1)} = e*(QWHat) + tr [OW]. 4-86
The first term of this expression is obviously minimal when é(t) = 0. This
can be achieved by letting é(¢)) = 0, since by Theorem 1.52 (Section 1.11.2)
€(t) obeys the homogeneous differential equation
&(t) = [A@) — KNC@MIA(), = t > to. 4-87
We can make é@(f)) = 0 by choosing the initial condition of the observer as
4 (to) = Xo. 4-88
Since the second term of 4-86 does not depend upon é@(f), it can be minimized
independently. From Theorem 1.52 (Section 1.11.2), we obtain the following
differential equation for Q(t):
O(t) = [A(t) — K(NC(HIO() + OLA — KWCH]?
+ V(t) + K()V(t)K7(t). 4-89
The corresponding initial condition is
Or ee 0.. 4-90
Let us now introduce a differential equation in a matrix function P(t),
which is derived from 4-89 by reversing time (Lemma 4.1):
—P(t) = [AT(t* — 1) — C7t* — NK 7(t* — t)| P(t)
+ P()[ATEe=— 1) — C74" SRA =D)
+ V,(t* — t) + K(t* — tV.(t* — )K7(t* — 0), t<t,. 4-91
Here
OP eeitobot et 4-92
with ft, > fo. We associate with 4-91 the terminal condition
P(t,) = O>. 4-93
It immediately follows from Lemma 4.1 that
00) She Sy erie 4-94
4.3 The Optimal Observer 343
Letus now apply Lemma 3.1 (Section 3.3.3) to 4-91. This lemma shows that
the matrix P(t) is minimized if K(t* — 7),t <7 < t,, ischosen as K®°(t* — 7)
t<7< t,, where
>
K°(t* — 7) = Vz (t* — 7)C(t* — 7)P(z). 4-95
In this expression P(t) is the solution of 4-91 with K replaced by K®, that is,
—P(t) = V,(t* — 1) — P()CT(t* — NVF(t* — 1C(t* — 1P(t)
+ P(t)A*(t* — t) + A(t* — t)P(t), t<t,, 4-96
with the terminal condition
P(ty) = Qo. 4-97
The minimal value of P(t) is P(t), where the minimization is in the sense that
PO) = PO), aa oe 4-98
By reversing time back again in 4-96, we see that the variance matrix Q(t) of
e(t) is minimized in the sense that
ONS OO. ta 4-99
by choosing K(r) = K°%(r), t) < 7 < t, where
Kr) = Q(r)C™(7)V2"(7), 7 S to, 4-100
and where the matrix Q(f) satisfies the matrix Riccati equation
O(t) = V(t) — ANDC*(1)Vs"(HCMHQY + QHA(H + AMC),
t>t, 4-101
with the initial condition
Ot) = Qo. 4-102
Since 4-99 implies that
tr (O(NW(t)] < tr [OMW(O) 4-103
for any positive-definite symmetric matrix W(t), we conclude that the gain
matrix 4-100 optimizes the observer. We moreover see from 4-86 that for the
optimal observer the mean square reconstruction error is given by
Efe*(t)W(t)e(t)} = tr [O() W(t), 4-104
while the variance matrix of e(t) is Q(t).
We finally remark that the result we have obtained is independent of the
particular time ¢ at which we have chosen to minimize the mean square
reconstruction error. Thus if the gain is determined according to 4-100, the
mean square reconstruction error is simultaneously minimized for all t > t).
Our findings can be summarized as follows.
344 Optimal Reconstruction of the State
Theorem 4.5. Consider the optimal observer problem of Definition 4.3.
Suppose that the problem is nonsingular and that the state excitation and
observation noise are uncorrelated. Then the solution of the optimal observer
problem is obtained by choosing for the gain matrix
KD) =OOCHOVs Os . file, 4-105
where Q(t) is the solution of the matrix Riccati equation
O(t) = A(NOQ(t) + Q(HNAT(1) + Vi(t) — Q(NC7*(YVE'OCHQ(,
t>t, 4-106
with the initial condition
O(to) = Qo. 4-107
The initial condition of the observer should be chosen as
If 4-105 and 4-108 are satisfied,
E{[zx(t) — 4)" Wa) — 4} 4-109
is minimized for all t > ty. The variance matrix of the reconstruction error is
given by
E{[x(t) — &) fe) — #(]"} = QC, 4-110
while the mean square reconstruction error is
E{[x(t) — €())"WOla() — €)]}} = tr (QW). 4-111
It is noted that the solution of the optimal observer problem is, surprisingly,
independent of the weighting matrix W(t).
The optimal observer of Theorem 4.5 is known as the Kalman—Bucy filter.
In this section we have derived this filter by first assuming that it has the form
of an observer. In the original derivation of Kalman and Bucy (1961),
however, it is proved that this filter is the minimum mean square linear
estimator, that is, we cannot find another linear functional of the observa-
tions y(r) and the input u(r), tf) < 7 < t, that produces an estimate of the
state a(t) with a smaller mean square reconstruction error. It can also be
proved (see, e.g., Jazwinski, 1970) that if the initial state x(t) is Gaussian,
and the state excitation noise w, and the observation noise w, are Gaussian
white noise processes, the Kalman—Bucy filter produces an estimate £(t) of
a(t) that has minimal mean square reconstruction error among ail estimates
that can be obtained by processing the data y(r) and u(r), tp) < 7 < t.
The close relationship between the optimal regu/ator problem and the
optimal observer problem is evident from the fact that the matrix Riccati
equation for the observer variance matrix is just the time-reversed Riccati
4.3. The Optimal Observer 345
equation that holds for the regulator problem. In later sections we make
further use of this relationship, which will be referred to as the duality
property, in deriving facts about observers from facts about regulators.
The gain matrix K°(t) can be obtained by solving the matrix Riccati
equation 4-106 in real time and using 4-105. Alternatively, K°(t) can be
computed in advance, stored, and played back during the state reconstruction
process. It is noted that in contrast to the optimal regulator described in
Chapter 3 the optimal observer can easily be implemented in real time,
since 4-106 is a differential equation with given initial conditions, whereas the
optimal regulator requires solution of a Riccati equation with given terminal
conditions that must be solved backward in time.
In Theorem 3.3 (Section 3.3.2), we saw that the regulator Riccati equation
can be obtained by solving a set of 2n x 2n differential equations (where n
is the dimension of the state). The same can be done with the observer
Riccati equation, as is outlined in Problem 4.3.
We now briefly discuss the steady-state properties of the optimal observer.
What we state here is proved in Section 4.4.3. It can be shown that under
mildly restrictive conditions the solution Q(t) of the observer Riccati equa-
tion 4-106 converges to a steady-state solution Q(t) which is independent of
Q, as the initial time f) approaches — oo. In the time-invariant case, where all
the matrices occurring in Definition 4.3 are constant, the steady-state solution
O is, in addition, a constant matrix and is, in general, the unique non-
negative-definite solution of the algebraic observer Riccati equation
0 = AO + QA? + V, — OCTV;CO. 4-112
This equation is obtained from 4-106 by setting the time derivative equal to
zero.
Corresponding to the steady-state solution Q of the observer Riccati
equation, we obtain the steady-state optimal observer gain matrix
K(t) = O(1)C7(1)Vz"(0). 4-113
It is proved in Section 4.4.3, again under mildly restrictive conditions, that
the observer with K as gain matrix is, in general, asymptotically stable. We
refer to this observer as the steady-state optimal observer. Since in the time-
invariant case the steady-state observer is also time-invariant, it is very
attractive to use the steady-state optimal observer since it is much easier to
implement. In the time-invariant case, the steady-state optimal observer is
optimal in the sense that
tea7>—a
lim Efe7(t)We(t)} = lim E{e7(t)We(t)} tc
4-114
is minimal with respect to all other time-invariant observers.
346 Optimal Reconstruction of the State
We conclude this section with the following discussion which is restricted
to the time-invariant case. The optimal observer provides a compromise
between the speed of state reconstruction and the immunity to observation
noise. The balance between these two properties is determined by the mag-
nitudes of the white noise intensities V, and V,. This balance can be varied
by keeping V, constant and setting
as ant. 4-115
where M is a constant positive-definite symmetric matrix and p is a positive
scalar that is varied. It is intuitively clear that decreasing p improves the
speed of state reconstruction, since less attention can be paid to filtering the
observation noise. This increase in reconstruction speed is accompanied by a
shift of the observer poles further into the left-half complex plane. In cases
where one is not sure of the exact values of V, or V,, a good design pro-
cedure may be to assume that V, has the form 4-115 and vary p until a
satisfactory observer is obtained. The limiting properties of the optimal
observer as p | 0 or p > © are reviewed in Section 4.4.4.
Example 4.3. The estimation of a “constant”
In many practical situations variables are encountered that stay constant
over relatively long periods of time and only occasionally change value. One
possible approach to model such a constant is to represent it as the state of an
undisturbed integrator with a stochastic initial condition. Thus let &(t)
represent the constant. Then we suppose that
EG) = 0)
£(0) = &),
4-116
where é, is a scalar stochastic variable with mean &, and variance Q,. We
assume that we measure this constant with observation noise »,(f), that is,
we observe
y(t) = E(t) + v(t), 4-117
where ¥,(¢) is assumed to be white noise with constant scalar intensity V9.
The optimal observer for &(r) is given by
E(t) = k(n — €()]
AO) =e.
where the scalar gain k(t) is, from 4-105, given by
4-118
Q(t)
| a
k(t) = i 4-119
2
4.3 The Optimal Observer 347
The error variance Q(t) is the solution of the Riccati equation
2
: t
OG a= ae , Q(0)=Q. 2
4-120
Equation 4-120 can be solved explicitly:
CO ee) 4-121
V2 a3 Qot
so that
as ee iore:
k(t) = » 120. 4-122
V2 + Qot
We note that as f — oo the error variance Q(t) approaches zero, which means
that eventually a completely accurate estimate of &(t) becomes available. As
a result, also k(t) > 0, signifying that there is no point in processing any
new data.
This observer is not satisfactory when the constant occasionally changes
value, or in reality varies slowly. In such a case we can model the constant
as the output of an integrator driven by white noise. The justification for
modeling the process in this way is that integrated white noise has a very
large low-frequency content. Thus we write
E(t) = (0),
4-123
y(t) = S(t) + v(t),
where ¥, is white noise with constant intensity V, and », is white noise as
before, independent of »,. The steady-state optimal observer is now easily
found to be given by
Ea) = k[n() — 2), 4-124
where :
k = VV,/Vo. 4-125
In transfer function form we have
e V,/V.
X(s) = eae. —— ¥(s), 4-126
Sok: NALA
where X(s) and Y(s) are the Laplace transforms of E(t) and x(t), respectively.
As can be seen, the observer is a first-order filter with unity gain at zero
frequency and break frequency ave
Example 4.4. Positioning system
In Example 2.4 (Section 2.3), we considered a positioning system which is
described by the state differential equation
Od 0
a ( Jeo + | Jo 4-127
0 o K
348 Optimal Reconstruction of the State
Here x(t) = col [&,(t), &,(t)], where &,(t) denotes the angular displacement
6(t) and &,(t) the angular velocity 6(t). Let us now assume, as in Example 2.4,
that a disturbing torque 7,(t) acts upon the shaft of the motor. Accordingly,
the state differential equation must be modified as follows:
0 | 0 0
x= (_ Jor (Jaen + (Jr 4-128
K
( My
where |/y is the rotational moment of inertia of all the rotating parts. If
the fluctuations of the disturbing torque are fast as compared to the motion
of the system itself, the assumption might be justified that 7,(t) is white
noise. Let us therefore suppose that 7,(t) is white noise, with constant, scalar
intensity V,. Let us furthermore assume that the observed variable is given by
n(t) = (1, 0)x(t) + »,,(t), 4-129
where »,,(t) is white noise with constant, scalar intensity V,,,.
We compute the steady-state optimal observer for this system. The
variance Riccati equation takes the form
w=(° "Jaora(? 4
; 0 il 0 0
0 —« 1 —«
( x - ‘ee 1,0 4-13
ae t . 4
» ay, 2M gfy, O20. 4130
In terms of the entries ¢;;(t), i, 7 = 1, 2, of Q(t), we obtain the following set
of differential equations (using the fact that g,.(t) = g2,(t)):
ful) = 2aull) — Fah,
™m
: 1
Gro(t) = Qo2(t) — «qy9(t) — V. Gii(t)qr2(t), 4-131
, 1
Gaot) = —2agoo(t) + y°Vy — V. qi2(t).
It can be found that the steady-state solution of the equations as t > oo is
given by
O= val —a + Jo2 + 28 a2 + B— aja? + 28
Noe B— afer +28 —o — 2aB + (a2 + B) Jo? + =
where
4-132
pay) Vall. 4-133
4.3. The Optimal Observer 349
It follows that the steady-state optimal gain matrix is given by
—a + Vo? + 28 )
4-134
a + B— an a2 + 26
The characteristic polynomial of the matrix A — KC can be found to be
det (sJ — A+ KC) = 52+ sv a2 + 26 + B, 4-135
from which it can be derived that the poles of the steady-state optimal
observer are
4(—V 02 + 28 + V2 — 28). 4-136
Let us adopt the following numerical values:
« = 0.787 rad/(V s?),
CSAS.
pia OAK Ora tir 4-137
B= 10 IN4 mts,
Vo = L077 rad? s:
m
It is supposed that the value of V, is derived from the knowledge that the
disturbing torque has an rms value of ,/1000 ~ 31.6 N m and that its power
spectral density is constant from about —S0 to 50 Hz and zero outside this
frequency band. Similarly, we assume that the observation noise, which has
an rms value of 0.01 rad, has a flat power spectral density function from
about —500 to 500 Hz and is zero outside this frequency range. We carry
out the calculations as if the noises were white with intensities as indicated
in 4-137 and then see if this assumption is justified.
With the numerical values as given, the steady-state gain matrix is found
to be
a 40.36
Ke : 4-138
814.3
The observer poles are —22.48 + j22.24. These pole locations apparently
provide an optimal compromise between the speed of convergence of the
reconstruction error and the immunity against observation noise.
The break frequency of the optimal observer can be determined from the
pole locations. The observer characteristic polynomial is
st + so? + 28 + PB s* + 45s + 1000, 4-139
350 Optimal Reconstruction of the State
which represents a second-order system with undamped natural frequency
Wo = 31.6 rad/s ~ 5 Hz and relative damping of about 0.71. The undamped
natural frequency is also the break frequency of the observer. Since this
frequency is quite small as compared to the observation noise bandwidth of
about 500 Hz and the disturbance bandwidth of about 50 Hz, we conjecture
that it is safe to approximate both processes as white noise. We must compare
both the disturbance bandwidth and the observation noise bandwidth to the
observer bandwidth, since as can be seen from the error differential equation
4-82 both processes directly influence the behavior of the reconstruction
error. In Example 4.5, at the end of Section 4.3.5, we compute the optimal
filter without approximating the observation noise as white noise and see
whether or not this approximation is justified.
The steady-state variance matrix of the reconstruction error is given by
_ /0,000004036 nes)
4-140
~ \0,00008143 0.003661 |
By taking the square roots of the diagonal elements, it follows that the rms
reconstruction error of the position is about 0.002 rad, while that of the
angular velocity is about 0.06 rad/s.
We conclude this example with a discussion of the optimal observer that
has been found. First, we note that the filter is completely determined by the
ratio V,/V,,, which can be seen as a sort of ‘signal-to-noise’ ratio. The
expression 4-136 shows that as this ratio increases, which means that £
increases, the observer poles move further and further away. As a result, the
observer becomes faster, but also more sensitive to observation noise. For
f = © we obtain a differentiating filter, which can be seen as follows. In
transfer matrix form the observer can be represented as
X(s) = (sI — A + KC)"[KY(s) + BU(s)]
ee eee
s? + sVa? + 28+ 8
(ee eee ( K | |
s(a? + B — ava? + 28) $a + Va 28
4-141
Here X(s), ¥(s), and U(s) are the Laplace transforms of &(1), y(t), and u(?),
respectively. As the observation noise becomes smaller and smaller, that is,
B — oo, 4-141 converges to
. |
AS) = | veo. 4-142
S!
4.3 The Optimal Observer 351
This means that the observed variable is taken as the reconstructed angular
position and that the observed variable is differentiated to obtain the re-
constructed angular velocity.
4.3.3* The Nonsingular Optimal Observer Problem with Correlated
State Excitation and Observation Noises
In this section the results of the preceding section are extended to the case
where the state excitation noise and the measurement noise are correlated,
that is, Vjo(t) # 0, t > ft). To determine the optimal observer, we proceed
in a fashion similar to the correlated case. Again, let O(t) denote the variance
matrix of the reconstruction error when the observer is implemented with an
arbitrary gain matrix K(t), ¢ > t). Using Theorem 1.52 (Section 1.11.2), we
obtain the following differential equation for Q(t), which is an extended
version of 4-89:
O(t) = [A(t) — K(NCMIOM) + GOLA — KNCOE
+ V(t) — Vi2(t)K 7(t) = KjVe() ar K(t)V,(t)K7(t), ey ae
with the initial condition
4-143
O(to) = Qo. 4-144
To convert the problem of finding the optimal gain matrix to a familiar
problem, we reverse time in this differential equation. It then turns out that
the present problem is dual to the “extended regulator problem’”’ discussed in
Problem 3.7 in which the integral criterion contains a cross-term in the state
x and the input uw. By using the results of Problem 3.7, it can easily be shown
that the solution of the present problem is as follows (see, e.g., Wonham,
1963).
Theorem 4.6. Consider the optimal observer problem of Definition 4.3
(Section 4.3.1). Suppose that the problem is nonsingular, that is, V,(t) > 0,
t >t. Then the solution of the optimal observer problem is achieved by
choosing the gain matrix K(t) of the observer 4-73 as
Kt) = [QC + VOWS), 1 2 bo, 4-145
where Q(t) is the solution of the matrix Riccati equation
O(t) = [A(t) — Viol Ve (NCHIQ(
+ O(N[A(t) — Via(t)Vz()C(t)|7
— Q(t)CT(t)Vz"(t)C(HQ(t)
+ V(t) — Vite (OViEO), t > to, 4-146
352 Optimal Reconstruction of the State
with the initial condition
Ot i= 0%. 4-147
The initial condition of the observer is
Lf) =e. 4-148
For the choices 4-145 and 4-148, the mean square reconstruction error
E{[x(t) — 4)" Wl) — £()]} 4-149
is minimized for all t > ty. The variance matrix of the reconstruction error is
given by
hence
E{[u(t) — 4(][x() — &()]"} = OM), 4-150
E{[a(t) — 4) WOle(t) — 4(H]} = tr (WHOM), 1D ty. 4151
4,3.4* The Time-Invariant Singular Optimal Observer Problem
This section is devoted to the derivation of the optimal observer for the
singular case, namely, the case where the matrix V(t) is not positive-definite.
To avoid the difficulties that occur when V,(t) is positive-definite during
certain periods and singular during other periods, we restrict the derivation
of this section to the time-invariant case, where all the matrices occurring
in Definition 4.3 (Section 4.3.1) are constant. Singular observation problems
arise when some of the components of the observed variable are free of
observation noise, and also when the observation noise is not a white noise
process, as we see in the following section. The present derivation roughly
follows that of Bryson and Johansen (1965).
First, we note that when V, is singular the derivation of Section 4.3.2
breaks down; upon investigation it turns out that an infinite gain matrix
would be required for a full-order observer as proposed. As a result, the
problem formulation of Definition 4.3 is inadequate for the singular case.
What we do in this section is to reduce the singular problem to a nonsingular
problem (of lower dimension) and then apply the results of Sections 4.3.2
or 4.3.3.
Since V, is singular, we can always introduce another white noise process
w(t), with nonsingular intensity Vj, such that
w(t) = Hw,(t), 4-152
with dim (w3) < dim (w,), and where H has full rank. This means that the
observed variable is given by
y(t) = Cax(t) + Hw,(t). 4-153
4.3. The Optimal Observer 353
With this assumption the intensity of w(t) is given by
Ve= HVA". 4-154
Since V, is singular, it is possible to decompose the observed variable into
two parts: a part that is “completely noisy,’ and a part that is noise-free.
We shall see how this decomposition is performed.
Since dim (w;) < dim (w4), it is always possible to find an/ x /nonsingular
matrix 7 (/ is the dimension of the observed variable y) partitioned as
qT
P= 4-155
T;
such that
ip H,
H= 4-156
ve: 0
Here H, is square and nonsingular, and the partitioning of T has been chosen
corresponding to that in the right hand side of 4-156. Multiplying the output
equation
y(t) = Ca(t) + Hw,(t) 4-157
by T we obtain
y(t) = C, x(t) + Hyw,(t), 4-158a
y(t) = C,2(t), 4-158b
where
py=(iben (Q)=(e om Yo(t) Ts Cy T,
y(t) ie Cy T,
We see that 4-158 represents the decomposition of the observed variable y(t)
into a “completely noisy’ part y,(t) (since H,V3H," is nonsingular), and a
noise-free part y,(f).
We now suppose that C, has full rank. If this is not the case, we can re-
define y(t) by eliminating all components that are linear combinations of
other components, so that the redefined C, has full rank. We denote the
dimension of y,(t) by k.
Equation 4-158b will be used in two ways. First, we conclude that since
y2(t) provides us with k linear equations for x(t) we must reconstruct only
n—k (n is the dimension of x) additional linear combinations of x(t).
Second, since y,(f) does not contain white noise it can be differentiated in
order to extract more data. Let us thus define, as we did in Section 4.2.3, an
(n — k)-dimensional vector variable
Tih) = C2), 4-160
354 Optimal Reconstruction of the State
where Cy, is so chosen that the n x n matrix
C2 4-161
C2
is nonsingular. From y,(t) and p(t) we can reconstruct x(t) exactly by the
relations
Y(t) = C,2(0), 4-162
p(t) = Cy2x(t),
or
Cz\*/ ye(t)
x(t) = ( i ( ied f Cy p(t)
4-163
It is convenient to introduce the notation
C,\-1 J = Caley 4-164
2
so that x(t) = Lyys(t) + Lop(t). 4-165
Our next step is to construct an observer for p(t). The reconstructed p(t) will
be denoted by f(t). It follows from 4-165 that (1), the reconstructed state, is
given by
&(t) = Lyyo(t) + Lep(t). 4-166
The state differential equation for p(t) is obtained by differentiation of
4-160. It follows with 4-165
p(t) = CLa(t) = CfAa(t) + CiBu(t) + Céw,(t)
= C,A[Lyy2(t) + Lep(t)] + CzBu(t) + Cw,(1), 4-167
or
P(t) = A'p(t) + Bu(t) + B’yo(t) + Cow, (2), 4-168
where
A ’= CAAL,, 1B Cp wanes 4-169
Note that both u(t) and y,(¢) are forcing variables for this equation. The
observations that are available are y,(t), as well as ¥,(t), for which we find
Yt) = Cy#(t) = C,Ax(t) + C,Bu(t) + C.w,(t)
= C,A[Ly y(t) + Lep(t)] + C,Bu(t) + C2w,(t). 4-170
For y,(t) we write
y(t) = Cyx(t) + Hyw,(t)
= C,[Lyy(t) + Lep(t)] + Hyw,3(t). 4-171
4.3 The Optimal Observer 355
Combining y,(t) and ¥,(t) we write for the observed variable of the system
4-168
’ y(t) , w,(t)
y= | = C'p(t) + D'u(t) + D"y.(t) + H’ haa
Y(t) W(t)
where
| p=(°), Peale | w=(° a)
CAls CB GAT. Cr.20
4-173
Note that in the state differential equation 4-168 and in the output equation
4-172 we treat both u(t) and y,(t) as given data. To make the problem
formulation complete, we must compute the a priori statistical data of the
auxiliary variable p(t):
D(to) = E{Cyz2(to) | Yo(to)} 4-174
and
O(ty) = E{[p(to.) — A(t) [p(to) — P(to)]* | Yo(to)}. 4-175
It is outlined in Problem 4.4 how these quantities can be found.
The observation problem that we now have obtained, and which is defined
by 4-168, 4-172, 4-174, and 4-175, is an observation problem with correlated
state excitation and observation noises. It is either singular or nonsingular.
If it is nonsingular it can be solved according to Section 4.3.3, and once /(f) is
available we can use 4-166 for the reconstruction of the state. If the observa-
tion problem is still singular, we repeat the entire procedure by choosing a
new transformation matrix T for 4-172 and continuing as outlined. This
process terminates in one of two fashions:
(a) A nonsingular observation problem is obtained.
(b) Since the dimension of the quantity to be estimated is reduced at each
step, eventually a stage can be reached where the matrix C, in 4-162 is square
and nonsingular. This means that we can solve for a(t) directly and no
dynamic observer is required.
We conclude this section by pointing out that if 4-168 and 4-172 define a
nonsingular observer problem, in the actual realization of the optimal
observer it is not necessary to take the derivative of y,(t), since later this
derivative is integrated by the observer. To show this consider the following
observer for p(t):
A(t) = A'p(t) + Biu(t) + B’y(t)
+ K(t)[y'(t) — D’u(t) — D"y,(t) — C'p(t)]. 4-176
356 Optimal Reconstruction of the State
Partitioning
K(t) = [K,(t), K2(t)], 4-177
it follows for 4-176:
P(t) = [A’ — K(t)C’']A(t) + B'u(t) + B’ys(t)
+ K,(t)y,(t) + K.(t)y(t) — K(t)[D'u(t) + D”y(t)]. 4-178
Now by defining
g(t) = p(t) — K,(t)y2(t), 4-179
a state differential equation for q(t) can be obtained with y,(t), y(t), and
u(t), but not ¥,(t), as inputs. Thus, by using 4-179, p(t) can be found without
using #,(t).
4.3.5 The Colored Noise Observation Problem
This section is devoted to the case where the state excitation noise w,(t) and
the observation noise w,(t) cannot be represented as white noise processes.
In this case we assume that these processes can be modeled as follows:
w(t) = C,(t)2(t) + wyi(t),
w(t) = C,(t)x’(t) + w(t), 4-180
with
a(t) = Al(t)x'(t) + w9(t). 4-181
Here w(t), w2(t), and w(t) are white noise processes that in general need not
be uncorrelated. Combining 4-180 and 4-181 with the state differential and
output equations #(t) = A(t)e(t) + BOu(t) + w,(0),
y(t) = C()e(t) + weld),
4-182
we obtain the augmented state differential and output equations
fed ia a Cy eo ee
= + u(t) + ;
a'(t) Oo A(t) a(t) 0 W3(t)
x
t
y(t) = [C(4), cx) °) + w2(t).
x!
To complete the problem formulation the mean and variance matrix of the
initial augmented state col [2(¢), «’(t)] must be given. In many cases the white
noise w(t) is absent, which makes the observation problem singular. If the
4.3 The Optimal Observer 357
problem is time-invariant, the techniques of Section 4.3.4 can then be applied.
This approach is essentially that of Bryson and Johansen (1965).
We illustrate this section by means of an example.
Example 4.5. Positioning system with colored observation noise
In Example 4.4 we considered the positioning system with state differential
equation
OF i 0 0'
= f eo A. ( Juco + jr 4-184
ates K Y
and the output equation
n(t) = (1, O)a(t) + »,,(t). 4-185
The measurement noise v,,(t) was approximated as white noise with intensity
V,,. Let us now suppose that a better approximation is to model »,,(t) as
exponentially correlated noise (see Example 1.30, Section 1.10.2) with power
spectral density function
2
Se) 4-186
ee ake
This means that we can write (Example 1.36, Section 1.11.4)
V(t) = €(t), 4-187
where
é(t) = — 5 el) + w(t). 4-188
Here w(t) is white noise with scalar intensity 207/60. In Example 4.4 we
assumed that 7,(¢) is also white noise with intensity V,. In order not to
complicate the problem too much, we stay with this hypothesis. The aug-
mented problem is now represented by the state differential and output
equations:
E(t) O\ /&,(t) 0 0
E,(t) =,0 -« 0 E(t) P+ [ « Ju) + yt4(t) >
Et) 0 0 3 E(t) 0 o(t)
4-189
E,(t)
y(t) = (1, 0, 1)] .(¢) J,
£3(t)
358 Optimal Reconstruction of the State
where col [é,(t), &(t)] = 2(t). This is obviously a singular observation
problem, because the observation noise is absent. Following the argument of
Section 4.3.4, we note that the output equation is already in the form 4-158,
where C, and H, are zero matrices. It is natural to choose
p(t) = x(t), 4-190
so that
ep UT,
Cy = | ) 4-191
On. 100
Writing
p(t) = col [m(¢), 72(4)], it follows by matrix inversion from
y(t) AS Ne eae)
at) {= [1 0 Of 0) 17(t) Ord Ue eae)
4-192
4-193
that
1) Ores 0 n(t)
S(t) | = | 0 0 1} | 7.() 7. 4-194
§3(t), Nao 0/ \7,2(t)
Since p(t) = x(t), it immediately follows that p(t) satisfies the state differen-
tial equation
(al 0 0
p(t) = E Jp + ( Jo +. | }rato oF ‘
K
To obtain the output equation, we differentiate (t):
H(t) = (1, 0)a(t) + €,(t). 4-195
4-196
Using 4-184, 4-188, and 4-194, it follows that we can write
I 1
1) = (1) 0 = An) +o. 4-197
Together, 4-195 and 4-197 constitute an observation problem for p(t) that
is nonsingular and where the state excitation and observation noises happen
to be uncorrelated. The optimal observer is of the form
ee 0 ey 0 eel 1 mil ,
A= ( lo + ("co + K%1) ko + onl le 1) 0}.
4-198
4.3 The Optimal Observer 359
where the optimal gain matrix K°(t) can be computed from the appropriate
Riccati equation. From 4-194 we see that the optimal estimates £(t) of the
state of the plant and &,(t) of the observation noise are given by
E(t) = p(t),
: 4-199
Sa(t) = n(t) + (—1, O)A(0).
Let us assume the following numerical values:
K = 0.787 rad/(Vs’),
a=46s7,
=O Kem,
V, = 10 N? m’s, ae
G= 5x 10s,
o = 0.01 rad.
The numerical values for o and 0 imply that the observation noise has an rms
value of 0.01 rad and a break frequency of 1/6 = 2000 rad/s ~ 320 Hz.
With these values we find for the steady-state optimal gain matrix in 4-198
0.01998
K°= : 4-201
0.4031
The variance matrix of the reconstruction error is
0.000003955 0.0000798 1
0.00007981 0.003628 | 4-202
Insertion of K° for K°(t) into 4-198 immediately gives us the optimal steady-
state observer for a(t). An implementation that does not require differentia-
tion of 7(t) can easily be found.
The problem just solved differs from that of Example 4.4 by the assumption
that v,, is colored noise and not white noise. The present problem reduces to
that of Example 4.4 if we approximate »,, by white noise with an intensity
V,, which equals the power spectral density of the colored noise for low
frequencies, that is, we set
V,, = 206. 4-203
The numerical values in the present example and in Example 4.4 have been
chosen consistently. We are now in a position to answer a question raised in
Example 4.4: Are we justified in considering »,, white noise because it has a
large bandwidth, and in computing the optimal observer accordingly? In
360 Optimal Reconstruction of the State
order to deal with this question, let us compute the reconstruction error
variance matrix for the present problem by using the observer found in
Example 4.4. In Example 4.4 the reconstruction error obeys the differential
equation
é(t) ine 1 )ro+ : ‘
A) t WO) V(t), -
ies (" (t) a (1) 4-204
2
where we have set K = col (k,, k,). With the aid of 4-187 and 4-188, we
obtain the augmented differential equation
é,(t) Stk | il ee) 0
é(t)} =| —k, -—a —k, €o(t) | + J y7,(t) 4-205
E(t) oO -; E,(t) oot)
where e(t) = col [e,(t), €,(t)]. It follows from Theorem 1.52 (Section 1.11.2)
that the variance matrix Q(t) of col [e,(t), e.(t), &3(t)] satisfies the matrix
differential equation
—k, 1 —k,
AS ga
Q(t) = : feo
0 (in re 6
=k. 0 On 20 <0
ee 0 0 vv, O
+ O(t) ; if yu 4-206
at ea A ae (uO 20"
At 2 6 6
Numerical solution with the numerical values 4-200 and 4-138 yields for the
steady-state variance matrix of the reconstruction error e(f)
0.000003995 0.00008062
0.00008062 0.003645 /- 4-207
Comparison with 4-202 shows that the rms reconstruction errors that result
from the white noise approximation of Example 4.4 are only very slightly
greater than for the more accurate approach of the present example. This
confirms the conjecture of Example 4.4 where we argued that for the optimal
observer the observation noise v,,(t) to a good approximation is white noise,
so that a more refined filter designed on the assumption that »,,(¢) is actually
exponentially correlated noise gives very little improvement.
4.3 The Optimal Observer 361
4.3.6* Innovations
Consider the optimal observer problem of Definition 4.3 and its solution as
given in Sections 4.3.2, 4.3.3, and 4.3.4. In this section we discuss an interesting
property of the process
y(t) — C(t)£(t), tt > ty, 4-208
where £(t) is the optimal reconstruction of the state at time ¢ based upon data
up to time ¢. In fact, we prove that this process, 4-208, is white noise with
intensity V,(t), which is precisely the intensity of the observation noise w,(t).
This process is called the innovation process (Kailath, 1968), a term that can
be traced back to Wiener. The quantity y(t) — C(t)#(t) can be thought of as
carrying the new information contained in y(t), since y(t) — C(t)£(t) is
the extra driving variable that together with the model of the system con-
stitutes the optimal observer. The innovations concept is useful in under-
standing the separation theorem of linear stochastic optimal control theroy
(see Chapter 5). It also has applications in state reconstruction problems
outside the scope of this book, in particular the so-called optimal smoothing
problem (Kailath, 1968).
We limit ourselves to the situation where the state excitation noise w, and
the observation noise w, are uncorrelated and have intensities V,(t) and V,(f),
respectively, where V,(t) > 0, ¢ > fo. In order to prove that y(t) — C(t)&(t)
is a white noise process with intensity V,(¢), we compute the covariance
matrix of its integral and show that this covariance matrix is identical to the
covariance matrix of the integral of a white noise process with intensity
V,(t).
Let us denote by s(t) the integral of y(t) — C(‘)@(t), so that
S(t) = y(t) — CEM),
s(t) = 0. 4-209
Furthermore,
e(t) = x(t) — &(t) 4-210
is the reconstruction error. Referring back to Section 4.3.2, we obtain from
4-209 and 4-82 the following joint state differential equation for s(t) and e(¢):
s(t) 0 C(t) (2) F [ I ion
Ea - iF A(t) — K°(t)C(t)} \e(t) I —K(t)}\w(d)? 4-211
where K(f) is the gain of the optimal observer. Using Theorem 1.52 (Section
1.11.2), we obtain the following matrix differential equation for the variance
362 Optimal Reconstruction of the State
matrix Q(t) of col [s(t), e(t)]:
‘ ( C(t) | ry 511) ( 0 0
= t t
2) 0 A(t) — K()C(t) eae Cit) Al) Ck)
( I G9 0 \(° I
a5 Ae?
F —Rihae On) Vatt \ ieee Read)
with the initial condition
Oty mare 4-213
O(ty az ’ =
0 OQ
where Q, is the variance matrix of x(¢)). Let us partition O(t) as follows:
Ou(1) ae
O(t) = ( 4-214
OR) Qso(1)/
Then we can rewrite the matrix differential equation 4-212 in the form
Ox(t) = C()QR(t) + Qi(1)C7(1) + Volt), — Quilt) = 0, Drolt) = C(t)Qoo(t) + Qi(t[A(t) — KC)? — Va(t)K°7(1),
4-215
Q1(to) = 0, 4-216
Oo9(t) = [A(t) — K°(t)C(1)]Qo0(t) + Qoo(D[A(t) — K°HCO]”
+ V,(t) + K°(t)V.(t)K°7(1), Qoo(to) = Qo. 4-217
As can be seen from 4-217, and as could also have been seen beforehand,
Q..(t) = Q(t), where Q(t) is the variance matrix of the reconstruction error.
It follows with 4-105 that in 4-216 we have
C(t)Qo0(t) — Ve(t)K°*(t) = 0, 4-218
so that 4-216 reduces to
Q,.(t) = Q,,(t)[A(t) — K*(t)C(t)]}*, Q1(to) = 9, 4-219
which has the solution
Q,(t)=0, tD> bo. 4-220
Consequently, 4-215 reduces to
0,,(t) = V(t), Q11(to) = 0, 4-221
so that
Q(t) = { V(r) dr. 4-222
4.3. The Optimal Observer 363
By invoking Theorem 1.52 once again, the covariance matrix of col [s(t), e(t)]
can be written as
OG) G&G, ty) for) > ti,
R(t, te) = 4-223
VG to) O( te) fOE* ty >is,
where W(t, fy) is the transition matrix of the system
(") ' C(t) |
= , 4-224
\é(t) 0 A(t) — K*(t)C// \e(t)
It is easily found that this transition matrix is given by
ty
es if i COC dt
P(t, to) = to et i 4-225
0 THs to)
where ‘’(t,, ¢9) is the transition matrix of the system
é(t) = [A(t) — K®(t)C(DJe(t). 4-226
The covariance matrix of s(t) is the (1, 1)-block of R(t,, t,), which can be
found to be given by
min(¢y,t2)
Rhy, te) =| V,(t) dt. 4-227
to
This is the covariance matrix of a process with uncorrelated increments (see
Example 1.29, Section 1.10.1). Since the process y(t) — C(t)£(t) is the
derivative of the process s(t), it is white noise with intensity V(t) (see Example
i733, section 1, )1.1),
We summarize as follows.
Theorem 4.7. Consider the solution of the nonsingular optimal observer
problem with uncorrelated state excitation noise and observation noise as given
in Theorem 4.5. Then the innovation process
y(t) — CHO, 1 2 bo, 4-228
is a white noise process with intensity V,(t).
It can be proved that this theorem is also true for the singular optimal
observer problem with correlated state excitation and observation noises.
364 Optimal Reconstruction of the State
4.4* THE DUALITY OF THE OPTIMAL OBSERVER
AND THE OPTIMAL REGULATOR; STEADY-STATE
PROPERTIES OF THE OPTIMAL OBSERVER
4.4.1* Introduction
In this section we study the steady-state and stability properties of the optimal
observer. All of these results are based upon the properties of the optimal
regulator obtained in Chapter 3. These results are derived through the
duality of the optimal regulator and the optimal observer problem (Kalman
and Bucy, 1961). Section 4.4.2 is devoted to setting forth this duality, while
in Section 4.4.3 the steady-state properties of the optimal observer are dis-
cussed. Finally, in Section 4.4.4 we study the asymptotic behavior of the
steady-state time-invariant optimal observer as the intensity of the observa-
tion noise goes to zero.
4.4.2* The Duality of the Optimal Regulator and the Optimal Observer
Problem
The main result of this section is summarized in the following theorem.
Theorem 4.8. Consider the optimal regulator problem (ORP) of Definition
3.2 (Section 3.3.1) and the nonsingular optimal observer problem (OOP)
with uncorrelated state excitation and observation noises of Definition 4.3
(Section 4.3.1). In the observer problem let the matrix V,(t) be given by
V(t) = G(t)V,(1)G7(1), t > bo, 4-229
where
VeG)=.0s iat ae 4-230
Let the various matrices occurring in the definitions of the ORP and the OOP
be related as follows:
A(t) of the ORP equals A™(t* — t) of the OOP,
B(t) of the ORP equals Cotte 7) of the OOP,
D(t) of the ORP equals Gin) of the OOP, R,(t) of the ORP equals V,(t* — t) of the OOP,
R,(t) of the ORP equals V,(t* — t) of the OOP,
P, of the ORP equals Q, of the OOP,
4-231
all for t < t,. Here
t* =f +1; 4-232
Under these conditions the solutions of the optimal regulator problem (Theorem
4.4 Duality and Steady-State Properties 365
3.4, Section 3.3.3) and the nonsingular optimal observer problem with un-
correlated state excitation and observation noises (Theorem 4.5, Section
4.3.2) are related as follows:
(a) P(t) of the ORP equals Q(t* — t) of the OOP for t < t,;
(b) F(t) of the ORP equals Kr (* — 2) of the OOP fort < t;
(c) The closed-loop regulator of the ORP:
a(t) = [A(t) — BOF O)<(), 4-233
and the unforced reconstruction error equation of the OOP:
é(t) = [A(¢t) — K°@#)CMJe(), 4-234
are dual with respect to t* in the sense of Definition 1.23 (Section 1.8).
The proof of this theorem easily follows by comparing the regulator Riccati
equation 3-130 and the observer Riccati equation 4-106, and using time
reversal (Lemma 4.1, Section 4.3.2).
In Section 4.4.3 we use the duality of the optimal regulator and the optimal
observer problem to obtain the steady-state properties of the optimal
observer from those of the optimal regulator. Moreover, this duality enables
us to use computer programs designed for optimal regulator problems for
optimal observer problems, and vice versa, by making the substitutions
4-231.
4.4.3* Steady-State Properties of the Optimal Observer
Theorem 4.8 enables us to transfer from the regulator to the observer problem
the steady-state properties (Theorem 3.5, Section 3.4.2), the steady-state
stability properties (Theorem 3.6, Section 3.4.2), and various results for the
time-invariant case (Theorems 3.7, Section 3.4.3, and 3.8, Section 3.4.4).
In this section we state some of the more important steady-state and stability
properties. Theorem 3.5, concerning the steady-state behavior of the Riccati
equation, can be rephrased as follows (Kalman and Bucy, 1961).
Theorem 4.9. Consider the matrix Riccati equation
Q(t) = A(t1)O(t) + O(t)AT(t) + G(t)V9(t)G7 (t)
— Q(1)C7()VE(NC(HO(1). 4-235
Suppose that A(t) is continuous and bounded, that C(t), G(t), V3(t), and V2(t)
are piecewise continuous and bounded, and furthermore that
Vali) = Gh Vata Ble “forall t, 4-236
where « and f are positive constants.
366 Optimal Reconstruction of the State
(i) Then if the system
a(t) = A(t)a(t) + G(t)w,(t),
y(t) = C(t)x(t), 4-237
is either
(a) completely reconstructible, or
(b) exponentially stable,
the solution Q(t) of the Riccati equation 4-235 with the initial condition
Q(t )) = 0 converges to a nonnegative-definite matrix O(t) as ts > —2. O(t)
is a solution of the Riccati equation 4-235.
(ii) Moreover, if the system 4-237 is either
(c) both uniformly completely reconstructible and uniformly completely
controllable, or
(d) exponentially stable,
the solution Q(t) of the Riccati equation 4-235 with the initial condition
Q(t) = Qy converges to O(t) as ty > — © for any Qy > 0.
The proof of this theorem immediately follows by applying the duality
relations of Theorem 4.8 to Theorem 3.5, and recalling that if a system is
completely reconstructible its dual is completely controllable (Theorem 1.41,
Section 1.8), and that if a system is exponentially stable its dual is also
exponentially stable (Theorem 1.42, Section 1.8).
We now state the dual of Theorem 3.6 (Section 3.4.2):
Theorem 4.10. Consider the nonsingular optimal observer problem with
uncorrelated state excitation and observation noises and let
V,(t) = G(t)Ve(t)G7(t), for all t, 4-238
where V(t) > 0, for all t. Suppose that the continuity, boundedness, and
positive-definiteness conditions of Theorem 4.9 concerning A, C, G, V3, and
V, are satisfied. Then if the system 4-237 is either
(a) uniformly completely reconstructible and uniformly completely con-
trollable, or
(b) exponentially stable,
the following facts hold.
(1) The steady-state optimal observer
&(t) = A(1)€(t) + R([y(t) — CA), 4-239
where
K@) SOO Ve; 4-240
is exponentially stable. Here Q(t) is as defined in Theorem 4.9.
4.4 Duality and Steady-State Properties 367
(ii) The steady-state optimal observer gain K(t) minimizes
lim Efe™(t)W(t)e(t)} 4-241
to7—a@
for every Qo > 0. The minimal value of 4-241, which is achieved by the steady-
state optimal observer, is given by
tr [O(t) W(t). 4-242
We also state the counterpart of Theorem 3.7 (Section 3.4.3), which is
concerned with time-invariant systems.
Theorem 4.11. Consider the time-invariant nonsingular optimal observer
problem of Definition 4.3 with uncorrelated state excitation and observation
noises for the system
&(t) = Ax(t) + Gw,(t),
4-243
y(t) = Cx(t) + we(t).
Here wg is white noise with intensity V3, and w, has intensity V,. It is assumed
that Vz > 0, V. > 0, and Q, > 0. The associated Riccati equation is given by
O(t) = AQ(t) + O()AT + GV,GT — QO(t)CTV;CQ(N), 4-244
with the initial condition
O(to) = Qo. 4-245
(a) Assume that Qo =0. Then as ty» —© the solution of the Riccati
equation approaches a constant steady-state value Q if and only if the system
4-243 possesses no poles that are at the same time unstable, unreconstructible,
and controllable.
(b) If the system 4-243 is both detectable and stabilizable, the solution of the
Riccati equation approaches the value O as t; > — © for every Qy > 0.
(c) If O exists, it is a nonnegative-definite symmetric solution of the algebraic
Riccati equation
0 = AQ + QA” + GV,G7 — QCTV;°CQ. 4-246
If the system 4-243 is detectable and stabilizable, O is the unique nonnegative-
definite solution of the algebraic Riccati equation.
(d) If O exists, it is positive-definite if and only if the system is completely
controllable.
(e) If O exists, the steady-state optimal observer
&(t) = A&(t) + R[y(t) — Cad), 4-247
where
K = QC*V;", 4-248
is asymptotically stable if and only if the system is detectable and stabilizable.
368 Optimal Reconstruction of the State
(f) If the system is detectable and stabilizable, the steady-state optimal
observer 4-247 minimizes
lim Efe(t)We(t)} 4-249
tg7—©o0
for all Q, > 0. For the steady-state optimal observer, 4-249 is given by
tr [OW]. 4-250
We note that the conditions (b) and (c) are sufficient but not necessary.
4.4.4* Asymptotic Properties of Time-Invariant Steady-State
Optimal Observers
In this section we consider the properties of the steady-state optimal filter
for the time-invariant case, when the intensity of the observation noise
approaches zero. This section is quite short since we are able to obtain our
results immediately by ‘“‘dualizing”’ the results of Section 3.8.
We first consider the case in which both the state excitation noise w,(t) (see
4-237) and the observed variable are scalar. From Theorem 3.11 (Section
3.8.1), the following result is obtained almost immediately.
Theorem 4.12. Consider the n-dimensional time-invariant system
a(t) = Ax(t) + Bu(t) + ga,(t),
cipweier ete (i aaa
where ws is scalar white noise with constant intensity V3, 2 scalar white noise
uncorrelated with w3 with positive constant intensity V,, g a column vector,
and c a row vector. Suppose that {A, g} is stabilizable and {A, c} detectable.
Let H(s) be the scalar transfer function
% II (s — %)
H(s) = c(sI — A) 'g = WS) gag dete $(s) ITG By
i=1
4-252
where $(s) is the characteristic polynomial of the system, and 7,, i=
1,2,°-°-,n, its characteristic values. Then the characteristic values of the
steady-state optimal observer are the left-half plane zeroes of the polynomial
(—1)"4(s)4(—s) 1 + = A(—9H) |. 4-253
As a result, the following statements hold.
4.4 Duality and Steady-State Properties 369
(a) As V./V3— 0, p of the n steady-state optimal observer poles approach the
numbers $,,i = 1,2,°-+, p, where
v; if Re (»;) 2S 0,
Up 4-254
—», if Re(v,) > 0.
(b) As V,/V3— 0, the remaining n — p observer poles asymptotically approach
straight lines which intersect in the origin and make angles with the negative
real axis of
n—p—l1
+1 : Peet elite! ety eae ne n — p odd,
n= p 2
(+ 4)7 n—p pd
26 = — . =O 1: n — p even.
n—p Zz
These faraway observer poles asymptotically are at a distance
1/[2(n—p)]
Wy = G 4) 4-256
V2
from the origin.
(c) As V,/V3—> 00, the n observer poles approach the numbers #,;, i=
1,2,°°*,, where
1; if Re (7;) < 0,
i,= f 4-257
—7; if Re (ar,) > 0:
It follows from (b) that the faraway poles approach a Butterworth con-
figuration.
For the general case we have the following results, which follow from
Theorem 3.12 (Section 3.8.1).
Theorem 4.13. Consider the n-dimensional time-invariant system
x(t) = Ax(t) + Bu(t) + Gw,(t),
4-258
y(t) = Cx(t) + we(t),
where ws; is white noise with constant intensity Vz and w, is white noise un-
correlated with ws, with constant intensity V, > 0. Suppose that {A, G} is
stabilizable and {A, C} detectable. Then the poles of the steady-state optimal
observer are the left-half plane zeroes of the polynomial
(—1)"$(s)¢(—s) det [I + V2"H(s)V3H7(—s)], where H(s) is the transfer matrix
H(s) = C(sI — A)"G, 4-259
4-260
370 Optimal Reconstruction of the State
and 4(s) is the characteristic polynomial of the system 4-258. Suppose that
dim (w3) = dim (y) = k, so that H(s) is ak x k transfer matrix. Let
p
yo “UC-»
det [H(s)] = 4-261
#(s) Il (s—=<77,)
—s
and assume that « # 0. Also, suppose that
Ve= pn; 4-262
with N > 0 and p a positive scalar.
(a) Then as p|0, p of the optimal observer poles approach the numbers
Va, 1 = ld ep. where
Y; L Re (”;) < 0,
i,= at 4-263
—?; if Re (»,) > 0.
The remaining observer poles go to infinity and group into several Butterworth
configurations of different orders and different radii. A rough estimate of the
distance of the faraway poles to the origin is
& ccder (Vs) 1/([2(n—p)]
G See :
4-264
p* det (N)
(b) As p— ©, the n optimal observer poles approach the numbers #;, i =
1,2,°°:,n, where
5 if Re (77;) = 0,
t.= 4-265
—T; if Re (z,) > 0.
Some information concerning the behavior of the observer poles when
dim (w3) ¥ dim (y) follows by dualizing the results of Problem 3.14.
We finally transcribe Theorem 3.14 (Section 3.8.3) as follows.
Theorem 4.14. Consider the time-invariant system
a(t) = Ax(t) + Gw,(t),
4-266
y(t) = Ca(t) + w(t),
where G and C have full rank, wy is white noise with constant intensity V, and
ws is white noise uncorrelated with ws with constant nonsingular intensity
V,= pN, p>0, N> 0. Suppose that {A, G} is stabilizable and {A, C}
detectable and let Q be the steady-state solution of the variance Riccati
equation 4-244 associated with the optimal observer problem. Then the following
facts hold.
4.4 Duality and Steady-State Properties 371
(a) The limit
limO= 0, 4-267
: pt0
exists.
(b) Let e,(t) denote the contribution of the state excitation noise to the re-
construction error e(t) = x(t) — &(t), and e,(t) the contribution of the observa-
tion noise to e(t). Then for the steady-state optimal observer the following limits
hold:
lim E{e"(t)We(t)} = tr(Q,W),
p+0
lim E{e,7(t)We,(t)} = tr(Q,W), 4-268
lim E{e,“(t)We,(t)} = 0.
(c) If dim (ws) > dim (y), then QO, # 0.
(d) Jf dim (ws) = dim (y), and the numerator polynomial p(s) of the square
transfer matrix
C(sI — A)1G 4-269
is nonzero, then Q, = 0 if and only if w(s) has zeroes with nonpositive real
parts only.
(e) If dim (ws) < dim (y), then a sufficient condition for Q, to be the zero
matrix is that there exists a rectangular matrix M such that the numerator
polynomial of the square transfer matrix MC(sI — A)“G is nonzero and has
zeroes with nonpositive real parts only.
This theorem shows that if no observation noise is present, completely
accurate reconstruction of the state of the system is possible only if the number
of components of the observed variable is at least as great as the number of
components of the state excitation noise w,(¢). Even if this condition is
satisfied, completely faultless reconstruction is possible only if the transfer
matrix from the system noise ws to the observed variable y possesses no
right-half plane zeroes.
The following question now comes to mind. For very small values of the
observation noise intensity V,, the optimal observer has some of its poles very
far away, but some other poles may remain in the neighborhood of the
origin. These nearby poles cause the reconstruction error to recover relatively
slowly from certain initial values. Nevertheless, Theorem 4.14 states that the
reconstruction error variance matrix can be quite small. This seems to be a
contradiction. The answer to this question must be that the structure of the
system to be observed is so exploited that the reconstruction error cannot be
driven into the subspace from which it can recover only slowly.
372 Optimal Reconstruction of the State
We conclude this section by remarking that Q,, the limiting variance
matrix for p | 0, can be computed by solving the singular optimal observer
problem that results from setting w,(t) = 0. As it turns out, occasionally the
reduced-order observation problem thus obtained involves a nondetectable
system, which causes the appropriate algebraic Riccati equation to possess
more than one nonnegative-definite solution. In such a case one of course has
to select that solution that makes the reduced-order observer stable (asymp-
totically or in the sense of Lyapunov), since the full-order observer that
approaches the reduced-order observer as V, — 0 is always asymptotically
stable.
The problem that is dual to computing Q,, thatis, the problem of computing
P,.= lim P 4-270
R270
for the optimal deterministic regulator problem (Section 3.8.3), can be
solved by formulating the dual observer problem and attacking the resulting
singular optimal observer problem as outlined above. Butman (1968) gives a
direct approach to the “control-free costs’’ linear regulator problem.
Example 4.6. Positioning system
In Example 4.4 (Section 4.3.2), we found that for the positioning system
under consideration the steady-state solution of the error variance matrix is
given by
Fe rl —o + Va? + 28 a2 + B— ava? + 28
a? + B— al a® 2B —a — 2048 + (a? + BV oe + 26
4-271
where BW ValVn 4-272
As V,, | 0, the variance matrix behaves as
PNA Baka hae yV eV es
an yVieyue 24/2,,8/2y8/ay 1/4 4-273
Obviously, Q approaches the zero matrix as V,, | 0. In Example 4.4 we
found that the optimal observer poles are
4(—V a? + 28 + Vo? — 28). 4-274
Asymptotically, these poles behave as
Ra Vi 1/4 3
4/2 (4) y/(—1+4)), 4-275
4.6 Problems 373
which represents a second-order Butterworth configuration. All these facts
accord with what we might suppose, since the system transfer function is
given by
H(s) = c(sI — A)*g = ; 4-276
s(s + a)
which possesses no zeroes. As we have seen in Example 4.4, for V,, | 0 the
optimal filter approaches the differentiating reduced-order filter
E(t) = y(t),
‘ 4-277
So(t) = 77(t).
If no observation noise is present, this differentiating filter reconstructs the
state completely accurately, no matter how large the state excitation noise.
4.5 CONCLUSIONS
In this chapter we have solved the problem of reconstructing the state of a
linear differential system from incomplete and inaccurate measurements.
Several versions of this problem have been discussed. The steady-state and
asymptotic properties of optimal observers have been reviewed. It has been
seen that some of the results of this chapter are reminiscent of those obtained
in Chapter 3, and in fact we have derived several of the properties of optimal
observers from the corresponding properties of optimal regulators as
obtained in Chapter 3.
With the results of this chapter, we are in a position to extend the results
of Chapter 3 where we considered linear state feedback control systems.
We can now remove the usually unacceptable assumption that all the com-
ponents of the state can always be accurately measured. This is done in
Chapter 5, where we show how output feedback control systems can be
designed by connecting the state feedback laws of Chapter 3 to the observers
of the present chapter.
4.6 PROBLEMS
4.1. An observer for the inverted pendulum positioning system
Consider the inverted pendulum positioning system described in Example
374 Optimal Reconstruction of the State
1.1 (Section 1.2.3). The state differential equation of this system is given by
0 1 0 O 0
(at Seo ato ae
oe M M :
ah) = 0 0 a x(t) + 0 u(t). 4-278
g g
as 2°
E Es d
Suppose we choose as the observed variable the angle ¢(r) that the pendulum
makes with the vertical, that is, we let
1 1
m(t) ( atx )x@
Nes (= =O, = 50) doy 4-279
Consider the problem of finding a time-invariant observer for this system.
(a) Show that it is impossible to find an asymptotically stable observer.
Explain this physically.
(b) Show that if in addition to the angle ¢(t) the displacement s(t) of the
carriage is also measured, that is, we add a component
H(t) = (1,0, 0, O)a(t) 4-280
to the observed variable, an asymptotically stable time-invariant observer
can be found.
4.2. Reconstruction of the angular velocity
Consider the angular velocity control system of Example 3.3 (Section 3.3.1),
which is described by the state differential equation
E(t) = —a&(t) + «u(t), 4-281
where &(f) is the angular velocity and w(t) the driving voltage. Suppose that
the system is disturbed by a stochastically varying torque operating on the
shaft, so that we write
E(t) = —a&(t) + x(t) + @,(2), 4-282
where ,(t) is exponentially correlated noise with rms value o, and time
constant 0,. The observed variable is given by
y(t) = €(t) + o,(¢), 4-283
where w, is exponentially correlated noise with rms value o, and time
constant 6,. The processes w, and w, are uncorrelated.
4.6 Problems 375
The following numerical values are assumed:
= OS Se.
« = 150 rad/(V s2),
o, = 54.78 rad/s?,
G35 fads,
0, = 0.01 s.
(a) Since the state excitation noise and the observation noise have quite
large bandwidths as compared to the system bandwidth, we first attempt to
find an optimal observer for the angular velocity by approximating both the
state excitation noise and the observation noise as white noise processes, with
intensities equal to the power spectral densities of w, and w, at zero frequency.
Compute the steady-state optimal observer that results from this approach.
(b) To verify whether or not it is justified to represent m, and w, as white
noise processes, model w, and w, as exponentially correlated noise processes,
and find the augmented state differential equation that describes the angular
velocity control system. Using the observer differential equation obtained
under (a), obtain a three-dimensional augmented state differential equation
for the reconstruction error e(t) = &(t) — &(f) and the state variables of the
processes wm, and w,. Next compute the steady-state variance of the recon-
struction error and compare this number to the value that has been pre-
dicted under (a). Comment on the difference and the reason that it exists.
(c) Attempt to reach a better agreement between the predicted and
the actual results by reformulating the observation problem as follows. The
state excitation noise is modeled as exponentially correlated noise, but the
approximation of the observation noise by white noise is maintained, since
the observation noise bandwidth is very large. Compute the steady-state
optimal observer for this situation and compare its predicted steady-state
mean square reconstruction error with the actual value (taking into account
that the observation noise is exponentially correlated noise). Comment on
the results.
(d)* Determine the completely accurate solution of the optimal observer
problem by modeling the observation noise as exponentially correlated noise
also. Compare the performance of the resulting steady-state optimal observer
to that of the observer obtained under (c) and comment.
4.3. Solution of the observer Riccati equation
Consider the matrix Riccati equation
O(t) = A(tQ(1) + Q(HA7(t) + Vi) — QWMC*(HVa"(HCHQ(t) 4-285
with the initial condition
O(to) = Qo. 4-286
376 Optimal Reconstruction of the State
Define Y(t, f9) as the (2n x 2n)-dimensional [Q(¢) isn x n] solution of
kee C7()Vz (HCO)
Lashes 3 0/>
= (t,t)
V,(t) A(t)
4-287
¥'(to; to) = I.
Partition ‘W(t, tg) corresponding to the partitioning occurring in 4-287 as
follows.
VU, =| (t,:t) (t “I
Yu a2) Was 2-0,
4-288
Yat, 7) Yoe(t, to)
Show that the solution of the Riccati equation can be written as
O(t) = [Warlt, fo) + Poot, fo )Qol[Vir(t, to) + Past, fo)Qol*. 4-289
4.4.* Determination of a priori data for the singular optimal observer
When computing an optimal observer for the singular observation problem
as described in Section 4.3.4, we must determine the a priori data
B(to) = E{Cyx(ty) | Yo(to) } 4-290
and
Q(to) = E{[p(t.) — B(to)ILp(to) — A(to)]” | Ya(to)}: 4-291
where
Yo(to) = Cyx(to). 4-292
We assume that
E{x(to)} = %q 4-293
and
E{[x(t) — Zo][x(to) — %]7} = Qo are given. Prove that if 2(¢)) is Gaussian then
4-294
E{x(to) | Yo(to)} = &(ty) = % + QC" (CzQoCs7) [yal to) — C2%] 4-295
and
E{[x(to) — &(to)[%(to) — &(t)) |" | Yo to)} = Q) — OCs (C.0,Ca*) C0.
4-296
Determine from these results expressions for 4-290 and 4-291. Hint: Use the
vector formula for a multidimensional Gaussian density function (compare
1-434) and the expression for the inverse of a partitioned matrix as given by
Noble (1969, Exercise 1.59, p. 25).
39 OPTIMAL LINEAR OUTPUT
FEEDBACK CONTROL SYSTEMS
5.1 INTRODUCTION
In Chapter 3 we considered the conirol of linear systems described by a state
differential equation of the form
&(t) = A(t)e(t) + B(d)u(t). 5-1
An essential part of the theory of Chapter 3 is that it is assumed that the
complete state vector x(t) is available for measurement and feedback.
In this chapter we relax this assumption and study the much more realistic
case where there is an observed variable of the form
y(t) = C()x(t), 5-2
which is available for measurement and feedback. Control systems where
the observed variable y serves as input to the controller, and not the state z,
will be called output feedback control systems.
In view of the results of Chapter 4, it is not surprising that the optimal
output feedback controller turns out to be a combination of an observer,
through which the state of the system is reconstructed, and a control law
which is an instantaneous, linear function of the reconstructed state. This
control law is the same control law that would have been obtained if the state
had been directly available for observation.
In Section 5.2 we consider a deterministic approach to the output feedback
problem and we obtain regulators through a combination of asymptotically
stable observers and linear, stabilizing control laws. In Section 5.3 a
stochastic approach is taken, and optimal linear feedback regulators are
derived as interconnections of optimal observers and optimal linear state
feedback laws. In Section 5.4 tracking problems are studied. In Section 5.5
we consider regulators and tracking systems with nonzero set points and
constant disturbances. Section 5.6 concerns the sensitivity of linear optimal
feedback systems to disturbances and system variations, while the chapter
concludes with Section 5.7, dealing with reduced-order feedback controllers.
377
378 Optimal Linear Output Feedback Control Systems
5.2 THE REGULATION OF LINEAR SYSTEMS
WITH INCOMPLETE MEASUREMENTS
5.2.1 The Structure of Output Feedback Control Systems
In this section we take a deterministic approach to the problem of regulating
a linear system with incomplete measurements. Consider the system described
by the state differential equation
a(t) = A(t)a(t) + B(t)u(t), 5-3
while the observed variable is given by
u(t) = CO)z(h): 5-4
In Chapter 3 we considered control laws of the form
u(t) = —F(t)zx(t), 5-5
where it was assumed that the whole state x(t) can be accurately measured.
If the state is not directly available for measurement, a natural approach
is first to construct an observer of the form
#1) = A(DR(t) + BU(t) + KOLO — CO*OI, 5-6
and then interconnect the control law with the reconstructed state £(t):
u(t) = —F(t)&(t), 5-7
where F(t) is the same as in 5-5. Figure 5.1 depicts the interconnection of the
plant, the observer, and the control law. By substitution of the control law
5-7 into the observer equation 5-6, the controller equations take the form
A(t) = [A(t) — BINF() — KCK + Ky,
5-8u(t) = —F(t)&(t).
This leads to the simplified structure of Fig. 5.2.
The closed-loop system that results from interconnecting the plant with
the controller is a linear system of dimension 2” (where n is the dimension
of the state x), which can be described as
& ( A(t) — B(t)F(t) x(t) re
Ome Zt acter oe
We now analyze the stability properties of the closed-loop system. To this
end we consider the state x(t) and the reconstruction error
e(t) = 2(t) — &(2). 5-10
0
(})9 Cs
—_
}uo\d
(V)X
Qs
GQ)»
(4)9
an ~ oe)
“BLY
“T'S
OU,
jo omMjONNs
uv
Jansasqo
JOJUOD YOegpsey
jndjno
‘wa}ss
380
f
‘
7 ee
(J3)8-Q)9Q)x-QV
“waoj yoedwios asour & Ul ["¢ “SE Jo wajsks JoNUOD YORgps9j jndjno ey, “7's “BIA
te ge et ti J2]}04}U09
JOJOW!}SA 3}0}S
5.2 Regulation with Incomplete Measurements 381
By subtracting 5-3 and 5-6, it easily follows with the use of 5-4 that e(t)
satisfies
é(t) = [A(t) — K(HCMJe(t). 5-11
Substitution of £(t) = x(t) — e(¢) into 5-3 and 5-7 yields
“(t) = [A(t) — B(t)F(O)x(t) + BI) F(t)e(t). 5-12
When considering 5-11, it is seen that e(t) converges to zero, independent of
the initial state, if a gain matrix K(t) can be found that makes 5-11 asymp-
totically stable. However, finding a gain matrix K(t) that makes 5-11 stable
is equivalent to determining K(t) such that the observer is asymptotically
stable. As we know from Chapter 4, such a gain often can be found.
Next we consider 5-12. If B(t) and F(t) are bounded and e(t) > 0ast— o,
x(t) will always converge to zero if the system
&(t) = [A(t) — BD) F(1)|x(0) 5-13
is asymptotically stable. From Chapter 3 we know that often F(t) can be
determined so that 5-13 is asymptotically stable. Thus we have seen that it is
usually possible to find gain matrices F(t) and K(t) such that Eqs. 5-11 and
5-12 constitute an asymptotically stable system. Since the system 5-9 is
obtained from the system described by 5-11 and 5-12 by a nonsingular linear
transformation, it follows that it is usually possible to find gain matrices
F(t) and K(t) such that the closed-loop control systems 5-9 is stable. In the
following subsection the precise conditions under which this can be done are
stated.
Finally, we remark the following. Combining 5-11 and 5-12 we obtain
x(t) A(t) — B(t)F(t) B(t)F(t) i
5-14
al fs | 0 A(t) — ee ie
Let us consider the time-invariant case, where all the matrices occurring in
5-14 are constant. Then the characteristic values of the system 5-14, which
are also the characteristic values of the system 5-9, are the zeroes of
det
sl —A-+ BF —BF
0 sI—A+ KC
= det (s] — A + BF)det (sJ — A+ KC). 5-15
The reason that the systems 5-9 and 5-14 have the same characteristic values
is that their respective state vectors are related by a nonsingular linear
transformation (see Problem 1.3). Consequently, the set of closed-loop
characteristic values comprises the characteristic values of A — BF (the
382 Optimal Linear Output Feedback Control Systems
regulator poles) and the characteristic values of A — KC (the observer
poles):
Theorem 5.1. Consider the interconnection of the time-invariant system
a(t) = Ax(t) + Bu(t), y(t) = Ca(t),
5-16
the time-invariant observer
and the time-invariant control law
&(t) = A&(t) + Bu(t) + K[y(t) — C&(t)], 5-17
u(t) = — F(t). 5-18
Then the characteristic values of the interconnected system consist of the
regulator poles (the characteristic values of A — BF) together with the observer
poles (the characteristic values of A — KC).
These results show that we can consider the problem of determining an
asymptotically stable observer and an asymptotically stable state feedback
control law separately, since their interconnection results in an asymptotically
stable control system.
Apart from stability considerations, are we otherwise justified in separately
designing the observer and the control law? In Section 5.3 we formulate a
stochastic optimal regulation problem. The solution of this stochastic version
of the problem leads to an affirmative answer to the question just posed.
In this section we have considered full-order observers only. It can be
shown that reduced-order observers interconnected with state feedback laws
also lead to closed-loop poles that consist of the observer poles together
with the controller poles.
Example 5.1. Position control system.
Consider the positioning system described by the state differential equation
(see Example 2.1, Section 2.2.2, and Example 2.4, Section 2.3)
il 0
“(= | ao + ( Jue 5-19
0 —«a K
with
Kk = 0.787 rad/(V s?),
5-20
oS alag,
The control law
H(t) = —(f#,. fe) 5-21
5.2 Regulation with Incomplete Measurements 383
produces the regulator characteristic polynomial
det (sJ — A + BF) = s? + (a + Kfa)s + Ky. 5-22
By choosing
fi = 254.1 V/rad,
Se = 19.57 V s/rad, 5-23
the regulator poles are placed at —10 + 710 s~?. Let us consider the observer
. ae '0 ky
&(t) = a(t) + { |u(t) + [n(t)— (1, 0)#(], 5-24
0 -—«a K ies
where it is assumed that
n(t)= (1, O)a(r) 5-25
is the observed variable. The observer characteristic polynomial is
det (sI — A + KC) = s? + (a + ky)s + ak, + ky. 5-26
To make the observer fast as compared to the regulator, we place the
observer poles at —50 + j50s-1. This yields for the gains:
ky = 95.40 s+,
ky = 4561 s-2. 5-27
In Fig. 5.3 we sketch the response of the output feedback system to the
initial state (0) = col (0.1, 0), (0) = 0. For comparison we give in Fig. 5.4
the response of the corresponding state feedback system, where the control
law 5-21 is directly connected to the state. We note that in the system with
an observer, the observer very quickly catches up with the actual behavior
of the state. Because of the slight time lag introduced by the observer, how-
ever, a greater input is required and the response is somewhat different from
that of the system without an observer.
Example 5.2. The pendulum positioning system.
In this example we discuss the pendulum positioning system of Example 1.1
(Section 1.2.3). The state differential equation of this system is given by
0 1 0 O 0
ee er
a=] 49 6 9 ft] g [Oo 5-28
ae oe 0
cS th/
384 Optimal Linear Output Feedback Control Systems
O14, reconstructed
ongulor
position
(rad)
_zactual
0
0
t——=—(s)
0.5
t ——>_(s)
20
input
voltage
0 0.5
ae 1 ————— (5)
= 20
t{ ——-_(s)
-40
- 60
Fig. 5.3. The response and the input of
the position control system with observer
for «(0) = col(0.1, 0); (0) = col(0, 0).
Fig. 5.4. The response and the input
of the position control system with state
feedback (without observer) for #(0) =
The components of the state are
E(t) — s(t),
Ea) = 4);
5-29
E(t) = s(t) + L'd(a),
E(t) = §(t) + L’'d(0).
Here s(t) is the displacement of the carriage and (t) the angle the pendulum
makes with the vertical. We assume that both these quantities can be meas-
ured. This yields for the observed variable
0
m,(t)
y(t) = =
not) SS
0
~
x(t). 5-30
5.2 Regulation with Incomplete Measurements 385
The main function of the control system is to stabilize the system. We
therefore choose as the controlled variable the position of the pendulum
C(t) = &,(t) = s(t) + L’d(?). 5-31
We first select the regulator poles by solving the regulator problem with the
criterion
i “TW + peo) at. 5-32
To determine an appropriate value of p, we select it such that the estimated
radius @, of the faraway poles such as-given in Theorem 3.11 (Section 3.8.1)
is 10s-1. This yields a settling time of roughly 10/m») = 1 s. It follows from
the numerical values of Example 1.1 that the oscillation period of the
pendulum is 27\/L’/g ~ 1.848, so that we have chosen the settling time
somewhat less than the oscillation period.
To compute p from w», we must know the transfer function H(s) of the
system from the input force w to the controlled variable £. This transfer
function is given by
ee.
EE
H(s\ = ace eee eee ; raea M E
5-33
It follows with 3-486 that
, 2451/8
Wo = fe ; 5-34
p
With the numerical values of Example 1.1, it can be found that we must
choose
p = 10-° m?/N? 5-35
to make m,) approximately 10s~?. It can be computed that the resulting
steady-state gain matrix is given by
F = (389.0, 26.91, —1389, —282.4), 5-36
while the closed-loop poles are —9.870 + 73.861 and —4,.085 + 79.329 st.
Figure 5.5 gives the response of the state feedback control system to the
initial state s(0) = 0, s(0) = 0, 4(0) = 0.1 rad (~ 6°), 6(0) = O. It is seen
that the input force assumes values up to about 100 N, the carriage displace-
ment undergoes an excursion of about 0.3m, and the maximal pendulum
displacement is about 0.08 m.
Assuming that this performance is acceptable, we now proceed to deter-
mine an observer for the system. Since we have two observed variables, there
is considerable freedom in choosing the observer gain matrix in order to
corriage output feedbock
displocement 96 Eee control '
Ss
4
: state feedbock
02 oe control
(m) F IEE 1
: ee
-0.2 eee)
-0.4
-0.6
$+1'$
0.08
pendulum
displacement 96 state feedbock
s+ io ~~. control
0.04}
0.02
(m) 0
0.02}
-0.04F
-0.08- we output feedbock
control
200
input
force
i output feedback
100 ee contro.
(N) 0 ]
t ———» (s)
stote feedbock
-100 control
Fig. 5.5. Responses of the state feedback and output feedback pendulum-balancing
systems to the initial state 7(0) = col(0, 0, 0.0842, 0) [the observer initial state is (0) = 0].
386
5.2 Regulation with Incomplete Measurements 387
attain a given set of observer poles. To simplify the problem we impose the
restriction that the first component of the observed variable (the displace-
ment) is used only to reconstruct the state of the carriage (i.e., €, and &,),
and the second component of the observed variable is used only to recon-
struct the motion of the pendulum (i.e., é, and &,). Thus we assume the
following structure of the observer:
0 1 0 0 0
F 1
Oe 10) 0 =
xy M
ia) = a+ |“ | wo
0 0 il 0
g g
—-= 0 2 9 0
i L
k, O
oe 12? OPC OG
Uo) = 1 \ a(t) |. 5-37
0 iss Oe
‘ie ed 0) ae 0
if 1b
Here the gains k,, k,, kg, and k, are to be determined. It is easily found that
with the structure of 5-37 the observer characteristic polynomial is given by
[st s(ta + F) + Fk + bal [st 4 s+ SE]. 5-38
M M LU cL
It is clearly seen that one pair of poles governs the speed of reconstruction
of the motion of the carriage, and the other that of the pendulum. We now
choose the gains k, to k, such that both pairs of poles are somewhat further
away from the origin than the regulator poles obtained above. There is no
point in choosing the observer poles very far away, since the resulting high
observer gains will give difficulties in the implementation without improving
the control system response very much. We thus select both pairs of observer
poles as 21.2(-1 + j) st.
The distance of these poles to the origin is 30s. It can be found with the
numerical values of Example 1.1 that to achieve these observer poles the
gains must be chosen as
k, = 41.4, k; = 35.6,
beg 859, chy =-767. 5-39
388 Optimal Linear Output Feedback Control Systems
Figure 5.5 also gives the response of the interconnection of the resulting
observer with the control law and the pendulum positioning system to
the same initial conditions as before, with #(0) = 0. The estimate S(t) of the
carriage displacement is not shown in the figure since it coincides with the
actual carriage displacement right from the beginning owing to the special
set of initial conditions. It is seen that the estimate § + L’¢ of the pendulum
displacement s + L’¢ very quickly catches up with the correct value. Never-
theless, because of the slight time lag in the reconstruction process, the
motion of the output feedback pendulum balancing system is more violent
than in the state feedback case. From a practical point of view, this control
system is probably not acceptable because the motion is too violent and the
system moves well out of the range where the linearization is valid; very
likely the pendulum will topple. A solution can be sought in decreasing p
so as to damp the motion of the system. An alternative solution is to make
the observer faster, but this may cause difficulties with noise in the system.
5.2.2* Conditions for Pole Assignment and Stabilization of Output
Feedback Control Systems
In this section we state the precise conditions on the system described by
5-3 and 5-4 such that there exist an observer 5-6 and a control law 5-7
that make the closed-loop control system 5-9 asymptotically stable (G. W.
Johnson, 1969; Potter and VanderVelde, 1969):
Theorem 5.2. Consider the interconnection of the system
#(t) = A(t)x(t) + B(Ou(s),
y(t) = C(t)x(t), 5-40
the observer
#(t) = A(t)#(t) + B(t)u(t) + Ky) — CH*O), 5-41
and the control law
u(t) = —F(t)£(t). 5-42
Then sufficient conditions for the existence of gain matrices K(t) and F(t),
t > to, such that the interconnected system is exponentially stable, are that
the system 5-40 be uniformly completely controllable and uniformly completely
reconstructible or that it be exponentially stable. In the time-invariant situation
(i.e., all matrices occurring in 5-40, 5-41, and 5-42 are constant), necessary
and sufficient conditions for the existence of stabilizing gain matrices K and F
are that the system 5-40 be both stabilizable and detectable. In the time-
invariant case, necessary and sufficient conditions for arbitrary assignment of
both the regulator and the observer poles (within the restriction that complex
5.3 Regulators with Incomplete and Noisy Measurements 389
poles occur in complex conjugate pairs) are that the system be completely
controllable and completely reconstructible.
The proof of this theorem is based upon Theorems 3.1 (Section 3.2.2), 3.2
(Section 3.2.2), 3.6 (Section 3.4.2), 4.3 (Section 4.2.2), 4.4 (Section 4.2.2),
and 4.10 (Section 4.4.3).
5.3 OPTIMAL LINEAR REGULATORS WITH
INCOMPLETE AND NOISY MEASUREMENTS
5.3.1 Problem Formulation and Solution
In this section we formulate the optimal linear regulator problem when the
observations of the system are incomplete and inaccurate, that is, the
complete state vector cannot be measured, and the measurements that are
available are noisy. In addition, we assume that the system is subject to
stochastically varying disturbances. The precise formulation of this problem
is as follows.
Definition 5.1. Consider the system
x(t) = A(t)a(t) + B(t)u(t) + w,(d), betas
5-43
x(to) = Xo,
where x, is a stochastic vector with mean X, and variance matrix Qo. The
observed variable is given by
y(t) = C(fz(t) + w(t), tt > to. 5-44
The joint stochastic process col (w,, W,) is a white noise process with intensity
Vit) Vial)
’ = to. 5-45
Vio(t) V2(t)
The controlled variable can be expressed as
z(t) = D(t)x(t), feoate: 5-46
Then the stochastic linear optimal output feedback regulator problem is the
problem of finding the functional
u(t)=f[y(7),t0 57 St], wth, 5-47
such that the criterion
ty
= el | [27 (t)R,(t)2(t) + u7(t)Ro(t)u(t)] dt + M1 )Pyx() 5-48
0
390 Optimal Linear Output Feedback Control Systems
is minimized. Here R,(t), R2(t), and P, are symmetric weighting matrices
such that R,(t) > 0, R(t) > 054 <1 < hand Py > 0.
The solution of this problem is, as expected, the combination of the solutions
of the stochastic optimal regulator problem of Chapter 3 (Theorem 3.9,
Section 3.6.3) and the optimal reconstruction problem of Chapter 4. This
rather deep result is known as the separation principle and is stated in the
following theorem.
Theorem 5.3. The optimal linear solution of the stochastic linear optimal
output feedback regulator problem is the same as the solution of the corre-
sponding stochastic optimal state feedback regulator problem (Theorem 3.9,
Section 3.6.3) except that in the control law the state x(t) is replaced with
its minimum mean square linear estimator &(t), that is, the input is chosen as
u(t) = —F%(t)e(t), 5-49
where F°(t) is the gain matrix given by 3-344 and £(t) is the output of the optimal
observer derived in Sections 4.3.2, 4.3.3, and 4.3.4 for the nonsingular un-
correlated, nonsingular correlated, and the singular cases, respectively.
An outline of the proof of this theorem for the nonsingular uncorrelated
case is given in Section 5.3.3. We remark that the solution as indicated is the
best /inear solution. It can be proved (Wonham, 1968b, 1970b; Fleming, 1969;
Kushner, 1967, 1971) that, if the processes w, and w, are Gaussian white
noise processes and the initial state x) is Gaussian, the optimal linear solution
is the optimal solution (without qualification).
Restricting ourselves to the case where the problem of estimating the state
is nonsingular and the state excitation and observation noises are uncorrelated,
we now write out in detail the solution to the stochastic linear output feed-
back regulator problem. For the input we have
u(t) = —F(t)&(t), 5-50
with
F'(t) = Re Gee). 5-51
Here P(7) is the solution of the Riccati equation
—P(t) = D*(t)R3(t)D(t) — P(t)B(t)Ry (t)B7 (1) P(t)
+ A*(t)P(t) + P(t)A(t), 5-52
P(t) Pi.
The estimate #(f) is obtained as the solution of
#(t) = A()£(t) + BOXU(t) + KWIY) — CKO),
5-53
#(ty) = Lo,
5.3. Regulators with Incomplete and Noisy Measurements 391
where
KE) = ODE? Vat), 5-54
The variance matrix Q(t) is the solution of the Riccati equation
Olt) = Vit) — ADC™(HVZ(HCHOA(1) + A(NO(1) + Q(AT(N),
Q(to) = Qo.
5-55
Figure 5.6 gives a block diagram of this stochastic optimal output feedback
control system.
5.3.2 Evaluation of the Performance of Optimal Output Feedback
Regulators
We proceed by analyzing the performance of optimal output feedback
control systems, still limiting ourselves to the nonsingular case with un-
correlated state excitation and observation noises. The interconnection of the
system 5-43, the optimal observer 5-53, and the control law 5-50 forms a
system of dimension 2n, where n is the dimension of the state x. Let us
define, as before, the reconstruction error
e(t) = x(t) — &(t). 5-56
It is easily obtained from Eqs. 5-43, 5-53, and 5-50 that the augmented vector
col [e(t), £(t)] satisfies the differential equation
a i. — K%t)C(t) 0 \ (
a(t) K°(t)C(t) Pree é(t)
( ra) te
ot :
0 Kt) /\we(0)
with the initial condition
es = ee a ") 5.58
#(to) Xo
The reason that we consider col (e, #) is that the variance matrix of this
augmented vector is relatively easily found, as we shall see. All mean square
quantities of interest can then be obtained from this variance matrix. Let us
denote the variance matrix of col [e(t), €(t)] as
(t) — Efe(t
l(’ 3 4 Jae — Efe(t)}]*, [4 — ecannr
A(t) — Etat}
e ie zu a
~— NeZ0) Q.s(1)
‘sjuawiainsvew Asiou pure ojajdwoour yim Joye[nser reour] yeumdo oy, *9"s “BIA
J3}]04} U0
JOJOW!IZSS 37DYS
(3}509)8- (9 GQ) GA)
392
5.3 Regulators with Incomplete and Noisy Measurements 393
The differential equations for the matrices Q,,, Q,2, and Qs. can be obtained
by application of Theorem 1.52 (Section 1.11.2). It easily follows that these
matrices satisfy the equations:
Oi) = [A(t) — K°*(1H)C(H]O1,(t) + Qu(D[A(D — K(1)C(t)]"
+ V,(t) + K°(t)V.(t)K°7 (1),
Q,(t) = Qn(t)C*()K°"(t) + O.(H[A() — BOF]?
+ [A(t) — K°(t)C(t)]O.(t) — K°(t)Vo(1)K°7(1), 5-60
Oo2(t) = Q(t)C7(t)K*(t) + Qoo(t)[A(t) — BNF]? + K°(t)C(1)Q,0(1)
+ [A(t) — B(t)F°(t)]Oo0(t) + K°(t)Vo(t)K°7(t),
with the initial conditions
Or1(to) = Oo, QO12(to) = 0, Oo At) = 0. 5-61
When considering these equations, we immediately note that of course
Oult)=ON), tab. 5-62
As a result, in the differential equation for Q,.(t) the terms Q,,(t)C7 (t)K®" (t)
and —K°(t)V,(t)K°”(t) cancel because K°(t) = QO(t)C7(t)Vz1(t). What is left
of the equation for Qj,(t) is a homogeneous differential equation in Q,,(t)
with the initial condition Q,5(t)) = 0, which of course has the solution
Q,.(t) = 0, t> tb. 5-63
Apparently, e(¢) and £(¢) are uncorrelated stochastic processes. This is why
we have chosen to work with the joint process col (e, #). Note that e(t) and
&(t) are uncorrelated no matter how the input to the plant is chosen. The
reason for this is that the behavior of the reconstruction error e is independent
of that of the input uw, and the contribution of the input u(7), %) <7 <t,
to the reconstructed state £(7) is a known quantity which is subtracted to
compute the covariance of e(f) and (1). We use this fact in the proof of the
separation principle in Section 5.3.3.
The differential equation for Q,.(f) now simplifies to
Q.(t) = [A(t) — B(t)F°(t)]Q..(t) + Qs(t)[A(t) — B()F*(t)]"
+ K(t)V(t)K°"(t), 5-64
with the initial condition
Ovo(to) = 0. 5-65
Once we have computed Q,,(f), the variance matrix of the joint process
col (e, @) is known, and all mean square quantities or integrated mean square
quantities of interest can be obtained, since
x(t) = e(t) + &(0). 5-66
394 Optimal Linear Output Feedback Control Systems
Thus we can compute the mean square regulation error as
Efz"(t)W,(ta()} = E{x7(t)D7(t)W,(t) D(t)2(t)
= tr [D7(1)W,(t) D(DE{a(1)x7(t)}] 5-67
= tr {D™()W(t)DH[AHz"(t) + Qult) + QDI},
where W,(t) is the weighting matrix and Z(t) is the mean of x(t). Similarly,
we can compute the mean square input as
E{u (t)W,,(t)u(t)} = Efe? (t)F°* ()W,,(t)F(t)4(t)}
= tr [F°"(t)W,, (F(t) E{e(t)47 (1)}]
= tr {F°"(1)W,(t)F(t)[z(t)x" (t) + Q,,(t)f}, 5-68
where W,,(¢) is the weighting matrix of the mean square input.
It follows that in order to compute the optimal regulator gain matrix
F°(t), the optimal filter gain matrix K°(t), the mean square regulation error,
and the mean square input one must solve three n X n matrix differential
equations: the Riccati equation 5-52 to obtain P(t) and from this F°(t),
the Riccati equation 5-55 to determine Q(t) and from this K°(t), and finally
the linear matrix differential equation 5-64 to obtain the variance matrix
Q»,(t) of £(t). In the next theorem, however, we state that if the mean square
regulation error and the mean square input are not required separately, but
only the value of the criterion o as given by 5-48 is required, then merely the
basic Riccati equations for P(t) and Q(t) need be solved.
Theorem 5.4. Consider the stochastic regulator problem of Definition 5.1.
Suppose that
Vth Os Vio(t) = 0 for all t. 5-69
Then the following facts hold:
(a) All mean square quantities of interest can be obtained from the variance
matrix diag [Q(t), Qoo(t)] of col [e(t), #()], where e(t) = a(t) — £(t), O(t)
is the variance matrix of e(t), and Q(t) can be obtained as the solution of the
matrix differential equation
OQro(t) = [A(t) — BEL)F%()]Oz0(t) + Qoo(t)[A) — B)F(N |?
ROO) GK (1) ta O10
Q22(to) = 0.
(b) The minimal value of the criterion 5-48 can be expressed in the following
two alternative forms
o° = X" P(ty)%) + tr | | ‘[P()K(t)Va(1)K°"(8) + O()R,(1)] dt + P,O(t,)
5-71
5.3 Regulators with Incomplete and Noisy Measurements 395
and
ty
of = Fel Plt) + 10 (PCE). + | TREOKD + OCF ORADFD) ae,
to
Here we have abbreviated
5-72
Rai) = DADDY), 5-73
and P(t) and Q(t) are the solutions of the Riccati equations 5-52 and 5-55,
respectively.
(c) Furthermore, if the optimal observer and regulator Riccati equations have
the steady-state solutions O(t) and P(t) as t) > — © and t, > ©, respectively,
then the time-averaged criterion
ty
6 = lim : z(| [27 (t)R3(t)2(t) + u7(t)R,(t1)u(t)] ai), 5-74
to > — 00 {>> +o to
t17 0
if it exists, can be expressed in the alternative forms
¢ = lim ae tr [| PoevanKty + O(t)R,(t)] dt 5-75
and ae
& = lim ; ~ tr | "TBOV,(1) + O()F()RADF(D)] a 5-76
to7—o ly — lo to
Here K(t) and F(t) are the gains corresponding to the steady-state solutions
O(t) and P(t), respectively. ‘. i
(d) Finally, in the time-invariant case, where Q(t) and P(t) and thus also
F(t) and K(t) are constant matrices, the following expressions hold:
& = E{z7(t)Rge(t) + u*(t)R,u(t)}
= tr [PKV,K7 + OR,] = tr (PV, + OF'R,F). 5-77a
5-77b
This theorem can be proved as follows. Setting W,(t) = R,(t) and W,(t) =
R,(t) in 5-67 and 5-68, we write for the criterion
elf eTOR (0 Si u*(t)R2(t)u(t)] dt + a (GP eh)
2 i “POR ANA) + A(R HD] dt + F7(4)P,2(4)
+ tr ff TRIO + Onl) + FMORDF(OOaA0] a
0
+ P,[Q(t) + On(t)]. 5-78
396 Optimal Linear Output Feedback Control Systems
Let us separately consider the expression ie eek
: | "TR \(t) + F°"(t)Ro(1)F%(t)]Oox(t) dt + P,Qoo(t)\, 5-79
where, as we know, Qyo(t) is the solution of the matrix differential equation
Ooo(t) = [A(t) — B(t)F°(t)]Q20(t) + Q22(H[A() — BC) F°(1)]*
+ K(t)V,(t)K°7(t), 5-80
Q(t) = 0.
It is not difficult to show (Problem 5.5) that 5-79 can be written in the form
tr [| seoxrorcnnro ai), 5-81
0
where S(¢) is the solution of the matrix differential equation
—S(t) = [A(t) — BO)F°()]* S(t) + S()[A() — B)F°(1)] + Ri(d)
+ F°?(t)R,(t)F°(t), 5-82
S(t,) = Et
Obviously, the solution of this differential equation is
S(t) = PO); Eerie 5-83
Combining these results, and using the fact that the first two terms of the
right-hand side of 5-78 can be replaced with %)" P(t,)%), we obtain the desired
expression 5-71 from 5-78.
The alternative expression 5-72 for the criterion can be obtained by
substituting
R(t) = P(t)B(t)Rz'(t)B7(t)P(t) — AT(t)P(t) — P(t)A(t) — P(t) 5-84
into 5-71 and integrating by parts. The proofs of parts (c) and (d) of Theorem
5.4 follow from 5-71 and 5-72 by letting tj -- — co and ft, > oo.
Of course in any practical situation in which f,; — f) is large, we use the
steady-state gain matrices K(t) and F(t) even when ft, — fy is not infinite.
Particularly, we do so in the time-invariant case, where K and F are constant.
From optimal regulator and observer theory and in view of Section 5.2, we
know that the resulting steady-state output feedback control system is asymp-
totically stable whenever the corresponding state feedback regulator and
observer are asymptotically stable.
Before concluding this section with an example, two remarks are made.
First, we note that in the time-invariant steady-state case the following lower
5.3 Regulators with Incomplete and Noisy Measurements 397
bounds follow from 5-77a and 5-77b:
limo > tt (OR;), 5-85a
R270
lim & > tr( PY). 5-85b
V270
These inequalities can be interpreted as follows. Even if we do not at all
weight the input uw, and thus do not constrain the input amplitude, the
criterion G still cannot be less than tr (QR,) according to 5-85a. This minimum
contribution to the criterion is caused by the unavoidable inaccuracy in
reconstructing the state. Similarly, even when no measurement noise is
present, that is, V, approaches zero, the criterion ¢ cannot be less then
tr (PV,). This value is not surprising since it is exactly the value of the criterion
for the state feedback stochastic regulator (see Theorem 3.9, Section 3.6.3).
The second remark concerns the locations of the control system poles in
the time-invariant steady-state case. In Section 5.2 we saw that the control
system poles consist of the regulator poles and the observer poles. It seems a
good rule of thumb that the weighting matrices R, and V, be chosen so that
the regulator poles and the observer poles have distances to the origin of
roughly the same order of magnitude. It seems to be wasteful to have very
fast regulation when the reconstruction process is slow, and vice versa. In
particular, when there is a great deal of observation noise as compared to the
Staite excitation noise, the observer poles are relatively close to the origin
and the reconstruction process is slow. When we now make the regulator
just a little faster than the observer, it is to be expected that the regulator can
keep up with the observer. A further increase in the speed of the regulator will
merely increase the mean square input without decreasing the mean square
regulation error appreciably. On the other hand, when there is very little
observation noise, the limiting factor in the design will be the permissible
mean square input. This will constrain the speed of the regulator, and there
will be very little point in choosing an observer that is very much faster, even
though the noise conditions would permit it.
Example 5.3. Position control system.
Let us consider the position control system discussed in many previous
examples. Its state differential equation is
som (° 1 )aa+ (oo 0, 1 0
54
Here x(t) = col [&,(t), &(t)], with &,(t) the angular position and &,(t) the
angular velocity of the system. The input variable u(r) is the input voltage.
398 Optimal Linear Output Feedback Control Systems
The controlled variable is the position, hence is given by
€@) = Cd, 0)z@). 5-87
In Example 3.8 (Section 3.4.1), we solved the deterministic regulator problem
with the criterion
ty
| [°(t) + pu*(t)] dt. 5-88
With the numerical values .
k = 0.787 rad/(V s?),
a= 46s", 5-89
p = 0.00002 rad?/V?,
we found the steady-state feedback gain matrix
m5 (22364 015.09), 5-90
The steady-state solution of the regulator Riccati equation is given by
0.1098 0.005682
Brae ey 5-91
The closed-loop regulator poles are —9.66 + j9.09s~*. From Fig. 3.9
(Section 3.4.1), we know that the settling time of the system is of the order
of 0.3 s, while an initial deviation in the position of 0.1 rad causes an input
voltage with an initial peak value of 25 V.
In Example 4.4 (Section 4.3.2), we assumed that the system is disturbed
by anexternal torque on the shaft 7, (t). This results in the following modifica-
tion of the state differential equation:
wo=( '\o+(por( hun sm
OF 0 0
K
where 1!/y is the rotational moment of inertia of the rotating parts. It was
furthermore assumed that the observed variable is given by
n(t) = (1, O)e(t) + (1), 5-93
where ,,(¢) represents the observation noise. This expression implies that the
angular displacement is measured. Under the assumption that 7,(t) and
Y(t) are adequately represented as uncorrelated white noise processes with
intensities
V, = 10 N? m*s 5-94
and
Veale gadis; 5-95
5.3. Regulators with Incomplete and Noisy Measurements 399
respectively, we found in Example 4.4 that with y = 0.1 kg-! m- the steady-
state optimal observer is given by
; Ome 0
a(t) = i }eo 5 | Jue + K[n(t)— (1, 0)€@], 5-96
Se, K
where the steady-state gain matrix is
2 40.36
K= 5-97
814.3
The observer poles are —22.48 + j22.24s~1, while the steady-state variance
matrix is given by
0.04036 x 10% 0.8143 x 10-4
= 5-98
0.8143 x 10 36.61 x 10-4
With
u(t) = —Fé(t), 5-99
the steady-state optimal output feedback controller is described by
8 Oe ye ONE - P
x(t) = et) —{ JRE) + K[y() — U, 0],
ee ‘ 5-100
p(t) = — FE).
It follows that
lim E{C(t) + pur(t)} = tr (PRV,R® + GR,) = 0.00009080 rad?. 5-101
to7—o
From this result we find the following bounds on the steady-state rms tracking
error and rms input voltage:
lim JVE{C()} < ./0.00009080 ~ 0.0095 rad, 5-102a
to? —a2
lim E{py?(t)} < 0.00009080 rad’, 5-102b
so that fl,
lim J E{u(t)} < [eee a Pals Ve 5-103
to7—0
The exact values of the steady-state rms tracking error and rms input voltage
must be obtained by solving for the steady-state variance matrix of the
augmented state col [x(t), #(t)]. As outlined in the text (Section 5.3.2), this
is most efficiently done by first computing the steady-state variance matrix
diag (Q,,, Qe.) of col [e(t), #(t)], which requires only the solution of an
400 Optimal Linear Output Feedback Control Systems
additional 2 x 2 linear matrix equation. It can be found that the steady-
state variance matrix IT of col [x(t), £(t)] is given by
fi = & as Ons Aa
Ove Ors
0.00004562 0 0.00004158 —0.00008145
0 0.006119 — 0.00008 145 0.002458
- 0.00004158 —0.00008145 0.00004158 —0.00008145
—0.00008145 0.002458 —0.00008145 0.002458
5-104
This yields for the steady-state mean square tracking error
1
0
lim E{@()} = tr [fl 0 (1, 0, 0, 0)] = 0.00004562 rad*, 5-105
to>—2
0
so that the rms tracking error is ./0.00004562 ~ 0.00674 rad. We see that
this is somewhat less than the bound 5-102. Similarly, we obtain for the
mean square input voltage
0
lim E{p*(t)} = tr in( °,] (0, PF) S258 5-106
to? —@
so that the rms input voltage is about 1.5 V. It depends, of course, on the
specifications of the system whether or not this performance is satisfactory.
It is noted that the regulator poles (—9.66 + 79.09) and the observer
poles (—22.48 + j22.24) are of the same order of magnitude, which is a
desirable situation. Had we found that, for example, the observer poles are
very far away as compared to the regulator poles, we could have moved the
observer poles closer to the origin without appreciable loss in performance.
5.3.3* Proof of the Separation Principle
In this section we prove the separation principle as stated in Theorem 5.3
for the nonsingular uncorrelated case, that is, we assume that the intensity
V,(t) of the observation noise is positive-definite and that V,.(t) = 0 on
[to, t:]. It is relatively straightforward to prove that the solution as given is
the best /inear solution of the stochastic linear output feedback regulator
5.3. Regulators with Incomplete and Noisy Measurements 401
problem. Denoting
R,(t) = D7(t)R,(t) D(t), 5-107
we write
Elz"(t)Rg(t)2(t)]
= Elx(1)R,(t)2(0)]
= E{[x(t) — £(t) + £())7 RO) [x(t) — 4(1) + 2(H]}
= E{[x(t) — &(t)]*Ri(O[a(t) — 4()]}
+ 2E{[a(t) — &()]*R,Ha()} + EL€7OR (Hz). 5-108
Here £(¢) is the minimum mean square linear estimator of x(t) operating on
y(7) and u(r), t) < + < ¢. From optimal observer theory we know that
E{[x(t) — &(1)]* Ri) [x(t) — &()]} = tr [RDO], 5-109
where Q(t) is the variance matrix of the reconstruction error x(t) — &(t).
Furthermore,
E{[a(t) — €())]7R,(H4@)} = tr [E{[x(t) — £()47(H RD] = 0, 5-110
since as we have seen in Section 5.3.2 the quantities e(t) = a(t) — #(t) and
£(t) are uncorrelated. Thus we find that we can write
Efx(1)R,(t)e(t)} = tr [R,()O(1)] + E{47(OR(HA(},
5-111
E{a7(t,)P,2(t))} = tr [P,Q(t)] + E{&*(t,)P,4(t,)}.
Using 5-111, we write for the criterion 5-48:
B| [ “er ornaey + u?(t)Ro(t)u(t)] dt + eM 1,)PrA(n)|
0
+ tr [| me dt + P.O(H) | 5-112
We observe that the last two terms in this expression are independent of the
control applied to the system. Also from optimal observer theory, we know
that we can write (since by assumption the reconstruction problem is non-
singular)
#(t) = A(Ha(t) + BOu) + KDW) — CHA), 5-113
where K°(t) is the optimal gain matrix. However, in Section 4.3.6 we found
that the innovation process y(t) — C(t)#(t) is a white noise process with
intensity V(t). Then the problem of minimizing the criterion 5-112, with
the behavior of £(t) described by 5-113, is a stochastic linear regulator
problem where the complete state can be observed, such as described in Section
3.6.1. It follows from Theorem 3.9 that the optimal Jinear solution of
402 Optimal Linear Output Feedback Control Systems
this state feedback stochastic regulator problem is the linear control law
u(t) = —F°(t)£(0), 5-114
where F°(t) is given by 5-51.
This terminates the proof of Theorem 5.3 for the case where the recon-
struction problem is nonsingular and the state excitation and observation
noises are uncorrelated. The proof can be extended to the singular correlated
case.
5.4 LINEAR OPTIMAL TRACKING SYSTEMS WITH
INCOMPLETE AND NOISY MEASUREMENTS
In Section 3.6.2 we considered tracking problems as special cases of stochastic
state feedback regulator problems. Necessarily, we found control laws that
require that both the state of the plant and the state of the reference variable
are available. In this section we consider a similar problem, but it is assumed
that only certain linear combinations of the components of the state can be
measured, which moreover are contaminated with additive noise. We
furthermore assume that only the reference variable itself can be measured,
also contaminated with white noise.
We thus adopt the following model for the reference variable z,(t):
a(t) = D(a tt), 5-115
where
&,(t) = A,(t)x,(t) + w,(t). 5-116
In this expression w,, is white noise with intensity V,,(¢). It is furthermore
assumed that we observe
y,(t) = z(t) + w,o(t). 5-117
Here w,, is white noise with intensity V,o(t).
The system to be controlled is described by the state differential equation
a(t) = A(t)a(t) + B)u(t) + w(t), 5-118
where w, is white noise with intensity V,(t). The system has the controlled
variable
At) = D(a) 5-119
and the observed variable y(t) = C(t)x(t) + welt). 5-120
Here w, is white noise with intensity V,(t). We assume that V,.(t) > 0,
AG et eer
5.4 Tracking with Incomplete and Noisy Measurements 403
To obtain an optimization problem, we consider the criterion
al| Teo — z(t) R3(t)[e(t) — z,(t)] + u7()R(tu(t)] dt}. 5-121
Here R,(t) > 0, R(t) > 0, t9 < t < 4. The first term of the integrand serves
to force the controlled variable z(t) to follow the reference variable z,(t),
while the second term constrains the amplitudes of the input.
We now phrase the stochastic optimal tracking problem with incomplete
and noisy observations as follows.
Definition 5.2. Consider the system
“(t) = A(t)u(t) + B)u(t) + w(t), ben; 5-122
where x(t)) is a stochastic variable with mean %, and variance matrix Qo,
and w, is white noise with intensity V,(t). The controlled variable is
2(t) = D(t)x(t), 5-123
and the observed variable is
y(t) = C(t)x(t) + w(t), 5-124
where w, is white noise with intensity V(t), with V(t) >0, %<t<t.
Consider furthermore the reference variable
Z(t) = D(t)z,(0), 5-125
where
z,(t) = A,(t)z,(t) + w~a(d), 1 ie: 5-126
Here «,(to) is a stochastic variable with mean %,. and variance matrix Q,9,
and w,, is white noise with intensity V,,(t). The observed variable for the x,
process is y,(t) = C,(t)a,(t) + w,s(t), 5-127
where Wr: is white noise with intensity V,.(t) > 0, to <t<t,. Then the
optimal linear tracking problem with incomplete and noisy observations is the
problem of choosing the input to the system 5-122 as a function of y(r) and
y,(T), to <7 < t, such that the criterion
B| | ‘ [fe(t) — 2,(t)]* R(t) [e(t) — 2,()] + uw ()R.At)u(t)] a| 5-128
to
is minimized, where R;(t) > 0 and R(t) > 0 forts <t < ty.
To solve the problem we combine the reference model and the plant in an
augmented system. In terms of the augmented state 2(t) = col [z(¢), x,(0)],
we write
; A(t) 0 B(t) w(t)
H(t) = | }x + | Ju + | } 5-129
0: natn 0 W,a(t)
404 Optimal Linear Output Feedback Control Systems
The observed variable for the augmented system is
y(t) Cit) =O w(t) \
= | jx + } 5-130
y,(t) 0 C,@) W,o(t)
For the criterion we write
el | TO DM ORUDOAO + u7(t)R,(t)u(t)] ai), 5-131
where .
D(t) = [D(t), —D,(0)). 5132
The tracking problem is now in the form of a standard stochastic regulator
problem and can be solved by application of Theorem 5.3. It follows that we
can write
£(t)
u(t) = —F°(4) } 5-133
#,(t),
If we assume that all the white noise processes and initial values associated
with the plant and the reference process are uncorrelated, two separate
observers can be constructed, one for the state of the plant and one for the
state of the reference process. Furthermore, we know from Section 3.6.3
that because of the special structure of the tracking problem we can write
P@¢)=([FKi@), —F.(0)), 5-134
where the partitioning is consistent with the other partitionings, and where
the feedback gain matrix F,(t) is completely independent of the properties
of the reference process.
Figure 5.7 gives the block diagram of the optimal tracking system, still
under the assumption that two separate observers can be used. It is seen that
y, (t) observer
for
reference
observer
for
plant
controller
Fig. 5.7. The structure of the optimal tracking system.
5.4 Tracking with Incomplete and Noisy Measurements 405
the feedback link of the controller is completely independent of the properties
of the reference variable.
We conclude this section with an examination of the transmission 7(s)
of the system in the steady-state time-invariant case. A simple way to find
this transfer matrix is as follows. Set x(0) = 4(0) = 0, and assume that the
system is free of noise. It follows that a(t) = &(t) for t > 0. We can thus
completely omit the plant observer in the computation of 7(s) and substitute
a(t) wherever we find ¢(t). We thus have the following relations:
a(t) = Ax(t) + Bu(t),
2(t) = Dx(t), E e 5-135
u(t) = —F,a(t) + F,#,(2),
#(t) = A,t,(t) + R,ly,() — C,4,(0)].
It easily follows that
Z(s) = T(s)Y,(s), 5-136
where Z(s) and Y,(s) are the Laplace transforms of z(t) and y,(t), and where
T(s) = D(sI — A + BF,)"BF,(sI — A, + K,C,)1K,. 5-137
In general 7(0) does not equal the unit matrix, so that step changes in the
reference cause a steady-state error. The reason for this is that the present
control system has not been designed for steps in the reference variable.
If it is important that the control system have a zero steady-state error to
constant references, the design method suggested in the next section should
be adopted. We finally note that in the transmission only the regulator poles
and the reference observer poles occur, while the plant observer poles have
been canceled.
Example 5.4. Position servo
We return to the by now familiar positioning system. Consider the problem
of designing a control system such that the angular position tracks a reference
variable. For the system itself, the disturbances, and the observation noise
we use the equations and numerical data of Example 5.3 (Section 5.3.2). We
model the reference variable as exponentially correlated noise:
C(t) = €,(0), 5-138
with
E() = — 5&0 + Wald, 1 > th, 5-139
Here w,, is scalar white noise with constant intensity V,,. It is assumed that
the reference variable is observed with additive white noise, so that we
406 measure
Optimal Linear Output Feedback Control Systems
N,(t) = E(t) ae W,o(t), 5-140
where w’,» has constant intensity V,. and is uncorrelated with w,,. The steady-
state optimal observer for the reference process is easily computed. It is
described by
A a:
Syke) = Feuer E,(t) + K Ay,(t) a EO), 5-141
where
; ioe ee
LQ = an 5-142
i 6 +2 3
The optimization criterion is expressed as
ti
el [(o(t) — CDP + pu*(t)] at} 5.143
to
The resulting steady-state control law is given by
a(t) = —Fe() + Fé). 5-144
P,, and F, have been computed in Example 3.8 (Section 3.4.1), in which we
obtained the following results:
Nes fehee “e
Py =
VP P(—« + fet re =) 5-145
x:
K
Dagan gee)
Using the results of Section 3.6.3, it can be found that
| OIA
fo 5-146
= +3, are AG +4)
Since we now have the reference observer and the regulator gains available,
we can use 5-137 to calculate the transmission T(s) of the closed-loop tracking
5.4 Tracking with Incomplete and Noisy Measurements 407
system. We obtain
iS
1 S (2 i ta)"
Ga Vis —. 5.147
: x (- » va)"
OP Vee
We note that the break frequency of the transmission is the least of the break
frequency of the closed-loop plant and the break frequency of the reference
observer. The break frequency of the closed-loop plant is m), where w,? =
«x/./p, while the break frequency of the reference observer is
eae is
E =H ta) 5-148
ae Ves
Which break frequency is the lowest depends upon the ‘“‘signal-to-noise”’
ratio V,,/V,. of the reference variable and the value of p, which in turn is
determined by the allowable input amplitudes to the plant. Let us first
consider the effect of V,,/V,.. If the reference variable is accurately measured,
(i.e., V,9 is small) the reference observer break frequency is high and the
closed-loop feedback system break frequency will prevail. On the other
hand, if the reference variable is inaccurately measured, the reference
observer limits the total bandwidth of the system.
When we next consider the effect of the weighting factor p, we see that if
p is small, that is, large input amplitudes are allowed, the closed-loop system
break frequency is high and the reference observer determines the break
frequency. Conversely, if p is large, the break frequency is limited by the
closed-loop plant.
Let us assume the following numerical values for the reference process:
G== 5's;
ie r
i= OA rad?/s. 5-149
This makes the reference variable break frequency 0.2 rad/s, while the
reference variable rms value is | rad. Let us furthermore assume that the
reference variable measurement noise w,. is exponentially correlated noise
with rms value 0.181 rad and time constant 0.025 s. This makes the break
frequency of the reference variable measurement noise 40 rad/s. Since this
break frequency is quite high as compared to 0.2 rad/s, we approximate the
408 Optimal Linear Output Feedback Control Systems
measurement noise as white noise with density
V9 = 2(0.1)?0.0816 = 0.001636 rad?/s. 5-150
With the numerical values 5-149 and 5-150, we find for the reference observer
break frequency the value
1 A 1/2
le + va) ~ 15.6 rad/s. 5-151
mee
Since the break frequency of the reference observer is less than the break
frequency of 40 rad/s of the reference measurement noise, we conclude that it
is justified to approximate this measurement noise as white noise.
We finally must determine the most suitable value of the weighting factor
p. In order to do this, we evaluate the control law for various values of p
and compute the corresponding rms tracking errors and rms input voltages.
Omitting the disturbing torque 7, and the system measurement noise 7,,
we write for the system equations
#(t) = A(t) + but),
w(t) = —F,x(t) + FE,(0),
2 cea Repti HpaI
f,(t) ar 6 &,(t) oh K, [nt é,(t)], 5-152
EW) = = 580 + Wald.
A(t) = &(t) + W(t).
Combining all these relations we obtain the augmented differential equation
a(t) A — bF, bF, 0 a(t)
5 1 ve “
g 0 ti Ky K, oe t
Beas ; (0
: 1
E(t) 0 0 a 5,(t)
(oe
+ | K,w,.(t) ]. 5-153
Wya(t)
From this equation we can set up and solve the steady-state variance matrix
of the augmented state col [a(t), &,(t), &.(t)], and from this the Steady-state
rms tracking error and rms input voltage can be computed. Of course we can
also use the technique of Section 5.3.2. Table 5.1 lists the results for de-
creasing values of the weighting coefficient p. Note that the contributions
5.5 Nonzero Set Points and Constant Disturbances 469
of the reference excitation noise w,, and the reference measurement noise
W,2 are given separately, together with their total contribution.
If the maximally allowable input voltage is about 100 V, the weighting
coefficient p should certainly not be chosen less than 0.00001; for this value
the rms input voltage is nearly 50 V. The corresponding rms tracking error is
about 0.27 rad, which is still quite a large value as compared to the rms value
of the reference variable of | rad. If this rms value is too large, the require-
ments on the reference variable bandwidth must be lowered. It should be
remarked, however, that the values obtained for the rms tracking error and
the rms input are probably larger than the actual values encountered, since
modelling stochastic processes by exponentially correlated noise usually leads
to power spectral density functions that decrease much slower with increasing
frequency than actual density functions.
For p = 0.00001 it can be computed from 5-152 that the zero-frequency
transmission is given by 7(0) = 0.8338. This means that the proposed
control system shows a considerable steady-state error when subjected to a
constant reference variable. This phenomenon occurs, first, because exponen-
tially correlated noise has relatively much of its power at high frequencies
and, second, because the term that weights the input in the optimization
criterion tends to keep the input small, at the expense of the tracking accu-
racy. In the following section we discuss how tracking systems with a zero
steady-state error can be obtained.
The rms values given in Table 5.1 do not include the contributions of the
system disturbances and observation errors. Our findings in Example 5.3
suggest, however, that these contributions are negligible as compared to
those of the reference variable.
5.5 REGULATORS AND TRACKING SYSTEMS
WITH NONZERO SET POINTS AND
CONSTANT DISTURBANCES
5.5.1 Nonzero Set Points
As we saw in Chapter 2, sometimes it is important to design tracking systems
that show a zero steady-state error response to constant values of the reference
variable. The design method of the preceding section can never produce such
tracking systems, since the term in the optimization criterion that weights
the input always forces the input to a smaller value, at the expense of a
nonzero tracking error. For small weights on the input, the steady-state
tracking error decreases, but it never disappears completely. In this section
we approach the problem of obtaining a zero steady-state tracking error,
FF
88h 80°EC AO 7 08970 9900 96S7 0 10000'0
ere S18 P8'IC 9SSo'0 CLVO'O vCSe 0 T000°0
L9'0I 69°C ce Ol 0s6r'0 08720°0 tr6r'0 100°0
cry Vv $780 S9e'V £8890 Sz10'0 >889°0 10°0
ssr'l C7 0 ser I 07L8'0 8£00'0 07L8°0 10
ares at eee ee. Ss Ve aS SS ee a Pe en eee
(A) (A) (A) (pei) (ped) (pet) d
a3ei[0A yndut ade}{0A yndut ade]JOA Jol Suryoey = Joa BuLyORI} IOIO
SUI [B}OL SUII 0} 9sIOU yndur sui SUI [210.1 SUI 0} asIou BUIyOVI} SUI
JUST INSBOU 0} 9IQeIIVA yUdWOINSeOU 0} OIQeLIeA
QOUdIOJaI JO QOUdIOJOI JO QoudIajal JO goudIajar JO
uonnqiuod uolNgIyUOD uonngimuog uonnqimuod
WI}SKG OAIAS UOTJISOY 94} JO VdULULIOJI9g 9Y} UO d 1OJIBY SUNYSIOAA 94} JO JIAYY OUT «L's MqeL
410
5.5 Nonzero Set Points and Constant Disturbances 411
as in Section 3.7.1, from the point of view of a variable set point. Consider
the system
#(t) = Ax(t) + Bu(t) 5-154
with the controlled variable
2(t) = Dzx(t). 5-155
In Section 3.7.1 we derived the nonzero set point optimal control law
u(t) = —Fx(t) + Hz'(0)zp. F is the steady-state gain matrix for the criterion
5-156
| [27 (t)Rs2(t) + u7?(t)Rou(t)] dt, 5-157
to
while H,(s) is the closed-loop transfer matrix
H(s) = D(s] — A + BF)“B. 5-158
It is assumed that the dimension of wu equals that of z, and that the open-loop
transfer matrix H(s) = D(sJ — A)1B has no zeroes at the origin. These
assumptions guarantee the existence of H,'(0). Finally, z) is the set point
for the controlled variable. The control law 5-156 causes the control system
to reach the set point optimally from any initial state, and to make an optimal
transition to the new set point whenever z, changes.
Let us now consider a stochastic version of the nonzero set point regulator
problem. We assume that the plant is described by
x(t) = Ax(t) + Bu(t) + w,(t), 5-159
where w, is white noise. The controlled variable again is
Air Dart), 5-160
but we introduce an observed variable
y(t) = Ca(t) + w(t), 5-161
where w, is also white noise. Suppose that the set point 2, for the controlled
variable of this system is accurately known. Then the nonzero set point
steady-state optimal controller for this system obviously is
u(t) = —Fa(t) + H,"(0)zo,
&(t) = A(t) + Bu(t) + K[y(t) — C&(t)],
5-162where K is the steady-state optimal observer gain and where F and H,(s)
are as given before. If no state excitation noise and observation noise are
present, the controlled variable will eventually approach 2, as ¢ increases.
412 Optimal Linear Output Feedback Control Systems
The control law is optimal in the sense that the steady-state value of
E{z"(t)R32(t) + u*(t)Rou(t)} 5-163
is minimized, where z and w are taken relative to their set points. When the
set point changes, an optimal transition to the new set point is made.
The controller described by 5-162 may give quite good results when the
set point z) is a slowly varying quantity. Unsatisfactory results may be
obtained when the set point occasionally undergoes step changes. This may
result in the input having too large a transient, necessitating reduction in the
loop gain of the system. This in turn deteriorates the disturbance suppression
properties of the system. This difficulty can be remedied by interpreting quick
changes in the set point as “‘noise.’’ Thus we write the control law 5-162
in the form
u(t) = —F&(t) + H,*(0)4)(1), 5-164
where 4,(t) is the estimated set point. The observed set point, r(t), is rep-
resented as
r(t) = 2(t) + w,(t), 5-165
where w, is white noise and 2, is the actual set point. In order to determine
29(t) (compare Example 4.3, Section 4.3.2, on the estimation of a constant),
we model 2, as
Z(t) = wol(t), 5-166
where wy is another white noise process. The steady-state optimal observer
for the set point will be of the form
4,(t) = Ko[r(t) — 49(t)], 5-167
where K, is the appropriate steady-state observer gain matrix.
The controller defined by 5-164 and 5-167 has the property that, if no noise
is present and the observed set point r(t) is constant, the controlled variable
will in the steady state precisely equal r(t). This follows from 5-167, since in
the steady state 2,(¢) = r(t) so that in 5-164 Z,(t) is replaced with r(t), which
in turn causes z(t) to assume the value r(f). It is seen that in the case where
r, 2, u, and z are scalar the prefilter (see Fig. 5.8) defined by 5-164 and 5-167
is nothing but a first-order filter. In the multidimensional case a generaliza-
tion of this first-order filter is obtained. When the components of the un-
correlated white noise processes wy and w, are assumed to be uncorrelated
as well, it is easily seen that Rs diagonal, so that the prefilter consists
simply of a parallel bank of scalar first-order filters. It is suggested that the
time constants of these filters be determined on the basis of the desired
response to steps in the components of the reference variable and in relation
to likely step sizes and permissible input amplitudes.
5.5 Nonzero Set Points and Constant Disturbances 413
setpoint
observer
prefilter
]
|
!
:
|
|
plant
observer
control
low
Fig. 5.8. Nonzero set point optimal controller with set point observer.
Example 5.5. The positioning system
In Example 5.3 (Section 5.3.2), we found a zero set point optimal controller
for the positioning system. Let us determine the corresponding nonzero set
point control system. We first determine the nonzero set point optimal
control law. It follows from Example 3.8 (Section 3.4.1) that the closed-loop
transfer function H,(s) is given by
Ls) SSS 5-168
Consequently, the nonzero set point control law 5-164 is
w(t) = —Fa() + + 20, 5-169
Vp
where €,(t) is the estimated set point. Let us design for step changes in the
observed set point. The observer 5-167 for the set point is of the form
E(t) = kolr(t) — &()). 5-170
where r(t) is the reference variable and k, a scalar gain factor. Using the
numerical values of Example 5.3, we give in Fig. 5.9 the responses of the
nonzero set point control system defined by 5-169 and 5-170 to a step of |
rad in the reference variable r(t) for various values of the gain ky. Assuming
that an input voltage of up to 100 V is tolerable, we see that a suitable value
of ky is about 20s~!. The corresponding time constant of the prefilter is
1/ky = 0.05 s.
414 Optimal Linear Output Feedback Control Systems
angular
position
C(t)
(rad)
input
voltoge
u(t)
(V)
0.8
SSS)
Fig. 5.9. Responses of the position control system as nonzero set point control system
to a step in the set point of 1 rad for various values of the prefilter gain ko.
§.5.2* Constant Disturbances
In the preceding section we discussed nonzero set point regulators. In the
present section the question of constant disturbances is investigated, which is
somewhat similar to the nonzero set point problem. The approach presented
in this section is somewhat different from that in Section 3.7.2. As in Section
3.7.2, however, controllers with integrating action will be obtained.
Constant disturbances frequently occur in control problems. Often they
are caused by inaccuracies in determining consistent nominal values of the
input, the state, and the controlled variable. These disturbances can usually
be represented through an additional constant forcing term vp in the state
differential equation as follows:
a(t) = Ax(t) + Bu(t) + vp. 5-171
As in the preceding section, we limit our discussion to the time-invariant
case. For the controlled variable we write
2(t) = De2(t). 5-172
Let us assume, for the time being, that the complete state a(t) can be
5.5 Nonzero Set Points and Constant Disturbances 415
observed at all times. Then we can consider the control law
u(t) = —Fa(t) + uy, 5-173
where F is a gain matrix selected according to some quadratic optimization
criterion of the usual form and where the constant vector uy is to be chosen
such that in steady-state conditions the contribution of the constant dis-
turbance v, to the controlled variable z is canceled.
With the control law 5-173, the closed-loop system equations are
a(t) = (A — BF)x(t) + Buy + vp,
2(t) = Da(t). 5-174
Since the closed-loop system will be assumed to be asymptotically stable, the
controlled variable eventually approaches a constant value, which is easily
seen to be given by |
lim z(t) = D(—A)“*Buy + D(—A) "np. 5-175
t— 00
Here we have abbreviated
A=A— BF. 5-176
Does there exist a uy such that the steady-state value of z(t) as given by
5-175 is zero? As in the nonzero set point problem, three cases must be
distinguished :
(a) The dimension of z is greater than that of u: In this case the vector
equation
D(—A)“Bu, + D(—A)>n, = 0 5-177
represents more equations than there are variables, which means that in
general no solution exists. This is the case where it is attempted to control
the variable z(t) with an input u(t) of smaller dimension and too few degrees
of freedom are available.
(b) The dimensions of u and z are the same: In this case 5-177 can be solved
for uy as follows:
uy = —H,'(0)D(—A) ‘up. 5-178
Here H,(s) is the closed-loop transfer matrix
H,(s) = D(sI — A — BF)“B. 5-179
As we know from Theorem 3.10 (Section 3.7), the inverse of H,(0) exists if
the open-loop system transfer matrix D(s! — A)'B has no zeroes at the
origin.
416 Optimal Linear Output Feedback Control Systems
(c) The dimension of z is less than that of u: In this case there are too many
degrees of freedom and the dimension of z can be increased by adding com-
ponents to the controlled variable.
In case (b), where dim (z) = dim (u), the control law
u(t) = —Fx(t) — H7'(0)D(—A) ‘v9 5-180
has the property that constant disturbances are compensated in an optimal
manner. This control law, which has been given by Eklund (1969), will be
referred to as the zero-steady-state-error optimal control law. As we have
seen, it exists when dim (z) = dim (wu) and the open-loop system has no
zeroes at the origin.
Let us now suppose that in addition to v, fluctuating disturbances act upon
the system as well, and that the system state can only be incompletely and
inaccurately observed. We thus replace the state differential equation with
a(t) = Ax(t) + Bu(t) + vp + wilt), 5-181
where vy is the constant disturbance and w, white noise with intensity Vj.
Furthermore, we assume that we have for the observed variable
y(t) = Cx(t) + w(t), 5-182
where w, is white noise with intensity V5.
In this situation the control law 5-180 must be replaced by
u(t) = —F&(t) — Hz*(0)D(—A)“é, 5-183
where #(t) and o) are the minimum mean square estimates of x(t) and vp.
An optimal observer can be obtained by modeling the constant disturbance
through
Uo(t) = 0. 5-184
The resulting steady-state optimal observer, however, will have a zero gain
matrix for updating the estimate of vo, since according to the model 5-184
the value of vy never changes (compare Example 4.3, Section 4.3.2, concern-
ing the estimation of a constant). Since in practice v varies slowly, or
occasionally changes value, it is better to model vy through
Dif) =a, (2), 5-185
where the intensity V) of the white noise wy» is so chosen that the increase in
the fluctuations of vo reflects the likely variations in the slowly varying
disturbance. When this model is used, the resulting steady-state optimal
observer continues to track v,(t) and is of the form
&(t) = A&(t) + Bu(t) + f(t) + Kily() — C&D),
. 5-186
iy(t) = Ky[y(t) — C&(t)].
5.5 Nonzero Set Points and Constant Disturbances 417
The control system that results from combining this observer with the
control law 5-183 has the property that in the absence of other disturbances
and observation noise the constant disturbance is always compensated so
that a zero steady-state regulation or tracking error results (Eklund, 1969).
As expected, this is achieved by “‘integrating action’’ of the controller (see
Problem 2.3). The procedure of this section enables us to introduce this
integrating action and at the same time improve the transient response of the
control system and the suppression of fluctuating disturbances. The procedure
is equally easily applied to multivariable as to single-input single-output
systems.
It is not difficult to see that the procedure of this section can be combined
with that of Section 5.5.1 when encountering tracking or regulating systems
subject to nonzero set points as well as constant disturbances, by choosing
the input as
u(t) = —F£(t) — H,"(0)D(—A) “by + Hz'(0)%p. 5-187
Here 2, is either the estimated set point and can be obtained as described in
Section 5.5.1, or is the actual set point.
We remark that often is it is possible to trace back the constant disturb-
ances to one or two sources. In such a case we can replace v, with
Vo = G0, 5-188
where G is a given matrix and v, a constant disturbance of a smaller dimen-
sion than vp. By modeling v, as integrated white noise, the dimension of the
observer can be considerably decreased in this manner.
Example 5.6. Integral control of the positioning system
In this example we devise an integral control system for the positioning
system. We assume that a constant disturbance can enter into the system in
the form of a constant torque 7) on the shaft in addition to a disturbing
torque tT, which varies quickly. Thus we modify the state differential equation
5-92 of Example 5.3 (Section 5.3.2) to
Onnaall 0 0 0
a(t) = | jo | Ju =F ( Juco + | )re 5-189
0 16.4 K y y
As in Example 5.3, we represent the variable part of the disturbing torque
as white noise with intensity V,.
It is easily seen from 5-189 that the zero-steady-state-error optimal control
law is given by
Hiv Srey es, 5-190
K
418 Optimal Linear Output Feedback Control Systems
where F is an appropriate steady-state optimal feedback gain matrix, and 7
is an estimate of 7».
To obtain an observer we model the constant part of the disturbance as
T(t) = Wot), 5-191
where the white noise w, has intensity Vy). As in Example 5.3, the observed
variable is given by
y(t) = (1, O)a(t) + »,,(2), 5-192
where »,, is white noise with intensity V,,. The steady-state optimal observer
thus has the form
. 0 Iie 0 0 ky ’
&(t) = AO) +{ JoO+ | JAO+ (_ Jn — 0,0),
Vir: K y ky
F(t) = Ks[n(t) — (1, 0)€@],
5-193
where the scalar gains k,, k,, and k, follow from the steady-state solution of
the appropriate observer Riccati equation. With the numerical values of
Example 5.3, and with the additional numerical value
Vy ='60.N? m? 5-4, 5-194
it follows that these gains are given by
ky = 42,74, ke 91322, k, = 24495. 5-195
The assumption 5-194 implies that the rms value of the increment of 7»
during a period of 1 s is 60 ~ 7.75 Nm. This torque is equivalent to an
ongulor
displacement
ey 0.005
(rad)
0 jesse
0 } 2
¢{ ———_» (s)
input 0 1 2
voltage ’
rv ee
(V)
Fig. 5.10. Response of the zero steady-state error position control system to a constant
torque of 10 N m on the shaft.
5.6 Sensitivity 419
input voltage of nearly 1 V. The observer poles corresponding to the gains
5-195 are —22.44 4+ j22.27 and —2.450 s-1.
By substituting the control law 5-190 into the observer equations 5-193,
it is easily found that the controller has a pole at the origin, hence exhibit
integrating action, as expected. For F we choose the steady-state optimal gain
matrix 5-90 derived in Example 5.3. The corresponding regulator poles are
—9.66 + j9.09 s+. In Fig. 5.10 we give the response of the control system
from zero initial conditions to a constant disturbance 7, = 10 Nm. It is
seen that the maximum deviation of the angular displacement caused by this
constant torque is not more than about 0.008 rad.
5.6* SENSITIVITY OF TIME-INVARIANT OPTIMAL
LINEAR OUTPUT FEEDBACK CONTROL
SYSTEMS
In Chapter 3, Section 3.9, we saw that time-invariant linear optimal state
feedback systems are insensitive to disturbances and parameter variations
in the sense that the return difference matrix J(s), obtained by opening the
feedback loop at the state, satisfies an inequality of the form
J?(—jo)WJ(jw) > W, for all real «, 5-196
where W is the weighting matrix F’R,F.
In this section we see that optimal output feedback systems generally do
not possess such a property, although it can be closely approximated.
Consider the time-invariant system
a(t) = Ax(t) + Bu(t) + w,(t), 5-197
where w, is white noise with constant intensity V,. The observed variable is
given by
y(t) = Ca(t) + w(t), 5-198
where w, is white noise uncorrelated with w, with constant intensity Vo.
The controlled variable is
Oe Dali 5-199
while the optimization criterion is specified as
ty e( | [27(t)Raz(t) + u7(t)Reu(t)] dt}, to
5-200
with R, and R, symmetric, constant, positive-definite weighting matrices.
To simplify the analysis, we assume that the controlled variable is also the
observed variable (apart from the observation noise), that is, C = D. Then
420 Optimal Linear Output Feedback Control Systems
controller
Fig. 5.11. Simplified output feedback control configuration.
we can schematically represent the control configuration as in Fig. 5.11,
where observer and control law have been combined into the controller.
Let us now consider the steady-state controller that results by letting tg ~ — oo
and t, — oo. Then the steady-state observer is described by
a(t) = A&(t) + Bu(t) + R[y(t) — D&(d), 5-201
where K is the steady-state observer gain matrix. Laplace transformation of
5-201 and solution for the transform X(s) of £(t) yields
X(s) = (sI — A + RD)>[BU(s) + RY(s)], 5-202
where U(s) and Y¥(s) are the Laplace transforms of u(t) and y(t), respectively.
All initial conditions are assumed to be zero. For the input we have in terms
of Laplace transforms
U(s) = —FX(s), 5-203
where F is the steady-state feedback gain matrix. Substitution of 5-203 into
5-202 and solution for U(s) yields
U(s) = —G(s)Y(s), 5-204
where
G(s) = [I+ F(sI — A + KD)? B}'F(s] — A+ KD)>R. 5-205
We now consider the return difference matrix
J(s) = I+ H(s)G(s) 5-206
for the control system, where
H(s) = D(sI — A)>B 5-207
5.6 Sensitivity 421
is the plant transfer matrix. Generally, there does not exist a nonnegative-
definite weighting matrix W such that an inequality of the form
J7(—jo)WJ(jo) > W 5-208
is satisfied for all real frequencies w. Indeed, it can easily be proved (see
Problem 5.6) that in the single-input single-output case 5-208 is never satisfied
for all when W > 0. Of course the inequality 5-208 must hold in some useful
frequency range, adapted to the frequency band of the disturbances acting
upon the plant, since it follows from the optimality of the controller that the
specific disturbances for which the control system has been designed are
attenuated.
We now prove, however, that under certain conditions satisfaction of
5-208 for all frequencies can be obtained asymptotically. Consider the
algebraic Riccati equation
0 = D?R,D — PBR, *B'P + AtP + PA, 5-209
which must be solved to obtain the regulation gain F = R,'B*P. Suppose
that
R, = pN, 5-210
where p is a positive scalar and N a positive-definite matrix. Then it follows
from Theorem 3.14 (Section 3.8.3) that if dim (z) = dim (uw), and the open-
loop transfer matrix H(s) = D(s! — A)*B has zeroes with nonpositive
real parts only, as p | 0 the desired solution P of 5-209 approaches the zero
matrix. This implies that
lim PB e N ‘1B? P = D?R;D, po p
5-211
or
lim pF7NF = DTR,D. 5-212
pto
Now the general solution of the matrix equation X’X¥ = MM, where X
and M have equal dimensions, can be written in the form XY = UM, where U
is an arbitrary unitary matrix, that is, U satisfies U"U = J. We therefore
conclude from 5-212 that as p | 0 the gain matrix F asymptotically behaves as
os Nee UR: 5-213
p
As a result,
G(s) > [D@I — A+ KD)7ABP DI — A+ RD) RK, 5-214
422 Optimal Linear Output Feedback Control Systems
as p | 0. It is not difficult to prove that
[D(sI — A + KD)“B]"*D(sI — A+ KD)1K
= [D(sI — A) B}1D(sI — A) 1K. 5-215
With this it follows for the return difference matrix J(s) of the configuration
of Fig. 5.11 that as R, ~ 0
J(s) + Jy(s), 5-216
where
J,\(s) = I+ D(sI — A) K. 5-217
We now derive an inequality for the asymptotic return difference matrix Jo(s).
The steady-state variance matrix Q satisfies the algebraic Riccati equation
0=V,— ODTVz'DO + AO + OA, 5-218
assuming that the state excitation noise and observation noise are un-
correlated, that V, > 0, and that the Riccati differential equation possesses a
steady-state solution. We can now go through manipulations very similar to
those in Section 3.9, where we dealt with the sensitivity of the state
feedback regulator. Addition and subtraction of s@ and rearrangement yield
0=V,— OD*Vz"DO — (sI — A)O — O(—sI — A*). 5-219
Premultiplication by D(sIJ — A)~4 and postmultiplication by (—sJ — A*)1D™
give
0 = D(sI — A)"(V, — OD*Vz"DO)(—sI — AT)*DT
— DQ(—sI — At) *D® — D(sI — A) 'OD*. 5-220
By adding and subtracting an extra term V3, this expression can be rearranged
into the form
[I + D(sI — A)" ODTV,;"]V.[I + Vy'DO(—sI — AT) *D*]
= V, + D(sI — A)"'V,(—sI — AT)"*D*t. 5-221
Since OD" V,~" = RK we immediately recognize that this expression implies
the equality
Jo(5) Vado" (—38) = Ve + Dsl — A) 71V,(—SI — A*)4D*, +5222
Substituting s = jw we see that the second term on the right-hand side is a
nonnegative-definite Hermitian matrix; thus we have
Jo(J@)Velo?(—jo) > Vz for all real w. 5-223
It follows from Theorem 2.2 (Section 2.10) that
So (—J@)Vs Sx jo) < V5 for areal o, 5-224
5.6 Sensitivity 423
where S)(s) is the asymptotic sensitivity matrix:
Sy(S) == Jy (8): 5-225
We also have
Joi (—jo Vz Jojo) > Va".
We thus have the following result (Kwakernaak, 1969).
Theorem 5.5. Consider the steady-state time-invariant stochastic optimal
output feedback regulator. Suppose that the observed variable is also the
controlled variable, that is,
y(t) = Dx(t) + w,(t),
2(t) = Dz(t). 5-226
Also assume that the state excitation noise w,(t) and the observation noise
w2(t) are uncorrelated, that the observation problem is nonsingular, that is,
V2 > 0, and that the steady-state output feedback regulator is asymptotically
stable. Then if dim (u) = dim (z), and the open-loop transfer matrix H(s) =
D(sI — A)*B possesses no right-half plane zeroes, the return difference
matrix of the closed-loop system asymptotically approaches J,(s) as R, > 0,
where
J)(s) = 1+ D(sI — A)71K. 5-227
K is the steady-state observer gain matrix. The asymptotic return difference
matrix satisfies the relation
JS) Vad og" (—s) = Ve + Dist — AYV(—sI — AT)" D*... 5-228
The asymptotic return difference matrix J,(s) and its inverse, the asymptotic
sensitivity matrix S)(s) = J, “(s), satisfy the inequalities
Jo(jo)V2I 97 (—jw) > Vo for all real w,
So? (—jo)Ve S(jo)< Vs, for all real o, 5-229
Ie (F=jOVa J JO) Sa Ve for all real w.
This theorem shows that asymptotically the sensitivity matrix of the output
feedback regulator system satisfies an inequality of the form 5-196, which
means that in the asymptotic control system disturbances are always reduced
as compared to the open-loop steady-state equivalent control system no
matter what the power spectral density matrix of the disturbances. It also
means that the asymptotic control system reduces the effect of all (sufficiently
small) plant variations as compared to the open-loop steady-state equivalent
The following points are worth noting:
(i) The weighting matrix in the sensitivity criterion is V,*. This is not
surprising. Let us assume for simplicity that V, is diagonal. Then if one of the
424 Optimal Linear Output Feedback Control Systems
diagonal elements of V, is small, the corresponding component of the
observed variable can be accurately measured, which means that the gain in
the corresponding feedback loop can be allowed to be large. This will have a
favorable effect on the suppression of disturbances and plant variations at
this output, which in turn is reflected by a large weighting coefficient in the
sensitivity criterion.
(ii) The theorem is not valid for systems that possess open-loop zeroes
in the right-half plane.
(iii) In practical cases it is never possible to choose R, very small. This
means that the sensitivity criterion is violated over a certain frequency range.
Examples show that this is usually the case in the high-frequency region. It is
to be expected that the sensitivity reduction is not spoiled too badly when
R, is chosen so small that the faraway regulator poles are much further away
from the origin than the observer poles.
(iv) The right-hand side of 5-228 can be evaluated directly without
solving Riccati equations. It can be used to determine the behavior of the
return difference matrix, in particular in the single-input single-output case.
(v) It can be shown (Kwakernaak, 1969), that a result similar to Theorem
5.5 holds when
D
ut) = | Jno + w,(f), M
5-230
that is, y(t) includes the controlled variable z(f).
Example 5.7. Position control system
Again we consider the positioning system described by the state differential
equation
0 | 0 0
0 x(t) + )ue + | }rao. 5-231
0 -«a K y
Here 7,(t) is white noise with intensity V,. The observed variable is
y(t) = (1, O)a(t) + »,,(0), 5-232
where y,,,(t) is white noise with intensity V,,. The controlled variable is
L(t) = CF Ojz@): 5-233
The system satisfies the assumptions of Theorem 5.5, since the controlled
variable is the observed variable, the state excitation and observation noise
are assumed to be uncorrelated, and the open-loop transfer function,
H(s) 5-234
Bre ee ahs
5.6 Sensitivity 425
possesses no right-half plane zeroes. To compute the asymptotic return
difference Jo(s), we evaluate 5-228, which easily yields
Jo(s)Jo(—s) = 1+
ValVin
(9)Jo(=s) a ae rie
4 2.2 2
a8 oe ey ValVin 5-235
—s*(—s*? + a”)
Substitution of s = jw provides us with the relation
4 Pie ed 2
|Jo(jo)|" — a2) Le aw oy ue Val Vin wo (a + «”)
5-236
or
ere) ee eo'(w" + a")
yO) |e eer gece werennane”, ; 5-237
wo + avo + vVa/lVin
which shows that |So(jw)| < 1 for all real w.
0.1
0.01
Fig. 5.12. Asymptotic Bode plots of the sensitivity function of the position control system
for p = 0 and p= 0.5 x 107°.
Figure 5.12 gives an asymptotic Bode plot of |S(ja)| which shows that the
limiting controller provides protection against all disturbances and param-
eter variations up to a frequency of about (y?V,/V,,,)'/*. With the numerical
values
yO. Ket mn,
Vo = 1ON* im? s; ee Omer ders.
™
5-238
this break frequency is about 31.6 rad/s.
426 Optimal Linear Output Feedback Control Systems
The frequency range over which disturbance protection is obtained is
reduced when the weighting factor p in the criterion
E| I (eo + py(t)] a 5-239
is chosen greater than zero. It is reasonable to assume that the disturbance
reduction is not affected so long as the regulator break frequency is much
larger than the observer break frequency. Since the regulator break frequency
(Example 5.3, Section 5.3.2) is (x// py”, we conclude that with x = 0.787
rad/(Vs?) the value of p should be 0.5 x 10-® or less (for this value of p
the regulator break frequency is 33.4 rad/s). It can be computed, using
Theorem 5.4 (Section 5.3.2), that with this value of p we have
lim E{7(t) + py?(t)} = 0.00001906 rad’. 5-240
t> 2
It follows that the rms input voltage is bounded by
VEU} < | OOOO et TV. 5.241
p
which is quite an acceptable value when input amplitudes of up to 100 V are
permissible. It can be calculated that the sensitivity function of the steady-
state controller for this value of p is given by
soe s(s + 4.6)(s* + 1s + 3859) 5-242
(s* + 47.5s + 1125)(s” + 44.96s + 1000)
The asymptotic Bode plot of |S(jw)| is given in Fig. 5.12 as well and is
compared to the plot for p = 0. It is seen that the disturbance attenuation
cutoff frequency is shifted from about 30 to about 20 rad/s, while disturbances
in the frequency range near 30 rad/s are slightly amplified instead of atten-
uated. By making p smaller than 0.5 x 10~*, the asymptotic sensitivity
function can be more closely approximated.
Using the methods of Section 5.5.1, it is easy to determine the nonzero set
point optimal controller for this system. Figure 5.13 gives the response of the
resulting nonzero set point output feedback control system to a step of
0.1 rad in the set point of the angular position, from zero initial conditions,
for the nominal parameter values, and for two sets of off-nominal values.
As in Example 3.25 (Section 3.9), the off-nominal values of the plant con-
stants « and « are assumed to be caused by changes in the inertial load of the
dc motor. It is seen that the effect of the parameter changes is moderate.
5.7 Controllers of Reduced Dimensions 427
Position
ee wg
(rad)
0 0.2 0.4
t ——»(s)
Fig. 5.13. The effect of parameter variations on the response of the output feedback
position control system. (a) Nominal load; (6) inertial load 2 of nominal; (c) inertial load
2 of nominal.
5.7* LINEAR OPTIMAL OUTPUT FEEDBACK
CONTROLLERS OF REDUCED DIMENSIONS
5.7.1* Introduction
In Section 5.3.1 we obtained the solution of the stochastic linear optimal
output feedback regulator problem. It is immediately clear that the dimension
of the controller by itself equals the dimension of the plant, since the optimal
observer has the dimension of the plant. This may be a severe drawback of the
design methods suggested, since in some cases a controller of much lower
dimension would render quite satisfactory, although not optimal, perfor-
mance. Moreover, the dimension of the mathematical model of a system is a
number that very much depends on the accuracy of the model. The model
may incorporate some marginal effects that drastically increase the dimension
of the model without much improvement in the accuracy of the model.
When this is the case, there seems to be no reason why the dimension of the
controller should also be increased.
Motivated by the fact that the complexity and cost of the controller
increase with its dimension, we intend to investigate in this section methods
for obtaining controllers of lower dimensions than those prescribed by the
methods of Section 5.3. One obvious way to approach the problem of
designing controllers of low dimension is to describe the plant by a cruder
mathematical model, of lower dimension. Methods are available (see e.g.,
Mitra, 1967; Chen and Shieh, 1968b; Davison, 1968a; Aoki, 1968; Kuppura-
julu and Elangovan, 1970; Fossard, 1970; Chidambara and Schainker, 1971)
for reducing the dimension of the model while retaining only the “significant
428 Optimal Linear Output Feedback Control Systems
modes”’ of the model. In this case the methods of Section 5.3 result in con-
trollers of lower dimension. There are instances, however, in which it is
not easy to achieve a reduction of the dimension of the plant. There are also
situations where dimension reduction by neglecting the “‘parasitic’’ effects
leads to the design of a controller that makes the actual control system un-
stable (Sannuti and Kokotovic¢, 1969).
Our approach to the problem of designing low-dimensional controllers is
therefore as follows. We use mathematical models for the systems which are
as accurate as possible, without hesitating to include marginal effects that
may or may not have significance. However we limit the dimension of the
controller to some fixed number m, less than n, where n is the dimension of
the plant model. In fact, we attempt to select the smallest m that still produces
a satisfactory control system. We feel that this method is more dependable
than that of reducing the dimension of the plant. This approach was origin-
ally suggested by Newton, Gould, and Kaiser (1957), and was further
pursued by Sage and Eisenberg (1966), Sims and Melsa (1970), Johnson
and Athans (1970), and others.
5.7.2* Controllers of Reduced Dimensions
Consider the system described by the equations
#(t) = A()x(t) + BYU) + wi, Ut) = Xo,
5-243
y(t) = CMax(t) + walt),
where, as usual, x(t) is an n-dimensional state vector, u(t) is a k-dimensional
input variable, y(t) is an /-dimensional observed variable, and w, and w,
are white noise processes. The joint process col (w,, w,) has the intensity V(t).
It is furthermore assumed that the initial state x) is a stochastic vector,
uncorrelated with w, and wy, with mean #y and variance matrix Qp.
We now consider a controller for the system given above described by
q(t) = Li{t)q(t) + K(y(t), (to) = 4,
5-244u(t) = —F(t)q(?),
where q is the m-dimensional state vector of the controller. The observed
variable y serves as input to the controller, and the input to the plant w is the
output of the controller. It is noted that we do not allow a direct link in the
controller. The reason is that a direct link causes the white observation noise
w, to penetrate directly into the input variable u, which results in infinite
input amplitudes since white noise has infinite amplitudes.
We are now in a position to formulate the linear optimal output feedback
control problem for controllers of reduced dimensions (Kwakernaak and
Sivan, 1971a):
5.7 Controllers of Reduced Dimensions 429
Definition 5.3. Consider the system 5-243 with the statistical data given.
Then the optimal output feedback control problem for a controller of reduced
dimension is to find, for a given integer m, with 1 <m <n, and a given final
time t,, matrix functions L(t), K(t), and F(t), t) < t < t,, and the probability
distribution of qo, so as to minimize o,,, where
Om = elf eR a0 + u7(t)R,(t)u(t)] dt}. 5-245
Here R(t) and R,(t), th <t <t,, are given matrices, nonnegative-definite
and positive-definite, respectively, for all t.
In the special case in which m = n, the solution to this problem follows from
Theorem 5.3 which states that F(t) and K(f) in 5-244 are the optimal regulator
and observer gains, respectively, and
L(t) = A(t) — B(t)F(t) — K(t)C(t). 5-246
It is easy to recognize that o,,, m= 1,2,--:, forms a monotonically
nonincreasing sequence of numbers, that is,
OR, Sy SO SP oO Sy 5-247
since an m-dimensional controller is a special case of an (m + 1)-dimensional
controller. Also, for m > n the value of o,, no longer decreases, since we
know from Theorem 5.3 that the optimal controller (without restriction on
its dimension) has the dimension n; thus we have
Op S03 209 S08 2 Ons Sn = Say = Ong = 5-248
One way to approach the problem of Definition 5.3 is to convert it to a
deterministic dynamic optimization problem. This can be done as follows.
Let us combine the plant equation 5-243 with the controller equation 5-244.
The control system is then described by the augmented state differential
equation
(“0 A(t) seeealie) i " 0 \("")
‘ola K()C(t) ~— L(t) q(t) 0 K(t)/\w.(t))
5-249
We now introduce the second-order joint moment matrix
x(t) ; ia
S(t) = {( a(t), 0) q(t)
5-250
430 Optimal Linear Output Feedback Control Systems
It follows from Theorem 1.52 (Section 1.11.2) that S(t) is the solution of the
matrix differential equation
SW) = M(NS(D) + SCOM7(D) + NQVONT (0, fa
S(to) = So,
where
( A(t) ea) f i
M(t) = , ND=
K(t)C(t) L(t) On KD’
fees ee
Sy 8
dJoXo- God
Using the matrix function S(t), the criterion 5-245 can be rewritten in the form
Om = tr [[, tsucorcn + S2o(t)F 7(1)Ro(t)F(t)] ai 5-253
where S,,(t) and S(t) are the n x n and m x m diagonal blocks of S(t),
respectively.
The problem of determining the optimal behaviors of the matrix functions
L(t), F(t), and K(t) and the probability distribution of g, has now been
reduced to the problem of choosing these matrix functions and S, such that
Om as given by 5-253 is minimized, where the matrix function S(t) follows
from 5-251. Application of dynamic optimization techniques to this problem
(Sims and Melsa, 1970) results in a two-point boundary value problem for
nonlinear matrix differential equations; this problem can be quite formidable
from a computational point of view.
In order to simplify the problem, we now confine ourselves to time-
invariant systems and formulate a steady-state version of the problem that
is numerically more tractable and, moreover, is more easily implemented.
Let us thus assume that the matrices A, B, C, V, R,, and R, are constant.
Furthermore, we also restrict the choice of controller to time-invariant
controllers with constant matrices L, K, and F. Assuming that the inter-
connection of plant and controller is asymptotically stable, the limit
6, = lim E{x"(t)R,x(t) + u*(t)Rou(t)} 5-254
to>—o
will exist. As before, the subscript m refers to the dimension of the controller.
We now consider the problem of choosing the constant matrices L, K, and F
(of prescribed dimensions) such that G,, is minimized.
As before, we can argue that
Oy 2 Og 20g 2 SP On 2 Og SS Ons One 5-255
The minimal value that can ever be obtained is achieved for m =n, since
as we know from Theorem 5.4 (Section 5.3.2) the criterion 5-254 is minimized
5.7 Controllers of Reduced Dimensions 431
by the interconnection of the steady-state optimal observer with the steady-
state optimal control law.
The problem of minimizing 5-254 with respect to L, K, and F can be
converted into a mathematical programming problem as follows. Since by
assumption the closed-loop control system is asymptotically stable, that is,
the constant matrix M has all its characteristic values strictly within the left-
half complex plane, as t, - — oo the variance matrix S(t) of the augmented
state approaches a constant steady-state value S that is the unique solution
of the linear matrix equation
MS + SM? + NVN7 = 0. 5-256
Also, 6, can be expressed as
Or, He CSigy + Sash Rot); 5-257
where S,, and S;, are then x nandm x m diagonal blocks of S, respectively.
Thus the problem of solving the steady-state version of the linear time-
invariant optimal feedback control problem for controllers of reduced
dimension is reduced to determining constant matrices L, K, and F of
prescribed dimensions that minimize
on = ir OSS, + Soaf" R3F), 5-258
and satisfy the constraints
(i) MS + SM? + NVN?t = 0, 5-259a
(ii) Re [A,(M)] < 0, bee et te ae 5-259b
Here the 1,(M), i = 1,2,---, + m, denote the characteristic values of the
matrix M, and Re stands for “the real part of.”’
It is noted that the problem of finding time-varying matrices L(t), K(t),
and F(t), tg < ¢ < 4, that minimize the criterion o,, always has a solution as
long as the matrix A(f) is continuous, and all other matrices occurring in the
problem formulation are piecewise continuous. The steady-state version of
the problem, however, that is, the problem of minimizing o,, with respect
to the constant matrices L, K, and F, has a solution only if for the given
dimension m of the controller there exist matrices L, K, and F such that the
compound matrix M is asymptotically stable. For m =n necessary and
sufficient conditions on the matrices A, B, and C so that there exist matrices
L, K, and F that render M asymptotically stable are that {A, B} be stabilizable
and {A, C} detectable (Section 5.2.2). For m <n such conditions are not
known, although it is known what is the least dimension of the controller
such that all closed-loop poles can be arbitrarily assigned (see, e.g., Brash
and Pearson, 1970).
432 Optimal Linear Output Feedback Control Systems
In the following subsection some guidelines for the numerical determina-
tion of the matrices L, K, and F are given. We conclude this section with a
note on the selection of the proper dimension of the controller. Assume that
for given R, and R, the optimization problem has been solved for m =
1,2,--:+,n, and that 6,, G,,°--,6, have been computed. Is it really mean-
ingful to compare the values of 6), 6,,°**,G,, and thus decide upon the
most desirable of m as the number that gives a sufficiently small value of
G,,2 The answer is that this is probably not meaningful since the designs
all have different mean square inputs. The maximally allowable mean square
input, however, is a prescribed number, which is not related to the complexity
of the controller selected. Therefore, a more meaningful comparison results
when for each m the weighting matrix R, is so adjusted that the maximally
allowable mean square input is obtained. This can be achieved by letting
R, = PmRoo, 5-260
where p,, iS a positive scalar and Ryo a positive-definite weighting matrix
which determines the relative importance of the components of the input.
Then we rephrase our problem as follows. For given m, R,, and Ry», minimize
the criterion a ns
Oe= tr(SGRi kK pSek Ra 5-261
with respect to the constant matrices L, K, and F, subject to the constraints
(1) and (ii), where p,, is so chosen that
tr (Sas Risk) 5-262
equals the given maximally allowable mean square input.
5.7.3* Numerical Determination of Optimal Controllers of
Reduced Dimensions
In this section some results are given that are useful in obtaining an efficient
computer program for the solution of the steady-state version of the linear
time-invariant optimal output feedback control problem for a controller of
reduced dimension as outlined in the preceding subsection. In particular, we
describe a method for computing the gradient of the objective function
(in this case 6,,) with respect to the unknown parameters (in this case the
entries of the matrices L, K, and F). This gradient can be used in any standard
function minimization algorithm employing gradients, such as the conjugate
gradient method or the Powell-Fletcher technique [see, e.g., Pierre (1969)
or Beveridge and Schechter (1970) for extensive reviews of unconstrained
optimization methods].
Gradient methods are particularly useful for solving the present function
minimization problem, since the gradient can easily be computed, as we
shall see. Moreover, meeting constraint (ii), which expresses that the control
5.7 Controllers of Reduced Dimensions 433
system be asymptotically stable, is quite simple when care is taken to choose
the starting values of L, K, and F such that (ii) is satisfied, and we move with
sufficiently small steps along the search directions prescribed. This is because as
the boundary of the region where the control system is stable is approached,
the criterion becomes infinite, and this provides a natural barrier against
moving out of the stability region.
A remark on the representation of the controller is in order at this point.
Clearly, the value of the criterion c,, is determined only by the external
representation of the controller, that is, its transfer matrix F(sl — L)1K, or,
equivalently, its impulse response matrix F exp [L(t — 7)]K. It is well-known
that for a given external representation many internal representations (in the
form of a state differential equation together with an output equation)
are possible. Therefore, when the optimization problem is set up starting
from an internal representation of the controller, as we prefer to do, and all
the entries of the matrices L, K, and F are taken as free parameters, the
minimizing values of L, K, and F are not at all unique. This may give numer-
ical difficulties. Moreover, the dimension of the function minimization prob-
lem is unnecessarily increased. These difficulties can be overcome by choosing
a canonical representation of the controller equations. For example, when the
controller is a single-input system, the phase canonical form of the state
equations (see Section 1.9) has the minimal number of free parameters.
Similarly, when the controller is a single-output system, the dual phase
canonical form (see also Section 1.9) has the minimal number of free param-
eters. For multiinput multioutput systems related canonical forms can be
used (Bucy and Ackermann, 1970). It is noted, however, that considerable
reduction in the number of free parameters can often be achieved by imposing
structural constraints on the controller, for example, by blocking certain
feedback paths that can be expected to be of minor significance.
We discuss finally the evaluation of the gradient of ¢,, with respect to the
entries of L, K, and F. Let y be one of the free parameters. Then introducing
the matrix Ry 0
Re | ) 5-263
0 FR FT
the gradient of o,, with er to y can be written as
os OR
Cie Sosy (= r+ 5S). 5-264
dy oy oy oy
Furthermore, taking the partial derivative of 5-259a with respect to the
same parameter we find that
OM 0S , as «OM S+M—+—M?7+4+585 + ee (NVI). 5-265
oy dy oy oy y
434 Optimal Linear Output Feedback Control Systems
At this point it is convenient to introduce a linear matrix equation which is
adjoint to 5-259a and is given by
MT0 + 0M+R=0. 5-266
Using the fact that for any matrices A, B, and C of compatible dimensions
tr (AB) = tr (BA) and tr (C) = tr (C”), we write with the aid of 5-265
and 5-266 for 5-264
2m ty |= (-m70 UM) + ce
oy oy oy
. Os os = OR
=tr| 0(-—M— mt) S|
al ( ay oy o oy
Tt
=t{o['s RE OO +5
dy oy oy
= tr 250 80 + Os (NYNT) + $2]. 5-267
oy oy
Thus in order to compute the gradient of the objective function ¢,, with
respect to y, one of the free parameters, the two linear matrix equations
5-259a and 2-266 must be solved for S and U, respectively, and the resulting
values must be inserted into 5-267. When a different parameter is considered,
the bulk of the computational effort, which consists of solving the two
matrix equations, need not be repeated. In Section 1.11.3 we discussed
numerical methods for solving linear matrix equations of the type at hand.
Example 5.8. Position control system
In this example we design a position control system with a constraint on
the dimension of the controller. The system to be controlled is the de motor
of Example 5.3 (Section 5.3.2), which is described by the state differential
and observed variable equations
. f I 0
OFA Os ; TAY), 5-268
m(t) = (1, O)a(t) + rm(t),
where 7, and »,, are described as white noise processes with intensities V,
and V,,, respectively. As in Example 5.3, we choose the criterion to be
minimized as
lim E{*(t) + pu(t}, 5-269
to? —o
where C(t) = (1, 0)a(t) is the controlled variable. As we saw in Example 5.3,
the optimal controller without limitations on its dimension is of dimension
5.7 Controllers of Reduced Dimensions 435
two. The only possible controller without a direct link of smaller dimension
is a first-order controller, described by the scalar equations
q(t) = oq(t) + n (0),
5-270
u(t) = —eq(t).
Here we have taken the coefficient of 4(¢) equal to 1, without loss of generality.
The problem to be solved thus is: Find the constants 6 and « that minimize
the criterion 5-269.
In Example 5.3 we used the following numerical values:
« = 0.787 rad/(V s?), Chie A chor y= 0.1 ke mm,
V, = 10 N? m’s, Y= 10 Tae ss: 5-271
For p = 0.00002 rad?/V* we found an optimal controller characterized by
the data in the first column of Table 5.2.
Table 5.2 A Comparison of the Performances of the Position Control System
with Controllers of Dimensions One and Two
Second-order First-order First-order
optimal controller optimal controller optimal controller
with p = 0.00002 with p = 0.00002 with rms input 1.5 V
Rms input voltage
(V) ils lee 15
Rms regulating
error (rad) 0.00674 0.00947 0.0106
E{O(t)} + pE{u(t)}
(rad?) 9.08 + 10° IS. Se OF? IS. SO
Closed-loop poles = 9,009 79.09 —400 —350
Gu) —22,48 + j22.24 Seo eae omy US = 2) Soe 9.92
It is not difficult to find the parameters of the first-order controller 5-270
that minimize the criterion 5-269. In the present case explicit expressions for
the rms regulating error and input voltage can be found. Numerical or
analytical evaluation of the optimal parameter values for p = 0.00002
rad?/V? leads to
6 = —400s 1, 6 = 6375 x 10* V/(rad s). 5-272
The performance of the resulting controller is listed in the second column of
Table 5.2. It is observed that this controller results in an rms input voltage
436 Optimal Linear Output Feedback Control Systems
that is larger than that for the second-order optimal controller. By slightly
increasing p a first-order controller is obtained with the same rms input
voltage as the second-order controller. The third column of Table 5.2 gives
the performance of this controller. It is characterized by the parameters
6 = —350s7, e = 4.65 x 104 V/(rad s). 5-273
A comparison of the data of Table 5.2 shows that the first-order optimal
controller has an rms regulating error that is about 1.5 times that of the
second-order controller. Whether or not this is acceptable depends on the
system specifications. We note that the locations of the dominating closed-
loop poles at —2.15 + 79.92 of the reduced-order contro] system are not at
all close to the locations of the dominant poles at —9.66 + 79.09 of the
second-order system. Finally, we observe that the first-order controller
transfer function is
6 PAGS CIO
G(s) = V/rad. 5-274
s—o s + 350
This controller has a very large bandwidth. Unless the bandwidth of the
observation noise (which we approximated as white noise but in practice
has a limited bandwidth) is larger than the bandwidth of the controller, the
controller may as well be replaced with a constant gain of
465-108
~ 133 V/rad. 5-275
350
This suggests, however, that the optimization procedure probably should be
repeated, representing the observation noise with its proper bandwidth, and
searching for a zero-order controller (consisting of a constant gain).
5.8 CONCLUSIONS
In this final chapter on the design of continuous-time optimal linear feedback
systems, we have seen how the results of the preceding chapters can be
combined to yield optimal output feedback control systems. We have also
analyzed the properties of such systems. Table 5.3 summarizes the main
properties and characteristics of linear optimal output feedback control
system designs of full order. Almost all of the items listed can be considered
favorable features except the last two.
We first discuss the aspects of digital computation. Linear optimal control
system design usually requires the use of a digital computer, but this hardly
constitutes an objection because of the widespread availability of computing
facilities. In fact, the need for digital computation can be converted into an
5.8 Conclusions 437
Table 5.3 Characteristics of Linear Optimal Output Feedback Control System
Designs
Design characteristic
Characteristic judged
favorable (+),
indifferent (1), or
unfavorable (—)
Stability is guaranteed +
A good response from initial conditions and to a
reference variable can be obtained +
Information about the closed-loop poles is available +
The input amplitude or, equivalently, the loop gain, is
easily controlled
Good protection against disturbances can be obtained
Adequate protection against observation noise can be
obtained ae
The control system offers protection against plant
variations +
Digital computation is usually necessary for control
system design oO
The control system may turn out to be rather complex =
advantage, since it is possible to develop computer programs that largely
automate the control system design procedure and at the same time produce
a great deal of detailed information about the proposed design. Table 5.4
lists several subroutines that could be contained in a computer program
package for the design and analysis of time-invariant, continuous-time linear
optimal control systems. Apart from the subroutines listed, such a package
should contain programs for coordinating the subroutines and handling
the data.
The last item in the list of Table 5.3, concerning the complexity of linear
output feedback controllers, raises a substantial objection. In Section 5.7
we discussed methods for obtaining controllers of reduced complexity. At
present, too little experience with such design methods is available, however,
to conclude that this approach solves the complexity problem.
Altogether, the perspective that linear optimal control theory offers for
the solution of real, everyday, complex linear control problems is very
favorable. It truly appears that this theory is a worthy successor to tradi-
tional control theory.
438 Optimal Linear Output Feedback Control Systems
Table 5.4 Computer Subroutines for a Linear Optimal Control System Design
and Analysis Package
For discussion and
Subroutine task references see
Computation of the exponential of a matrix Section 1.3.2
Simulation of a time-invariant linear system Computation of the transfer matrix and characteristic
values of a linear time-invariant system Section 1.3.2
Section 1.5.1
Computation of the zeroes of a square transfer matrix Section 1.5.3
Simulation of a linear time-invariant system driven by
white noise Section 1.11.2
Solution of the linear matrix equation
M,X + XM,7 = M, Section 1.11.3
Solution of the algebraic Riccati equation and
computation of the corresponding closed-loop
regulator or observer poles Section 3.5
Numerical determination of an optimal controller of
reduced dimension Section 5.7.3
5.9 PROBLEMS
5.1. Angular velocity regulation system
Consider the angular velocity system described by the state differential
equation
E(t) = —a&(t) + xu(t) + w,(0). 5-276
Here is the angular velocity, u the driving voltage, and the disturbance w,
is represented as white noise with intensity N. The controlled variable is the
angular velocity:
C(t) = (2). 5-277
The observed variable is also the angular velocity:
y(t) = E(t) + w,(2), 5-278
where w, is represented as white noise with intensity M. The following
5.9 Problems 439
numerical values are assumed:
t= 025551,
« = 150 rad/(Vs?), 5-279
N = 600 rad?/s3,
M = 0.5 rad?/s.
Suppose that the angular velocity system is to be made into a regulator
system, which keeps the angular velocity at a constant value. Determine the
optimal output feedback regulator such that the rms input is 10 V. Compute
the rms regulating error and compare this to the rms regulating error when
no control is applied.
5.2. Angular velocity tracking system
Suppose that the system of Problem 5.1 is to be made into an angular
velocity tracking system. For the reference variable we assume exponentially
correlated noise with time constant § and rms value o. Furthermore, we
assume that the reference variable is measured with additive white noise with
intensity M,. Compute the optimal tracking system. Assume the numerical
values
2s ils.
go = 30 rad/s, 5-280
M, = 0.8 rad?/s3.
Determine the optimal tracking system such that the total rms input is 10 V.
Compute the total rms tracking error and compare this to the rms value of
the reference variable.
5.3. Nonzero set point angular velocity control system
The tracking system of Problem 5.2 does not have the property that a
constant value of the reference variable causes a zero steady-state tracking
error. To obtain such a controller, design a nonzero set point controller as
suggested in Section 5.5.1. For the state feedback law, choose the one obtained
in Problem 5.1. Choose the prefilter such that a step of 30 rad/s in the
reference variable causes a peak input voltage of 10 V or less. Compare the
resulting design to that of Problem 5.2.
5.4.* Integral control of the angular velocity regulating system
Consider the angular velocity control system as described in Problem 5.1.
Suppose that in addition to the time-varying disturbance represented by
w,(t) there is also a constant disturbance v9(t) operating upon the de motor,
so that the state differential equation takes the form
E(t) = —a&(t) + xu(t) + wy(t) + v9(t). 5-281
440 Optimal Linear Output Feedback Control] Systems
The observed variable is given by 5-278, while the numerical values 5-279 are
assumed. The controlled variable is given by 5-277. Design for the present
situation a zero-steady-state-error controller as described in Section 5.5.2.
To this end, assume that v(t) is represented as integrated white noise and
choose the intensity of this white noise as 250 rad?/s*. Compute the response
of the resulting integral control system to a step of 50 rad/s? in the constant
disturbance vy from steady-state conditions and comment on this response.
What is the effect of increasing or decreasing the assumed white noise intensity
of 250 rad?/s*?
5.5.* Adjoint matrix differential equations
Consider the matrix differential equation
O(t) = A(HNQ(t) + Q(A*(1) + R(t), — Oto) = Qos together with the linear functional
5-282
tr | i "O(A)S(1) dt + (1), to
5-283
Prove that 5-283 equals
ty
tr | | P(t)R(t) dt + P(t) Qo|, to
5-284
where P(t) is the solution of the adjoint matrix differential equation
— P(t) = P(t)A(t) + A7(t)P(t) + S(t), = P(t) = Py. 5-285
5.6.* A property of scalar sensitivity functions
In Section 5.6 we remarked that optimal linear output feedback systems
generally do not possess the property that disturbances are attenuated at all
frequencies as compared to the equivalent open-loop system. For single-
input single-output systems this follows from the following theorem (Bode,
1945; Westcott, 1952).
Consider a single-input single-output linear time-invariant system with
transfer function H(s). Let the controller transfer function (see Fig. 5.14)
be given by G(s) so that the control system loop gain function is
L@) = A(s)GG), 5-286
and the sensitivity function is
eer a
S(s) 5-287felectal ah
Let v denote the difference of the degree of the denominator of L(s) and that
of its numerator. Assume that the control system is asymptotically stable.
5.9 Problems 441
Fig. 5.14. A time-invariant linear feedback system.
Then
+00 for y = 0,
| In [|S(jo)|] do = alge fory =1, 5-288
0 for » > 2,
where
y = lim sL(s). 5-289
Prove this result. Conclude that for plants and controllers without direct
links the inequality
|SUjo)| < 1 5-290
cannot hold for all w. Hint: Integrate In[S(s)] along a contour that consists
of part of the imaginary axis closed with a semicircle in the right-half complex
s-plane and let the radius of the semicircle go to infinity.
6* LINEAR OPTIMAL CONTROL
THEORY FOR DISCRETE-TIME
SYSTEMS
6.1 INTRODUCTION
In the first five chapters of this book, we treated in considerable detail linear
control theory for continuous-time systems. In this chapter we give a con-
densed review of the same theory for discrete-time systems. Since the theory
of linear discrete-time systems very closely parallels the theory of linear con-
tinuous-time systems, many of the results are similar. For this reason the
comments in the text are brief, except in those cases where the results for
discrete-time systems deviate markedly from the continuous-time situation.
For the same reason many proofs are omitted.
Discrete-time systems can be classified into two types:
1. Inherently discrete-time systems, such as digital computers, digital
filters, monetary systems, and inventory systems. In such systems it makes
sense to consider the system at discrete instants of time only, and what
happens in between is irrelevant.
2. Discrete-time systems that result from considering continuous-time systems
at discrete instants of time only. This may be done for reasons of convenience
(e.g., when analyzing a continuous-time system on a digital computer), or
may arise naturally when the continuous-time system is interconnected with
inherently discrete-time systems (such as digital controllers or digital process
control computers).
Discrete-time linear optimal control theory is of great interest because of
its application in computer control.
6.2 THEORY OF LINEAR DISCRETE-TIME
SYSTEMS
6.2.1 Introduction
In this section the theory of linear discrete-time systems is briefly reviewed.
The section is organized along the lines of Chapter 1. Many of the results
stated in this section are more extensively discussed by Freeman (1965).
442
6.2 Linear Discrete-Time Systems 443
6.2.2 State Description of Linear Discrete-Time Systems
It sometimes happens that when dealing with a physical system it is relevant
not to observe the system behavior at all instants of time ¢ but only at a
sequence of instants ¢,, i = 0,1, 2,---. Often in such cases it is possible to
characterize the system behavior by quantities defined at those instants only.
For such systems the natural equivalent of the state differential equation is the
state difference equation
“i+ 1) = f[«@, u@, i], 6-1
where (7) is the state and u(7) the input at time f;. Similarly, we assume that
the output at time ¢, is given by the output equation
yi) = g[x@), ut), i]. 6-2
Linear discrete-time systems are described by state difference equations of
Us es Fe es Ae BORON 6-3
where A(i) and B(/) are matrices of appropriate dimensions. The correspond-
ing output equation is
y(i) = Cai) + Dui). 6-4
If the matrices A, B, C, and D are independent of i, the system is time-
invariant.
Example 6.1. Savings bank account
Let the scalar quantity x(n) be the balance of a savings bank account at the
beginning of the n-th month, and let « be the monthly interest rate. Also,
let the scalar quantity u() be the total of deposits and withdrawals during the
n-th month. Assuming that the interest is computed monthly on the basis of
the balance at the beginning of the month, the sequence x(n),n = 0,1, 2,°°-,
satisfies the linear difference equation
a(n + 1) = (1 + a«)a(n) + u(n), igh — 10), Hl, ro OO
20) = x, 6-5
where 2, is the initial balance. These equations describe a linear time-in-
variant discrete-time system.
6.2.3 Interconnections of Discrete-Time and Continuous-Time Systems
Systems that consist of an interconnection of a discrete-time system and a
continuous-time system are frequently encountered. An example of particular
interest occurs when a digital computer is used to control a continuous-time
plant. Whenever such interconnections exist, there must be some type of
interface system that takes care of the communication between the discrete-
time and continuous-time systems. We consider two particularly simple types
444 Discrete-Time Systems
¢*(i)
sampler
f(t)
tg ty to t3 to ty to t3
SETI — > time
Fig. 6.1. Continuous-to-discrete-time conversion.
of interface systems, namely, continuous-to-discrete-time (C-to-D) converters
and discrete-to-continuous-time (D-to-C) converters.
A C-to-D converter, also called a sampler (see Fig. 6.1), is a device with a
continuous-time function f(t), ¢ > ft), as input, and the sequence of real
numbers ft), 1 = "0, 12.0 sat times f, 3 == 0, 12. = 2 as, Oulu.
where the following relation holds:
f@O=fG), i= 0,1, 2,°°°. 6-6
The sequence of time instants’/,;, 7 = 0,1, 2,-°-, with, < 4 << “A=
is given. In the present section we use the superscript + to distinguish
sequences from the corresponding continuous-time functions.
A D-to-C converter is a device that accepts a sequence of numbers /+(i),
P= O1j25> at eiven instants. f,,¢ = 0,12)" ) with ty < Ff <i ee,
and produces a continuous-time function f(t), f > tf), according to a well-
defined prescription. We consider only a very simple type of D-to-C con-
verter known as a zero-order hold. Other converters are described in the
literature (see, e.g., Saucedo and Schiring, 1968). A zero-order hold (see
Fig. 6.2) is described by the relation
TE) ate Pipe Ty = OG Dee 6-7
F#(i) zero —order
hold
f(t)
to ty tr ty tovth tome ty
—»time —» time
Fig. 6.2. Discrete-to-continuous-time conversion.
6.2 Linear Discrete-Time Systems 445
Figure 6.3 illustrates a typical example of an interconnection of discrete-
time and continuous-time systems. In order to analyze such a system, it is
often convenient to represent the continuous-time system together with the
D-to-C converter and the C-to-D converter by an equivalent discrete-time
system. To see how this equivalent discrete-time system can be found in a
specific case, suppose that the D-to-C converter is a zero-order hold and
that the C-to-D converter is a sampler. We furthermore assume that the
continuous-time system of Fig. 6.3 is a linear system with state differential
equation
x(t) = A(t)x(t) + B(t)u(t), 6-8
and output equation
y(t) = C(t)a(t) + D(t)u(t). 6-9
Since we use a zero-order hold,
u(t) = u(t,), Ct eS tea EON re 6-10
Then from 1-61 we can write for the state of the system at time f;,,
tit+1
2(ti41) = Ot, t,)a(t,) + [| O(t,,4, 7) B(7) ar u(t,), 6-11
where (tf, f) is the transition matrix of the system 6-8. This is a linear state
difference equation of the type 6-3. In deriving the corresponding output
equation, we allow the possibility that the instants at which the output is
sampled do not coincide with the instants at which the input is adjusted.
Thus we consider the output associated with the i-th sampling interval, which
is given by
y(t), 6-12
where ey ty 6-13
fori=0,1,2,:--. Then we write
;
y(t) = C(t) O(t,, t)a(t,) + ke i (t/, 7) B(r) ar |u(t) + D(tiu(t,). 6-14
Now replacing x(t;) by x+(i), u(t;) by u*(i), and y(t) by y"(i), we write the
system equations in the form
at(i + 1) = A,(ia*() + Buti),
yt(i) = Cixi) + DDut(), 1=0,1,2,++, 615
446
aWiy-a}asosip
Wa}Shks p10y
Japso-01az
jUa]DAINba
wa }SkS auWt}-3a}asINSIP
8W1}-SNONUI}U09
SAS
Wa
"SuI9}SA$ OULII]-SNONUT}UOD PUP SLT}-d}J9IOSIP JO UOTJIOUUODIOIUT «*¢°9 “BI
Jaj}dwos
wa isks
BUWI}-a}aJOSIP
6.2 Linear Discrete-Time Systems 447
where
A,(i) as O(t,.1, t,),
ti+.
B,(i) =| O(t,.4, 7) B(r) dr,
He
CD) = CE)OG, &); 6-16
D,(i) = C(t) | " (1;, 7)B(r) dr + D(t)).
We note that the discrete-time system defined by 6-15 has a direct link even
if the continuous-time system does not have one because D,,(i) can be different
from zero even when D(t;) is zero. The direct link is absent, however, if
D(t) = 0 and the instants ¢; coincide with the instants 7,, that is, t; = ¢,,
OL er
In the special case in which the sampling instants are equally spaced:
Git, = A, 6-17
and
i ae t; — rae 6-18
while the system 6-8, 6-9 is time-invariant, the discrete-time system 6-15 is
also time-invariant, and
A
A, = e“, B= (| pt ar) B;
0 6-19
e
C,=Ce44, D,= c(| eft dr) B 4D;
0
We call A the sampling period and 1/A the sampling rate.
Once we have obtained the discrete-time equations that represent the
continuous-time system together with the converters, we are in a position
to study the interconnection of the system with other discrete-time systems.
Example 6.2. Digital positioning system
Consider the continuous-time positioning system of Example 2.4 (Section
2.3) which is described by the state differential equation
Oil 0)
ae) ( Ja = | \to. 6-20
0 -—« K!
Suppose that this system is part of a control system that is commanded by a
digital computer (Fig. 6.4). The zero-order hold produces a piecewise constant
input y(t) that changes value at equidistant instants of time separated by
448 Discrete-Time Systems
digital
computer
zero-order
hold
positioning sompler
system
Fig. 6.4. A digital positioning system.
intervals of length A. The transition matrix of the system 6-20 is
1 Li = ea
a ;
O(t, to) = 6-21
0 e t't-to)
From this it is easily found that the discrete-time description of the positioning
system is given by
ati + 1) = Axt(i) + bu*(i), 6-22
where
il oa 1 ras
ele ee 6-23
0 e
and
“(a = 1 =f t -~)
b= | % am : 6-24
= (Leet)
og
Note that we have replaced a(t;) by x*(i) and w(t;) by w*(i).
With the numerical values
CS GRAS.
x ==. 00787 rad/CV s*), Aves 01-52
6-25
we obtain for the state difference equation
1 0.08015 0.003396
atii+1j)= at (i Lt
0 0.6313 0.06308
6-26
Let us suppose that the output variable 7(t) of the continuous-time system,
where
y(t) = (1, O)a(t), 6-27
is sampled at the instants ¢,, 7 = 0, 1, 2,-+-. Then the output equation for
6.2 Linear Discrete-Time Systems 449
the discrete-time system clearly is
m=, Oat), 6-28
where we have replaced 7(t,) with 1+(i).
Example 6.3. Stirred tank
Consider the stirred tank of Example 1.2 (Section 1.2.3) and suppose that
it forms part of a process commanded by a process control computer. As a
result, the valve settings change at discrete instants only and remain constant
in between. It is assumed that these instants are separated by time intervals
of constant length A. The continuous-time system is described by the state
differential equation
a(t) = \ a(t) + eee ae u(t). 6-29
6 Vo Vo
It is easily found that the discrete-time description is
a*(i + 1) = Axt(i) + Bu'(d,
where
eA! (28) 0)
a ,
0 e 4/8
20(1 a gn) 20(1 — Be Aiieeyy
B= O(c, — Cp) 0) ( — e~A/9) O(cz — €
Beg 6) f= e~4/9) 6-30
Vo Vo
With the numerical data of Example 1.2, we find
0.9512 0
A= ;
0 0.9048 6-31
4.877 4.877
~ \_1,1895 3.569/’
where we have chosen
IN = SS. 6-32
Example 6.4. Stirred tank with time delay
As an example of a system with a time delay, we again consider the stirred
tank but with a slightly different arrangement, as indicated in Fig. 6.5. Here
450 Discrete-Time Systems
feed Fy feed Fo
concentration cy concentration co
transport delay
Tt
volume V
concentration c
outgoing flow F
concentration c
Fig. 6.5. Stirred tank with modified configuration.
the feeds are mixed before they flow into the tank. This would not make any
difference in the dynamic behavior of the system if it were not for a transport
delay 7 that occurs in the common section of the pipe. Rewriting the mass
balances and repeating the linearization, we find that the system equations
now are
E() = — 5g 2) + uy(t) + f(t),
6-33
Oe : £,(1) + i=
Cr 169 Co — Co
[a(t — 7),
0 0
where the symbols have the same meanings as in Example 1.2 (Section
6.2 Linear Discrete-Time Systems 451
1.2.3). In vector form we write
; 26
a(t) = a(t) + u(t) + u(t — 7).
0 0 Cy Co. Ca Cp
D |
Vo Vo
6-34
Note that changes in the feeds have an immediate effect on the volume but a
delayed effect on the concentration.
We now suppose that the tank is part of a computer controlled process so
that the valve settings change only at fixed instants separated by intervals of
length A. For convenience we assume that the delay time 7 is an exact multiple
kA of the sampling period A. This means that the state difference equation of
the resulting discrete-time system is of the form
at(i + 1) = Axt(i) + But () + Bout(i — k). 6-35
It can be found that with the numerical data of Example 1.2 and a sampling
A=5s, 6-36
period
A is as given by 6-31, while
4.877 4.877) 0 0
B, = ; B, = : 6-37
0 0) =1.1895 3.569
It is not difficult to bring the difference equation 6-35 into standard state
difference equation form. We illustrate this for the case k = 1. This means
that the effect of changes in the valve settings are delayed by one sampling
interval. To evaluate the effect of valve setting changes, we must therefore
remember the settings of one interval ago. Thus we define an augmented
state vector
E,(i)
E"(i)
‘() = ; 6-38
oo Hy (i — 1)
fia" (i — 1)
By using this definition it is easily found that in terms of the augmented state
the system is described by the state difference equation
xvi +1) = A'e'(i) + But (i), 6-39
452 Discrete-Time Systems
where
0.9512 ) 0 0
: 0 0.9048 —1.1895 3.569
caionl la 0 0 o |
0 0 0 0
6-40
4.877 4.877
0 0
Bos
l 0
0 1
We point out that the matrix A’ has two characteristic values equal to zero.
Discrete-time systems obtained by operating finite-dimensional time-invariant
linear differential systems with a piecewise constant input never have zero
characteristic values, since for such systems A, = exp (AA), which is always
a nonsingular matrix.
6.2.4 Solution of State Difference Equations
For the solution of state difference equations, we have the following theorem,
completely analogous to Theorems 1.1 and 1.3 (Section 1.3).
Theorem 6.1. Consider the state difference equation
xi + 1) = A(i)x(i) + B(i)u(i).
6-41
The solution of this equation can be expressed as
(i) = O(i, i)2ig) + SOG) + DBGU(), 1D in +1,
I=i0
where D(i, ij), i > ig, is the matrix
Ale= DAGAD) SUG) fori Sie
O(i, ig) = ; ;
FOL i ma Epp
6-42
6-43
The transition matrix (i, iy) is the solution of the difference equation
Oi + 1, i) = ADO(i, ip), 1 > i,
Deis) = se
6-44
If A(i) does not depend upon i,
OG, ip) = Ame.
6-45
6.2 Linear Discrete-Time Systems 453
Suppose that the system has an output
yi) = C(x). 6-46
If the initial state is zero, that is, x(i)) = 0, we can write with the aid of
6-42:
Here pee
COG, 7 + 1) Bj), P<i-l,
K(i, j) = ! } 6-48
0, =o
will be termed the pulse response matrix of the system. Note that for time-
invariant systems K depends upon i — / only. If the system has a direct link,
that is, the output is given by
yi) = CHa) + D@u(i), 6-49
the output can be represented in the form
where
Ci) Oi, 7 + 1)B(j) for 7 =< 1 — 1,
K(i,j) = ‘ J i 6-51
D(i) for j =i.
Also in the case of time-invariant discrete-time linear systems, diagonaliza-
tion of the matrix A is sometimes useful. We summarize the facts.
Theorem 6.2. Consider the time-invariant state difference equation
x(i + 1) = Az(i). 6-52
Suppose that the matrix A has n distinct characteristic values ),,43,°** 5 An
with corresponding characteristic vectors 1, €:,°**,@,- Define then xn
matrices
T= (é1, Co, aes 2s
A = diag (Ay, Aas ++ 5 An). 6-53
Then the transition matrix of the state difference equation 6-41 can be written
as
O(i, ig) = Ato = TAP oT, 6-54
454 Discrete-Time Systems
Suppose that the inverse matrix T~ is represented as
fi
he
yee lied ( 6-55
iP
where fi, fo,°** » fy are row vectors. Then the solution of the difference equa-
tion 6-52 can be expressed as
\
~
ai) = > A; te, f;%0, g=1
6-56
where 2%» = X(io).
Expression 6-56 shows that the behavior of the system can be described as a
composition of expanding (for |A,| > 1), sustained (for |A;| = 1), or con-
tracting (for |/;| < 1) motions along the characteristic vectors e,, @:,°°*, €
n
of the matrix A.
6.2.5 Stability
In Section 1.4 we defined the following forms of stability for continuous-time
systems: stability in the sense of Lyapunov; asymptotic stability; asymptotic
stability in the large; and exponential stability. All the definitions for the
continuous-time case carry over to the discrete-time case if the continuous
time variable ¢ is replaced with the discrete time variable 7. Time-invariant
discrete-time linear systems can be tested for stability according to the follow-
ing results.
Theorem 6.3. The time-invariant linear discrete-time system
x(i + 1) = Ax(i) 6-57
is stable in the sense of Lyapunov if and only if
(a) all the characteristic values of A have moduli not greater than 1, and
(b) to any characteristic value with modulus equal to I and multiplicity m
there correspond exactly m characteristic vectors of the matrix A.
The proof of this theorem when A has no multiple characteristic values is
easily seen by inspecting 6-56.
Theorem 6.4. The time-invariant linear discrete-time system
x(i + 1) = Ax(i) 6-58
is asymptotically stable if and only if all of the characteristic values of A have
moduli strictly less than 1.
6.2 Linear Discrete-Time Systems 455
Theorem 6.5. The time-invariant linear discrete-time system
a(i + 1) = Az(i), 6-59
is exponentially stable if and only if it is asymptotically stable.
We see that the role that the left-half complex plane plays in the analysis
of continuous-time systems is taken by the inside of the unit circle for
discrete-time systems. Similarly, the right-half plane is replaced with the
outside of the unit circle and the imaginary axis by the unit circle itself.
Completely analogously to continuous-time systems, we define the stable
subspace of a linear discrete-time system as follows.
Definition 6.1. Consider the n-dimensional time-invariant linear discrete-time
t
P aaialle a(i + 1) = Ax(i). 6-60
Suppose that A has n distinct characteristic values. Then we define the stable
subspace of this system as the real linear subspace spanned by those characteristic
vectors of A that correspond to characteristic values with moduli strictly less
than I. Similarly, the unstable subspace of the system is the real subspace
spanned by those characteristic vectors of A that correspond to characteristic
values with moduli equal to or greater than 1.
For systems where the characteristic values of A are not all distinct, we have:
Definition 6.2. Consider the n-dimensional time-invariant linear discrete-time
ey ATEN (i + 1) = Az(i). 6-61
Let N, be the null space of (A — 4,1)", where 4, is a characteristic value of
A and m, the multiplicity of this characteristic value in the characteristic poly-
nomial of A. Then we define the stable subspace of the system as the real
subspace of the direct sum of those null spaces N, that correspond to
characteristic values of A with moduli strictly less than 1. Similarly, the unstable
subspace is the real subspace of the direct sum of those null spaces N, that
correspond to characteristic values of A with moduli greater than or equal to 1.
Example 6.5. Digital positioning system
It is easily found that the characteristic values of the digital positioning
system of Example 6.2 (Section 6.2.3) are | and exp (—«A). As a result, the
system is stable in the sense of Lyapunov but not asymptotically stable.
6.2.6 Transform Analysis of Linear Discrete-Time Systems
The natural equivalent of the Laplace transform for continuous-time vari-
ables is the z-transform for discrete-time sequences. We define the z-transform
456 Discrete-Time Systems
V(z) of a sequence of vectors v(i), i= 0,1,2,°°*, as follows
V2) = S20), 6-62
where z is a complex variable. This transform is defined for those values of
z for which the sum converges.
To understand the application of the z-transform to the analysis of linear
time-invariant discrete-time systems, consider the state difference equation
x(i + 1) = Ax(i) + Bu(i). 6-63
Multiplication of both sides of 6-63 by z~* and summation over 7 = 0, 1,
2,°°° yields
zX(z) — za(0) = AX(z) + BU(z), 6-64
where X(z) is the z-transform of x(i), i = 0,1,2,--++, and U(z) that of u(i),
i=0,1,2,---. Solution for X(z) gives
X(z) = (ef — A) BU(z) + (2 — A) 2x(0). 6-65
In the evaluation of (zJ — A)~', Leverrier’s algorithm (Theorem 1.18,
Section 1.5.1) may be useful. Suppose that an output y(i) is given by
y(i) = Cx(i) + Du(i). 6-66
Transformation of this expression and substitution of 6-65 yields for x(0) = 0
Y(2) = H@)UQ), 6-67
where Y(z) is the z-transform of y(i), i= 0,1,2,---,and
H(z) = C(I — A)7B + D 6-68
is the 2-transfer matrix of the system.
For the inverse transformation of z-transforms, there exist several methods
for which we refer the reader to the literature (see, e.g., Saucedo and Schiring,
1968).
It is easily proved that the z-transform transfer matrix H(z) is the z-trans-
form of the pulse response matrix of the system. More precisely, let the pulse
transfer matrix of time-invariant system be given by K(i — /) (with a slight
inconsistency in the notation). Then
H(z) = > ies Gt 6-69
We note that H(z) is generally of the form
HG) =P(e) EARS EE RT 6-70
det (zJ — A)
6.2 Linear Discrete-Time Systems 457
where P(z) is a polynomial matrix in z. The poles of the transfer matrix
H(z) are clearly the characteristic values of the matrix A, unless a factor of the
form z — A, cancels in all entries of H(z), where /, is a characteristic value
of A.
Just as in Section 1.5.3, if H(z) is a square matrix, we have
det [H(z)] = uo, -71
[H(@)] 4(2) 6-7
where ¢(z) is the characteristic polynomial 4(z) = det (zJ — A) and y(z) isa
polynomial in z. We call the roots of w(z) the zeroes of the system.
The frequency response of discrete-time systems can conveniently be in-
vestigated with the aid of the z-transfer matrix. Suppose that we have a com-
plex-valued input of the form
u(i) = ne a. i= 0, ie 23 ties 6-72
where j = /—1. We refer to the quantity 0 as the normalized angular fre-
quency. Let us first attempt to find a particular solution to the state difference
equation 6-63 of the form
ie tne i= 0-1, 23-2. 6-73
It is easily found that this particular solution is given by
x,(i) = (e7°I — A) *Bu,,e, Vi 0 (ia The general solution of the homogeneous difference equation is
6-74
ai) = A’a, 6-75
where a is an arbitrary constant vector. The general solution of the inhomo-
geneous state difference equation is therefore
a(i) = Ata + (eI — A)"Bu,,e™, P= 00152 > 6-76
If the system is asymptotically stable, the first term vanishes as i— 00;
then the second term corresponds to the steady-state response of the state to
the input 6-72. The corresponding steady-state response of the output 6-66
is given by
y(i) = C(e*I — A) "Bu,,e°" + Du,,e*"
= H(e*)u,,e*, 6-77
where H(z) is the transfer matrix of the system.
We see that the response of the system to inputs of the type 6-72 is deter-
mined by the behavior of the z-transfer matrix for values of z on the unit circle.
The steady-state response to real “sinusoidal inputs,” that is, inputs of the
458 Discrete-Time Systems
form
u(i) = « cos (if) + f sin (0), pes Oat easly oe 6-78
can be ascertained from the moduli and arguments of the entries of H(e’”).
The steady-state response of an asymptotically stable discrete-time system
with z-transfer matrix H(z) to a constant input
u(i) = Um, be Dale dae se, 6-79
is given by
lim y(i) = H(1)u,,. 6-80
In the special case in which the discrete-time system is actually an equiva-
lent description of a continuous-time system with zero-order hold and
sampler, we let
0 = oA, 6-81
where A is the sampling period. The harmonic input
u(i) = en. = ey ae i= 0, L 2: Sh eked 6-82
is now the discrete-time version of the continuous-time harmonic function
eon. i220; 6-83
from which 6-82 is obtained by sampling at equidistant instants with sampling
rate 1/A.
For sufficiently small values of the angular frequency w, the frequency
response H(e’®4) of the discrete-time version of the system approximates the
frequency response matrix of the continuous-time system. It is noted that
H(e’®4) is periodic in w with period 27/A. This is caused by the phenomenon
of aliasing; because of the sampling procedure, high-frequency signals are
indistinguishable from low-frequency signals.
Example 6.6. Digital positioning system
Consider the digital positioning system of Example 6.2 (Section 6.2.3) and
suppose that the position is chosen as the output:
y(i) = (1, 0)x(i). 6-84
It is easily found that the z-transfer function is given by
0.003396z + 0.002912
H(z) = 6-85G=NhG@—.0.6313) _
Figure 6.6 shows a plot of the modulus and the argument of H(e’®4),
where A = 0.1 s. In the same figure the corresponding plots are given of the
frequency response function of the original continuous-time system, which
6.2 Linear Discrete-Time Systems 459
w —==(rad/s)
80 100
0.01 discrete-time
(rad/V)
O00; Ly et OR ee
continuous-time
w —= (rad/s)
0 0 20 40 60 80 100
arg(H) -90
-270
(degrees)
-360
-450
-540
-180 Slag ey pias es ae ae Pe : continuous-time
discrete-time
Fig. 6.6. The frequency response functions of the continuous-time and the discrete-time
positioning systems.
is given b 0.787
6-86
jo(jo + 4.6)
We observe that for low frequencies (up to about 15 rad/s) the continuous-
time and the discrete-time frequency response function have about the same
modulus but that the discrete-time version has a larger phase shift. The plot
also illustrates the aliasing phenomenon.
6.2.7 Controllability
In Section 1.6 we defined controllability for continuous-time systems. This
definition carries over to the discrete-time case if the discrete-time variable i
is substituted for the continuous-time variable ¢. For the controllability of
time-invariant linear discrete-time systems, we have the following result
which is surprisingly similar to the continuous-time equivalent.
Theorem 6.6. The n-dimensional linear time-invariant discrete-time system
with state difference equation
a(i + 1) = Ax(i) + Bu(i) 6-87
460 Discrete-Time Systems
is completely controllable if and only if the column vectors of the controllability
matrix
Pat BEAB yA BAM) 6-88
span the n-dimensional space.
For a proof we refer the reader to, for example, Kalman, Falb, and Arbib
(1969). At this point, the following comment is in order, Frequently, com-
plete controllability is defined as the property that any initial state can be
reduced to the zero state in a finite number of steps (or in a finite length of
time in the continuous-time case). According to this definition, the system
with the state difference equation
xi+1)=0 6-89
is completely controllable, although obviously it is not controllable in any
intuitive sense. This is why we have chosen to define controllability by the
requirement that the system can be brought from the zero state to any non-
zero state in a finite time. In the continuous-time case it makes little differ-
ence which definition is used, but in the discrete-time it does. The reason is
that in the latter case the transition matrix @(i, i,), as given by 6-43, can be
singular, caused by the fact that one or more of the matrices A(j) can be
singular (see, e.g., the system of Example 6.4, Section 6.2.3).
The complete controllability of time-varying linear discrete-time systems
can be tested as follows.
Theorem 6.7. The linear discrete-time system
ai + 1) = A(i)x(i) + BMu(i) 6-90
is completely controllable if and only if for every iy there exists an iy > iy + 1
such that the symmetric nonnegative-definite matrix
4-1
Wi, i:) = ¥ O(i,, i + 1I)B(DB7(DO7(i,, i + 1) 6-91
t=70
is nonsingular. Here (i, iy) is the transition matrix of the system.
Uniform controllability is defined as follows.
Definition 6.3. The time-varying system 6-90 is uniformly completely
controllable if there exist an integer k > 1 and positive constants a, 0, Bo,
and B, such that
(a) Way ip HK) S>O0 for all iy; (b) mI << Wi, ip HK) <a forall iy; (c) Bol < O*(ig + k, ip)W~(ig, ip + KO(ig + k, ip) < Bil
6-92
6-93
for all iy. 6-94
6.2 Linear Discrete-Time Systems 461
Here Wig, i;) is the matrix 6-91, and (i, i) is the transition matrix of the
system,
It is noted that this definition is slightly different from the corresponding
continuous-time definition. This is caused by the fact that in the discrete-
time case we have avoided defining the transition matrix (i, i)) for i < ip.
This would involve the inverses of the matrices A(j), which do not necessarily
exist.
For time-invariant systems we have:
Theorem 6.8. The time-invariant linear discrete-time system
x(i + 1) = Ax(i) + Bu(i) 6-95
is uniformly completely controllable if and only if it is completely controllable.
For time-invariant systems it is useful to define the concept of controllable
subspace.
Definition 6.4. The controllable subspace of the linear time-invariant discrete-
DEC ICE na eda) eebaG) 6-96
is the linear subspace consisting of the states that can be reached from the zero
state within a finite number of steps.
The following characterization of the controllable subspace is quite con-
venient.
Theorem 6.9. The controllable subspace of the n-dimensional time-invariant
linear discrete-time system
a(i + 1) = Ax(i) + Bu(i) 6-97
is the linear subspace spanned by the column vectors of the controllability
matrix P.
Discrete-time systems, too, can be decomposed into a controllable and an
uncontrollable part.
Theorem 6.10. Consider the n-dimensional linear time-invariant discrete-
time system
x(i + 1) = Ax(i) + Bu(i). 6-98
Form a nonsingular transformation matrix T = (Ty, Tz), where the columns
of T, form a basis for the controllable subspace of the system, and the column
vectors of T, together with those of T, span the whole n-dimensional space.
Define the transformed state variable
a'(i) = T(i). 6-99
462 Discrete-Time Systems
Then the transformed state variable satisfies the state difference equation
Aj, Aj By
eit) = ( ‘ ) w'(i) + | ‘ac 6-100
0 Abs 0
where the pair {Aj,, Bi} is completely controllable.
Here the terminology “‘the pair {A, B} is completely controllable”’ is short-
hand for “‘the system «(i + 1) = Ax(i) + Bu(i) is completely controllable.”
Also stabilizability can be defined for discrete-time systems.
Definition 6.5. The linear time-invariant discrete-time system
a(i + 1) = Ax(i) + Bu(i) 6-101
is stabilizable if its unstable subspace is contained in its controllable subspace.
Stabilizability may be tested as follows.
Theorem 6.11. Suppose that the linear time-invariant discrete-time system
x(i + 1) = Ax(i) + Bu(i) 6-102
is transformed according to Theorem 6.10 into the form 6-100. Then the system
is stabilizable if and only if all the characteristic values of the matrix Az have
moduli strictly less than 1.
Analogously to the continuous-time case, we define the characteristic
values of the matrix Aj; as the controllable poles of the sytem, and the remain-
ing poles as the uncontrollable poles. Thus a system is stabilizable if and only if
all its uncontrollable poles are stable (where a stable pole is defined as a
characteristic value of the system with modulus strictly less than 1).
6.2.8 Reconstructibility
The definition of reconstructibility given in Section 1.7 can be applied to
discrete-time systems if the continuous time variable f is replaced by the
discrete variable i. The reconstructibility of a time-invariant linear discrete-
time system can be tested as follows.
Theorem 6.12. The n-dimensional time-invariant linear discrete-time system
a(i + 1) = Aa(i) + Bu(i),
y() = Ce(i), ae
6.2 Linear Discrete-Time Systems 463
is completely reconstructible if and only if the row vectors of the reconstructi-
bility matrix
C
Q= 6-104
CAl eS
span the whole n-dimensional space.
A proof of this theorem can be found in Meditch (1969). For general, time-
varying systems the following test applies.
Theorem 6.13. The linear discrete-time system
xii + 1) = A(i)a(i) + BM)u(i),
6-105
y(i) = C(a(i)
is completely reconstructible if and only if for every i, there exists an iy <
i; — 1 such that the symmetric nonnegative-definite matrix
a1
M(ig, i) = > O7(i, ip + 1)C7()CWO(i, iy + 1) 6-106
7=70+1
is nonsingular. Here D(i, iy) is the transition matrix of the system.
A proof of this theorem is given by Meditch (1969).
Uniform complete reconstructibility can be defined as follows.
Definition 6.6. The time-varying system 6-105 is uniformly completely
reconstructible if there exist an integer k > | and positive constants %, %,
fy, and B, such that
(a) M(i, —k, i) >90 = for all iy; (ob) ol <M Gy — ki) Saf forall i,; (c) Bol < (i, tp — NM“, — k, i)O7(i, i, — kK) S Bil
6-107
6-108
for all i,. 6-109
Here M(i, i;) is the matrix 6-106 and (i, iy) is the transition matrix of the
system.
We are forced to introduce the inverse of M(ig, i) in order to avoid defining
(i, i) for i less than ig.
For time-invariant systems we have:
464 Discrete-Time Systems
Theorem 6.14. The time-invariant linear discrete-time system
x(i + 1) = Ax(i), y(i) = Ca(i) 6-110
is uniformly completely reconstructible if and only if it is completely recon-
structible.
For time-invariant systems we introduce the concept of unreconstructible
subspace.
Definition 6.7. The unreconstructible subspace of the n-dimensional linear
time-invariant discrete-time system
“(i + 1) = Ax(i) + Bu(i), y(i) = Celi)
6-111
is the linear subspace consisting of the states x, for which
YEs Xor%p,0)=0, 1D hp. 6-112
Here 6-112 denotes the response of the output variable y of the system to the
initial state x(ij) = 2%), with u(i) = 0, i > iy. The following theorem gives
more information about the unreconstructible subspace.
Theorem 6.15. The unreconstructible subspace of the linear time-invariant
discrete-time system He 1S Ae) eon.
6-113
y@) = Cx(i)
is the null space of the reconstructibility matrix Q.
Using the concept of an unreconstructible subspace, discrete-time linear
systems can also be decomposed into a reconstructible and an unrecon-
structible part.
Theorem 6.16. Consider the linear time-invariant discrete-time system
x(i+ 1) = Ax(i) + Bu(i), 6-114
y(i) = Cx(i).
Form the nonsingular transformation matrix
Uy
U= ; 6-115
U2
where the rows of U, form a basis for the subspace which is spanned by the
rows of the reconstructibility matrix Q of the system. U, is so chosen that its
rows together with those of U, span the whole n-dimensional space. Define
the transformed state variable x'(t) = Ux(t). 6-116
6.2 Linear Discrete-Time Systems 465
Then in terms of the transformed state variable the system can be represented
by the state difference equation
ae ee DUA By
et - 1) ; KZ (i) + u(i), 6-117
Ay 22 By
y(i) = (Cj, 0)z"(i),
where the pair {Aj,, Ci} is completely reconstructible.
Here the terminology “‘the pair {A, C} is completely reconstructible’”’ means
that the system (i + 1) = Az(i), y(i) = Ca(i) is completely reconstructible.
A detectable discrete-time system is defined as follows.
Definition 6.8. The linear time-invariant discrete-time system
x(i + 1) = Ax(i) + Bu(i),
6-118
y(i) = Ca(i),
is detectable if its unreconstructible subspace is contained within its stable
subspace.
One way of testing for detectability is through the following result.
Theorem 6.17. Consider the linear time-invariant discrete-time system
x(i + 1) = Ax(i) + Bu(i),
y(i) = Cx(i).
6-119
Suppose that it is transformed according to Theorem 6.16 into the form 6-117.
Then the system is detectable if and only if all the characteristic values of the
matrix Ags have moduli strictly less than one.
Analogously to the continuous-time case, we define the characteristic
values of the matrix Aj, as the reconstructible poles, and the characteristic
values of Aj, as the unreconstructible poles of the system. Then a system is
detectable if and only if all its unreconstructible poles are stable.
6.2.9 Duality
As in the continuous-time case, discrete-time regulator and filtering theory
turn out to be related through duality. It is convenient to introduce the follow-
ing definition.
Definition 6.9. Consider the linear discrete-time system
ai + 1) = Aa) + BOu®),
y(i) = Cx(i). 6-120
466 Discrete-Time Systems
In addition, consider the system
ai + 1) = AtG* —i)27@) + CO — iu"),
6-121
y*(i) = B*(i* — i)x*(i),
where i* is an arbitrary fixed integer. Then the system 6-121 is termed the dual
of the system 6-120 with respect to i*.
Obviously, we have the following.
Theorem 6.18. The dual of the system 6-121 with respect to i* is the
original system 6-120.
Controllability and reconstructibility of systems and their duals are related
as follows.
Theorem 6.19. Consider the system 6-120 and its dual 6-121:
(a) The system 6-120 is completely controllable if and only if its dual is com-
pletely reconstructible.
(b) The system 6-120 is completely reconstructible if and only if its dual is
completely controllable.
(c) Assume that 6-120 is time-invariant. Then 6-120 is stabilizable if and only
if 6-121 is detectable.
(d) Assume that 6-120 is time-invariant. Then 6-120 is detectable if and only
if 6-121 is stabilizable.
The proof of this theorem is analogous to that of Theorem 1.41 (Section
1.8).
6.2.10 Phase-Variable Canonical Forms
Just as for continuous-time systems, phase-variable canonical forms can be
defined for discrete-time systems. For single-input systems we have the
following definition.
Definition 6.10. A single-input time-invariant linear discrete-time system is
in phase-variable canonical form if it is represented in the form
0 1 emai Ai 0 i)
eo en ee ree re a(i) + vee (i),
co) S —_— (=)
—Kyp — Oy tet mens —On 4 1
y(t) = Cx(i). 6-122
6.2 Linear Discrete-Time Systems 467
Here the «;, i= 0,1,:-+,n—=1 are the coefficients of the characteristic
polynomial
> az 6-123
7=0
of the system, where «, = 1. Any completely controllable time-invariant
linear discrete-time system can be transformed into this form by the pre-
scription of Theorem 1.43 (Section 1.9).
Similarly we introduce for single-output systems the following definition.
Definition 6.11. A single-output time-invariant linear discrete-time system is
in dual phase-variable canonical form if it is represented as follows
Oughta grees aes
dy 0900 Oiled
ei+t+lj= Of <0" r= 10 | —«, x(i) + Bu(i),
Qin esa she 0 1 pee
ni) = (0, 0,°°-,0, 1)x(i). 6-124
6.2.11 Discrete-Time Vector Stochastic Processes
In this section we give a very brief discussion of discrete-time vector sto-
chastic processes, which is a different name for infinite sequences of stochastic
vector variables of the form v(i), i=-+::,—1, 0, 1, 2,--+. Discrete-time
vector stochastic processes can be characterized by specifying all joint
probability distributions
Pi{v(i;) < Vj, v(iz) < V2, RRs V(in) ce Um} 6-125
for all real v,, v2,°** , 0,,, for all integers i,, i,,°°-+,i,,, and all integers m.
If
P{v(i,) <= Vi, Cy) = Ub V(im) <— Vint
= Pio(i, 5 k) & V1, V(ip “ls k) <s Vo5 ax as Im =f k) < Vm} 6-126
for all real v1, vo, °° * , Um, for all integers i,, i;,°+*, i,, and for any integers
mand k the process is called stationary. If the joint distributions 6-126 are all
multidimensional Gaussian distributions, the process is termed Gaussian.
We furthermore define:
Definition 6.12. Consider the discrete-time vector stochastic process v(i).
Then we call
m(i) = Efv()} 6-127
468 Discrete-Time Systems
the mean of the process,
Ci, f) = Efoliv7(j)} 6-128
the second-order joint moment matrix, and
RAG, f) = E{[o) — mG) — mI} 6-129
the covariance matrix of the process. Finally,
Q(i) = E{[o(i) — mo) — m@HI"} = RG, i) 6-130
is the variance matrix and C,(i,i) the second-order moment matrix of the
process.
If the process v is stationary, its mean and variance matrix are independent
of i, and its joint moment matrix C,(7, 7) and its covariance matrix R,,(/, /)
depend upon i — 7 only. A process that is not stationary, but that has the
property that its mean is constant, its second-order moment matrix is finite
for all i and its second-order joint moment matrix and covariance matrix
depend on i — j only, is called wide-sense stationary.
For wide-sense stationary discrete-time processes, we define the following.
Definition 6.13. The power spectral density matrix & (0), —7 <9< 7, ofa
wide-sense stationary discrete-time process v is defined as
(9) = Seek z= e? —7<0< 7, 6-131
7=— 00
if it exists, where R,(i — k) is the covariance matrix of the process and where
jev-—l.
The name power spectral density matrix stems from its close connection with
the identically named quantity for continuous-time stochastic processes.
The following fact sheds some light on this.
Theorem 6.20. Let v be a wide-sense stationary zero mean discrete-time
stochastic process with power spectral density matrix &,,(0). Then
E{v(i)v7(i)} = &,(0) = - i >, (6) dO. 6-132
A nonrigorous proof is as follows. We write
- [20 do = a [e ( > Roe") do
: R()(+ lies a6)
7=— 00 20
= R,(0), 6-133
6.2 Linear Discrete-Time Systems 469
since
TIM ios oar fon =.)
i easel | 6-134
—1 0 otherwise.
Power spectral density matrices are especially useful when analyzing the
response of time-invariant linear discrete-time systems when a realization of a
discrete-time stochastic process serves as the input. We have the following
result.
Theorem 6.21. Consider an asymptotically stable time-invariant linear
discrete-time system with z-transfer matrix H(z). Let the input to the system
be a realization of a wide-sense stationary discrete-time stochastic process u
with power spectral density matrix &,(0), which is applied from time — 0 on.
Then the output y is a realization of a wide-sense stationary discrete-time
stochastic process with power spectral density matrix
(0) = Hes. OH (e7); —7<6< 7. 6-135
Example 6.7. Sequence of mutually uncorrelated variables
Suppose that the stochastic process v(i), i=--:, —1,0,1,2,°°-, con-
sists of a sequence of mutually uncorrelated, zero-mean, vector-valued sto-
chastic variables with constant variance matices Q. Then the covariance
matrix of the process is given by
Cakes amb 6-136
0 for i A j.
This is a wide-sense stationary process. Its power spectral density matrix is
x (6) = Q. 6-137
This process is the discrete-time equivalent of white noise.
Example 6.8. Exponentially correlated noise
Consider the scalar wide-sense stationary, zero-mean discrete-time sto-
chastic process v with covariance function
tanh R,(i — k) = o* exp (- :
6-138
We refer to A as the sampling period and to 7 as the time constant of the
process. The power spectral density function of the process is easily found
to be
o(1 - aes
¥,(6) = —7<0< 7. 6-139(ce — eAIT)(g-19 _ g-AITY’
470 Discrete-Time Systems
6.2.12 Linear Discrete-Time Systems Driven by White Noise
In the context of linear discrete-time systems, we often describe disturbances
and other stochastically varying phenomena as the outputs of linear discrete-
time systems of the form
a(i+ 1) = A(i)x(i) + Bw),
: — 6-140
y(i) = Cli)a(i).
Here 2(i) is the state variable, y(i) the output variable, and w(i),i=-:-,
—1,0,1,2,-+-, a sequence of mutually uncorrelated, zero-mean, vector-
valued stochastic vectors with variance matrix
E{w(i)w?()} = Vi). 6-141
As we saw in Example 6.7, the process w shows resemblance to the white noise
process we considered in the continuous-time case, and we therefore refer to
the process w as discrete-time white noise. We call V(i) the variance matrix of
the process. When V(i) does not depend upon /, the discrete-time white noise
process is wide-sense stationary. When w(i) has a Gaussian probability distri-
bution for each i, we refer to w as a Gaussian discrete-time white noise process.
Processes described by 6-140 may arise when continuous-time processes
described as the outputs of continuous-time systems driven by white noise
are sampled. Let the continuous-time variable x(t) be described by
a(t) = A(t)a(t) + B(t)w(t), 6-142
where w is white noise with intensity V(t). Then if ¢;,7=0,1,2,---,isa
sequence of sampling instants, we can write from 1-61:
tiga
ti) = Obrstde(t) +] Ola DBE WG) de, 6143
tj
where (f, fo) is the transition matrix of the differential system 6-142. Now
using the integration rules of Theorem 1.51 (Section 1.11.1) it can be seen
that the quantities
t+1 | D(t,41,7)B(r)w(7) dr, 6-144
ti
i=0,1,2,---, form a sequence of zero mean, mutually uncorrelated sto-
chastic variables with variance matrices
ti4a
(| O(ti44, T)B(r)V(7)B? (7) ®7 (t,.,., T) dr. 6-145
It is observed that 6-143 is in the form 6-140.
It is sometimes of interest to compute the variance matrix of the stochastic
process x described by 6-140. The following result is easily verified.
6.2 Linear Discrete-Time Systems 471
Theorem 6.22. Let the stochastic discrete-time process x be the solution of
the linear stochastic difference equation
a(i + 1) = A()a(i) + BU)w(d), 6-146
where w(i), i= —1,0,1,2,--++, is a sequence of mutually uncorrelated
zero-mean, vector-valued stochastic variables with variance matrices V‘(i).
Suppose that x(ig) = %) has mean my and variance matrix Qy. Then the mean
of x(i) PhD Een). 6-147
and the variance matrix of x(i),
Q(i) = E{[x(i) — m(i)][x@) — mi)" }, can be given as follows. The mean is
6-148
mt) = OU, ims, Tats 6-149
where D(i, iy) is the transition matrix of the difference equation 6-146, while
Q(i) is the solution of the matrix difference equation
O(i + 1) = A(DO(i)A7(i) + B(DV DB? (i), esa a ee Sel |
6-150
Q(ig) = Qp.
When the matrices A, B, and V are constant, the following can be stated
about the steady-state behavior of the stochastic process 2.
Theorem 6.23. Let the discrete-time stochastic process x be the solution of
the stochastic difference equation
“(i + 1) = Ax(i) + Bwi(i),
where A and B are constant and where the uncorrelated sequence of zero-mean
stochastic variables w has a constant variance matrix V. Then if all the char-
acteristic values of A have moduli strictly less than 1, and i) > — ©, the co-
variance matrix of the process tends to an asymptotic value R,(i,j) which
depends on i — j only. The corresponding asymptotic variance matrix Q is the
unique solution of the matrix equation
O = AOA™ + BVB?. 6-152
In later sections we will be interested in quadratic expressions. The following
results are useful.
Theorem 6.24. Let the process x be the solution of
a(i + 1) = A(i)x(i) + BU)w(),
6-153
X(ig) = Xo,
472 Discrete-Time Systems
where the w(i) are a sequence of mutually uncorrelated zero mean stochastic
variables with variance matrices V(i). Let R(i) be a given sequence of non-
negative-definite symmetric matrices. Then
[3 «t@R(a(i|—tr| Ear" PC) + SaOvOBOPG+ 1], 6154
where the nonnegative-definite symmetric matrices P(i) are the solution of the
matrix difference equation
Pi) = A*@PG+)AD+RO, t=ih—1,h —2,°°-, bp,
6-155
P(ix) = R(iy).
If A and R are constant, and all the characteristic values of A have moduli
strictly less than 1, P(i) approaches a constant value P as i, -> «©, where P is
the unique solution of the matrix equation
Pw APA +R: 6-156
One method for obtaining the solutions to the linear matrix equations 6-152
and 6-156 is repeated application of 6-150 or 6-155. Berger (1971) gives another
method. Power (1969) gives a transformation that brings equations of the
type 6-152 or 6-156 into the form
M,X + XM," = Ns, 6-157
or Vice versa, so that methods of solution available for one of these equations
can also be used for the other (see Section 1.11.3 for equations of the type
6-157).
A special case occurs when all stochastic variables involved are Gaussian.
Theorem 6.25. Consider the stochastic discrete-time process x described by
xi + 1) = A(i)x(i) + Bw),
2(ig) = Xp. 6-158
Then if the mutually uncorrelated stochastic variables w(i) are Gaussian and
the initial state x) is Gaussian, x is a Gaussian process.
Example 6.9. Exponentially correlated noise
Consider the stochastic process described by the scalar difference equation
where the w(i) form a sequence of scalar uncorrelated stochastic variables
with variance o,,” and where |«| < 1. We consider & the output of a time-
invariant discrete-time system with z-transfer function
1
led 6-160
6.2 Linear Discrete-Time Systems 473
and with the sequence w as input. Since the power spectral density function of
@ is
2 (0) =o. 6-161
we find for the spectral density matrix of €, according to 6-135,
oe
2,(6) = 6-162
(e*? as a)(e 7 i= a) ‘
We observe that 6-162 and 6-139 have identical appearances; therefore,
6-159 generates exponentially correlated noise. The steady-state variance
o,” of the process € follows from 6-152; in this case we have
of =a'o) + 64° 6-163
or
6-164
Example 6.10. Stirred tank with disturbances
In Example 1.37 (Section 1.11.4), we considered a continuous-time model
of the stirred tank with disturbances included. The stochastic state differential
equation is given by
== 0 0 0 1 1
20
0 ae 1 F yo Fog Cio ary Co Coo a Co
a) = ' =(1) + u(t)
0 0: y=" -0 0 0
0,
1
0 0 0 = 0 0
0,
0 0
0 0
ss w(t), 6-165
Co
474 Discrete-Time Systems
where w is white noise with intensity
Ia;7 panel 0
6,
a : 6-166
205°
@) Lae —
95
Here the components of the state are, respectively, the incremental volume
of fluid, the incremental concentration in the tank, the incremental concen-
tration of the feed F,, and the incremental concentration of the feed Fy.
The variations in the concentrations of the feeds are represented as exponenti-
ally correlated noise processes with rms values o, and o, and time con-
stants 0, and 6,, respectively.
When we assume that the system is controlled by a process computer so
that the valve settings change at instants separated by intervals A, the dis-
crete-time version of the system description can be found according to the
method described in the beginning of this section. Since this leads to some-
what involved expressions, we give only the outcome for the numerical
values of Example 1.37 supplemented with the following values:
o, = 0.1 kmol/m,
Oo, = 0.2 kmol/m?,
C= 40's; 6-167
6, = 50 S,
/S\ = SVE
With this the stochastic state difference equation is
0.9512 0 0 0
0 0.9048 0.0669 0.02262
eit 1)= x(i)
0 0 0.8825 0
0 0 0 0.9048
4.877 4.877
—1.1895 3.569
‘ u(i) + w(i), 6-168
0 0
where w(i), 7 > i, is a sequence of uncorrelated zero-mean stochastic vectors
6.3 Linear Discrete-Time Control Systems 475
with variance matrix
0
0 0 0
0 0.00004886 0.00009375 0.0001
6-169
0 0.00009375 0.002212 0
0 0.0001 0 0.007252
By repeated application of 6-150, it is possible to find the steady-state value
Q of the variance matrix of the state. Numerically, we obtain
0 0 0 0
* 0 0.00390 0.00339 0.00504
O= : 6-170
0 0.00339 0.0100 0
0 0.00504 0 0.0400
This means that the rms value of the variations in the tank volume is zero
(this is obvious, since the concentration variations do not affect the flows),
the rms value of the concentration in the tank is 0.00390 ~ 0.0625 kmol/m,
and the rms values of the concentrations of the incoming feeds are 0.1
kmol/m? and 0.2 kmol/m?, respectively. The latter two values are of course
precisely o, and oy.
6.3 ANALYSIS OF LINEAR DISCRETE-TIME
CONTROL SYSTEMS
6.3.1 Introduction
In this section a brief review is given of the analysis of linear discrete-time
control systems. The section closely parallels Chapter 2.
6.3.2 Discrete-Time Linear Control Systems
In this section we briefly describe discrete-time control problems, introduce
the equations that will be used to characterize plant and controller, define the
notions of the mean square tracking error and mean square input, and state
the basic design objective. First, we introduce the plant, which is the system
to be controlled and which is represented as a linear discrete-time system
476 Discrete-Time Systems
characterized by the equations
x(i + 1) = A(ix(i) + B(u(i) + v,(0),
(ig) = Xp,
yi) = C@x(i) + Ey@ud) + vp (i),
ai) = D(i)x(i) + E,(i)u(),
fort =ajeigei
6-171
Here 2 is the state of the plant, x, the initial state, u the input variable, y the
observed variable, and z the controlled variable. Furthermore v, represents
the disturbance variable and v,, the observation noise. Finally, we associate
with the plant a reference variable r(i), i = ig, ig) + 1,+* +. It is noted that in
contrast to the continuous-time case we allow both the observed variable
and the controlled variable to have a direct link from the plant input. The
reason is that direct links easily arise in discrete-time systems obtained by
sampling continuous-time systems where the sampling instants of the output
variables do not coincide with the instants at which the input variable changes
value (see Section 6.2.3). As in the continuous-time case, we consider sepa-
rately tracking problems, where the controlled variable z(i) is to follow a
time-varying reference variable r(i), and regulator problems, where the refer-
ence variable is constant or slowly varying.
Analogously to the continuous-time case, we consider closed-loop and
open-loop controllers. The general closed-loop controller is taken as a linear
discrete-time system described by the state difference equation and the output
equation qi + 1) = L(q(i) + K,@r(i) — Kyi),
6-172
uli) = F@q@) + A,Or@) — Hy@Oy@.
We note that these equations imply that the controller is able to process the
input data r(i) and y(i) instantaneously while generating the plant input
u(i). If there actually are appreciable processing delays, such as may be the
case in computer control when high sampling rates are used, we assume that
these delays have been accounted for when setting up the plant equations
(see Section 6.2.3).
The general open-loop controller follows from 6-172 with K, and H,
identical to zero.
Closely following the continuous-time theory, we judge the performance
of a control system, open- or closed-loop, in terms of its mean square tracking
error and its mean square input. The mean square tracking error is defined as
C,(i) = Efe7(i)W,(e(i)}, 6-173
6.3 Linear Discrete-Time Control Systems 477
where
e(i) = 2(i) — r(i). 6-174
Wi) is a nonnegative-definite symmetric weighting matrix. Similarly, the
mean square input is defined as
C,(i) = E{u7@)W,@u}, 6-175
where W,(i) is another nonnegative-definite weighting matrix. Our basic
objective in designing a control system is to reduce the mean square tracking
error as much as possible, while at the same time keeping the mean square
input down to a reasonable value.
As in the continuous-time case, a requirement of primary importance is
contained in the following design rule.
Design Objective 6.1. A control system should be asymptotically stable.
Discrete-time control systems, just as continuous-time control systems,
have the property that an unstable plant can be stabilized by closed-loop
control but never by open-loop control.
Example 6.11. Digital position control system with proportional feedback
As an example, we consider the digital positioning system of Example 6.2
(Section 6.2.3). This system is described by the state difference equation
1 0.08015 0.003396
Aue y= a(i) + pi). 6-176
0 0.6313 0.06308
Here the first component §,(i) of a(i) is the angular position, and the second
component &,(i) the angular velocity. Furthermore, (7) is the input voltage.
Suppose that this system is made into a position servo by using proportional
feedback as indicated in Fig. 6.7. Here the controlled variable ¢(i) is the
position, and the input voltage is determined by the relation
wi) = Alri) — ()]. 6-177
In this expression r(i) is the reference variable and A a gain constant. We
assume that there are no processing delays, so that the sampling instant of the
digital positioning
system
C(i) = £4 (1)
Fig. 6.7. A digital positioning system with proportional feedback.
478 Discrete-Time Systems
output variable coincides with the instant at which a new control interval is
initiated. Thus we have Paves Owe). 6-178
In Example 6.6 (Section 6.2.6), it was found that the open-loop z-transfer
function of the plant is given by
0.003396(z + 0.8575)
H(z) = 6-179
(e—= 12 — 0.0313)
By using this it is easily found that the characteristic polynomial of the closed-
loop system is given by
(z — 1)(2 — 0.6313) + 0.003396A(z + 0.8575). 6-180
In Fig. 6.8 the loci of the closed-loop roots are sketched. It is seen that when
A changes from 100 to 150 V/rad the closed-loop poles leave the unit circle,
Fig. 6.8. The root loci of the digital
position control system. x, Open-loop
poles; O, open-loop zero.
hence the closed-loop system becomes unstable. Furthermore, it is to be
expected that, in the stable region, as A increases the system becomes more and
more oscillatory since the closed-loop poles approach the unit circle more and
more closely. To avoid resonance effects, while maximizing A, the value of 4
should be chosen somewhere between 10 and 50 V/rad.
6.3.3 The Steady-State and the Transient Analysis
of the Tracking Properties
In this section the response of a linear discrete-time control system to the
reference variable is studied. Both the steady-state response and the transient
response are considered. The following assumptions are made.
6.3 Linear Discrete-Time Control Systems 479
1. Design Objective 6.1 is satisfied, that is, the control system is asymptoti-
cally stable.
W,, are constant.
to zero.
2. The control system is time-invariant and the weighting matrices W, and
3. The disturbance variable v, and the observation noise v,, are identical
4. The reference variable can be represented as
ri) = ro + 7, (i), Lae 1658. sh ae 6-181
where the constant part r, is a stochastic vector with second-order moment
matrix
and the variable part r,, is a wide-sense stationary zero-mean vector stochastic
process with power spectral density matrix &,(0).
Assuming zero initial conditions, we write for the z-transform Z(z) of the
controlled variable and the z-transform U(z) of the input
Z(z) = T(2)R@),
U(z) = N(z)R(). 6-183
Here 7(z) is the transmission of the system and N(z) the transfer matrix from
reference variable to input of the control system, while R(z) is the z-transform
of the reference variable. The control system can beeither closed- or open-
loop. Thus if E(z) is the z-transform of the tracking error e(i) = 2(i) — r(i),
we have
E(z) = [T(z) — T]R(). 6-184
To derive expressions for the steady-state mean square tracking error and
input, we study the contributions of the constant part and the variable
part of the reference variable separately. The constant part of the reference
variable yields a steady-state response of the tracking error and the input as
follows:
lim e(i) = [T() — I]ro,
t> 0
6-185
me) NG re
i7 ©
From Section 6.2.11 it follows that in steady-state conditions the response of
the tracking error to the variable part of the reference variable has the power
spectral density matrix
(Te) — NEO (Te) — 1)". 6-186
480 Discrete-Time Systems
Consequently, the steady-state mean square tracking error can be expressed as
Cen = lim C,(i)
i> oo
= E{ro’[T(1) — 1)*W,.[T(1) — 1ro}
ae Fe “[T(e%) — I],(0)[T(e~*) — 1] W, as} 6-187
T J—T
This expression can be rewritten as
Oren {ir — NT W,TA) — TR,
+> “(T(e*) — NT WTC") = 115,(6) a6}. 6-188
Similarly, the steady-state mean square input can be expressed in the form
Cini Gea
= tr [N7UDWANCRy + 5 NT(e*\WAN(e)E,(6) dB}. 6-189
TT J—tT
Before further analyzing these expressions, we introduce the following
additional assumption.
5. The constant part and the variable part of the reference variable have
uncorrelated components, that is, both Ry, and &,(6) are diagonal and can be
written in the form
Ro = diag (Roi, Roa, °°" Ro y)s
6-190
=,(0) = diag [2,1(9), =,,2(8), ie Fa (HE
where p is the dimension of the reference variable and the controlled variable.
With this assumption we write for 6-188:
Cem = ¥ RofITA) — HP WTO) — 1} Sit
ce | *,,COMIT(C”) — 11 WIT (e*) — 1}, 40, 6-191
where {M},,; denotes the i-th diagonal entry of the matrix M. Following
Chapter 2, we now introduce the following notions.
Definition 6.14. Let p(i), i=---,—1,0,1,2,---, be a scalar wide-sense
stationary discrete-time stochastic process with power spectral density function
2,(9). Then the normalized frequency band © of this process is defined as the
6.3. Linear Discrete-Time Control Systems 481
set of normalized frequencies 6,0 < 6 < 7, for which
De) 2. 6-192
Here « is so chosen that the frequency band contains a given fraction 1 — «,
where é is small with respect to 1, of half the power of the process, that is,
[ z,(6) dd =(1 — 8) i D,(0) dO. 6-193
0e0 0
As in Chapter 2, when the frequency band is an interval [6,, 6,], we define
6. — 0, as the normalized bandwidth of the process. When the frequency band
is an interval [0, 6,], we define 0, as the normalized cutoff frequency of the
process.
In the special case where the discrete-time process is derived from a con-
tinuous-time process by sampling, the (not normalized) bandwidth and cut-
off frequency follow from the corresponding normalized quantities by the
relation
@ = 6/A, 6-194
where A is the sampling period and w the (not normalized) angular frequency.
Before returning to our discussion of the steady-state mean square tracking
error we introduce another concept.
Definition 6.15. Let T(z) be the transmission of an asymptotically stable
time-invariant linear discrete-time control system. Then we define the norma-
lized frequency band of the i-th link of the control system as the set of normalized
frequencies 6,0 < 0 < =, for which
{[T(e-*) — NTW.IT(e) — Mar < ©*Wease 6-195
Here « is a given number which is small with respect to 1, W, is the weighting
matrix for the mean square tracking error, and W, ,, the i-th diagonal entry of
W 5 é
Here as well we speak of the bandwidth and the cutoff frequency of the i-th
link, if they exist. If the discrete-time system is derived from a con-
tinuous-time system by sampling, the (not normalized) bandwidth and cutoff
frequency can be obtained by the relation 6-194.
We can now phrase the following advice, which follows from a considera-
tion of 6-191.
Design Objective 6.2. Let T(z) be the p x p transmission of an asymptotically
stable time-invariant linear discrete-time control system, for which both the
constant and the variable part of the reference variable have uncorrelated
components. Then in order to obtain a small steady-state mean square tracking
error, the frequency band of each of the p links should contain the frequency
482 Discrete-Time Systems
band of the corresponding component of the reference variable. If the i-th
component of the reference variable, i= 1,2,°::,p, is likely to have a
nonzero constant part, {{T(1) — IW, [TQ) — I}, should be small, pref-
erably zero.
Let us now consider the steady-state mean square input as given by 6-189.
Under assumption 5 this expression can be rewritten as
Cow = ¥ Roa{N DW ND ic
t=
p 7
4+ + | E, OLN (e)W,N(e)};,d0. 6-196
27 i=) =—T ;
Since C,,,, should not be made too large, we extract the following advice.
Design Objective 6.3. Jn order to obtain a small steady-state mean square
input in an asymptotically stable time-invariant linear discrete-time control
system with a p-dimensional reference variable with uncorrelated components,
{N7(e~%*) W,,N(e’*) hea 6-197
should be made small over the normalized frequency band of the i-th component
of the reference variable, fori=1,2,:°-:,p.
As in Chapter 2, we do not impose restrictions on the first term of 6-196
because only the fluctuations of the input variable about its set point need be
considered.
We conclude this section with a discussion of the transient behavior of the
response of the control system to the reference variable. As in the continuous-
time case, we define the settling time of the mean square tracking error, the
mean square input, or any other quantity, as the time it takes this quantity
to reach its steady-state value within a specified accuracy. This settling time
can be expressed as a number of intervals, or in seconds when the sampling
interval is known. Obviously, it is desirable that the mean square tracking
error of a control system settle down to its steady-state value as soon as
possible after start-up or after upsets. We thus have the following design
rule.
Design Objective 6.4. The settling time of the mean square tracking error
of a discrete-time control system should be as short as possible.
The transient behavior of the mean square tracking error, the mean square
input, and other quantities of interest can be computed in a manner similar
to the continuous-time approach. For the various stochastic processes that
influence the evolution of the control system, mathematical models are assumed
6.3 Linear Discrete-Time Control Systems 483
in the form of discrete-time systems driven by discrete-time white noise.
The variance matrix of the state of the system that results by augmenting
the control system difference equation with these models can be computed
according to Theorem 6.22 (Section 6.2.12). This variance matrix yields all
the data required. The example at the end of this section illustrates the pro-
cedure. Often, however, a satisfactory estimate of the settling time of a given
quantity can be obtained by evaluating the transient behavior of the response
of the control system to the constant part of the reference variable alone;
this then becomes a simple matter of computing step responses.
For time-invariant control systems, information about the settling time
can often be derived from the location of the closed-loop characteristic values
of the system. From Section 6.2.4 we know that all responses are linear com-
binations of functions of the form 4’, i = ip, ig + 1, +++, where A is a char-
acteristic value. Since the time it takes |A|’ to reach 1 °% of its initial value of 1
is (assuming that |A| < 1)
Ree eee
2 ( 1 6-198
810 ia]
time intervals, an estimate of the | % settling time of an asymptotically stable
linear time-invariant discrete-time control system is
max es
; \ 1 6-199
OZ TON near |A,|
time intervals, where 4,,/ = 1, 2,--+,n, are the characteristic values of the
control system. As with continuous-time systems, this formula may give
misleading results inasmuch as some of the characteristic values may not
appear in the response of certain variables.
We conclude this section by pointing out that when a discrete-time contro]
system is used to describe a sampled continuous-time system the settling
time as obtained from the discrete-time description may give a completely
erroneous impression of the settling time for the continuous-time system.
This is because it occasionally happens that a sampled system exhibits quite
satisfactory behavior at the sampling instants, while between the sampling
instants large overshoots appear that do not settle down for a long time. We
shall meet examples of such situations in later sections.
Example 6.12. Digital position control system with proportional feedback
We illustrate the results of this section for a single-input single-output
system only, for which we take the digital position control system of Example
6.11. Here the steady-state tracking properties can be analyzed by considering
484 Discrete-Time Systems
the scalar transmission 7(z), which is easily computed and turns out to be
given by
0.003396A(z + 0.8575)
T(z) 6-200
~ (2 — 1)(z — 0.6313) + 0.003396A(z + 0.8575)
In Fig. 6.9 plots are given of |T(ei”4)| for A = 0.1 s, and for values of A
between 5 and 100 V/rad. It is seen from these plots that the most favorable
value of A is about 15 V/rad; for this value the system bandwidth is maximal
without the occurrence of undesirable resonance effects.
10 i
[Tie Jw4)|
] A=100
0.1
A=50
A= 25
A= 15
A= 10
A=5
0.01
0 5 10
w ——= (rad/s)
Fig. 6.9. The transmissions of the digital position control system for various values of the
gain factor A.
To compute the mean square tracking error and the mean square input
voltage, we assume that the reference variable can be described by the model
rai + 1) = 0.9802r(i) + w(i). 6-201
Here w forms a sequence of scalar uncorrelated stochastic variables with
variance 0.0392 rad’. With a sampling interval of 0.1 s, this represents a
sampled exponentially correlated noise process with a time constant of 5 s.
The steady-state rms value of r can be found to be | rad (see Example 6.9).
With the simple feedback scheme of Example 6.11, the input to the plant
is given by
(i) = Ar(i) — AE), 6-202
which results in the closed-loop difference equation
0.94906 0.08015 0.05094
ai+1)= x(i | ri). 6-203
—0.9462 0.6313 0.9462
Here the value 2 = 15 V/rad has been substituted. Augmenting this equation
6.3 Linear Discrete-Time Control Systems 485
with 6-201, we obtain
&(i + 1) 0.94906 0.08015 0.05094\ /€,(i) 0
Ei + 1) ] = | —0.9462 0.6313 0.9462 E(t) | + | 0 Jw).
rG@+ 1) 0 0 0.9802 r(i) |
6-204
We now define the variance matrix
&(i)
QO(i) = Ey | &() |(40, €2(), r@) }- r(i)
6-205
Here it is assumed that E{x(i,))} = 0 and E{r(ij)} = 0, so that x(i) and r(i)
have zero means for all i. Denoting the entries of Q(/) as Q,,(i), j, k.= 1, 2, 3,
the mean square tracking error can be expressed as
C.@ = E[&@ — rOP}
= EE? ()} — 2E{E Mr} + BPO}
= Q1,(i) — 20,3(1) + Q33(7)
Por 4
=tri/Qi)| 0 oO o}f}. 6-206
=i. ©0nd 1
For the mean square input, we have
C.L.@) = Kw@} = BP [r@ — &@P} = ?C,0. 6-207
For the variance matrix Q(i), we obtain from Theorem 6.22 the matrix differ-
ence equation
Q(i + 1) = MQ(i)M7 + NVN?, 6-208
where M is the 3 x 3 matrix and N the 3 x | matrix in 6-204. V is the vari-
ance of w(i). For the initial condition of this matrix difference equation, we
choose 00 0
Q(0)={|0 0 Oo}. 6-209
001
This choice of Q(0) implies that at 7 = 0 the plant is at rest, while the initial
variance of the reference variable equals the steady-state variance | rad?.
Figure 6.10 pictures the evolution of the rms tracking error and the rms
486 Discrete-Time Systems
input voltage. It is seen that the settling time is somewhere between 10 and 20
sampling intervals.
It is also seen that the steady-state rms tracking error is nearly 0.4 rad,
which is quite a large value. This means that the reference variable is not very
well tracked. To explain this we note that continuous-time exponentially corre-
lated noise with a time constant of 5 s (from which the reference variable is
1 15
rms cS
tracking input
error voltage
0.5
(rad)
(V)
0 0
0 10 20
sampling instant | ——>
Fig. 6.10. Rms tracking error and rms input voltage for the digital position control
system.
derived) has a 1 % cutoff frequency of 63.66/5 = 12.7 rad/s (see Section 2.5.2).
The digital position servo is too slow to track this reference variable properly
since its 1 °%% cutoff frequency is perhaps 1 rad/s. We also see, however, that
the steady-state rms input voltage is about 4 V. By assuming that the maxim-
ally allowable rms input voltage is 25 V, it is clear that there is considerable
room for improvement.
Finally, in Fig. 6.11 we show the response of the position digital system
to a step of | rad in the reference variable. This plot confirms that the settling
time of the tracking error is somewhere between 10 and 20 time intervals,
i
position
C()
(rod)
0
10 20
sampling instant | ——s
Fig. 6.11. The response of the digital position control system to a step in the reference
variable of 1 rad.
6.3 Linear Discrete-Time Control Systems 487
depending upon the accuracy required. From the root locus of Fig. 6.8, we
see that the distance of the closed-loop poles from the origin is about 0.8.
The corresponding estimated 1% settling time according to 6-199 is 20.6
time intervals.
6.3.4 Further Aspects of Linear Discrete-Time Control System
Performance
In this section we briefly discuss other aspects of the performance of linear
discrete-time control systems. They are: the effect of disturbances; the effect
of observation noise; and the effect of plant parameter uncertainty. We can
carry Out an analysis very similar to that for the continuous-time case. We
very briefly summarize the results of this analysis. To describe the effect of
the disturbances on the mean square tracking error in the single-input single-
output case, it turns out to be useful to introduce the sensitivity function
1 SQ) 6-210
1 + H(z)G(z)
where
H(z) = D(zI — A)"B+ E is the open-loop transfer function of the plant, and
6-211
G(z) = F(zI — L)'K, + H, 6-212
is the transfer function of the feedback link of the controller. Here it is
assumed that the controlled variable of the plant is also the observed vari-
able, that is, in 6-171 C = D and E, = E, = E. To reduce the effect of the
disturbances, it turns out that |S(e?®)| must be made small over the frequency
band of the equivalent disturbance at the controlled variable. If
iste ex dl for all0O <0 <7, 6-213
the closed-loop system always reduces the effect of disturbances, no matter
what their statistical properties are. If constant disturbances are to be
suppressed, S(1) should be made small (this statement is not true without
qualification if the matrix A has a characteristic value at 1). In the case of a
multiinput multioutput system, the sensitivity function 6-210 is replaced with
the sensitivity matrix
Sz) = + H@G@Y", 6-214
and the condition 6-213 is replaced with the condition
ST(e-)W,S(e) <W, forall0<60<7, 6-215
where W, is the weighting matrix of the mean square tracking error.
488 Discrete-Time Systems
In the scalar case, making S(e”) small over a prescribed frequency band
can be achieved by making the controller transfer function G(e”) large over
that frequency band. This conflicts, however, with the requirement that the
mean square input be restricted, that the effect of the observation noise be
restrained, and, possibly, with the requirement of stability. A compromise
must be found.
The condition that S(e”) be small over as large a frequency band as pos-
sible also ensures that the closed-loop system receives protection against para-
meter variations. Here the condition 6-213, or 6-215 in the multivariable
case, guarantees that the effect of small parameter variations in the closed-
loop system is always less than in an equivalent open-loop system.
6.4 OPTIMAL LINEAR DISCRETE-TIME STATE
FEEDBACK CONTROL SYSTEMS
6.4.1 Introduction
In this section a review is given of linear optimal control theory for discrete-
time systems, where it is assumed that the state of the system can be com-
pletely and accurately observed at all times. As in the continuous-time
case, much of the attention is focused upon the regulator problem, although
the tracking problem is discussed as well. The section is organized along the
lines of Chapter 3.
6.4.2 Stability Improvement by State Feedback
In Section 3.2 we proved that a continuous-time linear system can be stabi-
lized by an appropriate feedback law if the system is completely controllable
or stabilizable. The same is true for discrete-time systems.
Theorem 6.26. Let
x(i + 1) = Aa(i) + Bu(i) 6-216
represent a time-invariant linear discrete-time system, Consider the time-
invariant control law
u(i) = —Fx(i). 6-217
Then the closed-loop characteristic values, that is, the characteristic values of
A — BF, can be arbitrarily located in the complex plane (within the restriction
that complex characteristic values occur in complex conjugate pairs) by
choosing F suitably if and only if 6-216 is completely controllable. It is possible
to choose F such that the closed-loop system is stable if and only if 6-216 is
stabilizable.
6.4 Optimal Discrete-Time State Feedback 489
Since the proof of the theorem depends entirely on the properties of the
matrix A — BF, it is essentially identical to that for continuous-time systems.
Moreover, the computational methods of assigning closed-loop poles are the
same as those for continuous-time systems.
A case of special interest occurs when all closed-loop characteristic values
are assigned to the origin. The characteristic polynomial of A — BF then is
of the form
det (I — A + BF) = 2", 6-218
where n is the dimension of the system. Since according to the Cayley-
Hamilton theorem every matrix satisfies its own characteristic equation, we
must have
(A — BF)” = 0. 6-219
In matrix theory it is said that this matrix is nilpotent with index n. Let
us consider what implications this has. The state at the instant 7 can be ex-
pressed as
a(i) = (A — BF)'x(0). 6-220
This shows that, if 6-219 is satisfied, any initial state (0) is reduced to the
zero state at or before the instant n, that is, in m steps or less (Cadzow, 1968;
Farison and Fu, 1970). We say that a system with this property exhibits a
state deadbeat response. In Section 6.4.7 we encounter systems with output
deadbeat responses.
The preceding shows that the state of any completely controllable time-
invariant discrete-time system can be forced to the zero state in at most n
steps, where 7 is the dimension of the system. It may very well be, however,
that the control law that assigns all closed-loop poles to the origin leads to
excessively large input amplitudes or to an undesirable transient behavior.
We summarize the present results as follows.
Theorem 6.27. Let the state difference equation
a(i + 1) = Ax(i) + Bu(i) 6-221
represent a completely controllable, time-invariant, n-dimensional, linear
discrete-time system. Then any initial state can be reduced to the zero state in at
most n steps, that is, for every x(0) there exists an input that makes x(n) = 0.
This can be achieved through the time-invariant feedback law
u(i) = —Fx(i), 6-222
where F is so chosen that the matrix A — BF has all its characteristic values
at the origin.
490 Discrete-Time Systems
Example 6.13. Digital position control system
The digital positioning system of Example 6.2 (Section 6.2.3) is described
by the state difference equation
1 0.08015 0.003396\
AoA ( 0.6313 | is aos Ne sae
The system has the characteristic polynomial
(z — 1)(2 — 0.6313) = 2% — 1.6313z + 0.6313. 6-224
In phase-variable canonical form the system can therefore be represented as
0 1 0
“(hy a'(i) + (i). 6-225
—0.6313 1.6313 1
The transformed state 2’ (i) is related to the original state x(i) by x(i) = Tx'(i),
where by Theorem 1.43 (Section 1.9) the matrix T can be found to be
0.002912 0.003396
( : 6-226
—0.06308 0.06308
It is immediately seen that in terms of the transformed state the state dead-
beat control law is given by
(i) = —(—0.6313, 1.6313)2’(i). 6-227
In terms of the original state, we have
(i) = — (—0.6313, 1.6313)T x(a), 6-228
or
(i) = —(158.5, 17.33)a(i). 6-229
In Fig. 6.12 the complete response of the deadbeat digital position control
system to an initial condition ~(0) = col (0.1, 0) is sketched, not only at the
sampling instants, but also at the intermediate times. This response has been
obtained by simulating the continuous-time positioning system while it is
controlled with piecewise constant inputs obtained from the discrete-time
control law 6-229. It is seen that the system is completely at rest after two
sampling periods.
6.4.3 The Linear Discrete-Time Optimal Regulator Problem
Analogously to the continuous-time problem, we define the discrete-time
regulator problem as follows.
Definition 6.16. Consider the discrete-time linear system
a(i + 1) = A(i)a(i) + B(i)u(i), 6-230
6.4 Optimal Discrete-Time State Feedback 491
0.1
angular
position
E,(t)
(rad)
0
0 01 0.2 0.3
t —— (s)
) 0.1 0.2 0.3
0
angular
velocity
Ea (t)
rad )
=-7b
10
input [
voltage
L(t)
Ne lor 0.2 0.3
t——=—— {6
(V)
> (H(0h—=
O————l
Fig. 6.12. State deadbeat response of the digital position control system.
where
with the controlled variable
Xp) = Xo, 6-231
2(i) = D(i)a(i). 6-232
Consider as well the criterion
%i—1 > 27 + Rai + Dei + 1) + u7* Ru] + 27(i,)Pi2(i,), 6-233
where R,i+1)>0 and RO) >0 for i=, in +1,°:-,4,—1, and
P, > 0. Then the problem of determining the input u(i) for i = ip,ig + 1,°°° ,
i, — 1, is called the discrete-time deterministic linear optimal regulator problem.
492 Discrete-Time Systems
If all matrices occurring in the problem formulation are constant, we refer to
it as the time-invariant discrete-time linear optimal regulator problem.
It is noted that the two terms following the summation sign in the criterion
do not have the same index. This is motivated as follows. The initial value of
the controlled variable z(i)) depends entirely upon the initial state x(i)) and
cannot be changed. Therefore there is no point in including a term with
z(i)) in the criterion. Similarly, the final value of the input u(i,) affects only
the system behavior beyond the terminal instant i,; therefore the term in-
volving u(i,) can be excluded as well. For an extended criterion, where the
criterion contains a cross-term, see Problem 6.1.
It is also noted that the controlled variable does not contain a direct link
in the problem formulation of Definition 6.16, although as we saw in Section
6.2.3 such a direct link easily arises when a continuous-time system is dis-
cretized. The omission of a direct link can be motivated by the fact that
usually some freedom exists in selecting the controlled variable, so that often
it is justifiable to make the instants at which the controlled variable is to be
controlled coincide with the sampling instants. In this case no direct link
enters into the controlled variable (see Section 6.2.3). Regulator problems
where the controlled variable does have a direct link, however, are easily
converted to the formulation of Problem 6.1.
In deriving the optimal control law, our approach is different from the
continuous-time case where we used elementary calculus of variations; here
we invoke dynamic programming (Bellman, 1957; Kalman and Koepcke,
1958). Let us define the scalar function o[x(i), i] as follows:
41—1
Nerney 20 G+ DRG + De + 1)
of2(i), i] = + uF(DRDuG) + eM Pix] 6-234
for? = 75, io + | Rte ena 8
We see that o[z(i), i] represents the minimal value of the criterion, computed
over the period 7,i + 1,--+,%,, when at the instant 7 the system is in the state
a(i). We derive an iterative equation for this function. Consider the instant
i — 1. Then if the input u(i — 1) is arbitrarily selected, but u(i), u(i + 1),---,
u(i, — 1) are chosen optimally with respect to the state at time 7, we can
write for the criterion over the period i — 1,i,+++, i:
2. ¥ BG + DRG + De +1) + uP(DR)uN] + 27i)P,2x(i))
j=i-1
= [27()R,(i)2(i) + u? i — 1)RAi — 1)u(i — 1)] + o[ax(i), i]. 6-235
6.4 Optimal Discrete-Time State Feedback 493
Obviously, to determine u°(i — 1), the optimal input at time i— 1, we
must choose u(i — 1) so that the expression
2" ()Ree(i) + ui — 1)Reu(li — 1) + ofz(), i] 6-236
is minimized. The minimal value of 6-236 must of course be the minimal
value of the criterion evaluated over the control periodsi — 1, i,-+-,i, — 1.
Consequently, we have the equality
o[x(i — 1), i — 1)] = min {27()R,(Hz(i)
u(i—1)
+ u*(i — 1)R,(i — 1)u(i — 1) + o[x(), i]}. 6-237
By using 6-230 and 6-232 and rationalizing the notation, this expression takes
the form
o(a, i — 1)=min{[A(i— 1)e + Bi — 1)uJ’R,()[ACi — 1)@ + Bi — 1)u]
eR = Disc a= Ae etl) ae 238
where
R,(i) = D7()R,(i) D(i). 6-239
This is an iterative equation in the function o(x, 7). It can be solved in the
order o(x, i), o(v,i, — 1), o(@, i; — 2),+*+, since o(a,i,) is given by
6-234. Let us attempt to find a solution of the form
a(x, i) = a* P(i)zx, 6-240
where P(i), i = ip, ig + 1,°-+ , i, 18 a sequence of matrices to be determined.
From 6-234 we immediately see that
PG ik 6-241
Substitution of 6-240 into 6-238 and minimization shows that the optimal
input is given by
u(i — t= —F(i— 1)x(i — 1), — lo + UI 210 ihe 6-242
where the gain matrix F(i — 1) follows from
F(i — 1) = {R,(i — 1) + B7(i — 1[R,(i) + P()IBGi — 1)}*
- BT(i — 1)[R,(i) + P(DJACG — 1). 6-243
The inverse matrix in this expression always exists since R,(i — 1) > 0
and a nonnegative-definite matrix is added. Substitution of 6-242 into
6-238 yields with 6-243 the following difference equation in P(i):
PG == 470 — DIR + POIAG = 1) — BG — 1)FG — 1),
Pay Lye tsi. 6-244
494 Discrete-Time Systems
It is easily verified that the right-hand side is a symmetric matrix.
We sum up these results as follows.
Theorem 6.28. Consider the discrete-time deterministic linear optimal
regulator problem. The optimal input is given by
u(i) = —F(i)ax(i), i=in 1,754 —2b 6-245
where
F(i) = {R,(i) + BT(D[Ri(i + 1) + Pi + DIB} *
- B7(i)[R\(i + 1) + P(i+ IIA). 6-246
Here the inverse always exists and
R,G). = D7 @MRAD)DG),. i. sig Pip + 2.7772. 6247
The sequence of matrices P(i), i = ip, ig + 1,°°* , i, — 1, satisfies the matrix
difference equation
P(i) = A*(i)[RiGi + 1) + PG + DIAG) — BOF,
1 = lo, ig + it. Tis ly = il. 6-248
with the terminal condition
Pt.) = Pe 6-249
The value of the criterion 6-233 achieved with this control law is given by
We note that the difference equation 6-248 is conveniently solved backward,
where first F(i) is computed from P(i + 1) through 6-246, and then P(i) from
P(i + 1) and F(i) through 6-248. This presents no difficulties when the aid of
a digital computer is invoked. Equation 6-248 is the equivalent of the con-
tinuous-time Riccati equation.
It is not difficult to show that under the conditions of Definition 6.16 the
solution of the discrete-time deterministic linear optimal regulator problem
as given in Theorem 6.28 always exists and is unique.
Example 6.14. Digital position control system
Let us consider the digital positioning system of Example 6.2 (Section
6.2.3). We take as the controlled variable the position, that is, we let
C(i) = (1, O)a(i). 6-251
6.4 Optimal Discrete-Time State Feedback 495
The following criterion is selected. Minimize
7a1—1
S(ICG+ D+ pO. 6-252
i=0
Table 6.1 shows the behavior of the gain vector F(i) for i; = 10 and p =
0.00002. We see that as i decreases, F(i) approaches a steady-state value
F = (10/4, 12.66), 6-253
The response of the corresponding steady-state closed-loop system to the
initial state ~(0) = col (0.1, 0) is given in Fig. 6.13.
Table 6.1 Behavior of the Feed-
back Gain Vector F(i) for the
Digital Position Control System
~.
F(i)
(107.7, 8.63)
(114.0, 12.66)
(109.4, 12.58)
(110.3, 12.64)
(110.4, 12.66)
(110.4, 12.66)
(110.4, 12.66)
(110.4, 12.66)
(110.4, 12.66)
Soe NwWHRUNA ~1 CO 0
(110.4, 12.66)
6.4.4 Steady-State Solution of the Discrete-Time Regulator Problem
In this section we study the case where the control period extends from i, to
infinity. The following results are in essence identical to those for the con-
tinuous-time case.
Theorem 6.29. Consider the discrete-time deterministic linear optimal
regulator problem and its solution as given in Theorem 6.28. Assume that
A(i), B(i), RiGi + 1), and R,(i) are bounded for i > iy, and suppose that
RG+1)ea, ROS fl, ib, 6-254
where « and f are positive constants.
(i) Then if the system 6-230 is either
(a) completely controllable, or
(b) exponentially stable,
496 Discrete-Time Systems
0.1
ongulor
Position
£4())
(rad)
0
0 10
sampling instant | ——==
0 10
0
angular
velocity
Eli)
05
rd (£94)
sampling instant | —— =
Ofo 10
rnput
voltage
H(i)
(V)
a Fig. 6.13. Response of the optimal digi-
tal position control system to the initial
condition «(0) = col(0.1, 0).
the solution P(i) of the difference equations 6-246 and 6-248 with the terminal
condition P(i,) = 0 converges to a nonnegative-definite sequence of matrices
P(i) as i, > ©, which is a solution of the difference equations 6-246 and 6-248.
(ii) Moreover, if the system 6-230, 6-232 is either
(c) both uniformly completely controllable and uniformly completely
reconstructible, or
(d) exponentially stable,
the solution P(i) of the difference equations 6-246 and 6-248 with the terminal
condition P(i,) = P, converges to P(i) as i, > 00 for any P, > 0.
6.4 Optimal Discrete-Time State Feedback 497
The stability of the steady-state control law that corresponds to the steady-
state solution P is ascertained from the following result.
Theorem 6.30. Consider the discrete-time deterministic linear optimal
regulator problem and suppose that the assumptions of Theorem 6.29 concerning
A, B, R,, R3, and Ry are satisfied. Then if the system 6-230, 6-232 is either
(a) uniformly completely controllable and uniformly completely recon-
structible, or
(b) exponentially stable,
the following facts hold.
(i) The steady-state optimal control law
u(i) = —F(ia(i), 6-255
where F(i) is obtained by substituting P(i) for P(i) in 6-246, is exponentially
stable.
(ii) The steady-state optimal control law 6-255 minimizes
lim | > [27(i + IR3(i + DeGit+ 1) + u7?(DR,(i)u(i)] + x7 (i,)Prx(i,)} 6-256
417 © \i=tg
for all P, > 0. The minimal value of 6-256, which is achieved by the steady-state
optimal control law, is given by
x! (ig) Pip) (ig). 6-257
The proofs of these theorems can be given along the lines of Kalman’s
proofs (Kalman, 1960) for continuous-time systems. The duals of these
theorems (for reconstruction) are considered by Deyst and Price (1968).
In the time-invariant case, the following facts hold (Caines and Mayne,
1970; 1971).
Theorem 6.31. Consider the time-invariant discrete-time linear optimal
regulator problem. Then if the system is both stabilizable and detectable the
following facts hold.
(i) The solution P(i) of the difference equations 6-246 and 6-248 with the
terminal condition P(i,) = P, converges to a constant steady-state solution Pp
as i, > © for any P, > 9.
(ii) The steady-state optimal control law is time-invariant and asymptotically
stable,
(iii) The steady-state optimal control law minimizes 6-256 for all P, > 0.
The minimal value of this expression is given by
w" (ig) Px( ip). 6-258
498 Discrete-Time Systems
In conclusion, we derive a result that is useful when studying the closed-loop
pole locations of the steady-state time-invariant optimal regulator. Define
the quantity
pi) = [RG + 1) 4+ PG + DieG + D,
i Sigpig + 1,779 — Ly 6259
where R, and P are as given in Theorem 6.28. We derive a difference equation
for p(i). From the terminal condition 6-249, it immediately follows that
Pi, — 1) = [Ri) + Pile). Furthermore, we have with the aid of 6-248
6-260
pli — 1) = R,(i)x(i) + P(i)x(i)
= R,(i)u(i) + A*()[RiG + 1) + PG + DAW — BU)FM)]<@)
= R,(i)e(i) + AT(i)[RiG + 1) + PG + I)e(i + 1)
= R,(i)x(i) + AT(i)p(i). 6-261
Finally, we express ui) in terms of p(i). Consider the following string of
equalities
— RB") p() = —Re'()B()[RG + 1) + P+ Die + 1)
I
— Re @B(H)IRG + 1) + PU + DILA@2(H) + BHU]
= —R,*(i)B"(i)[Rii + 1) + Pi + DIA(2(i)
—Ry()B*(i)[RiGi + 1) + PG + 1)]B)u°(i). 6-262
Now from 6-246 it follows that
BT(i)[R\G + 1) + PGi + DIA(@a(i)
I
{Ro(i) + B*()[R,(i + 1) + PG + DIB F()a(i)
—{R(i) + B()[R,(i + 1) + P(E + 1B) Ww(i). 6-263
Substitution of this into 6-262 yields
—Rz'(i)B7(i)p(i) = ui). 6-264
Inserting u°(i) as given here into the state difference equation, we obtain the
following two-point boundary-value problem
oi + 1) = A()x(i) — BO)RFWB?()p(), i= ggg +1,---, iy — 1,
pli — 1) = R,(i)x(i) + A*(i)p(d, i=i9+1,i9 +2,°°-,i,—1
X(ig) = Xp,
p(iy — 1) = [Ri(i) + P,)(i,). 6-265
6.4 Optimal Discrete-Time State Feedback 499
We could have derived these equations directly by a variational approach to
the discrete-time regulator problem, analogously to the continuous-time
version.
Let us now consider the time-invariant steady-state case. Then p(i) is
defined by
pi) = (R, + P)zli + 1), b= 1g, tg byes. In the time-invariant case the difference equations 6-265 take the form
6-266
a(i + 1) = Ax(i) — BRz'B" p(i), Pe aigete ye =o,
pli = 1) = Rial’) + AT Ui), : a : -2
ESC ee eae
Without loss of generality we take ij = 0; thus we rewrite 6-267 as
a(i + 1) = Ax(i) — BRz'B"p(i), i= 0;1,2,°--, 6-268
PY) =ReG Fi) ApG +1), 1=0,1,2,---.
We study these difference equations by z-transformation. Application of the
z-transformation to both equations yields
zX(z) — 2%) = AX(z) — BR, B*P(2),
6-269
P(z) = zR,X(z) — 2Ry% + zATP(z) — zAT py,
where 7% = x(0), Po = p(O), and X(z) and P(z) are the z-transforms of x and
Pp, tespectively. Solving for X(z) and P(z), we write
X(z) a) =A, oBRe Bo \= Bi.
= : 6-270
P(z) —R, 2 ’1—At —Rity— A“ ps
When considering this expression, we note that each component of X(z) and
P(z) is a rational function in z with singularities at those values of 2 where
2b =A. BRy AB?
det nl 6-271
—R, Selb se At
Let z;, 7 = 1,2,--+-, denote the roots of this expression, the left-hand side
of which is a polynomial in z and 1/2. If z, is a root, 1/z,; also is a root. More-
over, zero can never be a root of 6-271 and there are at most 2” roots (n is
the dimension of the state x). It follows that both 2(7) and p(i) can be de-
scribed as linear combinations of expressions of the form 2,", iz,;’, i?z,;",-°-,
for all values of j. Terms of the form i*z,’, k = 0,1,---,7—1, occur when
z; has multiplicity /. Now we know that under suitable conditions stated in
Theorem 6.31 the steady-state response of the closed-loop regulator is
asymptotically stable. This means that the initial conditions of the difference
equations 6-268 are such that the coefficients of the terms in x(i) with powers
of z; with |z,| > 1 are zero. Consequently, a(i) is a linear combination of
500 Discrete-Time Systems
powers of those roots z; for which |z,| < 1. This means that these roots are
characteristic values of the closed-loop regulator. Now, since 6-271 may have
less than 2n roots, there may be less than n roots with moduli strictly less
than 1 (it is seen in Section 6.4.7 that this is the case only when A has one or
more characteristic values zero). This leads to the conclusion that the re-
maining characteristic values of the closed-loop regulator are zero, since z
appears in the denominators of the expression on the right-hand side of
6-270 after inversion of the matrix.
We will need these results later (Section 6.4.7) to analyze the behavior of
the closed-loop characteristic values. We summarize as follows.
Theorem 6.32. Consider the time-invariant discrete-time deterministic linear
optimal regulator problem. Suppose that the n-dimensional system
ai + 1) = Ax(i) + Bu(i), 6-272
aL) = De);
is stabilizable and detectable. Let z;,] = 1,2,°-+:,r, withr <n, denote those
roots of
alas 2 BRS Bt
det ( 270) 6-273
Sp iRaD 27 A>
that have moduli strictly less than 1. Then z;, 7 = 1,2,:+++,1r, constitute r
of the characteristic values of the closed-loop steady-state optimal regulator.
The remaining n — r characteristic values are zero.
Using an approach related to that of this section, Vaughan (1970) gives a
method for finding the steady-state solution of the regulator problem by
diagonalization.
Example 6.15. Siirred tank
Consider the problem of regulating the stirred tank of Example 6.3
(Section 6.2.3) which is described by the state difference equation
0.95124 «40 . 4.877 4.877
xi+1)= |
x(i)
0 0.9048 —1.1895 3.569 Ju. 6-274
We choose as controlled variables the outgoing flow and the concentration,
that is, 0.01 0
=| ‘ }ooo. 6-275
I
The criterion is given by
¥ Bt + 1)R32(i + 1) + u7(i)Rou(d)]. 6-276
6.4 Optimal Discrete-Time State Feedback 501
Exactly as in the continuous-time case of Example 3.9 (Section 3.4.1), we
choose for the weighting matrices
au 0 eel
R3 = and i =p ; 6-277
0 0.02 0-3
where p is a scalar constant to be determined.
The steady-state feedback gain matrix can be found by repeated applica-
tion of 6-246 and 6-248. For p = | numerical computation yields
_ (0.07125 —0.7029
F= 0.01357 0.04548
6-278
The closed-loop characteristic values are 0.5982 + j0.08988. Figure 6.14
shows the response of the closed-loop system to the initial conditions 7(0) =
col (0.1, 0) and 7(0) = col (0, 0.1). The response is quite similar to that of the
corresponding continuous-time regulator as given in Fig. 3.11 (Section 3.4.1).
0.1 01
incremental incremental
volume volume .
‘zi ey
(m3) (m3)
0 Ol a vee oe
‘ . ae) 0 : ; 10
sompling instant | —— sompling instant | —=—
incremental O1fF incremental 0.1
concentration concentration
b2 §2
k mol k mol
(met) (meh)
0 Se ee ae ee 0
0 10 0 10
sampling instont | —=m— sompling instont | —=—
Fig. 6.14. Closed-loop responses of the regulated stirred tank, discrete-time version.
Left column: Responses of volume and concentration to the initial conditions § (0) =
0.1m? and &(0) = 0 kmol/m?. Right column: Responses of volume and concentration
to the initial conditions €,(0) = 0 m® and &,(0) = 0.1 kmol/m’.
502 Discrete-Time Systems
6.4.5 The Stochastic Discrete-Time Linear Optimal Regulator
The stochastic discrete-time linear optimal regulator problem is formulated
as follows.
Definition 6.17. Consider the discrete-time linear system
a(i + 1) = A(i)e(i) + Bu) + wid),
E(t) = kgs 6-279
where w(i), i = ip, in + 1,°°+, i, — 1, constitutes a sequence of uncorrelated,
zero-mean stochastic variables with variance matrices V(i), i= ip,***,
i, — 1. Let
21) = D@)aG) 6-280
be the controlled variable. Then the problem of minimizing the criterion
4-1 BS BME + DRG + NaC + 1) + uM ORADUO] + oT(i,)Pyx(i)}, 6-281
where R,(i + 1) > 0, Ro(i) > O for i = iy, +--+, i, — 1 and P, > O, is termed
the stochastic discrete-time linear optimal regulator problem. If all the matrices
in the problem formulation are constant, we refer to it as the time-invariant
stochastic discrete-time linear optimal regulator problem.
As in the continuous-time case, the solution of the stochastic regulator prob-
lem is identical to that of the deterministic equivalent (Astrém, Koepcke,
and Tung, 1962; Tou, 1964; Kushner, 1971).
Theorem 6.33. The criterion 6-281 of the stochastic discrete-time linear
optimal regulator problem is minimized by choosing the input according to
the control law
u(i) = —F(i)x(i), i=,i9 + 1,°°-,4 — 1, 6-282
where
F(i) = {R,(i) + B*()[RGi + 1) + P+ DIBO}"
- BT (i)[R\G + 1) + P(i+ 1)JA(i). 6-283
The sequence of matrices P(i), i = ig, +++ , i; — 1, is the solution of the matrix
difference equation
P(i) = A7*()[R\Gi + 1) + P(i+ DI[AM — BDF),
FRre Wek eel oon Peta me eg oN
with the terminal condition
PU ay. 6-285
Here
R,(i) = D*(i)R;(i) D(i). 6-286
6.4 Optimal Discrete-Time State Feedback 503
The value of the criterion 6-281 achieved with this control law is given by
a1
x9* Pip) ty + Ae Ors DRG) tak C)it: 6-287
I=i0
This theorem can be proved by a relatively straightforward extension of the
dynamic programming argument of Section 6.4.3. We note that Theorem
6.33 gives the linear control law 6-282 as the optimal solution, without
further qualification. This is in contrast to the continuous-time case (Theorem
3.9, Section 3.6.3), where we restricted ourself to linear control laws.
As in the continuous-time case, the stochastic regulator problem encom-
passes regulator problems with disturbances, tracking problems, and track-
ing problems with disturbances. Here as well, the structure of the solutions of
each of these special versions of the problem is such that the feedback gain
from the state of the plant is not affected by the properties of the disturbances
of the reference variable (see Problems 6.2 and 6.3).
Here too we can investigate in what sense the steady-state control law
is optimal. As in the continuous-time case, it can be surmised that, if it exists,
the steady-state control law minimizes
io+N-1 \
lim = EL > [(e?@+ DRG + eG + 1) + u*@DR ADU]
| 6-288
N->o t=70
(assuming that this expression exists for the steady-state optimal control
law) with respect to all linear control laws for which this expressions exists.
The minimal value of 6-288 is given by
ig tN
Lider ee I = 6-289
N>o« N Faia
where P(j), 7 > i, is the steady-state solution of 6-284. In the time-invariant
case, the steady-state control law moreover minimizes
lim Efz7(i + 1)R32(i + 1) + u7(i)R.u(d} 6-290
with respect to all time-invariant control laws. The minimal value of 6-290
is given by
tr [((R, + P)V]. 6-291
Kushner (1971) discusses these facts.
Example 6.16. Stirred tank with disturbances
In Example 6.10 (Section 6.2.12), we modeled the stirred tank with dis-
turbances in the incoming concentrations through the stochastic difference
equation 6-168. If we choose for the components of the controlled variable the
504 Discrete-Time Systems
outgoing flow and the concentration in the tank, we have
0.01 0 0 0
2(i) = x(i). 6-292
Piet
We consider the criterion
{SB + 1)Ra2(i + 1) + uM RauC 6-293
where the weighting matrices Rg and R, are selected as in Example 6.15. For
p = 1 numerical computation yields the steady-state feedback gain matrix
be —0.07029 —0.009772 ane
6-294
0.01357 0.04548 0.008671 0.003052
Comparison with the solution of Example 6.15 shows that, as in the contin-
uous-time case, the feedback link of the control law (represented by the first
two columns of F) is not affected by introducing the disturbances into the
model (see Problem 6.2).
The steady-state rms values of the outgoing flow, the concentration, and
the incoming flows can be computed by setting up the closed-loop system
state difference equation and solving for Q, the steady-state variance matrix
of the state of the augmented system.
6.4.6 Linear Discrete-Time Regulators with Nonzero Set Points and
Constant Disturbances
In this section we study linear discrete-time regulators with nonzero set
points and constant disturbances. We limit ourselves to time-invariant
systems and first consider nonzero set point regulators. Suppose that the
system n(i + 1) = Ax(i) + Bu(i),
z(t) = Dz(i), 6-295
must be operated about the set point
zZ(i) = 2, 6-296
where Z, iS a given constant vector. As in the continuous-time case of Section
3.7.1, we introduce the shifted state, input, and controlled variables. Then the
steady-state control law that returns the system from any initial condition to
the set point optimally, in the sense that a criterion of the form
¥ eG + DRG + 1D) + uw FORw'(d] 6-297
a
zo
6.4 Optimal Discrete-Time State Feedback 505
is minimized, is of the form
u'(i) = — Fx'(i), 6-298
where u’, x’, and z’ are the shifted input, state, and controlled variables,
respectively, and where F is the steady-state feedback gain matrix. In terms
of the original system variables, this control law must take the form
u(i) = — Fa(i) + ug, 6-299
where wu is a constant vector. With this control law the closed-loop system is
described by
a(i + 1) = Ax(i) + Buj,
Ailes DAU): coil
where
A=A-— BF. 6-301
Assuming that the closed-loop system is asymptotically stable, the controlled
variable will approach a constant steady-state value
lim 2) = Aus, 6-302
where H(z) is the closed-loop transfer matrix
H,(2) = D(el — A)"B. 6-303
The expression 6-302 shows that a zero steady-state error is obtained when
Ug is chosen as
uo = H,*(1)Zo, 6-304
provided the inverse exists, where it is assumed that dim (uv) = dim (z). We
call the control law
u(i) = —Fe(i) + Hy'(1)z,(i) 6-305
the nonzero set point optimal control law.
We see that the existence of this control law is determined by the existence
of the inverse of H,(1). Completely analogously to the continuous-time case,
it can be shown that
det [H,(z)] = ¥@) ; 6-306
$e(2)
where ¢,(z) is the closed-loop characteristic polynomial
¢,(z) = det (J — A + BF), 6-307
and where y(z) is the open-loop numerator polynomial; that is, p(z) follows
from
det [H(z)] = ut 6-308
$2)
506 Discrete-Time Systems
Here
H(z) = D(el — A)*1B 6-309
is the open-loop transfer matrix and
p(z) = det (zI — A) 6-310
is the open-loop characteristic polynomial. The relation 6-306 shows that
H,(l) exists provided y(1) # 0. Since H(e’’) describes the frequency response
of the open-loop system, this condition is equivalent to requiring that the
open-loop frequency response matrix have a numerator polynomial that does
not vanish at 6 = 0.
We summarize as follows.
Theorem 6.34. Consider the time-invariant discrete-time linear system
x(i + 1) = Ax(i) + Bu(i),
2(i) = De), 6-311
where dim(z) = dim(u). Consider any asymptotically stable time-invariant
control law
Let H(z) be the open-loop transfer matrix
u(i) = —Fa(i) + up. H(z) = DI — A)*B 6-312
6-313
and H(z) the closed-loop transfer matrix
H(z) = Dial — A + BF)"1B. 6-314
Then H_,(1) is nonsingular and the controlled variable z(i) can under steady-state
conditions be maintained ai any constant set point 2) by choosing
w= Ae (De 6-315
if and only if H(z) has a nonzero numerator polynomial that has no zeroes at
es AN
It is noted that this theorem holds not only for the optimal control law, but
for any stable control law.
Next we very briefly consider regulators with constant disturbances. We
suppose that the plant is described by the state difference and output equa-
tions
ai + 1) = Ax(i) + Bu(i) + v9,
2) = Dae), 6-316
where vo is a constant vector. Shifting the state and input variables, we reach
6.4 Optimal Discrete-Time State Feedback 507
the conclusion that the control law that returns the shifted state optimally
to zero must be of the form
u(i) = —Fax(i) + uj, 6-317
where ug is a suitable constant vector. The steady-state response of the con-
trolled variable with this control law is given by
lim 2(i) = H,(1)ug + DU — A) vy, 6-318
where H,(z) = D(zI — A + BF)“B. It is possible to make the steady-state
response 6-318 equal to zero by choosing
ug = —H,*(1)DU — A). 6-319
provided dim (z) = dim (wv) and H,(1) is nonsingular. Thus the zero-steady-
state-error optimal control law is given by
u(i) = —Fa(i) — HS) Dd — A)“. 6-320
The conditions for the existence of H,-1(1) are given in Theorem 6.34.
The disadvantage of the control law 6-320 is that its application requires
accurate measurement of the constant disturbance v9. This difficulty can be
circumvented by appending to the system an “integral state’? g (compare
Section 3.7.2), defined by the difference relation
git D=q +2), i> i, 6-321
with q(ip) given. Then it can easily be seen that any asymptotically stable
control law of the form
uli) = —F,x(i) — Fog(i) 6-322
suppresses the effect of constant disturbances on the controlled variable,
that is, 2(i) assumes the value zero in steady-state conditions no matter what
the value of vy is in 6-316. Necessary and sufficient conditions for the existence
of such an asymptotically stable control law are that the system 6-316 be
stabilizable, and [assuming that dim (wv) = dim (z)] that the open-loop
transfer matrix possess no zeroes at the origin.
Example 6.17. Digital position control system
In Example 6.6 (Section 6.2.6), we saw that the digital positioning system
of Example 6.2 (Section 6.2.3) has the transfer function
Hine 0.003396(z + 0.8575)
6-323ee Pe 8063.13).
Because the numerator polynomial of this transfer function does not have a
zero at z = 1, a nonzero set point optimal controller can be obtained. In
508 Discrete-Time Systems
Example 6.14 (Section 6.4.3), we obtained the steady-state feedback gain
vector F = (110.4, 12.66). It is easily verified that the corresponding
nonzero set point optimal control law is given by
wi) = —Fx(i) + 110.4£,, 6-324
where €, is the (scalar) set point. Figure 6.15 shows the response of the
closed-loop system to a step in the set point, not only at the sampling
instants but also at intermediate times, obtained by simulation of the
ongulor
position
E(t)
(rad)
0 0 t—=(s) !
ongulor
velocity
i 05
rod ()
0
t—=—('5)
10
input
voltage
u(t)
(V)
a Fig. 6.15. Responses of the digital position
t—»(s) control system to a step of 0.1 rad in the
set point.
6.4 Optimal Discrete-Time State Feedback 509
continuous-time system. The system exhibits an excellent response, not quite
as fast as the deadbeat response of Fig. 6.12, but with smaller input
amplitudes.
6.4.7 Asymptotic Properties of Time-Invariant Optimal Control Laws
In this section we study the asymptotic properties of time-invariant steady-
state optimal control laws when in the criterion the weighting matrix R, is
replaced with
Ry = pN, 6-325
where p | 0. Let us first consider the behavior of the closed-loop poles.
In Theorem 6.32 (Section 6.4.4) we saw that the nonzero closed-loop char-
acteristic values are those roots of the equation
zl — A BR,*Bt
det =0 6-326
that have moduli less than 1, where R, = D’?R,D. Using Lemmas 1.2
(Section 1.5.4) and 1.1 (Section 1.5.3), we write
(" a4 a
det —R, 2 u—A?
= det (zI — A) det [2 — A™ + R,(zl — A)"BR;'B7]
= det (2J — A) det (z7I — A*)
- det [I + R,(2I — A)“ BR;'B7(e"'I — AtT)"]
= det (2I — A) det (271 — A’)
- det [I + Ry (BT (z71I — AT)“*R,(2I — A) *B]
= det (zI — A) det (z J — A”)
- det E + 4 NOB%(et — AT) DTR, DEI — 4y*B|
p
= 4(z)¢(z") det lF + ; NAAT )RHE) | 6-327
where
(z) = det (2 — A) is the open-loop characteristic polynomial, and
H(z) = D@I — A)"*B 6-328
6-329
is the open-loop transfer matrix.
510 Discrete-Time Systems
To study the behavior of the closed-loop characteristic values, let us first
consider the single-input single-output case. We assume that the scalar
transfer function H(z) can be written as
H(z)
md, Bed) 6-330
(2)
where
q a@™=2""*[TT@-—7), mA0, i= 1,2,°°+,4, 6-331
7=1
with q < n, is the characteristic polynomial of the system, and where
Dp
v2) =a2?T[I(z—»), %#0, i=1,2,---,p, 6-332
Ce
with p < s <n — 1, is the numerator polynomial of the system. Then 6-327
takes the form (assuming Rs = | and N = 1):
IT = tr3) ( oe m) + “Tle — »,) (: = n). 6-333
To apply standard root locus techniques, we bring this expression into the
form
1 Aes = ap 7 1
IL @ ~ 2) -—} he = IL@—»)(»--). 6-334
i Z y IT (—*) ay
We conclude the following concerning the loci of the 2q roots of this ex-
pression, where we assume that g > p (see Problem 6.4 for the case q < p).
1. The 2 loci originate for p = 00 at m, and 1/7,,i=1,2,---,q.
2. As p | 0, the loci behave as follows.
(a) p roots approach the zeroes ,,i = 1,2,°-+:, p;
(b) p roots approach the inverse zeroes 1/»;,i = 1,2,--+, p;
(c) g — p roots approach 0;
(d) the remaining g — p roots approach infinity.
3. Those roots that go to infinity as p | 0 asymptotically are at a distance
D 1/(q—p)
2 LI 3 6-335
f Il 7;
g=1
6.4 Optimal Discrete-Time State Feedback 511
from the origin. Consequently, those roots that go to zero are asymptotically
at a distance
q 1/(q—p)
p ile ae 6-336
a Il pail
from the origin.
Information about the optimal closed-loop poles is obtained by selecting
those roots that have moduli less than 1. We conclude the following.
Theorem 6.35. Consider the steady-state solution of the time-invariant
single-input single-output discrete-time linear regulator problem. Let the
open-loop transfer function be given by
Dp az’? TT (2 — »)
i=1
H@)= - f oe 0, 6-337
TT (2 — 1m)
Js
where the 7,4 0,i=1,2,°*+,q, are the nonzero open-loop characteristic
values, and v; #0, i=1,2,°:**,p, the nonzero zeroes. Suppose that n >
g>p,n—12>8> pand thatin the criterion 6-233 we have R; = | and R, =
p. Then the following holds.
(a) Of the n closed-loop characteristic values n — gq are always at the origin.
(b) As p | 0, of the g remaining closed-loop characteristic values p approach
the numbers $,,i = 1,2,°°**,p, where
V; if |», | “<< 13
Vay 1 Taare 6-338
Y;
(c) As p| 0, the q — p other closed-loop characteristic values go to zero.
These closed-loop poles asymptotically are at a distance
qa 1/(q—p)
oye ell ;
6-339
ae
Il» j=1
from the origin.
(d) As p > ©, the qnonzero closed-loop characteristic values approach the
numbers @,,1 = 1,2,°** ,qg, where
BONE GP nS 1ee 6-340
512 Discrete-Time Systems
Let us now consider the behavior of the nonzero set point optimal control
law derived in Section 6.4.6. For a single-input single-output system, it is
easily seen that the system transfer function from the (scalar) set point
£,(i) (now assumed to be variable) to the controlled variable (7) is given by
AH
T() = BM ; 6-341
H (1)
where H,(z) is the closed-loop transfer function. As in the continuous-time
case (Section 3.8.2), it is easily verified that we can write
ve
H,(2) = 6-342
Pelz)
where y(z) is the open-loop transfer function numerator polynomial and
$,(z) the closed-loop characteristic polynomial. For y(z) we have
p
p(z) = az? T] ( — »), 6-343
i=1
while in the limit p | 0 we write for the closed-loop characteristic polynomial
$-(2) = oT] (a—y,): 6-344
Substitution into 6-342 and 6-341 shows that in the limit p | 0 the control
system transfer function can be written as
Tie I (: = =) I ( = =) 6-345
n—Ss z i=) Ne A
“— Y,
1 — Vy
Now if the open-loop transfer function has no zeroes outside the unit circle.
the limiting control system transfer function reduces to
T(z) = 6-346
Ome
This represents a pure delay, that is, the controlled variable and the variable
set point are related as follows:
Ci) = Oli — @ — 5). 6-347
We summarize as follows.
Theorem 6.36. Consider the nonzero set point optimal control law, as
described in Section 6.4.6., for a single-input single-output system. Let R; = 1
and R, = p. Then as p |, the control system transmission (that is, the
transfer function of the closed-loop system from the set point to the controlled
6.4 Optimal Discrete-Time State Feedback 513
variable) approaches roo SHEED CES, Zo" =i 2 — 9; 1 — »,
where the #;,i = 1,2,-++,p are derived from the nonzero open-loop zeroes
Y,,i= 1,2,°--, p, as indicated in 6-338, and where n is the dimension of the
system and s the degree of the numerator polynomial of the system. If the
open-loop transfer function has no zeroes outside the unit circle, the limiting
system transfer function is
1
T(z) = 6-349
ie
—s 2
which represents a pure delay.
We see that, if the open-loop system has no zeroes outside the unit circle,
the limiting closed-loop system has the property that the response of the
controlled variable to a step in the set point achieves a zero tracking error
after n — s time intervals. We refer to this as output deadbeat response.
We now discuss the asymptotic behavior of the closed-loop characteristic
values for multiinput systems. Referring back to 6-327, we consider the
roots of
$(2)6(2) det E aL NAHM) RGHE) |. 6-350
Apparently, for p = oo those roots of this expression that are finite are the
roots of
b(z)p(z4). 6-351
Let us write
qd
d(z) = 2" * [[ @ — my), j=1
6-352
and assume that 7, 4 0,i = 1,2,---,g. Then we have
qd
d(2)¢(2") = TI @ — a)(e* — »), tt
6-353
which shows that 2q root loci of 6-350 originate for p = oo at the nonzero
characteristic values of the open-loop system and their inverses.
Let us now consider the roots of 6-350 as p | 0. Clearly, those roots that
stay finite approach the zeroes of
b(z)b(z7) det [H"(2-)R,H(2)]. 6-354
Let us now assume that the input and the controlled variable have the same
514 Discrete-Time Systems
dimensions, so that H(z) is a square transfer matrix, with
_ ¥®) x
det [H(z)] = cae 6-355
Then the zeroes of 6-354 are the zeroes of
y(z)yp(z). 6-356
Let us write the numerator polynomial p(z) in the form
p
p(z) = a2*? [] (z — »), j=1
6-357
where », # 0,i = 1,2,--+, p. Then 6-356 can be written as
Pp
a T] (2 — »)(2* — »,). 6-358
j=1
This shows that 2p root loci of 6-350 terminate for p = 0 at the nonzero
zeroes ¥;,.1 = b, 2," +”, p, and the inverse zeroes 1/9, 1 = 1, 2,4 <> p.
Let us suppose that g > p (for the case g < p, see Problem 6.4). Then
there are 2q root loci of 6-350, which originate for p = oo at the nonzero
open-loop poles and their inverses. As we have seen, 2p loci terminate for
p = 0 at the nonzero open-loop zeroes and their inverses. Of the remaining
2q — 2p loci, g — p must go to infinity as p | 0, while the other g — p loci
approach the origin.
The nonzero closed-loop poles are those roots of 6-350 that lie inside the
unit circle. We conclude the following.
Theorem 6.37. Consider the steady-state solution of the time-invariant
regulator problem. Suppose that dim (u) = dim (2) and let H(z) be the open-
loop transfer matrix
H(z) = D(z — A)“B. 6-359
Furthermore, let
det [H(2)} = Be) ; (2)
6-360
where
qa
$2) =2"* [[@ — a), 6-361
j=1
with 7, #0, i= 1,2,°++,q, is the open-loop characteristic polynomial.
In addition, suppose that
Dp
p(z) = az” T] (z — »,), i=1
6-362
6.4 Optimal Discrete-Time State Feedback 515
with p = q,.and where y, 4 0, 1 =\1), 2, °- ,p. Finally, set R, = pN where
N > 0 and p is a positive scalar. Then we have the following.
(a) Of the n closed-loop poles, n — q always are at the origin.
(b) As p | 0, of the remaining q closed-loop poles, p approach the numbers
¥;,,0= 1,2,°°* , p, where
Y; WOM? Neste
i= hee
¥;
(c) As p | 0, the g — p other closed-loop poles go to zero.
(d) As p— ©, the q nonzero closed-loop poles approach the numbers #;,
P= 1274.9, were
vg SU Nod,
ie ate 6-364
Sy Wie) eed ca
We note that contrary to the continuous-time case the closed-loop poles
remain finite as the weighting matrix R, approaches the zero matrix.
Similarly, the feedback gain matrix F also remains finite. Often, but not
always, the limiting feedback gain matrix can be found by setting R, = 0 in
the difference equations 6-246 and 6-248 and iterating until the steady-state
value is found (see the examples, and also Pearson, 1965; Rappaport and
Silverman, 1971).
For the response of the closed-loop system with this limiting feedback
law, the following is to be expected. As we have seen, the limiting closed-loop
system asymptotically has m — p characteristic values at the origin. If the
open-loop zeroes are all inside the unit circle, they cancel the corresponding
limiting closed-loop poles. This means that the response is determined by the
n — p poles at the origin, resulting in a deadbeat response of the controlled
variable after n — p steps. We call this an output deadbeat response, in
contrast to the state deadbeat response discussed in Section 6.4.2. If a system
exhibits an output deadbeat response, the output reaches the desired value
exactly after a finite number of steps, but the system as a whole may remain
in motion for quite a long time, as one of the examples at the end of this
section illustrates. If the open-loop system has zeroes outside the unit circle,
the cancellation effect does not occur and as a result the limiting regulator
does not exhibit a deadbeat response.
It is noted that these remarks are conjectures, based on analogy with the
continuous-time case. A complete theory is missing as yet. The examples at
the end of the section confirm the conjectures. An essential difference between
the discrete-time theory and the continuous-time theory is that in the dis-
crete-time case the steady-state solution P of the matrix equation 6-248
516 Discrete-Time Systems
generally does not approach the zero matrix as R, goes to zero, even if the
open-loop transfer matrix possesses no zeroes outside the unit circle.
Example 6.18. Digital position control system
Let us consider the digital positioning system of Example 6.2 (Section
6.2.3). From Example 6.6 (Section 6.2.6), we know that the open-loop
transfer function is
__ 0.003396(z + 0.8575)
H(2) 6-365
Cia 06st)
It follows from Theorem 6.37 that the optimal closed-loop poles approach
0 and —0.8575 as p | 0. It is not difficult to find the loci of the closed-loop
characteristic values. Expression 6-334 takes for this system the form
(z — 1)(z — 0.6313)(z — 1)(z — 1.584)
0.000015 ip 66
2(z + 0.8575)(z + 1.166). 6-366
The loci of the roots of this expression are sketched in Fig. 6.16. Those loci
that lie inside the unit circle are the loci of the closed-loop poles. It can be
Im |
Re —»
Fig. 6.16. Loci of the closed-loop poles and the inverse closed-loop poles for the digital
position control system.
6.4 Optimal Discrete-Time State Feedback 517
found that the limiting feedback gain matrix F, for p = 0 is given by
F, = (294.5, 23.60). 6-367
Let us determine the corresponding nonzero set point optimal control law.
We have for the limiting closed-loop transfer function
H(z) = V2) — 0.003396(2 + 0.8575) _ 0.003396
= = 6-368
$,(z) 2(z + 0.8575) 3
Consequently, H,(1) = 0.003396 and the nonzero set point optimal control
law is
(i) = —Fox(i) + 294.5€,(i). 6-369
Figure 6.17 gives the response of the system to a step in the set point, not
only at the sampling instants but also at intermediate times. Comparing with
the state deadbeat response of the same system as derived in Example 6.13,
we observe the following.
(a) When considering only the response of the angular position at the
sampling instants, the system shows an output deadbeat response after one
sampling interval. In between the response exhibits a bad overshoot, however,
and the actual settling time is in the order of 2 s, rather than 0.1 s.
(b) The input amplitude and the angular velocity assume large values.
These disadvantages are characteristic for output deadbeat control
systems. Better results are achieved by not letting p go to zero. For p=
0.00002 the closed-loop poles are at 0.2288 + 0.3184. The step response
of the corresponding closed-loop system is given in Example 6.17 (Fig. 6.15)
and is obviously much better than that of Fig. 6.17.
The disadvantages of the output deadbeat response are less pronounced
when a larger sampling interval A is chosen. This causes the open-loop zero
at —0.8575 to move closer to the origin; as a result the output deadbeat
control system as a whole comes to rest much faster. For an alternative
solution, which explicitly takes into account the behavior of the system
between the sampling instants, see Problem 6.5.
Example 6.19. Stirred tank with time delay
Consider the stirred tank with time delay of Example 6.4 (Section 6.2.3).
As the components of the controlled variable we choose the outgoing
flow and concentration; hence
0.01 0 0 0
(i) = x(i). 6-370
Geert 0020
0.15
ongulor
position
E y(t)
0.1
(rod)
0.05
0
0 1
+ ——_2(s)
2
angulor
velocity
Eo(t)
]
(fo ) C———— |S)
Ss SH:
40
input
voltage
u(t)
20
(V) 0
0 1
-20
t ———_(s)
-40
Fig. 6.17. Response of the output deadbeat digital position control system to a step in the
set point of 0.1 rad.
518
6.4 Optimal Discrete-Time State Feedback 519
It can be found that the open-loop transfer matrix of the system is
4.877 4.877
2 — 0.9512 2 — 0.9512
H@ = 6-371
— 1.1895 3.569
22 — 0.9048) 2(z — 0.9048)
The determinant of the transfer matrix is
See ee ere — 0.9048) a
Because the open-loop characteristic polynomial is given by
f(z) = 2(2 — 0.9512)(z — 0.9048), 6-373
the numerator polynomial of the transfer matrix is
pz) = 26.62z. 6-374
As a result, two closed-loop poles are always at the origin. The loci of the
two other poles originate for p = 00 at 0.9512 and 0.9048, respectively, and
both approach the origin as p | 0. This means that in this case the output
deadbeat control law is also a state deadbeat control law.
Let us consider the criterion
8 [e7i + 1)Rge(i + 1) + u2(DRou(i)], 6-375
zt
where, as in previous examples,
50° 0 0
Col
Ko = and R, = p : 6-376
0 0.02 O78
When one attempts to compute the limiting feedback law for p = 0 by
setting R, = 0 in the difference equation for P(i) and F(i), difficulties occur
because for certain choices of P, the matrix
R, + BT[R, + P(i + 1)]B 6-377
becomes singular at the first iteration. This can be avoided by choosing a
very small value for p (e.g., p = 10-°). By using this technique numerical
computation yields the limiting feedback gain matrix
0.1463 —0.1720 0.2262 —0.6786
— : 6-378
0.04875 0.1720 —0.2262 0.6786
520 Discrete-Time Systems
volume &,
0.01
(m3)
oO nN oO N
concentration eo
| 0.01 0.01
(kmot/m3) 0 reg ‘ne
flow rate py 0.002 - 0.002
0 r 0
(m3/s) 0 2
NR
- 0.002 - 0,002
N oO No
flow rate 2 0 0 [Pare
(m3/s) - 0,002 -0.002
sampling instant | — am
Fig. 6.18. Deadbeat response of the stirred tank with time delay. Left column: Responses
of volume, concentration, feed no. 1, and feed no. 2 to the initial condition €,(0) = 0.01 m3,
while all other components of the initial state are zero. Right column: Responses of volume,
concentration, feed no. 1, and feed no. 2 to the initial condition §(0) = 0.01 kmo]/m?,
while all other components of the initial state are zero.
In Fig. 6.18 the deadbeat response to two initial conditions is sketched.
It is observed that initial errors in the volume &, are reduced to zero in one
sampling period. For the concentration &, two sampling periods are required;
this is because of the inherent delay in the system.
6.4.8 Sensitivity
In Section 3.9 we saw that the continuous-time time-invariant closed-loop
regulator possesses the property that it always decreases the effect of disturb-
ances and parameter variations as compared to the open-loop system. It is
shown in this section by a counter example that this is not generally the case
6.4 Optimal Discrete-Time State Feedback 521
for discrete-time systems. The same example shows, however, that protection
over a wide range of frequencies can still be obtained.
Example 6.20. Digital angular velocity control
Consider the angular velocity control system of Example 3.3 (Section
3.3.1), which is described by the scalar state differential equation
E(t) = —a&(t) + p(t). 6-379
Let us assume that the input is piecewise constant over intervals of duration
A. Then the resulting discrete-time system is described by
B(i + 1) = e*5() + “(1 — eu), 6-380
where we have replaced €(iA) with &(i) and w(iA) with w(i). With the
numerical values « = 0.5s1, « = 150 rad/(V s?), and A = 0.1 s, we obtain
E(@i + 1) = 0.9512E(i) + 14.64n(i). 6-381
The controlled variable ¢(7) is the angular velocity (7), that is,
c(i) = &(i). 6-382
Let us consider the problem of minimizing
[Ci + 1) + pe). 6-383
M8 i=0
It is easily found that with p = 1000 the steady-state solution is given by
P = 1.456,
F = 0.02240. 6-384
The return difference of the closed-loop system is
J(z) =I + (el — A)BF, 6-385
which can be found to be
Fe eee 6-386
z — 0.9512
To determine the behavior of /(z) for z on the unit circle, set
Ze,
where A = 0.1 is the sampling interval. With this we find
ie yl1.388 — 1.246 cos (wA)
= : 6-387
1.905 — 1.902 cos (wA)
522 Discrete-Time Systems
10
|J|
0 62.8 10e
w— (rad/s)
Fig. 6.19. Behavior of the return difference for a first-order discrete-time regulator.
Figure 6.19 gives a plot of the behavior of |J(e/°>)|. We see that sensitivity
reduction is achieved for low frequencies up to about 7 rad/s, but by no
means for all frequencies. If the significant disturbances occur within the
frequency band up to 7 rad/s, however, the sensitivity reduction may very
well be adequate.
6.5 OPTIMAL LINEAR RECONSTRUCTION OF THE
STATE OF LINEAR DISCRETE-TIME SYSTEMS
6.5.1 Introduction
This section is devoted to a review of the optimal reconstruction of the state
of linear discrete-time systems. The section parallels Chapter 4.
6.5.2 The Formulation of Linear Discrete-Time Reconstruction Problems
In this section we discuss the formulation of linear discrete-time reconstruc-
tion problems. We pay special attention to this question since there are
certain differences from the continuous-time case. As before, we take the
point of view that the linear discrete-time system under consideration is
obtained by operating a linear continuous-time system with a piecewise
constant input, as indicated in Fig. 6.20. The instants at which the input
changes value are given by ¢;,i = 0,1, 2,---, which we call the control
6.5 Optimal Reconstruction of the State 523
|
ut) f |
| pa
| | processing - del
t l
ty tj ti44 time
Fig. 6.20. Relationship of control actuation instant ¢, and observation instant is
instants. These instants form the basic time grid. We furthermore introduce
the observation instants t;, i = 0, 1,2,-++ ,which are the instants at which the
observed variable y(t) of the continuous-time system is sampled. It is assumed
that the observation instant ft; always precedes the control instant t,,,. The
difference t,,, — t; will be called the processing delay; in the case of a control
system, it is the time that is available to process the observation y(t;) in
order to determine the input u(t,,,).
Suppose that the continuous-time system is described by
x(t) = A(t)x(t) + B(t)u(t) + w(t), las 6-388
where w, is white noise with time-varying intensity V,(t). We furthermore
assume that the observed variable is given by
y(t) = C(t) x(t,) + we(ts), Pi Oper 6-389
where the w,(t;), 7 =0,1,2,---, form a sequence of uncorrelated sto-
chastic vectors. To obtain the discrete-time description of the system, we
write
Ae TOE | i 2 Oe 7)B(n) ar |u(t)
ti+a
+| O(t,.4,7)wi(7) dr, 6-390
tr
and
ae
witty = CCH) OC, eta) + [ C4) | “OCH, BC) Ar]
+ C(t) | “@(t!, Dw,(x) dr + w(t), 6-391
where in both cases i = 0, 1, 2,-- +, and where (f, fo) is the transition matrix
of the system 6-388. We see that the two equations 6-390 and 6-391 are of
524 Discrete-Time Systems
the form
ati + 1) = A,xt(i) + Ba@Dut@ + wit),
yi) = C,Hat (i) + Eg@ut@) + wet (i). 6-392
This method of setting up the discrete-time version of the problem has the
following characteristics.
1. In the discrete-time version of the reconstruction problem, we assume
that yt(i) is the latest observation that can be processed to obtain a recon-
structed value for a+(i + 1).
2. The output equation generally contains a direct link. As can be seen
from 6-391, the direct link is absent [i.e., E,(i) = 0] when the processing
delay takes up the whole interval (t;, t;,1).
3. Even if in the continuous-time problem the state excitation noise w,
and the observation noise w, are uncorrelated, the state excitation noise
w,* and the observation noise w,* of the discrete-time version of the problem
will be correlated, because, as can be seen from 6-390, 6-391, and 6-392,
both w,*(i) and w,*(i) depend upon w,(t) for t; << t < tj. Clearly, wy*(@)
and w,*(i) are uncorrelated only if t; = ¢,;, that is, if the processing delay
takes up the whole interval (¢;, t;,,).
Example 6.21. The digital positioning system
Let us consider the digital positioning system of Example 6.2 (Section
6.2.3). It has been assumed that the sampling period is A. We now assume
that the observed variable is the angular displacement &,, so that in the
continuous-time version
C = (1, 9). 6-393
We moreover assume that there is a processing delay A,, so that the observa-
tions are taken at an interval A, before the instants at which control actuation
takes place. Disregarding the noises that are possibly present, it is easily
found with the use of 6-391 that the observation equation takes the form
é 1 ; ;
a) = E =(1—e¢* ) a*(i) + “(a a + x Sie uO, 6-394
a (06 (04 og
where
A'=A— A,. 6-395
With the numerical value
i =2)'0.02's) 6-396
we obtain for the observation equation
nt (i) = (1, 0.06608)x+(i) + 0.002381 u+(i). 6-397
6.5 Optimal Reconstruction of the State 525
6.5.3. Discrete-Time Observers
In this section we consider dynamical systems that are able to reconstruct
the state of another system that is being observed.
Definition 6.18. The system
&i + 1) = AWW + BMu(id) + Cy) 6-398
is a full-order observer for the system
x(i + 1) = A(i)x(i) + B(u(i), yi) = CH) + Eu,
6-399
E(ig) = X(ig) 6-400
GV 6 (i) eee hs 6-401
ij
implies
for all u(i), i > io.
It is noted that consistent with the reasoning of Section 6.5.2 the latest
observation that the observer processes for obtaining x(i + 1) is y(i). The
following theorem gives more information about the structure of an
observer.
Theorem 6.38. The system 6-398 is a full order observer for the system
6-399 if and only if
A(i) = A(i) — KMC(),
Bi) = B(i) — K(i)E(i), Ci) = KQ),
6-402
all for i > ig, where K(i) is an arbitrary time-varying matrix.
This theorem is easily proved by subtracting the state difference equations
6-399 and 6-398. With 6-402 the observer can be represented as follows:
&G + 1) = AMD + BOui) + KOLYO — COLO — Eu). 6-403
The observer consists of a model of the system, with as extra driving variable
an input which is proportional to the difference y(i) — (i) of the observed
variable y(i) and its predicted value
$i) = C@L@ + E@u(i). 6-404
We now discuss the stability of the observer and the behavior of the
reconstruction error e(i) = x(i) — &(i).
526 Discrete-Time Systems
Theorem 6.39. Consider the observer 6-398 for the system 6-399. Then the
reconstruction error
e(i) = x(i) — £(i) 6-405
satisfies the difference equation
e(i + 1) = [A(Q) — KWMCMIJe@, (ese 6-406
The reconstruction error has the property that
e(i) > 0, as im o, 6-407
for all e(iy), if and only if the observer is asymptotically stable.
The difference equation 6-406 is easily found by subtracting the state difference
equations in 6-399 and 6-398. The behavior of A(i) — K(i)C(i) determines
both the stability of the observer and the behavior of the reconstruction
error; hence the second part of the theorem.
As in the continuous-time case, we now consider the question: When does
there exist a gain matrix K that stabilizes the observer and thus ensures that
the reconstruction error will always eventually approach zero? Limiting our-
selves to time-invariant systems, we have the following result.
Theorem 6.40. Consider the time-invariant observer
£(7i + 1) = A&(i) + Bui) + K[y@ — Cé(i) — Eu) 6-408
for the time-invariant system
x(i + 1) = Ax(i) + Bu(i),
6-409
y(i) = Cx(i) + Eu(i).
Then the observer poles (that is, the characteristic values of A — KC) can be
arbitrarily located in the complex plane (within the restriction that complex
poles occur in complex conjugate pairs) by suitably choosing the gain matrix K
if and only if the system 6-409 is completely reconstructible.
The proof of this theorem immediately follows from the continuous-time
equivalent (Theorem 4.3, Section 4.2.2). For systems that are only detectable,
we have the following result.
Theorem 6.41. Consider the time-invariant observer 6-408 for the time-
invariant system 6-409. Then a gain matrix K can be found such that the
observer is asymptotically stable if and only if the system 6-409 is detectable.
A case of special interest occurs when the observer poles are all located at
the origin, that is, all the characteristic values of A — KC are zero. Then the
6.5 Optimal Reconstruction of the State 527
characteristic polynomial of A — KC is given by
det [AI — (A — KC)] = A", 6-410
so that by the Cayley-Hamilton theorem
(A — KC)" = 0. 6-411
It follows by repeated application of the difference equation 6-406 for the
reconstruction error that now
e(n) = (A — KC)"e(0) = 0 6-412
for every e(0), which means that every initial value of the reconstruction
error is reduced to zero in at most n steps. In analogy with deadbeat control
laws, we refer to observers with this property as deadbeat observers. Such
observers produce a completely accurate reconstruction of the state after
at most 7 steps.
Finally, we point out that if the system 6-409 has a scalar observed variable
y, a unique solution of the gain matrix K is obtained for a given set of
observer poles. In the case of multioutput systems, however, in general
many different gain matrices exist that result in the same set of observer
poles.
The observers considered so far in this section are systems of the same
dimension as the system to be observed. Because of the output equation
y(i) = C(i)x(i) + E(iu(i), we have available m equations in the unknown
state x(i) (assuming that y has dimension m); clearly, it must be possible to
construct a reduced-order observer of dimension n — m to reconstruct
x(i) completely. This observer can be constructed more or less analogously to
the continuous-time case (Section 4.2.3).
Example 6.22. Digital positioning system
Consider the digital positioning system of Example 6.2 (Section 6.2.3),
which is described by the state difference equation
1 0.08015 0.003396
ait i= x(i) + u(i). 6-413
0 0.6313 0.06308
As in Example 6.21, we assume that the observed variable is the angular
position but that there is a processing delay of 0.02 s. This yields for the
observed variable:
n(i) = (1, 0.06608)a(i) + 0.002381 u(i). 6-414
It is easily verified that the system is completely reconstructible so that
528 Discrete-Time Systems
Theorem 6.40 applies. Let us write K = col (k,, kz). Then we find
1—k, 0.08015 — 0.06608k,
A—KC= ; 6-415
—k, 0.6313 — 0.06608k,
This matrix has the characteristic polynomial
2 + (—1.6313 + k, + 0.06608k,)z + (0.6313 — 0.6313k, + 0.01407k,).
6-416
We obtain a deadbeat observer by setting
— 1.6313 + k, + 0.06608k, = 0, 0.6313 — 0.6313k, + 0.01407k, = 0.
6-417
This results in the gain matrix
PES?
K= : 6-418
7.143
An observer with this gain reduces any initial reconstruction error to zero
in at most two steps.
6.5.4 Optimal Discrete-Time Linear Observers
In this section we study discrete-time observers that are optimal in a well-
defined sense. To this end we assume that the system under consideration is
affected by disturbances and that the observations are contaminated by
observation noise. We then find observers such that the reconstructed state
is optimal in the sense that the mean square reconstruction error is minimized.
We formulate our problem as follows.
Definition 6.19. Consider the system
“i + 1) = A@a@) + Bul) + wi), Ore
yi) = Cx) + E@uli) + wD, 1 > ip.
Here col [w,(7), Wo(i)], i > ip, forms a sequence of zero-mean, uncorrelated
vector stochastic variables with variance matrices
iEae oy
poe 6-420
Va@a VG)
Furthermore, x(ij) is a vector stochastic variable, uncorrelated with w, and
Ws, with
E{x(i9)} = Xo, E{[2(ig) — Xo][@(io) — Ray = Qo. 6-421
4
6.5 Optimal Reconstruction of the State 529
Consider the observer
&(i + 1) = A@MA() + BAUD) + Ky — CHA — EWDu(d]
6-422
for this system. Then the problem of finding the sequence of matrices K°(ig),
K% (ig + 1),°+ +, K°(i — 1), and the initial condition £(i), so as to minimize
E{e™(i)W(i)e(i)}, 6-423
where e(i) = x(i) — &(i), and where W(i) is a positive-definite symmetric
weighting matrix, is termed the discrete-time optimal observer problem. If
Vi >0, 12 ip,
the optimal observer problem is called nonsingular.
To solve the discrete-time optimal observer problem, we first establish the
difference equation that is satisfied by the reconstruction error e(i). Sub-
traction of the system state difference equation 6-419 and the observer
equation 6-422 yields
eGi + 1) = [AM — KOCOleM + wD — Kw), 1 D> bo. 6-424
Let us now denote by Q(i) the variance matrix of e(i), and by é(i) the mean
of e(i). Then we write
Efe(ije7(i)} = O(i) + &(De7 (i), 6-425
so that
Efe"(i)W(de(i)} = E* (DWE) + tr (O(DW(i)]. 6-426
The first term of this expression is obviously minimized by making é(i) = 0.
This can be achieved by letting @(i)) = 0, which in turn is done by choosing
£(ig) = Xp. 6-427
The second term in 6-425 can be minimized independently of the first term.
With the aid of Theorem 6.22 (Section 6.2.12), it follows from 6-424 that O
satisfies the recurrence relation
Oi + 1) = [AQ) — K(HMCHIOW[AW — KOCH!
+ Vi(i) — Vil) K7(i) — Ka) + K(VAK" (i),
i> ip, 6-428
with
OUi,) = 05: 6-429
Repeated application of this recurrence relation will give us O(i + 1) as a
function of K(i), K(i— 1),+++, K(ip). Let us now consider the problem of
minimizing tr [O(i + 1)W(i + 1)] with respect to K(ij), K(ip + 1), ++, K(i).
This is equivalent to minimizing Q(i + 1), that is, finding a sequence of
matrices K(ij), K°(ij) + 1),°*., K°(i) such that for the corresponding
530 Discrete-Time Systems
value O(i + 1) of O(i + 1) we have Q(i + 1) < O(i + 1). Now 6-428 gives
us O(i + 1) as a function of K(i) and Q(i), where Q(i) is a function of
K(ip), +++ , KG — 1). Clearly, for given K(i), O(i + 1) isa monotone function
of O(i), that is, if O(i) < O(i) then O(i + 1) < O(i + 1), where Q(i + 1) is
obtained from Q(i) by 6-428. Therefore, O(i + 1) can be minimized by first
minimizing O(i) with respect to K(ij), K(i) + 1),°+ +, K(i — 1), substituting
the minimal value Q(i) of O(i) into 6-428, and then minimizing O(i + 1)
with respect to K(7). Z
Let us suppose that the minimal value Q(i) of Q(i) has been found.
Substituting Q(i) for O(i) into 6-428 and completing the square, we obtain
Oi + 1) = [K — (AQC? + Vial Ve CQCT) "(Ve a CQc*)
- [K — (AQC? + Vis)(V2 + CQC*)"]?
= (AGGM Vi 1.G0G') (C04 re
+ AQAT + V,, 6-430
where for brevity we have omitted the arguments 7 on the right-hand side
and where it has been assumed that
Vi) + C(i)Q(i)C? (i) 6-431
is nonsingular. This assumption is always justified in the nonsingular observer
problem, where V,(i) > 0. When considering 6-430, we note that O(i + 1)
is minimized with respect to K(i) if we choose K(i) as K°(i), where
K°(i) = [AMEMC*() + VaADIUVA) + CHAMC*HI™. 6-432
The corresponding value of O(i + 1) is given by
ms OG + 1) = [A(i) — K°MCHIOMA*(i) + Vili) — KVR), 6-433
wit
Oi) = Qo- 6-434
The relations 6-432 and 6-433 together with the initial condition 6-434 enable
us to compute the sequence of gain matrices recurrently, starting with K(i,).
We summarize our conclusions as follows.
Theorem 6.42, The optimal gain matrices K°(i), i > ij, for the nonsingular
optimal observer problem can be obtained from the recurrence relations
Ki) = [AMOMC*() + VAI + CHEMC*MO,
6-435
Oi + 1) = [A) — MCMIOHA() + Vii) — KO) VB),
both for i > iy, with the initial condition
Olin) = Qo. 6-436
The initial condition of the observer should be chosen as
Eig) = Xp. 6-437
6.5 Optimal Reconstruction of the State 531
The matrix Q(i) is the variance matrix of the reconstruction error e(i) =
x(i) — &(i). For the optimal observer the mean square reconstruction error is
given by Reo eer E{e"(i)W(ie(i)} = tr [(O() W(i)). 6-438
Singular optimal observation problems can be handled in a manner that
is more or less analogous to the continuous-time case (Brammer, 1968; Tse
and Athans, 1970). Discrete-time observation problems where the state
excitation noise and the observation noise are colored rather than white noise
processes (Jazwinski, 1970) can be reduced to singular or nonsingular
optimal observer problems.
We remark finally that in the literature a version of the discrete-time linear
optimal observer problem is usually given that is different from the one con-
sidered here in that it is assumed that y(i + 1) rather than y(Z) is the latest
observation available for reconstructing x(7 + 1). In Problem 6.6 it is shown
how the solution of this alternative version of the problem can be derived
from the present version.
In this section we have considered optimal observers. As in the continuous-
time case, it can be proved (see, e.g., Meditch, 1969) that the optimal
observer is actually the minimum mean square linear estimator of x(i + 1)
given the data u(j) and y(j/), 7 = ip, 9 + 1,°°+, 7; that is, we cannot find
any other linear operator on these data that yields an estimate with a smaller
mean square reconstruction error. Moreover, if the initial state x) is Gaussian,
and the white noise sequences w, and w, are jointly Gaussian, the optimal
observer is the minimum mean square estimator of x(i + 1) given u(j), y(j),
J = io, I) + 1,°-+, 7; that is, it is impossible to determine any other estimator
operating on these data that has a smaller mean square reconstruction error
(see, e.g., Jazwinski, 1970).
Example 6.23. Stirred tank with disturbances
In Example 6.10 (Section 6.2.12), we considered a discrete-time version of
the stirred tank. The plant is described by the state difference equation
0.9512 0 0 0
0 0.9048 0.0669 0.02262
ait l= x(i)
0 0 0.8825 0
0 0 0 0.9048
4.877 4.877
—1.1895 3.569 u(i) + w,(i), 6-439
0
0 0
532 Discrete-Time Systems
where w,(i), i > ig, is a sequence of uncorrelated zero-mean stochastic
variables with the variance matrix 6-169. The components of the state are
the incremental volume of the fluid in the tank, the incremental concentration
in the tank, and the incremental concentrations of the two incoming feeds.
We assume that we can observe at each instant of time i the incremental
volume, as well as the incremental concentration in the tank. Both observa-
tions are contaminated with uncorrelated, zero-mean observation errors with
standard deviations of 0.001 m? and 0.001 kmol/m?, respectively. Further-
more, we assume that the whole sampling interval is used to process the data,
so that the observation equation takes the form
yi) = x(i) + we(i), -
( npr SS ( ( 6-440
) ra / ) + wal?)
where w,(i), i > ip, have the variance matrix
105 eg 2:0
OF a408
. 6-441
The processes w, and w, are uncorrelated. In Example 6.10 we found that the
steady-state variance matrix of the state of the system is given by
0
0 0 0
0 0.00369 0.00339 0.00504 6-442
0 0.00339 0.0100 0
0 0.00504 0 0.0400
Using this variance matrix as the initial variance matrix Q(0) = Qy, the
recurrence relations 6-435 can be solved. Figure 6.21 gives the evolution of
the rms reconstruction errors of the last three components of the state as
obtained from the evolution of Q(i), i > 0. The rms reconstruction error of
the first component of the state, the volume, of course remains zero all the
time, since the volume does not fluctuate and thus we know its value exactly
at all times.
It is seen from the plots that the concentrations of the feeds cannot be
reconstructed very accurately because the rms reconstruction errors approach
steady-state values that are hardly less than the rms values of the fluctuations
in the concentrations of the feeds themselves. The rms reconstruction error
of the concentration of the tank approaches a steady-state value of about
0.0083 kmol/m*. The reason that this error is larger than the standard
deviation of 0.001 kmol/m® of the observation error is the presence of the
6.5 Optimal Reconstruction of the State 533
tms reconstruction error
of concentration of feed
no.2
rms reconstruction error
of concentration of feed
no.)
rms reconstruction error
of concentration in tank
0 2 4 6
sampling instant | ——=—_
Fig. 6.21. Behavior of the rms reconstruction errors for the stirred tank with disturbances.
processing delay—the observer must predict the concentration a full sampling
interval ahead.
6.5.5 Innovations
In this section we state the following fact, which is more or less analogous to
the corresponding continuous-time result.
Theorem 6.43. Consider the optimal observer of Theorem 6.42. Then the
innovation process
y(i) — E(i)u(i) — CW@)£(i), eae he 6-443
is a@ sequence of zero-mean uncorrelated stochastic vectors with variance
matrices
COODEO-E VQ), 1 >i 6-444
That the innovation sequence is discrete-time white noise can be proved
analogously to the continuous-time case. That the variance matrix of 6-443
is given by 6-444 follows by inspection.
6.5.6 Duality of the Optimal Observer and Regulator Problems;
Steady-State Properties of the Optimal Observer
In this subsection we expose the duality of the linear discrete-time optimal
regulator and observer problems. Here the following results are available.
534 Discrete-Time Systems
Theorem 6.44. Consider the linear discrete-time optimal regulator problem
(DORP) of Definition 6.16 (Section 6.4.3) and the linear discrete-time optimal
observer problem (DOOP) of Definition 6.19 (Section 6.5.4). Let in the
observer problem V,(i) be given by
V,() = G(i)V,(i)G* (i), heute. 6-445
where
V3(i) > 0, I = lee 6-446
Suppose also that the state excitation noise and the observation noise are un-
correlated in the DOOP, that is,
Vio) = 0, 1 = Loe 6-447
Let the various matrices occurring in the DORP and the DOOP be related
as follows:
A(i) of the DORP equals A‘ (i* — i) of the DOOP,
B(i) of the DORP equals C*(i* — i) of the DOOP,
D(i + 1) of the DORP equals G* (i* — i) of the DOOP,
R3(i + 1) of the DORP equals V3(i* — i) of the DOOP,
R,(i) of the DORP equals V,(i* — i) of the DOOP,
PF of the DORP equals Qy of the DOOP,
all for i < i, — 1. Here
i* =i, +1, — 1. 6-448
Under these conditions the solutions of the DORP (Theorem 6.28, Section
6.4.3) and the DOOP (Theorem 6.42, Section 6.5.4) are related as follows.
(a) P@ + 1) of the DORP equals Q(i* — 1) — V,(i* — i) of the DOOP for
i<i,-—1;
(b) F(i) of the DORP equals K°" (i* — i) of the DOOP fori < i, — 1;
(c) The closed-loop regulator of the DORP,
“(i + 1) = [A(@) — BOF@](), and the unforced reconstruction error equation of the DOOP,
6-449
ei + 1) = [AZ — PMCMle(), 6-450
are dual with respect to i* in the sense of Definition 6.9.
The proof of this theorem follows by a comparison of the recursive matrix
equations that determine the solutions of the regulator and observer problems.
Because of duality, computer programs for regulator problems can be used
for observer problems, and vice versa. Moreover, by using duality it is very
6.5 Optimal Reconstruction of the State 535
simple to derive the following results concerning the steady-state properties
of the nonsingular optimal observer with uncorrelated state excitation and
observation noises from the corresponding properties of the optimal regulator.
Theorem 6.45. Consider the nonsingular optimal observer problem with
uncorrelated state excitation and observation noises of Definition 6.19 (Section
6.5.4). Assume that A(i), C(i), Vi(i) = G(i)V3(i)G" (i) and V,(i) are bounded
for all i, and that
V(i)>al, V,(i)> Bl, for alli, 6-451
where « and f are positive constants.
(i) Then if the system 6-419 is either
(a) completely reconstructible, or
(b) exponentially stable,
and the initial variance Q) =0, the variance Q(i) of the reconstruction
error converges to a steady-state solution Q(i) as ij—» —©, which satis-
fies the matrix difference equations 6-435.
(ii) Moreover, if the system
Hit 1) =ADeD)+GOw3,0, yO= CHa), 6-452
is either
(c) both uniformly completely reconstructible and uniformly completely
controllable (from ws), or
(d) exponentially stable,
the variance Q(i) of the reconstruction error converges to O(i) for iy
— 0 for any initial variance Qy > 0.
(iii) If either condition (c) or (d) holds, the steady-state optimal observer,
which is obtained by using the gain matrix K corresponding to the steady-
state variance Q, is exponentially stable.
(iv) Finally, if either condition (c) or (d) holds, the steady-state observer
minimizes
lim E{e"(i)W(i)e(i)} 6-453
for every initial variance Qy. The minimal value of 6-453, which is achieved
by the steady-state optimal observer, is given by
tr [O() W()]. 6-454
Similarly, it follows by “‘dualizing’? Theorem 6.31 (Section 6.4.4) that, in
the time-invariant nonsingular optimal observer problem with uncorrelated
state excitation and observation noises, the properties mentioned under (ii),
(iii), and (iv) hold provided the system 6-452 is both detectable and stabiliz-
able.
536 Discrete-Time Systems
We leave it as an exercise for the reader to state the dual of Theorem 6.37
(Section 6.4.7) concerning the asymptotic behavior of the regulator poles.
6.6 OPTIMAL LINEAR DISCRETE-TIME
OUTPUT FEEDBACK SYSTEMS
6.6.1 Introduction
In this section we consider the design of optimal linear discrete-time control
systems where the state of the plant cannot be completely and accurately
observed, so that an observer must be connected. This section parallels
Chapter 5.
6.6.2 The Regulation of Systems with Incomplete Measurements
Consider a linear discrete-time system described by the state difference
equation a(i + 1) = A(a(i) + BHu(d), 6-455
with the controlled variable
2(i) = D(i)x(i). 6-456
In Section 6.4 we considered controlling this system with state feedback
control laws of the form
u(i) = —Fi(i)x(i). 6-457
Very often it is not possible to measure the complete state accurately, how-
ever, but only an observed variable of the form
y(i) = Cai) + E@u(i) 6-458
is available. Assuming, as before, that y(i) is the latest observation available
for reconstructing x(i + 1), we can connect an observer to this system of the
form
Ai + 1) = ADE) + BOu() + KD[y) — EDu(D — CW). 6-459
Then a most natural thing to do is to replace the state x in 6-457 with its
reconstructed value #:
u(i) = —F(i)<(i). 6-460
We first consider the stability of the interconnection of the plant given by
6-455 and 6-458, the observer 6-459, and the control law 6-460. We have the
following result, completely analogous to the continuous-time result of
Theorem 5.2 (Section 5.2.2).
6.6 Optimal Output Feedback Systems 537
Theorem 6.46. Consider the interconnection of the system described by
6-455 and 6-458, the observer 6-459, and the control law 6-460. Then sufficient
conditions for the existence of gain matrices F(i) and K(i), i > ig, such that the
interconnected system is exponentially stable are that the system described by
6-455 and 6-458 be uniformly completely controllable and uniformly completely
reconstructible, or that it be exponentially stable. In the time-invariant case
(i.e., all matrices occurring in 6-455, 6-458, 6-459, and 6-460 are constant)
necessary and sufficient conditions for the existence of stabilizing gain matrices
K and F are that the system given by 6-455 and 6-458 be both stabilizable and
detectable. Moreover, in the time-invariant case, necessary and sufficient con-
ditions for arbitrarily assigning all the closed-loop poles in the complex plane
(within the restriction that complex poles occur in complex conjugate pairs) by
suitably choosing the gain matrices K and F are that the system be both com-
pletely reconstructible and completely controllable.
The proof of this theorem follows by recognizing that the reconstruction error
e(i) = x(i) — (i) 6-461
satisfies the difference equation
e(it+ 1) = [AQ — KMCHJe(. 6-462
Substitution of £(i) = x(i) + e(i) into 6-460 yields for 6-455
ai + 1) = [AQ@) — BW) FM) + B@F@e(i). 6-463
Theorem 6.46 then follows vy application of Theorem 6.29 (Section 6.4.4),
Theorem 6.45 (Section 6.5.4), Theorem 6.26 (Section 6.4.2), and Theorem
6.41 (Section 6.5.3). We moreover see from 6-462 and 6-463 that in the time-
invariant case the characteristic values of the interconnected system
comprise the characteristic values of A — BF (the regulator poles) and the
characteristic values of A — KC (the observer poles).
A case of special interest occurs when in the time-invariant case all the
regulator poles as well as the observer poles are assigned to the origin. Then
we know from Section 6.5.3 that the observer will reconstruct the state
completely accurately in at most n steps (assuming that 7 is the dimension of
the state x), and it follows from Section 6.4.2 that after this the regulator will
drive the system to the zero state in at most another 7 steps. Thus we have
obtained an output feedback control system that reduces any initial state to
the origin in at most 2n steps. We call such systems output feedback state
deadbeat control systems.
Example 6.24. Digital position out put feedback state deadbeat control system
Let us consider the digital positioning system of Example 6.2 (Section
6.2.3). In Example 6.13 (Section 6.3.3) we derived the state deadbeat control
538 Discrete-Time Systems
0.)
ongulor
position
Ey (i)
(rad)
0
10
sompling
instant | —»
angular 1
velocity
(i) e 10
=a sampling
instant i —.
(rad/s) 20
input 40
voltage
(V)
Bi) fe ‘
sompling
instont | —=
-40
Fig. 6.22. Response of the output feedback state deadbeat position control system from
the initial state col{~(0), £(0)] = col(0.1, 0, 0, 0). The responses are shown at the sampling
instants only and not at intermediate times.
law for this system, while in Example 6.22 (Section 6.5.3) we found the
deadbeat observer. In Fig. 6.22 we give the response of the interconnection of
deadbeat control law, the deadbeat observer, and the system to the initial
state
«(0) = col (0.1, 0), #(0)=0. 6-464
It is seen that the initial state is reduced to the zero state in four steps. Com-
parison with the state feedback deadbeat response of the same system, as
depicted in Fig. 6.12 (Section 6.3.3), shows that the output feedback control
system exhibits relatively large excursions of the state before it returns to the
zero state, and requires larger input amplitudes.
6.6 Optimal Output Feedback Systems 539
6.6.3 Optimal Linear Discrete-Time Regulators with Incomplete
and Noisy Measurements
We begin this section by defining the central problem.
Definition 6.20. Consider the linear discrete-time system
xi + 1) = A(ix(i) + Bii)u(i) + w,(i),
6-465
«(ig) = Xo, I> io,
where x, is a stochastic vector with mean x, and variance matrix Qy. The
observed variable of the system is
y(i) = C(i)a(i) + E(i)u(i) + w,(i). 6-466
The variables col [w,(i), we(i)] form a sequence of uncorrelated stochastic
vectors, uncorrelated with x), with zero means and variance matrices
A VG Viet
Af Jone. wertos| = Y 4 i> iy. 6-467
wali Visti) Ve(i)
The controlled variable can be expressed as
2(i) = D(i)x(i). 6-468
Then the stochastic linear discrete-time optimal output feedback regulator
problem is the problem of finding the functional
u(i) = f[y(io), Y (io te 1) et gee) y(i —, Wis i], Io a bs i a I 6-469
such that the criterion
41-1
o = E\S 2G + DRE + De + 1) + u7™DR Du] + &()P (i)
ri 6-470
is minimized. Here R;(i + 1)>0 and R,(i) > 0 for ip Si <i, — 1, and
Pe = 0;
As in the continuous-time case, the solution of this problem satisfies the
separation principle (Gunckel and Franklin, 1963; Astrém, 1970; Kushner,
1971).
Theorem 6.47. The solution of the stochastic linear discrete-time optimal
output feedback problem is as follows. The optimal input is given by
u(i) = —F@£(), ij es ge 6-471
where F(i), iy < i < i, — 1, is the sequence of gain matrices for the deterministic
optimal regulator as given in Theorem 6.28 (Section 6.4.3). Furthermore, £(i)
540 Discrete-Time Systems
is the minimum mean-square linear estimator of x(i) giveny(j),ip <j Si- 1;
&(i) for the nonsingular case [i.e., V:(i) > 0, ig < i < i, — 1] can be obtained
as the output of the optimal observer as described in Theorem 6.42 (Section
6.5.4).
We note that this theorem states the optimal solution to the stochastic linear
discrete-time optimal output feedback problem and not just the optimal
linear solution, as in the continuous-time equivalent of the present theorem
(Theorem 5.3, Section 5.3.1). Theorem 6.47 can be proved analogously to the
continuous-time equivalent.
We now consider the computation of the criterion 6-470, where we restrict
ourselves to the nonsingular case. The closed-loop control system is described
by the relations
x(i + 1) = A(x) + Bu) + w,(d),
y(i) = Cx) + E(u) + (i), u(i) = —F(@£(),
€G + 1) = AME) + BOuD + KOLYO — EOuD — CHO).
In terms of the reconstruction error,
e(i) = x(i) — &(i), 6-472
6-473
and the observer state £(i), 6-472 can be rewritten in the form
Lh ++ >) _ Ge — K(i)C(i) 0 e(i)
«i+ D) \ KOCH AD- fen bs)
I —K(i)\ /w,(i)
+ ( )( ) 6-474
0 KG) /\w.@
with the initial condition
en ie — X
Eig) Xo
= 3 6-475
Defining the variance matrix of col [e(i), €(i)] as
e(i) — ae) |
E T(\ __ Ti ati) — ns
(eo — E{&(i)} (eo) — Efe"@}, B°() — E{4*(H})
bee Q,2(i)
) i> ip, 6-476Qi5(i) Q»0(i)
it can be found by application of Theorem 6.22 (Section 6.2.12) that the
6.6 Optimal Output Feedback Systems 541
matrices Q;,(i), 7, k = 1, 2, satisfy difference equations, of which we give only
that for Qo:
Qp0(i a 1) = K (i)C(i)Q1,(i)C* (i) K* (i)
+ [A(i) — BOFMIORMC*()K7(i)
+ K()C()Q()LAW) — BUF)"
+ [A(i) — BU/)F(i)]Q20()[AG) — BUi)F(i)]*
+ K()V)K*(, i> io, 6-477
with the initial condition
Qo2(ip) = 0. 6-478
Now obviously Q,,(i) = Q(i), where Q(i) is the variance matrix of the
reconstruction error. Moreover, by setting up the difference equation for
Qj2, it can be proved that Q,.(i) = 0, i) < i < i; — 1, which means that
analogously with the continuous-time case the quantities e(i) and #(i) are
uncorrelated for ij <i <i, — 1. As a result, Q,, can be found from the
difference equation
Qo(i + 1) = K(i)[C()Q(iI)C7(i) + Ve(i)]K7(i)
+ [A(i) — BU) F()]Q2.()[AW) — BU)F@Y, 6-479
Qoolin) = 0.
When the variance matrix of col [e(i), £(i)] is known, all mean square and
rms quantities of interest can be computed. In particular, we consider the
criterion 6-470. In terms of the variance matrix of col (e, £) we write for the
criterion:
o = %"PCighiy + tr] > {RF + DOG + 1) + Quali + DI
+ F7(i)R.(i)F(i)Q22(i)} + PilQ(a) + Onli} 6-480
where
R,(i) = D7(i)R;(i) D(i), 6-481
and P(i) is defined in 6-248. Let us separately consider the terms
ir{ S1RG + DOaGi +1) + FUOROFOOaD] + PrOvlid|
i=70
= tr ps [R,(@i) + F"(i)R,(i)F(i)]Q22(i) noe ae Ri (iN). 6-482
1=to+
542 Discrete-Time Systems
where we have used the fact that Q.,(i)) = 0. Now using the results of
Problem 6.7, 6-482 can be rewritten as
tr lOse(in) Pig) + S PKU — 0)
J=io+1
ICG — DOG = HNeC*G —1) $V — 1IK7G — fy, 6483
where P satisfies the matrix difference equation
PG — 1) = [AG — 1) — BG — DFG — DFP
-[A(i— 1) — BG — 1) F(i— 1)] + RD + F7(i) Ri) F(i), 6-484
Pix) ae P, + R,(i,).
It is not difficult to recognize that P(i) = P(i)+ Ri), bh +1 <i < iy.
By using this, substitution of 6-483 into 6-480 yields for the criterion
ay-—1
o = %y" Plip)% + Dd tr Ri + NOG + 1) + [PG + 1) + RG + YIKM)
t=10
- [C(NOCCT (i) + voKr()} + tr [P,Q(i)]. 6-485
By suitable manipulations it can be found that the criterion can be expressed
in the alternative form:
O = Fy Pip) Xp. + tr [P(in) Qo]
+5 tr lire + 1) + PG + DIAG + OWFTO
- {R,(i) + B7(i)[Ri(i + 1) + P+ DIBW@}F()}. 6-486
We can now state the following theorem.
Theorem 6.48. Consider the stochastic output feedback regulator problem of
Definition 6.20. Suppose that V,(i) > 0 for alli. Then the following facts hold.
(a) The minimal value of the criterion 6-470 can be expressed in the
alternative forms 6-485 and 6-486.
(b) In the time-invariant case, in which the optimal observer and regulator
problems have steady-state solutions as ij — © and i, — 00, characterized
by QO and P, with corresponding steady-state gain matrices K and F, the
6.6 Optimal Output Feedback Systems 543
following holds:
lim - : me Seas 1)R3(i + te(i + 1) + w7RADuC]
to>—@ by — Ig i=t0
nee = lim Efz"(i + 1)Ry2(i + 1) + u7(R,u(i)}
= tr[R,O + (P + R,)K(COC? + V,)K7]
= tr {(R, + P)V, + QF*[R, + B7(R, + P)B)F}. 6-487
(c) All mean square quantities of interest can be obtained from the variance
matrix diag [Q(i), Qeo(i)] of col [e(i), £(i)]. Here e(i) = x(i) — (i), O(i) is
the variance matrix of e(i), and Qys(i) can be obtained as the solution of the
matrix difference equation
Ooi + 1) = [A(i) — BU)FMIO2()AM — BOFOP
+ K()[CHQHC") + VADIK™(), 1 > ig, 6-488
Qoo(ip) = 0.
The proof of part (b) of this theorem follows by application of part (a).
The general stochastic regulator problem can be specialized to tracking
problems, regulation problems for systems with disturbances, and tracking
problems for systems with disturbances, completely analogous to what we
have discussed for the continuous-time case.
6.6.4 Nonzero Set Points and Constant Disturbances
The techniques developed in Section 5.5 for dealing with time-invariant
regulators and tracking systems with nonzero set points and constant dis-
turbances can also be applied to the discrete-time case. We first consider the
case where the system has a nonzero set point Z, for the controlled variable.
The system state difference equation is
a(i + 1) = Ax(i) + Bu(i) + w, (i), Coie 6-489
the controlled variable is
Zi) = Dzii), ee Ns 6-490
and the observed variable is
y(i) = Cx(i) + Eu(i) + w,(0), ey Pe 6-491
The joint process col (w , w,) is given as in Definition 6.20 (Section 6.6.3).
From Section 6.4.6 it follows that the nonzero set point controller is spec-
ified by
u(i) = —Fé(i) + H7'(D%, 6-492
544 Discrete-Time Systems
where F is a suitable feedback gain matrix, and
H,(2) = D@l — A+ BF)*B 6-493
is the (square) closed-loop transfer matrix (assuming that dim (z) = dim (u)).
Furthermore, £(i) is the minimum mean square estimator of x(i) and Z
that of 2.
How 4, is obtained depends on how we model the set point. If we assume
that the set point varies according to
zo(i + 1) = 29(i) + wo(i), 6-494
and that we observe
r(i) = zo(i) + w,(i), 6-495
where col (w9, w,) constitutes a white noise sequence, the steady-state optimal
observer for the set point is of the form
(i + 1) = 4o(i) + K,[r() — 4(i))- 6-496
This observer in conjunction with the control law 6-492 yields a zero-steady-
state-error response when the reference variable r(i) is constant.
Constant disturbances can be dealt with as follows. Let the state difference
equation be given by
x(i + 1) = Ax(i) + Bu(i) + vp + w,(d), 6-497
where v, is a constant disturbance. The controlled variable and observed
variable are as given before. Then from Section 6.4.6, we obtain the zero-
steady-state-error control law
u(i) = —F&(i) — H,"(1)DU — A) “6, 6-498
with all quantities defined as before, A = A — BF, and @, an estimate of vo.
In order to obtain é), we model the constant disturbance as
Vo(i + 1) = vo(i) + wo(i), 6-499
where Ww» constitutes a white noise sequence. The steady-state optimal
observer for x(i) and 2 (i) will be of the form
&7i + 1) = A&(1) + Bu(i) + 61) + Kly@ — C#() — Eu),
8y(i + 1) = 6)(i) + Roly) — C&() — E(iu(i)]. | 6-500
This observer together with the control law 6-498 produces a zero-steady-
state-error response to a constant disturbance. This is a form of integral
control.
6.6 Optimal Output Feedback Systems 545
Example 6.25. Integral control of the digital positioning system
Consider the digital positioning system of previous examples. In Example
6.14 (Section 6.4.3), we obtained the state feedback control law
u(i) = —Fx(i) = —(110.4, 12.66)z(i). 6-501
Assuming that the servo motor is subject to constant disturbances in the form
of constant torques on the shaft, we must include a term of the form
0.003396
Vo = 0 6-502
0.06308
in the state difference equation 6-26, where « is a constant. It is easily seen
that with the state feedback law 6-501 this leads to the zero-steady-state-error
control law
(i) = —Fé(i) — &(i). 6-503
The observer 6-500 is in this case of the form
1 eats |* ee
10+) =|
C1
0 0.6313 0.06308 | ais
ky ips Afs
ot k Joo —(, 0)#@],
2
&(i + 1) = &(1) + kg[n@) — C1, 0)4&()). Here it has been assumed that
6-504
ni) = (1, 0)x@) 6-505
is the observed variable (i.e., the whole sampling interval is used for proc-
essing the data), and k,,k,, and k, are scalar gains to be selected. We
choose these gains such that the observer is a deadbeat observer; this results
in the following values:
ky = 2.6313, ky = 18.60, 3 = 158.4. 6-506
Figure 6.23 shows the response of the resulting zero-steady-state-error control
system from zero initial conditions to a relatively large constant disturbance
of 10 V (i.e., the disturbing torque is equivalent to a constant additive input
voltage of 10 V). It is seen that the magnitude of the disturbance is identified
after three sampling intervals, and that it takes the system another three to
four sampling intervals to compensate fully for the disturbance.
546 Discrete-Time Systems
10
estimated
constant
disturbance
ai)
(V)
0 0 10
sampling instant i —s
0 10
, 0
input
voltage
~10
(V)
-20
0.2
angular
position
€4(i) 0.1
(rad) 0
0 10
sampling instant i —»
Fig. 6.23. Response of the digital positioning system with integral control from zero
initial conditions to a constant disturbance.
6.7 CONCLUSIONS
In this chapter we have summarized the main results of linear optimal control
theory for discrete-time systems. As we have seen, in many instances the
continuous-time theory can be extended to the discrete-time case in a fairly
straightforward manner. This chapter explicitly reviews most of the results
needed in linear discrete-time control system design.
Although in many respects the discrete-time theory parallels the continuous-
time theory, there are a few differences. One of the striking dissimilarities is
that, in theory, continuous-time control systems can be made arbitrarily
fast. This cannot be achieved with discrete-time systems, where the speed of
6.8 Problems 547
action is restricted by the sampling interval. The fastest type of control that
can be achieved with discrete-time systems is deadbeat control.
In this chapter we have usually considered linear discrete-time systems
thought to be derived from continuous-time systems by sampling. We have
not paid very much attention to what happens between the sampling interval
instants, however, except by pointing out in one or two examples that the
behavior at the sampling instants may be misleading for what happens in
between. This is a reason for caution. As we have seen in the same examples,
it is often possible to modify the discrete-time problem formulation to obtain
a more acceptable design.
The most fruitful applications of linear discrete-time control theory lie in
the area of computer process control, a rapidly advancing field.
6.8 PROBLEMS
6.1. A modified discrete-time regulator problem
Consider the linear discrete-time system
xi + 1) = Axi) + Bu), 6-507
with the modified criterion
FOR Wx + 2x" DRaCDu) + uw DRUC]
oe + aT (G)P,2(i,). 6-508
Show that minimizing 6-508 for the system 6-507 is equivalent to a standard
discrete-time regulator problem where the criterion
41-1 SY (27G + DRG + Dei + DY + w'7@Ru'D] + 27 (H)Pi2(i,) 6-509
jS minimized for the system
a(i + 1) = A’(Dax(i) + Bu’ (i), 6-510
with
nye RQ) = Ry()Rz ORC), Bip ri dips, ty it
R,(i) = é .
5 l= 14,
u'(i) = u(i) + Re (DRAM zd, i=iy,ij +1,°°°,i,—1, 6-511
A'(i) = A(i) — Bi) Rs ‘RAM, Rea, Toney ace Wa i ee
6.2. Stochastic state feedback regulator problems structured as regulator
problems with disturbances
548 Discrete-Time Systems
Consider the linear discrete-time system
a(i + 1) = A()a(i) + Bui) + vi), 2(i) = Diz):
6-512
Here the disturbance variable v is modeled as
D1) = Dies);
) a(i)%4(i) oS
ai + 1) = A,(i)x,(i) + wad),
where the w,(i), i > ip, form a sequence of uncorrelated stochastic vectors
with given variance matrices. Consider also the criterion
E paca + Ri + Deli + 1) + u(DRADuCi] + iPr} 6-514
(a) Show how the problem of controlling the system such that the criterion
6-514 is minimized can be converted into a standard stochastic regulator
problem.
(b) Show that the optimal control law can be expressed as
uli) = —F(i)r) — FOr), t=, +1,°°+,4 —1, -6-515
where the feedback gain matrices F(i), i = ip,***, i, — 1, are completely
independent of the properties of the disturbance variable.
6.3. Stochastic state feedback regulator problems structured as tracking
problems
Consider the linear discrete-time system
a(i + 1) = A@)a(i) + BOul), 6-
2(i) = D(i)x(i). pe
Consider also a reference variable z,, which is modeled through the equations
2(i) = D,(i)a,(i),
x,(i + 1) = A,@2z,@ + w,(i), al
where w,(i), i > ij, forms a sequence of uncorrelated stochastic vectors with
variance matrices V,(i). Consider as well the criterion
qy-1
E\ > G+ 1) —z€i+ DPR + Ye + 1) — 2,6 + 1]
i=to
+ u7(i)R,(iu(i)}. 6-518
6.8 Problems 549
(a) Show how the problem of controlling the system such that the
criterion 6-518 is minimized can be converted into a standard stochastic
discrete-time optimal regulator problem.
(b) Show that the optimal control law can be expressed in the form
u(i) = —F(@)2(i) + F.)2,), i= tpn in t1y-**,i, —1, 6-519
where the feedback gain matrices F(i), i = ip,:-+,i, — 1, are completely
independent of the properties of the reference variable.
6.4. The closed-loop regulator poles
Prove the following generalization of Theorem 6.37 (Section 6.4.7).
Consider the steady-state solution of the time-invariant linear discrete-time
optimal regulator problem. Suppose that dim (z) = dim (uw) and let
H(z) = D(zl — A)“B,
p(z)
Pe he eee mn ee ht ee me
. —_
=
p
eyez a’ fey) with Ve AOt = Leap:
I=)
and
Ry = pN,
with N > 0 and pa positive scalar. Finally, set r = max (p,q). Then:
(a) Of the n closed-loop regulator poles, n — r always stay at the origin.
(b) As p | 0, of the remaining r closed-loop poles, p approach the numbers
¥,,1 = 1,2,«-*, p, which are defined as in 6-363.
(c) As p | 0, the r — p other closed-loop poles approach the origin.
(d) As p | ©, of the r nonzero closed-loop poles, g approach the numbers
f;,i = 1,°-+,9q, which are defined as in 6-364.
(e) As p | ©, the r — p other nonzero closed-loop poles approach the
origin.
6.5. Mixed continuous-time discrete-time regulator problem
Consider the discrete-time system that results from applying a piecewise
constant input to the continuous-time system
a(t) = A(t)a(t) + B(t)u(t). 6-521
Use the procedure and notation of Section 6.2.3 in going from the continuous-
time to the discrete-time version. Suppose now that one wishes to take into
account the behavior of the system between the sampling instants and consider
550 Discrete-Time Systems
therefore the integral criterion (rather than a sum criterion)
[, eORO# + u7(t)R,(t)u(t)] dt + a GaP tn): 6-522
Here f,, is the first sampling instant and f,, the last.
(a) Show that minimizing the criterion ‘6 522, while the system 6-521 is
commanded by stepwise constant inputs, is equivalent to minimizing an
expression of the form
z1—1
i=10
> [x7(t)Ri()-x(t,) a 2x7 (t,)Ria(i)u(t;) =f u7(t )Ri(Du(t,)]
+ a7 (t;,)P,x(t;,) 6-523
for the discrete-time system
@( tess) = P(tiza, te)u(ts) + | i O(a DBC) ar |u(t), 6-524
where (f, ¢)) is the transition matrix of the system 6-521. Derive expressions
for R, (i), Rie), and RG).
(b) Suppose that A, B, R,, and R, are constant matrices and also let the
sampling interval t,,, — t; = A be constant. Show that ifthe sampling interval
is small first approximations to Rj, Riz, and R; are given by
Ri RS
Rie & 4R, BA’, 6-525
Ri = (Ry + 4BTR,BA?)A.
6.6. Alternative version of the discrete-time optimal observer problem
Consider the system
xi + 1) = A(i)a(i) + BM)u(i) + wy (i),
6-526y@) = COai) + EOuH +e), i> ib,
where col [w,(i), w2(i)], i > ip, forms a sequence of zero-mean uncorrelated
vector stochastic variables with variance matrices
ne al a.
i aie 6-527
VEG VG)
Furthermore, a(i)) is a vector stochastic variable, uncorrelated with w, and
Wo, With mean X, and variance matrix Qy. Show that the best linear estimator
of x(i) operating on y(j/), in <j <i (not i — 1, as in the version of Section
6.5), can be described as follows:
G+ 1)= U—-— KG+ YCE+ II[AMEW + BOuH)
+kKGi+ )yG@+)—-£G+)uG+)D], i>. 6-528
6.8 Problems 551
Here the gain matrices K are obtained from the iterative relations
K(@i + 1) = [SG + I)C7G + 1) + VADIICG + DSC + CPG + 1)
+ Ci + 1)V,,(i) + V@C7G + 1) + VAT,
SGi+ 1) = A(NQ(A(i) + VACA),
OG) = [hk KG DCG DIS 4.1) KG + DVEG) -6529
all for i > ij. Here Q(i) is the variance matrix of the reconstruction error
x(i) — £(i), and S(i) is an auxiliary matrix. The initial condition for 6-528
is given by
where
Hig) = [I — K(ig)C(in) 1% + KCin)[yCio) — ECin)uCio)], 6-530
K(ig) = QoC* (ip) [CCig)QoC? Cig) + V,2{ PY) ee 6-531
The initial variance matrix, which serves as initial condition for the iterative
equations 6-529, is given by
O(in) = [IE — K(ig)C(in)]Qo. 6-532
Hint: To derive the observer equation, express y(i + 1) in terms of a(i) and
use the standard version of the observer problem given in the text.
6.7. Property of a matrix difference equation
Consider the matrix difference equation
OF) =AMIOLO PRO, Sis —1, 6-533
together with the linear expression
7-1
ur | Socnsca + P.0ti) J=70
6-534
Prove that this expression can also be written as
tr [oPC) + > RG — NPD], 6-535
j=iot1l
where the sequence of matrices P(/), ip) <j < i, satisfies the matrix difference
equation
P(i — 1) = A?(i — 1)P()ACi — 1) + S(i — 1), ib t1lsi< th,
6-536
P(iy) = P,.
552 Discrete-Time Systems
6.8. Linear discrete-time optimal output feedback controllers of reduced
dimensions
Consider the linear time-invariant discrete-time system
a(i + 1) = Ax(i) + Bu(i) + wid), pl CN a hy
2(i) = D(i)a(i), 6-537
y(i) = C@«(i) + E@u) + w2(i),
all for i > iy, where col [w,(i), w2(i)], i > ip, forms a sequence of uncorrelated
stochastic vectors uncorrelated with 2». Consider for this system the time-
invariant controller
qit+ )=LaO + Ky,
6-538
u(i) = —Fq(i) — Kyy(i).
Assume that the interconnection of controller and plant is asymptotically
stable.
the form
(a) Develop matrix relations that can be used to compute expressions of
lim E{z7( i)R32(i)} 6-539
and ai
lim E{uT(i)R,u(i)}. 6-540
Presuming that computer programs can be developed that determine the
controller matrices L, K,, F, and K, such that 6-539 is minimized while
6-540 is constrained to a given value, outline a method for determining
discrete-time optimal output feedback controllers of reduced dimensions.
(Compare the continuous-time approach discussed in Section 5.7.)
(b) When gradient methods are used to solve numerically the optimization
problem of (a), the following result is useful. Let M@, N, and R be given
matrices of compatible dimensions, each depending upon a parameter y.
Let S be the solution of the linear matrix equation
S = MSM* +N, 6-541
and consider the scalar
tr (SR) 6-542
as a function of y. Then the gradient of 6-542 with respect to y is given by
oo raCSRy) er (s+ 0+ 20% sur), 6-543
oy oy oy oy
where U is the solution of the adjoint matrix equation
U = M™UM +R. 6-544
Prove this.
REFERENCES
B. D. O. Anderson (1966a), ‘‘The inverse problem of optimal control,” Technical Report
No. 6560-3, Stanford Electronics Laboratories, Stanford University, Stanford, Calif.
B. D. O. Anderson (1966b), “‘Solution of quadratic matrix equations,” Electron. Letters,
2, 10, pp. 371-372.
B. D. O. Anderson and D. G. Luenberger (1967), “Design of multivariable feedback
systems,” Proc. IEE, 114, 3, pp. 395-399.
B. D. O. Anderson and J. B. Moore (1971), Linear Optimal Control, Prentice-Hall,
Englewood Cliffs, N.J.
M. Aoki (1968), “Control of large-scale dynamic systems by aggregation,” JEEE Trans.
Autom. Control, 13, 3, pp. 246-253.
K. J. Astrém (1970), Introduction to Stochastic Control Theory, Academic Press, New York.
K. J. Astrom, R. W. Koepcke, and F. Tung (1962), ‘On the control of linear discrete
dynamic systems with quadratic loss,” Research Report RJ-222, IBM, San Jose
Research Laboratory, San Jose, Calif.
M. Athans and P. L. Falb (1966), Optimal Control, An Introduction to the Theory and Its
Applications, McGraw-Hill, New York.
S. Barnett and C. Storey (1967), “‘Remarks on numerical solution of the Lyapunoy matrix
equation,” Electron. Letters, 3, p. 417.
S. Barnett and S. Storey (1970), Matrix Methods in Stability Theory, Nelson, London.
B. B. Barrow (1966), “IEEE takes a stand on units,” Spectrum, 3, 3, pp. 164-173.
R. W. Bass (1967), “‘Machine solution of high-order matrix Riccati equations,” Douglas
Paper No. 4538, Douglas Aircraft, Missile and Space Systems Division.
R. W. Bass and I. Gura (1965), ‘““High order system design via state-space considerations,”
Preprints, 1965 Joint Automatic Control Conference, pp. 311-318, Rensselaer Poly-
technic Institute, Troy, N.Y., June 22-25.
R. E. Bellman (1957), Dynamic Programming, Princeton Univ. Press, Princeton, N.J.
C. S. Berger (1971), ‘““A numerical solution of the matrix equation P = $P¢' + S,’ IEEE
Trans. Autom. Control, 16, 4, pp. 381-382.
G.S. G. Beveridge and R. S. Schechter (1970), Optimization: Theory and Practice, McGraw-
Hill, New York.
Th. A. Bickart (1968), ‘“Matrix exponential: Approximation by truncated power series,”
Proc. IEEE, 56, 5, pp. 872-873.
T. R. Blackburn (1968), “Solution of the algebraic Riccati equation via Newton—Raphson
iteration,” Preprints, 1968 Joint Automatic Control Conference, pp. 940-945, University
of Michigan, Ann Arbor, Mich., June 26-28.
T. R. Blackburn and J. C. Bidwell (1968), ‘“Some numerical aspects of control engineering
computations,” Preprints, 1968 Joint Automatic Control Conference, pp. 203-207,
University of Michigan, Ann Arbor, Mich., June 26-28.
J. H. Blakelock (1965), Automatic Control of Aircraft and Missiles, Wiley, New York.
H. W. Bode (1945), Network Analysis and Feedback Amplifier Design, Van Nostrand,
Princeton, N.J.
K. G. Brammer (1968), ‘“‘Lower order optimal filtering of nonstationary random sequences,”
IEEE Trans Autom, Control, 13, 2, pp. 198-199.
553
554 References
F. M. Brasch and J. B. Pearson (1970), “‘Pole placement using dynamic compensators,”
IEEE Trans. Autom. Control, 15, 1, pp. 34-43.
R. W. Brockett (1970), Finite Dimensional Linear Systems, Wiley, New York.
A. E. Bryson and D. E. Johansen (1965), “‘Linear filtering for time-varying systems using
measurements containing colored noise,” JEEE Trans. Autom. Control, 10, 1, pp. 4-10.
R. S. Bucy (1967a), ‘“‘Global theory of the Riccati equation,” J. Comp. Systems Sci., 1,
p. 349-361.
R. S. Bucy (1967b), ‘‘Two-point boundary value problems of linear Hamiltonian systems,”
SIAM J. Appl. Math., 15, 6, pp. 1385-1389.
R. S. Bucy and J. Ackermann (1970), “‘Ueber die Anzahl der Parameter von Mehrgrossen-
systemen,” Regelungstechnik, 18, 10, pp. 451-452.
R. S. Bucy and P. D. Joseph (1968), Filtering for Stochastic Processes with Applications to
Guidance, Interscience, New York.
S. Butman (1968), ‘“‘A method for optimizing control-free costs in systems with linear
controllers,” ZEEE Trans. Autom. Control, 13, 5, pp. 554-556.
J. A. Cadzow (1968), ““Nilpotency property of the discrete regulator,” JEEE Trans. Autom.
Control, 13, 6, pp. 734-735.
P. E. Caines and D. Q. Mayne (1970), ‘‘On the discrete time matrix Riccati equation of
optimal control,” Intern. J. Control, 12, 5, pp. 785-794.
P. E. Caines and D. Q. Mayne (1971), “‘On the discrete time matrix equation of optimal
control—A correction,” Intern. J. Control, 14, pp. 205-207.
R. H. Cannon, Jr. (1967), Dynamics of Physical Systems, McGraw-Hill, New York.
S. S. L. Chang (1961), Synthesis of Optimum Control Systems, McGraw-Hill, New York.
C. T. Chen (1968a), “Stability of linear multivariable feedback systems,” Proc. IEEE, 56,
5, pp. 821-828.
C. T. Chen (1968b), ‘‘A note on pole assignment,” JEEE Trans. Autom. Control, 13, 5,
p. 597-598.
C. F. Chen and L. S. Shieh (1968a), ““A note on expanding PA + AT Pp = —Q,” IEEE
Trans. Autom. Control, 13, 1, pp. 122-123.
C. F. Chen and L. S. Shieh (1968b), ‘‘A novel approach to linear model simplification,”
Preprints, 1968 Joint Automatic Control Conference, pp. 454-461, University of
Michigan, Ann Arbor, Mich., June 26-28.
M. R. Chidambara and R. B. Schainker (1971), ‘“‘Lower order generalized aggregated
model and suboptimal control,” JEEE Trans. Autom. Control, 16, 2, pp. 175-180.
J. B. Cruz and W. R. Perkins (1964), “‘A new approach to the sensitivity problem in multi-
variable feedback system design,” JEEE Trans. Autom. Control, 9, 3, pp. 216-222.
S. D. G. Cumming (1969), ‘Design of observers of reduced dynamics,” Electron. Letters,
5, 10, pp. 213-214.
W. B. Davenport and W. L. Root (1958), An Introduction to the Theory of Random Signals
and Noise, McGraw-Hill, New York.
H. T. Davis (1962), Introduction to Nonlinear Differential and Integral Equations, Dover,
New York.
E. J. Davison (1968a), ‘‘A new method for simplifying large linear dynamical systems,”
IEEE Trans. Autom. Control, 13, 2, pp. 214-215.
E. J. Davison (1968b), ‘‘On pole assignment in multivariable linear systems,” JEEE Trans.
Autom. Control, 13, 6, pp. 747-748.
References 555
E. J. Davison and F. T. Man (1968), ‘‘The numerical solution of A’O + QA = —C,”
IEEE Trans. Autom. Control, 13, 4, pp. 448-449.
E. J. Davison and H. W. Smith (1971), ‘‘Pole assignment in linear time-invariant multi-
variable systems with constant disturbances,” Automatica, 7, 4, pp. 489-498.
J. J. D’Azzo and C. H. Houpis (1966), Feedback Control System Analysis and Synthesis,
2nd ed., McGraw-Hill, New York.
C. A. Desoer (1970), Notes for a Second Course on Linear Systems, Van Nostrand Reinhold,
New York.
J. J. Deyst, Jr. and C. F. Price (1968), ‘Conditions for asymptotic stability of the discrete
minimum-variance linear estimator,’ JEEE Trans. Autom. Control, 13, 6, pp. 702-705.
U. diCaprio and P. P. Wang (1969), “A study of the output regulator problem for linear
systems with input vector,” Proc. Seventh Annual Allerton Conference on Circuit and
System Theory, pp. 186-188, Institute of Electrical and Electronics Engineers Catalog
No. 69 C 48-CT.
J. L. Doob (1953), Stochastic Processes, Wiley, New York.
K. Eklund (1969), ‘“‘Multivariable control of a boiler—An application of linear quadratic
control theory,” Report 6901, Lund Institute of Technology, Division of Automatic
Control, Lund, Sweden.
O. I. Elgerd (1967), Control Systems Theory, McGraw-Hill, New York.
W. Everling (1967), “‘On the evaluation of eAT by power series,” Proc. IEEE, 55, 3, p. 413.
J. B. Farison, F.-C. Fu (1970), ‘“‘The matrix properties of minimum-time discrete linear
regulator control,” JEEE Trans. Autom. Control, 15, 3, pp. 390-391.
A. F. Fath (1968), ‘Evaluation of a matrix polynomial,’ JEEE Trans. Autom. Control, 13,
2, pp. 220-221.
A. F. Fath (1969), ‘““Computational aspects of the linear optimal regulator problem,”
IEEE Trans. Autom. Control, 14, 5, pp. 547-550.
W. H. Fleming (1969), ‘‘Controlled diffusions under polynomial growth conditions,” in
Control Theory and the Calculus of Variations, A. V. Balakrishnan, Ed., pp. 209-234,
Academic Press, New York.
G. E. Forsythe and L. W. Strauss (1955), “‘The Souriau-Frame characteristic equation
algorithm on a digital computer,” J. Math. Phys., 34, pp. 152-156.
A. Fossard (1970), ‘On a method for simplifying linear dynamic systems,” JEEE Trans.
Autom. Control, 15, 2, pp. 261-262.
J. S. Frame (1964), ‘Matrix functions and applications, Part IV,”’ Spectrum, 1, 6, pp. 123-
shite
H. Freeman (1965), Discrete-Time Systems, Wiley, New York.
W. C. Freested, R. F. Webber, and R. W. Bass (1968), ‘““The ‘GASP’ computer program—
An integrated tool for optimal control and filter design,” Preprints, 1968 Joint Auto-
matic Control Conference, pp. 198-202, University of Michigan, Ann Arbor, Mich.,
June 26-28.
E. A. Gal’perin and N. N. Krasovskii (1963), ‘‘On the stabilization of stationary motions
in nonlinear control systems,” J. Appl. Math. Mech. (Translation of Prikl. Mat.
Mekh.), 27, pp. 1521-1546.
I. I. Gikhman and A. VY. Skorokhod (1969), Introduction to the Theory of Random Processes,
W. B. Saunders, Philadelphia.
556 References
T. L. Gunckel and G. F. Franklin (1963), ‘“‘A general solution for linear, sampled-data
control,” J. Basic Eng., Trans. ASME, Ser. D, 85, pp. 197-203.
P. Hagander (1972), ‘‘Numerical solution of A?S + SA + Q=0,” Information Sci.,
4, pp. 35-50.
P. H. Haley (1967), ‘‘Design of low-order feedback controllers for linear multivariable
systems,” Report CCS-10, Department of Engineering-Economic Systems, Stanford
University, Stanford, Calif.
T. C. Hendricks and G. W. Haynes (1968), ‘““The ‘GASP’ Computer Program,” Conference
Recora, Second Asilomar Conference on Circuits and Systems, Pacific Grove, Calif.
M. Heymann (1968), ‘“‘Comments on pole assignment in multi-input controllable linear
systems,’ IEEE Trans. Autom. Control, 13, 6, pp. 748-749.
T. Hida (1970), Stationary Stochastic Processes, Mathematical Notes, Princeton University
Press, Princeton, N.J.
I. M. Horowitz (1963), Synthesis of Feedback Systems, Academic Press, New York.
C.-H. Hsu, C.-T. Chen (1968), ‘A proof of the stability of multivariable feedback systems,”
Proc, IEEE, 56, 11, pp. 2061-2062.
IEEE Standards Committee (1971), “IEEE recommended practice: Rules for the use of
units of the international system of units,” Adopted December 3, 1970, reprinted in
Spectrum 8, 3, pp. 77-78.
International Organization for Standardization (various dates from 1958 to 1965),
Recommendations, 1SO/R31, Parts, I, Il, WI, 1V, V, VU, and XI.
A. Jameson (1968), ‘‘Solution of the equation AX + XB = C by inversion of an m X m
or X n matrix,” SIAM J. Appl. Math., 16, 5, pp. 1020-1023.
A. H. Jazwinski (1970), Stochastic Processes and Filtering Theory, Academic Press, New
York,
C. D. Johnson (1971a), ‘“‘A unified canonical form for controllable and uncontrollable
linear dynamical systems,” Intern. J. Control, 13, 3, pp. 497-518.
C. D. Johnson (1971b), “Accommodation of external disturbances in linear regulator and
servomechanism problems,” JEEE Trans, Autom. Control, 16, 6, pp. 635-644.
C. D. Johnson and W. M. Wonham (1966), ‘‘Another note on the transformation to
canonical (phase-variable) form,” JEEE Trans. Autom. Control, 11, 3, pp. 609-610.
G. W. Johnson (1969), ‘“‘A deterministic theory of estimation and control,’’ JEEE Trans.
Autom. Control, 14, 4, pp. 380-384.
T. L. Johnson and M. Athans (1970), “‘On the design of optimal constrained dynamic
compensators for linear constant systems,” ZEEE Trans. Autom. Control, 15, 6,
pp- 658-660.
|. Kailath (1968), ‘‘An innovations approach to least-squares estimation—Part I: Linear
filtering in additive white noise,’ IEEE Trans. Autom. Control, 13, 6, pp. 646-654.
R. E. Kalman (1960), “Contributions to the theory of optimal control,” Bol. Soc. Mat.
Mexicana, 5, pp. 102-119.
R. E. Kalman (1964), “‘When is a linear control system optimal?” J. Basic Eng., Trans.
ASME, Ser. D, 86, pp. 51-60.
R. E. Kalman (1966), “Toward a theory of difficulty of computation in optimal control,”
Proc, Fourth IBM Scientific Computing Symposium, pp. 25-43.
R. E. Kalman and J. E. Bertram (1960), “Control system analysis and design via the
‘Second method of Lyapunov’, I. Continuous-time systems.” J. Basic Eng., Trans.
ASME, Ser. D, 82, 2, pp. 371-393.
References 557
. E. Kalman and R. S. Bucy (1961), “New results in linear filtering and prediction theory,”
J. Basic Eng., Trans. ASME, Ser. D, 83, pp. 95-108.
. E. Kalman and T. S. Englar (1966), ‘‘A user’s manual for the automatic synthesis
program,’ NASA Report CR-475.
ro
. E. Kalman, P. L. Falb, and M. Arbib (1969), Topics in Mathematical System Theory,
McGraw-Hill, New York.
R. E. Kalman and R. W. Koepcke (1958), ‘“‘Optimal synthesis of linear sampling control
systems using generalized performance indexes,” Trans. ASME, Ser. D, 80, pp. 1820-
1826.
. L. Kleinman (1968), ‘‘On an iterative technique for Riccati equation computation,”
IEEE Trans. Autom. Control, 13, 1, pp. 114-115.
. L. Kleinman (1970a), ‘‘An iterative technique for Riccati equation computations,”
Technical Memorandum, Bolt, Beranek, and Newman, June 30.
. L. Kleinman (1970b), “‘An easy way to stabilize a linear constant system,”’ JEEE Trans.
Autom. Control, 15, 6. p. 692.
es
. Kreindler (1968a), “‘On the definition and application of the sensitivity function,” J.
Franklin Inst. 285, 1, pp. 26-36.
. Kreindler (1968b), “‘Closed-loop sensitivity reduction of linear optimal control systems,”
IEEE Trans. Autom. Control, 13, 3, pp. 245-262.
i
Kreindler (1969), “Sensitivity of time-varying linear optimal control systems,” J.
Optimal Theory Appl., 3, 2, pp. 98-106.
L. Krouse and E. D. Ward (1970), ‘‘Improved linear system simulation by matrix
exponentiation with generalized order hold,” Preprints, 11th Joint Automatic Control
Conference, pp. 794-802, Georgia Institute of Technology, Atlanta, Georgia, June
22-26.
. Kupperajulu and S. Elangovan (1970), ““System analysis by simplified methods,” IEEE
Trans. Autom. Control, 15, 2, pp. 234-237.
H. J. Kushner (1967), Stochastic Stability and Control, Academic Press, New York.
H. J. Kushner (1971), Introduction to Stochastic Control, Holt, Rinehart and Winston,
New York.
. Kwakernaak (1969), ‘Optimal low-sensitivity linear feedback systems,’ Automatica, 5,
3, pp. 279-286. %
H. Kwakernaak and R. Sivan (1971), “Linear stochastic optimal controllers of fixed
dimension,”’ Proc. Fifth Annual Princeton Conference on Information Sciences and
Systems, Princeton, N.J., March 25-26.
. Kwakernaak and R. Sivan (1972), “‘The maximally achievable accuracy of linear
optimal regulators and linear optimal filters,” JEEE Trans. Autom. Control, 17, 1, pp.
79-86.
rs)
. J. Leake (1965), ‘‘Return difference Bode diagram for optimal system design,” IEEE
Trans. Autom. Control, 10, 3, pp. 342-344.
A. M. Letov (1960), ‘‘Analytical controller design I,” Autom. Remote Control, 21, pp.
303-306.
. H. Levis (1969), ““Some computational aspects of the matrix exponential,” JEEE Trans.
Autom. Control, 14, 4, pp. 410-411.
n
. Levy and R. Sivan (1966), “On the stability of a zero-output system,” JEEE Trans.
Autom. Control, 11, 2, pp. 315-316.
558 References
M. L. Liou (1966a), “‘A novel method of evaluating transient response,” Proc. IEEE, 54, 1,
pp. 20-23:
M. L. Liou (1966b), “Steady-state response of linear time-invariant systems,”’ Proc. IEEE,
54, 12, pp. 1952-1953.
M. L. Liou (1967), “Response of linear time-invariant systems due to periodic inputs,”
Proc. IEEE, 55, 2, pp. 242-243.
M. L. Liou (1968), ‘Evaluation of state transition matrix and related topics,’ Conference
Record Second Asilomar Conference on Circuits and Systems, Pacific Grove, Calif.,
Oct. 30-Nov. 1.
C. S. Lu (1971), ‘Solution of the matrix equation AX + XB = C,” Electron. Letters,
7, 8, pp. 185-186.
D. G. Luenberger (1964), “Observing the state of a linear system,’ JEEE Trans. Mil.
Electron., 8, pp. 74-80.
D. G. Luenberger (1966), ‘“‘Observers for multivariable systems,” JEEE Trans. Autom.
Control, 11, 2, pp. 190-197.
D. G. Luenberger (1967), ‘Canonical forms for linear multivariable systems,’ JEEE
Trans. Autom. Control, 12, 3, pp. 290-293.
D. L. Lukes (1968), ‘“‘Stabilizability and optimal control,’ Funkcialaj Ekvacioj, 11, pp.
39-50.
N. H. McClamroch (1969), ‘‘Duality and bounds for the matrix Riccati equation,” J. Math.
Anal. Appl., 25, pp. 622-627.
A. G. J. MacFarlane (1963), ““The calculation of functionals of the time and frequency
response of a linear constant coefficient dynamical system,’ Quart. J. Mech. Appl.
Math., 15, Pt. 2, pp. 259-271.
F. T. Man and H. W. Smith (1969), *“‘Design of linear regulators optimal for time-multiplied
performance indices,’ [EEE Trans. Autom. Control, 14, 5, pp. 527-529.
K. Martensson (1971), “‘On the matrix Riccati equation,” /nformation Sci. 3, pp. 17-49.
E. J, Mastascusa and J. G. Simes (1970), ““A method for digital calculation of linear system
response,” Preprints, 11th Joint Automatic Control Conference, pp. 788-793, Georgia
Inst. of Technology, Atlanta, Georgia, June 22-26.
J. S. Meditch (1969), Stochastic Optimal Linear Estimation and Control, McGraw-Hill,
New York.
R. K. Mehra (1969), “Digital simulation of multi-dimensional Gauss-Markov random
processes.” JEEE Trans. Autom, Control, 14, 1, pp. 112-113.
J. L. Melsa (1970), Computer Programs for Computational Assistance in the Study of Linear
Control Theory, McGraw-Hill, New York.
D. Mitra (1967), “The equivalence and reduction of linear dynamical systems,’’ Ph.D.
thesis, University of London.
J. B. Moore and B. D. O. Anderson (1968), ‘Extensions of quadratic minimization theory.
I. Finite-time results,’’ Intern J. Control, 7, 5, pp. 465-472.
P. Chr. Miller (1970), “‘Solution of the matrix equation AX + XB = —Q and STX +
XS = —Q,” SIAM J, Appl. Math., 18, 3, 682-687.
R. B. Newell and D. G. Fisher (1971), “‘Optimal, multivariable computer control of a
pilot plant evaporator.” Preprints, Third International Conference on Digital Computer
Applications to Process Control, Helsinki, June 2-5.
References 559
G. C. Newton, L. A. Gould, and J. F. Kaiser (1957), Analytical Designs of Linear Feedback
Controls, Wiley, New York.
B. Noble (1969), Applied Linear Algebra, Prentice-Hall, Englewood Cliffs, N.J.
J. J. O'Donnell (1966), ‘‘Asymptotic solution of the matrix Riccati equation of optimal
control,” Proc. Fourth Allerton Conference on Circuit and Systems Theory, pp. 577-586,
University of Illinois, Urbana, Ill., Oct. 5-7.
J. B. Pearson (1965), ‘‘A note on the stability of a class of optimum sampled-data systems,”
IEEE Trans. Autom. Control, 10, 1, pp. 117-118.
D. A. Pierre (1969), Optimization Theory with Applications, Wiley, New York.
J. B. Plant (1969), “‘On the computation of transition matrices for time-invariant systems,”
Proc, IEEE, 57, 8, pp. 1397-1398.
M. Plotkin (1964), *‘Matrix theorem with applications related to multi-variable control
systems,” JEEE Trans. Autom. Control, 9, 1, pp. 120-121.
E, Polak and E. Wong (1970), Notes for a First Course on Linear Systems, Van Nostrand
Reinhold, New York.
B. Porter (1971), “Optimal control of multivariable linear systems incorporating integral
feedback,” Electron. Letters, 7, 8, pp. 170-172.
J. E. Potter (1964), *‘Matrix quadratic solutions,” SJAM J. Appl. Math., 14, 3, pp. 496-S01.
J. E. Potter and W. E. VanderVelde (1969), ‘‘On the existence of stabilizing compensation,”
IEEE Trans. Autom. Control, 14, 1, pp. 97-98.
H. M. Power (1969), ‘A note on the matrix equation A’LA — L = —K,” IEEE Trans.
Autom. Control, 14, 4, pp. 411-412.
H. M. Power and B. Porter (1970), “‘Necessary conditions for controllability of multi-
variable systems incorporating integral feedback,” Electron. Letters, 6, 25, pp. 815-816.
B. Ramaswami and K. Ramar (1968), ““Transformation to the phase-variable canonical
form,’ IEEE Trans. Autom. Control, 13, 6, pp. 746-747.
D. S. Rane (1966), “‘A simplified transformation to (phase-variable) canonical form,”
IEEE Trans. Autom. Control, 11, 3, p. 608.
D. Rappaport and L. M. Silverman (1971), “Structure and stability of discrete-time
optimal systems,” [EEE Trans. Autom. Control, 16, 3, pp. 227-233.
R. A. Rohrer (1970), Circuit Theory: An Introduction to the State Variable Approach,
McGraw-Hill, New York.
H. J. Rome (1969), ‘‘A direct solution to the linear variance equation of a time-invariant
system,” JEEE Trans. Autom. Control, 14, 5, pp. 592-593.
M. Roseau (1966), Vibrations non linéaires et théorie de la stabilité, Springer-Verlag, Berlin.
G. Rosenau (1968), “‘Héhere Wurzelortskurven bei Mehrgrossensystemen,” Preprints,
IFAC Symposium on Multivariable Systems, Diisseldorf, Oct. 7-8.
D. Rothschild and A. Jameson (1970), ‘Comparison of four numerical algorithms for
solving the Liapunov matrix equation,” Intern. J. Control, 11, 2, pp. 181-198.
A. P. Sage and B. R. Eisenberg (1966), “‘Closed loop optimization of fixed configuration
systems,” Intern. J. Control, 3, 2, pp. 183-194.
M. K. Sain (1966), “‘On the control applications of a determinant equality related to
eigenvalue computation,” JEEE Trans. Autom. Control, 11, 1, pp. 109-111.
P. Sannuti and P. V. Kokotovié (1969), ‘“‘Near-optimum design of linear systems by a
singular perturbation method,” [EEE Trans, Autom. Control, 14, 1, pp. 15-22.
560 References
R. Saucedo and E. E. Schiring (1968), Introduction to Continuous and Digital Control
Systems, Macmillan, New York.
D. G. Schultz and J. L. Melsa (1967), State Functions and Linear Control Systems, McGraw-
Hill, New York.
A. Schumitzky (1968), “‘On the equivalence between matrix Riccati equations and Fredholm
resolvents,” J. Comp. Systems Sci., 2, pp. 76-87.
R. J. Schwarz and B. Friedland (1965), Linear Systems, McGraw-Hill, New York.
W. W. Seifert and C. W. Steeg, Ed. (1960), Control Systems Engineering, McGraw-Hill,
New York.
Y. -P. Shih (1970), ‘Integral action in the optimal control of linear systems with quadratic
performance index,” Ind. Eng. Chem. Fundamentals, 9, 1, pp. 35-37.
C. S. Sims and J. L. Melsa (1970), “A fixed configuration approach to the stochastic linear
regulator problem,” Preprints, 11th Joint Automatic Control Conference, Atlanta,
Georgia, pp. 706-712.
R. Sivan (1965), ‘‘On zeroing the output and maintaining it zero,” JEEE Trans. Autom.
Control, 10, 2, pp. 193-194.
P. G. Smith (1971), ‘Numerical solution of the matrix equation AX + XAT + B=O.”
IEEE Trans. Autom. Control, 16, 3, pp. 278-279.
R. A. Smith (1968), ‘“‘Matrix equation XA + BX = C,” SIAM J. Appl. Math., 16, 1, pp.
198-201.
H. W. Sorenson (1970), ‘‘Least-squares estimation: From Gauss to Kalman,” Spectrum,
7, 7, pp. 63-68.
J. S. Tou (1964), Modern Control Theory, McGraw-Hill, New York.
E. Tse and M. Athans (1970), ‘Optimal minimal-order observer-estimators for discrete
linear time-varying systems,” JEEE Trans. Autom. Control, 15, 4, pp. 416-426.
W. G. Tuel, Jr. (1966), ““On the transformation to (phase-variable) canonical form,”
IEEE Trans. Autom. Control, 11, 3, p. 607.
J. E. Van Ness (1969), “Inverse iteration method for finding eigenvectors,” JEEE Trans.
Autom. Control, 14, 1, pp. 63-66.
D. R. Vaughan (1969), ““A negative exponential solution for the matrix Riccati equation,”
IEEE Trans, Autom. Control, 14, 1, pp. 72-75.
D. R. Vaughan (1970), ‘‘A nonrecursive algebraic solution for the discrete Riccati
equation.” JEEE Trans. Autom. Control, 15, 5, pp. 597-599.
Y. Wallach (1969), ‘‘On the numerical solution of state equations,” JEEE Trans, Autom.
Control, 14, 4, pp. 408-409.
O. H. D, Walter (1970), ‘‘Eigenvector scaling in a solution of the matrix Riccati equation,”’
IEEE Trans. Autom. Control, 15, 4, pp. 486-487.
L. Weinberg (1962), Network Analysis and Synthesis, McGraw-Hill, New York.
J. H. Westcott (1952), ‘The development of relationships concerning the frequency band-
width and the mean square error of servo systems from properties of gain-frequency
characteristics,” in Automatic and Manual Control, A. Tustin, Ed., Butterworths,
London.
D. E. Whitney (1966a), ‘“‘Propagated error bounds for numerical solution of transient
response,” Proc. IEEE, 54, 8, pp. 1084-1085.
D, E, Whitney (1966b), “‘Forced response evaluation by matrix exponential,’’ Proc, IEEE,
54, 8, pp. 1089-1090,
References 561
u E. Whitney (1966c), ‘‘Propagation and control of roundoff error in the matrix exponen-
tial method,” Proc. IEEE, 54, 10, pp. 1483-1484.
. A. Wolovich (1968), “‘On the stabilization of controllable systems,” [EEE Trans.
Autom. Control, 13, 5, pp. 569-572.
. A. Wolovich and P. L. Falb (1969), ‘‘On the structure of multivariable systems,”
SIAM J. Control, 7, 3, pp. 437-451.
. M. Wonham (1963), ‘‘Stochastic problems in optimal control,”’ 1963 JEEE Convention
Record, Part 2, pp. 114-124.
. M. Wonham (1967a), “On pole assignment in multi-input controllable linear systems,’*
IEEE Trans. Autom. Control, 12, pp. 660-665.
. M. Wonham (1967b), ‘“‘On matrix quadratic equations and matrix Riccati equations,”
Report, Center for Dynamical Studies, Brown University, Providence, R.I.
. M. Wonham (1968a), ““On a matrix Riccati equation of stochastic control,’ SIAM J.
Control, 6, 4, pp. 681-697.
. M. Wonham (1968b), “‘On the separation theorem of stochastic control,” SJAM J.
Control, 6, 2, pp. 312-326.
. M. Wonham (1970a), “‘Dynamic observers—Geometric theory,” JEEE Trans. Autom.
Control, 15, 2, pp. 258-259.
Se ee Se a ee See
. M. Wonham (1970b), “‘Random differential equations in control theory,”’ in Probabilistic
Methods in Applied Mathematics, A. T. Barucha-Reid, Ed., pp. 131-212, Academic
Press, New York.
=M. Wonham and W. F. Cashman (1968), “‘A computational approach to optimal
control of stochastic stationary systems,” Preprints, Ninth Joint Automatic Control
Conference, pp. 13-33, University of Michigan, Ann Arbor, Mich., June 26-28.
L. A. Zadeh and C. A. Desoer (1963), Linear System Theory: The State Space Approach,
McGraw-Hill, New York.
pag -
eee —~ ae hema)
CS =a? a
wet ws = iat ye Fon gh
ae
ea Phi ar aan aa
ent 7 = Gos
ame a er « ioauen aaah aes ALOR
2 jenn 7
i as oe . Lig lames =
ae Riad a> on er elt ate
ee Ya he Vou hee >
hae - =k
oe Ce) as | — eS aie.
j= hf Wore 47...
: a wl a ‘eet So etealll eae,
e. eubaca anata nar
aniice =a por ee Uae
te es Lei ta thors one 3
‘ l>.s >»
1 i x irs a aeore rd , rca
ma Aig Tin iy io
” i << 7 of i ihe o ye a = gt
fia AS ype OR” vis. Licey Srna
2 > Sa
oG,
AUTHOR INDEX
Boldface numbers indicate the page where the full reference is given.
Ackermann, J., 433, 554 Anderson, B. D. O., 83, 85, 219, 280, 314, 322, 553, 558 Aoki, M., 427, 553
Arbib, M., 64, 65, 66, 79, 460, 557 Astrdm, K. J., 100, 260, 502, 539, 553 Athans, M., 219, 428, 531, 553, 556, 560 Barnett, S., 104, 553 Barrow, B. B., ix, 553 Bass, R. W., 33, 34, 251, 324, 553, 555 Bellman, R. E., 492, 553 Berger, C. S., 472, 553 Bertram, J. E., 24,556
Beveridge, G. S. G., 432, 553 Bickart, Th. A., 14, 553 Bidwell, J. C., 251,553 Blackburn, T. R., 251, 253, 553 Blakelock, J. H., 292, 553 Bode, H. W., 440, 553 Brammer, K. G., 531, 553
Brash, F. M., 431, 554 Brockett, R. W., 26, 554 Bryson, A. E., 352, 357, 554 Bucy, R.S., 79, 219, 248, 341, 344, 364, 365, 433, 554, 557 Butman, S., 372, 554 Cadzow, J. A., 489, 554 Caines, P. E., 497, 554 Cannon, R. H., 4, 554 Cashman, W. F., 253, 561 Chang, S.S. L., 283,554 Chen, C. F., 104, 427, 554 Chen, C. T., 46, 198, 554, 556 Chidambara, M. R., 427, 554
Cruz, J. B., 187, 554
Cumming, S. D. G., 335,554
Davenport, W. B., 91,554
Davis, H. T., 217,554
Davison, E. J., 104, 198, 279, 427, 554, 555
DAzzo; Jed, 3829350140555
Desoct GaAce ll iet2nlSn lone anso54,
D5, 5011
Deyst, J. J., 497,555
di Caprio, U., 270,555
Doob, J. L., 100, 555
Eisenberg, B. R., 428, 559
Eklund, K., 416, 417, 555
Elangovan, S., 427,557
Elgerd, O.1., 4,555
Englar, T. S., 13, 219, 249,557
Everling, W., 14, 555
Falb, P. L., 64, 65, 66, 79, 85, 219, 460,
§53, 557, 561
Farison, J. B., 489, 555
Fath, A. F., 14, 251, 555
Fisher, D. G., 277, 558
Fleming, W. H., 390,555
Forsythe, G. E., 34, 555
Fossard, A., 427, 555
Frame, J. S., 103,555
Franklin, G. F., 539, 556
Freeman, H., 442,555
Freested, W. C., 251,555
Friedland, B., 29, 560
Fu, F.-C., 489, 555
563
564 Author Index
Gal’perin, E. A., 62, 555 Gikhman, I. I., 100, 555 Gould, L. A., 96, 150, 428, 559
Gunckel, T. L., 539, 556 Gura, I., 33, 34, 553 Luenberger, D. G., 83, 85, 335, 553, 558
Lukes, D. L., 237,558
Hagander, P., 104, 556 Haley, P. H., 39, 556 Haynes, G. W., 251, 556 Hendricks, T. C., 251, 556 Heymann, M., 198, 556 Hida, T., 100, 556 Horowitz, I. M., 181, 556 Houpis, C. H., 38, 53, 114, 555 Hsu, C.-H., 46, 556 McClamroch, N. H., 252, 558
MacFarlane, A. G. J., 104, 558
Man, F. T., 104, 253,555, 558
M§rtensson, K., 237, 558
Mastacusa, E. J., 14, 558
Mayne, D. Q., 497, 554
Meditch, J. S., 463, 531, 558
Mehra, R. K., 102, 558
Melsa, J. L., 14, 34, 38, 51, 194, 327, 428,
430, 558, 560
Mitra, D., 427, 558
Moore, J. B., 219, 280, 314, 322, 553, 558
Muller, P. Chr., 104,558
IEEE Standards Committee, ix, 556
International Organization for Standard- ization, ix, 556 Newell, R. B., 277, 558
Newton, G. C., 96, 150, 428, 559
Noble, B., 15, 19, 20, 376, 559
Jameson, A., 104, 556, 559
Jazwinski, A. H., 344, 531, 556 Johansen, D. E., 352, 357, 554
Johnson, C. D., 84, 85, 280, 556 Johnson, G. W., 388, 556 Johnson, T. L., 428, 556 Joseph, P. D., 79, 219, 248, 554 O’Donnel, J. J., 246, 247, 322, 326, 559
Pearson, J. B., 431,515, 554, 559
Perkins, W. R., 187, 554
Pierre, D. A., 432, 559
Plant, J. B., 14,559
Plotkin, M., 40, 559
Kailath, T., 361, 556 Polaky Elo sosrooS
Kaiser, J. F., 96, 150, 428, 559 Porter, B., 277, 279, 559
Kalman, R. E., 13, 24, 54, 64, 65, 66, 79, Potter, J. E., 322, 388,559
217,219,231,232,233,249,284 322,341, Power, H. M., 279, 472,559
344, 364, 365, 460, 492, 497, 556, 557 Price Cab ,49i 7055
Kleinman, D. L., 104, 252, 253, 557
Koepcke, R. W., 492, 502, 553, 557 Kokotovic, P. V., 428, 559 Krasovski, N. N., 62,555 Kreindler, E., 187, 314, 315, 557 Krouse, C. L., 14, 557 Kuppurajulu, A., 427, 557 Kushner, H. J., 100, 260, 263, 390, 502, 503, 539, 557 Kwakernaak, H., 306, 423, 424, 428, 557 Ramar, K., 84,559
Ramaswami, B., 84,559
Rane, D. S., 84, 559
Rappaport, D., 515,559
Rohrer, R. A., 14,559
Rome, H. J., 104,559
Root, W. L., 91, 554
Roseau, M., 3, 32, 559
Rosenau, G., 287, 559
Rothschild, D., 104,559
Reaken Ris o2 15017,
Letov, A. M., 247, 557 Levis, A. H., 14,557 Levy, S., 309, 557 Liou, M. L., 14, 558 Lu, C.S., 104, 558 Sage, A. P., 428, 559
Sain, M. K., 40, 559
Sannuti, P., 428,559
Saucedo, R., 444, 456, 560
Schainker, R. B., 427, 554
Schechter, R. S., 432, 553
Schiring, E. E., 444, 456, 560
Schultz, D. G., 327, 560
Schumitzky, A., 219, 560
Schwarz, R. J., 29, 560
Seifert, W. W., 96, 150, 560
Shieh, L. S., 104, 427, 554
Shih, Y.-P., 277, 560
Silverman, L. M., 515, 559
Simes, J. G., 14, 558
Sims, C. S., 428, 430, 560
Sivan, R., 306, 308, 309, 428, 557, 560
Skorokhod, A. V., 100,555
Smith, H. W., 253, 279, 555, 558
Smith, P. G., 104, 560
Smith, R. A., 104, 560
Sorenson, H. W., 341, 560
Steeg, C. W., 96, 150, 560
Storey, C., 104, 553
Strauss, L. W., 34,555
Tou, J. S., 502, 560
Tse, E., 531, 560
Author Index 565
Tuel Jr., W. G., 84, 560
Tung, F., 502,553
VanderVelde, W. E., 388, 559
Van Ness, J. E., 251, 560
Vaughan, D. R., 249, 325, 500, 560
Wallach, Y., 14,560
Walter, O. H. D., 326, 560
Wang, P. P., 270, 555
Ward, E. D., 14, 557
Webber, R. F., 251,555
Weinberg, L., 285, 299, 560
Westcott, J. H., 440, 560
Whitney, D. E., 14, 560, 561
Wolovich, W. A., 85, 198, 561
Wong, E., 13, 33,559
Wonham, W. M., 62, 77, 84, 198, 200, 218,
219, 237, 253, 336, 351, 390, 556, 561
Zadehe leeAc alee Zee Sel Oer2 24S Sts,
561
7 v1.
Pe eee S
- Zacpanemams Ll
aan Oe Le Wy ita
a ee a aes ae? eT AEC is
are, 6907, E>
“ie i, in natu ad ot
SUBJECT INDEX
Boldface numbers indicate the page where the item is defined or introduced.
Accuracy, maximally achievable, of
regulators and tracking systems,
306—310
Adjoint matrix differential equation, 440
Airplane, asymptotic regulation of the
longitudinal motions of an, 310—
312
nonzero set point pitch control of an,
302—303
pitch control of an, 291—293
regulation of the longitudinal motions of
an, 293—297
Aliasing, 458
Amplidyne, description of an, 114—115
nonzero set point regulator for an, 321
proportional feedback control of an, 116
regulation of an, 320
Angular velocity control system, an
observer for the, 374—375
digital version of the, 521—522
integral control of the, 439—440
as an output feedback regulator problem,
438-439
as an output feedback stochastic tracking
problem, 439
proportional feedback of the, 189-190
as a regulator problem, 205—206
solution of, the regulator problem for
the, 212—216
the Riccati equation for the, 220
the stochastic tracking problem for the,
266—269
steady-state solution of the regulator
problem for the, 222—223
as a stochastic tracking problem, 258—259
reconsidered, 321
Autonomous system, 24
Bandwidth, normalized, of a discrete-time
control system, 481
of a control system, 145
normalized, of a discrete-time stochastic
process, 481
of a stochastic process, 147
Bode, 181
Bode plot, 38
Break frequency, of a control system, 146
of a stochastic process, 147
Brownian motion, 90, 100
Butterworth, pole configuration, 285
polynomial, 299
transfer function, 299
Cayley-Hamilton theorem, 84
Characteristic polynomial, closed-loop, 46,
274
open-loop, 274
Complexity of output feedback control
systems, 437
Computer control, 442
Computer program package for linear
optimal control, 437—438
Constant disturbances, effect of, in control
systems, 171—172, 191-192
elimination of, in discrete-time regulators,
506-507
in discrete-time output feedback control
systems, 544
in regulators, 277—280
in output feedback control systems, 414—
417
Continuous-to-discrete-time converter, 444
567
568 Subject Index
Control instant, 522
Control variable, see Input variable
Controlled variable, 122, 128, 476
shifted, 270
Control law, asymptotically stable, 194
asymptotic properties of, discrete-time
optimal, 509-516
optimal, 281-312
discrete-time nonzero set point optimal,
505, 543
discrete-time steady-state optimal, 497
discrete-time zero-steady-state-error
optimal, 507, 544
interconnected with observer, 378—382
discrete-time case, 536—537
linear, 194
nonzero set point optimal, 273, 411
stability of, discrete-time steady-state
optimal, 497
steady-state optimal, 221, 233
time-invariant steady-state optimal, 238
steady-state optimal, 221, 232
time-invariant steady-state optimal, 238,
243
zero-steady-state-error optimal, 416
Controllability, 53—65
complete, 54
of discrete-time linear systems, 459—462
of the pair (4, B), 56
of time-invariant linear systems, 55—57
of time-varying linear systems, 64—65
uniform complete, 65
of discrete-time systems, 460—461
Controllability, canonical form, 60
of discrete-time systems, 461—462
matrix, 55
of discrete-time systems, 460
Controller, 119, 122
closed-loop, 123, 128—132, 476
open-loop, 122, 128, 476
Control problems, multivariable, 124
terminal, 127
Control system, 123, 131
Control systems, analysis of linear, 119-192
discrete-time, 475—488
stability of, 136—137, 184, 188, 477
stabilization of, 137
by open loop controllers, 184, 188
Covariance matrix, see Stochastic processes
Cutoff frequency, normalized, of a discrete-
time control system, 481
of a discrete-time stochastic process, 481
of a control system, 145
of a stochastic process, 147
of the i-th link, 156
Deadbeat observers, 527
Deadbeat response, output, 489, 513,515
state, 489, 537
Decoupling, 157
static, 157
Degrees of freedom of a control system, 272,
279, 308, 415—416
Design objective, basic, 131, 471
Detectability, 76—78, 77
of discrete-time systems, 465
of the pair (4, C), 77
Difference function, 157, 163, 164
Differential system, 2
Digital computation aspects of linear optimal
control, 436—438
Digital positioning system, a deadbeat
observer for the, 527—528
description of the, 447—449
frequency response of the, 458—459
integral control of the, 545—546
a nonzero set point regulator for the, 507—
509
observed variable of the, 524
optimal state feedback of the, 494-495
output deadbeat control of the, 516—517
output feedback state deadbeat control
of the, 537—538
with proportional feedback, 483—487
stability of the, 455
with proportional feedback, 477—478
state feedback deadbeat control of the, 490
Dimension of a linear system, 2
Direct link, 2
in discrete-time systems, 447, 524
Direct sum, 19
Discrete-time equivalent of a continuous-
time system, 445
Discrete-time systems, inherently, 442
linear optimal control theory for, 442—
So2
Discrete-to-continuous-time converter, 444
Disturbances, constant, effect of, in control
systems, 167-174, 184-186, 188
in discrete-time control systems, 487—
488
equivalent, at the controlled variable, 170
see Constant disturbances
Disturbance variable, 121, 128, 476
Duality, of discrete-time systems, 465—466
of discrete-time optimal observer and
regulator problems, 533—534
of optimal regulator and observer
problems, 364—365
of systems, 79—81
Equilibrium state, 24
Estimation of a constant, 346—347
Estimator, minimum mean square linear,
344, 531
Euclidean norm, 24
Exponentially correlated noise, break
frequency of, 148
cutoff frequency of, 148
definition of, 88
discrete-time, 469
modeled by a first-order system, 105—106
power spectral density, function of, 91
of discrete-time, 472—473
time constant of, 88
variance of, 88
Exponential of a matrix, 13, 20
computation of the, by diagonalization,
15-17, 21
by Laplace transformation, 33
numerical computation of the, 13—14
Faddeeva’s method, 34
Feedback, benefits of, 120
Feedback configuration, 43
Feedback link of a controller, 262—263
Feedforward link of a controller, 263
Frequency, normalized angular, 457
Frequency band, normalized, of a discrete-
time stochastic process, 480
of a control system, 145
normalized, of the i-th link of a discrete-
time control system, 481
of the i-th link, 156
of a stochastic process, 146
Frequency response, 37—38
of discrete-time systems, 457—458
Frequency response matrix, 38
Gain matrix, of an observer, 331
of a regulator, 194
Heating system, 119, 120
Subject Index 569
Impulse response matrix, 13
of a time-invariant system, 14, 35
Input, computation of mean square, 132, 150
dynamic range of, 149
integrated square, 203
magnitude of, in regulator problems, 201
mean square, 131
ts, 131
steady-stak mean square, 140—144, 264
Input variable, 2, 121, 476
shifted, 270
Innovation process, 361, 361--363, 401
discrete-time, 533
Integral control, in discrete-time output
feedback regulators, 544
in discrete-time state feedback regulators,
507
in output feedback regulators, 414—417
in state feedback regulators, 277—280
Integrating action, 171, 181, 191, 277, 417
Integral state, 277
for discrete-time regulators, 507
Interaction, 157
Interconnections, of discrete-time and
continuous-time systems, 443—447
of linear systems, 43—48
Interface system, 443
Inverted pendulum, an observer for the,
373-374
controllability of the, 57
control of the, with proportional feedback,
48—49
description of the, 4—7
detectability of the, 78
modes of the, 17—18
without friction, 22—23
reconstructibility canonical form of the,
75—76
reconstructibility of the, 67, 69—70
stability of the, 26
stabilization of the, by output feedback,
383—388
by state feedback, 139-140, 195-196
stable and unstabie subspaces of the
30-31
without friction, 31
Jacobian matrix, 3
Jordan normal form, 19—22, 20
570 Subject Index
Kalman-Bucy filter, 341, 344; see also
Optimal observer
Laplace transformation, 33
Leverrier’s algorithm, 34, 251, 456
Linearization, 2—3, 31—32
Loop gain matrix, 45
Low-pass, stochastic process, 147
transmission, 146
Lyapunov equation, 104, 111, 251
numerical solution of the, 104
Markov process, 117
Matrix difference equation, property of a,
$51
Measurement noise, 339; see also
Observation noise
Mode, 16, 22
Modes, hidden, in optimal regulators, 309
Nilpotency of a matrix, 489
Nominal, input, 2
plant transfer function, 179
solution, 24
trajectory, 2
Nonnegative-definiteness of a matrix, 87,
91
Null space, 19
Numerator polynomial, 41
numerical computation of the, 41—42
Observability, complete, 66; see also
Reconstructibility
Observation instant, 523
Observation noise, 122, 339, 476
effect of, in control systems, 174-176
in discrete-time control systems, 487—
488
in open-loop control systems, 186, 188
Observed variable, 122, 128, 328, 476
Observer, asymptotic properties of the
time-invariant optimal, 368—372
determination of a priori data of the
singular optimal, 376
full-order, 330
full-order discrete-time, 525
interconnected with a control law, 378—
382
discrete-time case, 536—537
optimal, 339—363
optimal discrete-time, 528—531
pole assignment in an, 332, 334
pole assignment in, a discrete-time, 526
a reduced-order, 336
poles, 332
reduced-order, 330, 335—337
reduced-order discrete-time, 527
stability of the, 331—332
discrete-time, 526
stabilization of a discrete-time, 526
stabilization of an, 334—335
steady-state optimal, 345, 366—368
steady-state properties of, the discrete-
time optimal, 535
the optimal, 345, 365—368
Observer problem, alternative version of the
discrete-time optimal, 5S50—551
the colored noise optimal, 356—357
the discrete-time optimal, 528—531
the nonsingular, with correlated noises,
351-352
with uncorrelated noises, 341—346
the optimal, 340
the singular time-invariant, 352—356
Observer Riccati equation, 343—345
asymptotic behavior of the solution of
the, 370—372
solution of the, 375—376
steady-state solution of the, 345, 365—
368
the algebraic, 345, 367
Output equation, 2
of discrete-time systems, 443
Output feedback control systems, constant
disturbances in, 414—417
discrete-time, 544
nonzero set point, 409—413
discrete-time, 543—544
numerical determination of optimal
reduced-order, 432—434
optimal, 389-419
optimal discrete-time, 536—546
optimal reduced-order, 427—434
discrete-time, 552
pole assignment in, 388—389
discrete-time, 537
sensitivity of, 419-424
stabilization of, 388—389
a discrete-time, 537
steady-state optimal, 396
structure of, 378—382
Output feedback regulator, evaluation of the
performance of, the optimal, 391—
397
the optimal discrete-time, 540—543
the optimal, 390—391
the optimal discrete-time, 539-540
Output feedback regulator problem, the
stochastic linear discrete-time
optimal, 539, 539-540
the stochastic linear optimal, 389, 389—
402
Output feedback tracking systems, 402—405
Output variable, 2
Parameter variations, effect of, in control
systems, 178—181, 187-188, 488
Phase-variable canonical form, 82, 82—85
of discrete-time systems, 466—467
dual, 84
of discrete-time systems, 467
Plant, 119, 128
dynamic range of a, 149
Poles, assignment of, in discrete-time
regulators, 488—489
in discrete-time observers, 526
in discrete-time output feedback systems,
$37
in observers, 332, 334—335, 336
in output feedback systems, 388—389
in regulators, 194, 198-199
asymptotic behavior of the closed-loop
regulator, 281—289
discrete-time case, 511, 513-515, 549
asymptotic behavior of the observer, 368—
370
closed-loop, 51
controllable, 61
of discrete-time systems, 462
distance to the origin of, closed-loop
regulator, 285, 288—289
closed-loop from Bode plot, 327
faraway, 284, 287
nearby, 289
observer, 332, 382, 537
open-loop, 51
patterns of closed-loop regulator, 281—
289
discrete-time case, 509-515, 549
reconstructible, 75
Subject Index 571
of discrete-time systems, 465
regulator, 382, 537
stable, 29
of discrete-time systems, 462
of a system, 17, 35
of a transfer matrix, 35
uncontrollable, 61
of discrete-time systems, 462
unreconstructible, 75
of discrete-time systems, 465
unstable, 29
Position servo, controllers for the, 133—136
description of the, 124
effect of, disturbances on the, 172—174
observation noise on the, 176—178
parameter variations on the, 181—183
with position and velocity feedback ,134—135
with position feedback only, 135
with proportional feedback, 133—134
settling time of the tracking error of the,
166—167
stability of the proportional feedback
scheme for the, 137-138
tracking properties of the, 150—155
Positioning system, a colored noise observer
for the, 357—360
asymptotic properties of the optimal
observer for the, 372—373
integral control of the, 280—281
integral output feedback control of the,
417-419
nonzero set point control of the, 275
nonzero set point output feedback control
of the, 413-414
an observer for the, 332—334
an optimal observer for the, 347—351
as an output feedback control problem,
382—383
as an output feedback tracking problem,
405-409
pole configuration of the optimal regula-
tor for the, 290
a reduced-order controller for the, 434—
436
a reduced-order observer for the, 337—
338
as a regulator problem, 206—207
with a frictionless dc motor, 319
sensitivity of, the optimal output feed-
back control system for the, 424—
427
572 Subject Index
the optimal regulator for the, 317—318
stabilization of regulators for the, 319
steady-state solution of the regulator
problem for the, 223—227
as a stochastic output feedback regulator
problem, 397—400
as a stochastic regulator problem, 320—
B21
terminal control of the, 127
Power spectral density matrix, see Stochastic
processes
Prefilter, 412
Process control, 547
Processing delay, 476, 523
Pulse response matrix, 453
Quadratic, expression for stochastic
processes, 94—96
integral expressions, 108—111
sums for discrete-time stochastic
processes, 471—472
Reconstructibility, 65—79
complete, 66
of discrete-time systems, 462—465
of the pair (A, C), 69
of time-invariant linear systems, 67—69
of time-varying linear systems, 78—79
uniform complete, 79
uniform complete, of discrete-time
systems, 463
Reconstructibility canonical form, 74
of discrete-time systems, 464—465
Reconstructibility matrix, 67
of discrete-time systems, 463
Reconstruction error, 331, 340
mean square, 340
Reduced-order output feedback
controllers, 427—436
discrete-time, 552
Reel-winding mechanism, 234—237
Reference variable, 122, 128, 476
constant part of the, 141
variable part of the, 141
Regulating error, integrated square, 203
Regulators, asymptotic properties of
nonzero set point, 297—302
discrete-time case, 512—513
asymptotic properties of optimal, 281—
B12
discrete-time case, 509-516
with incomplete and noisy measuret ents,
389—402
discrete-time case, 539-543
with incomplete measurements, 378—389
discrete-time case, 536—537
nonzero set point, 270—275
discrete-time case, 504—506
pole assignment in, 194, 198-199
discrete-time, 488—489
poles of time-invariant optimal, 247, 282—
283, 286
discrete-time case, 500, 509-510, 513
sensitivity of optimal, 312—317
discrete-time case, 520—521
| steady-state properties of optimal ,230—243
Regulator problem, 123
choice of the weighting matrices in the
optimal, 204
the deterministic linear optimal, 201—
220, 203
discrete-time case, 490—494, 491
with disturbances, 253—255, 261—263
discrete-time case, 547—548
existence of,the solution of the optimal,219
the optimal, 321—322
the optimal, discrete-time case, 547
frequency domain solution of the
optimal, 326
the mixed continuous-time discrete-time
optimal, 549—550
properties of the steady-state solution of
the stochastic optimal, 263—265
solution of the optimal, 207—212
by diagonalization, 243—248
steady-state solution of the linear optimal,
220—248
discrete-time case, 495 —500
the stochastic linear optimal, 253-255,
255, 259-265, 310
discrete-time case, 502, 502—503
the stochastic linear optimal output
feedback, 389, 389—402
discrete-time case, 539, 539-540
the time-invariant deterministic linear
optimal, 203
variational equations of the optimal, 209
Resolvent, 33, 34
Return difference matrix, 45, 186
asymptotic, 423
Riccati equation, 217
algebraic, 221, 238, 243, 322-325
derivation of the, 216—219
discrete-time equivalent of the, 494
existence of the solution of the, 219
negative exponential solution of the, 325
numerical solution of the, 248—253
by diagonalization, 250—251
by direct integration, 248—249
by the Kalman-Englar method, 249
by the Newton-Raphson method, 251-
253
observer, 343—345, 365-367, 375—376
solutions of the algebraic, 322—325
steady-state solution of the, 221, 231—
232
time-invariant, 237—238
Root loci, 51—53
of optimal observer poles, 368—370
of optimal regulator poles, 281—289
discrete-time case, 511, 514-515, 549
Root-square locus, 283
Routh-Hurwitz criterion, 28
Sampler, 444
Sampling, instant, 447
period, 447
rate, 447
Satellite, revolving, 113-114
Savings bank account, 443
Sensitivity, of control systems to, dis-
turbances, 167—172, 184—186, 188
parameter variations, 178-181,
187-188
of optimal output feedback control
systems, 419—424
of optimal state feedback control
systems, 312—317
discrete-time case, 520—521
Sensitivity function, 169, 181
of a discrete-time control system, 487
a property of the, 440—441
Sensitivity matrix, 185
asymptotic, 423
of a discrete-time control system, 487
Sensor, 119
Separation principle, 361, 390
proof of the, 400—402
Series connection, 43
Set point, 123, 141, 270
Subject Index 573
nonzero, in output feedback control
systems, 409-413, 417
discrete-time case, 543-544
in state feedback regulators, 270—275
discrete-time case, 504—506
Settling time, 141, 165
a bound for the, 166
discrete-time case, 483
Simulation of linear systems, 13-14
Smoothing problem, optimal, 361
Souriau’s method, 34
Stability, 24—32
asymptotic, 25, 26, 28
of discrete-time systems, 454
in the large, 25, 26, 28
of discrete-time systems, 454
of discrete-time systems, 454—455
exponential, 26, 28
of discrete-time systems, 454—455
of interconnections of systems, 46
of linear systems, 25—26
of a matrix, 28
of nonlinear systems, investigation of the,
31-32
in the sense of Lyapunov, 24, 26, 28
of discrete-time systems, 454
of solutions, 24—25
of time-invariant linear systems, 27—29
Stabilizability, 62, 62—64
of discrete-time systems, 462
of the pair (4, B), 63
State augmentation technique, 43—44
State difference equation, 443
solution of the, 452—453
State differential equation, 2
linearized, 3
solution of the, for linear systems, 11—23
by Laplace transformation, 33—35
State excitation noise, 339
State feedback, 193—327
of discrete-time systems, 488—522
optimal, see Regulator problem
stability improvement by, 193-201
of discrete-time systems, 488—489
State reconstruction, 328—376
for discrete-time systems, 522—536
optimal, see Observer problem
problem formulation for discrete-time,
522-524
574 Subject Index
State transformation, 10—11, 115, 116,
117
State variable, 2
augmented, 43
shifted, 270
Step response matrix, 13
Steady-state analysis of control systems,
see Tracking properties
Steady-state equivalent control scheme,
open-loop, 183, 183—188
Steady-state period, 141
Steady-state response, to a constant input,
38
of discrete-time systems, 458
to a harmonic input, 37
of discrete-time systems, 457
Steady-state solution of regulator problems,
see Regulator problem
Stirred tank, a decoupled control system
for the, 190-191
analysis of the steady-state tracking
properties of the controlled, 158—
165
computation of, a quadratic integral
criterion for the, 111—113
the mean square concentration varia-
tion in the, 96
controllability of the, 54—55, 61—62
damping effect of the, 117
description of the, 7-10
discrete-time version of the, an optimal
observer for the, 531—533
as a regulator problem, 500—501
as a stochastic regulator problem, 503—
504
description of the, 449
with disturbances, 473-475
frequency response matrix of the, 38—39
impulse response matrix of the, 14
modeling of the stochastic disturbances
of the, 107—108
nonzero set point regulation of the, 275—
276
pole configuration of the optimal
regulator for the, 290—291
proportional feedback control of the,
49-50
a regulator system for the, 124-127
solution of the stochastic regulator
problem for the, 265—266
stability improvement of the, 196
stability of the, 27, 29
stabilizability of the, 64
steady-state solution of the regulator
problem for the, 227—230
step response matrix of the, 15
with stochastic disturbances, 93—94
as a stochastic regulator problem, 256—
PE
transfer matrix of the, 36—37
zeroes of the, 42
Stirred tank with time delay, deadbeat
control of the, 517—520
description of the, 449—452
Stochastic processes, 85—96
covariance matrix of, 86
discrete-time, 468
discrete-time, 467—469
Gaussian, 87—88
Gaussian discrete-time, 467
independence of, 87
mean of, 86
discrete-time, 468
modeling of, 106
power spectral density function of, 90
power spectral density matrix of, 90,
90-91
discrete-time, 468—469
realizations of, 85
response of linear systems to, 91—93
discrete-time case, 469
second-order joint moment matrix of, 86
discrete-time, 468
second-order moment matrix of, 86
discrete-time, 468
stationarity of, 85
discrete-time, 467
uncorrelatedness of, 87
variance matrix of, 86
discrete-time, 468
wide-sense stationarity of, 87
discrete-time, 468
with uncorrelated increments, 88—90,
99-100
Subspace, controllable, 57,57—61, 116
of discrete-time systems, 461
invariance of a, 58
reconstructible, 75
stable, 30
of discrete-time systems, 455
uncontrollable, 61
unreconstructible, 70, 70—75
of discrete-time systems, 464
unstable, 30
of discrete-time systems, 455
Suspended pendulum, stability of the, 27
System equations, 2
Terminal control, 127
Terminal error, weighted square, 203
Trace of a matrix, 95
Tracking antenna, 119, 120, 124
Tracking error, 131
computation of the mean square, 131—
1325150
mean square, 131
rms, 131
steady-state mean square, 140—144, 142
Tracking problem, 121—123
stochastic optimal, 257—258, 263
discrete-time case, 548—549
optimal linear, with incomplete and
noisy measurements, 402—405, 403
Tracking properties, steady-state, of open-
loop control systems, 184, 188
steady-state analysis of, 140—165
discrete-time case, 478—482
multiinput multioutput case, 155—158
single-input single-output case, 144—
150
transient analysis of, 165—166
discrete-time case, 482—483
transient, of open-loop control systems,
184, 188
Transfer function, 35
Transfer matrix, 35
closed-loop, of a time-invariant regulator,
P47)
Transform analysis, 33—53
of discrete-time systems, 455—458
Transient analysis of control systems, see
Tracking properties
Transient period, 141
Subject Index 575
Transition matrix, 11
discrete-time case, 452
of a time-invariant system, 13—14
Transmission, 142
of a discrete-time control system, 479
first-order, 146
second-order, 146
White noise, 97, 97-100
discrete-time, 470
Gaussian, 100
Gaussian discrete-time, 470
integration rules for, 98
intensity of, 97
linear differential system driven by, 97—
1S)
linear discrete-time systems driven by,
470—472
Wiener, 361
Wiener process, 90
Wiener-Lévy process, 90
Zero, a system with a right-half plane,
304—306, 312
Zeroes, cancellation of open-loop, 289, 309
effect on sensitivity of, right-half plane,
316-317
output feedback control systems of
right-half plane, 424
open-loop, 51
outside the unit circle, 515
right-half plane, 300, 308—309
of systems, 39—42, 41
discrete-time case, 457
of transfer functions, 39
of transfer matrices, 39—42
Zero-order hold, 444
z-transform, 455—456
z-transfer matrix, 456
»™ 7 Stensmiee <2
o a . ee
Bh eA ane ome
8¢ 21 iy Heeeyaie
—? ome eso
, de _~ = Ni =
= 4 i. ure b-@e 4.
te oe u " or
> £2o 3 5 ue > =
an ay 7
>> ay on » Wee ‘0 ed
ae a ivf?) Oe BruPis
. = TONS Ao
SOM thane chi ded Ae
Fae) EL) dh a
rt : en a.
-@( aqulive 4 ¢ se
e 22 pied; WAG ty
= ( 7 =. >
a =_ r
i oo nM
- 6) dir Pets -
Om s weeny . i.
; A eet = (nee Mins fom -
> eat » >a
a a » ipl | poe
=< 4 = 7a = = -
aie , j+=z
Fy yr ae en
7 : * * , ae eae
— r é i
7 - Jal
‘ , a hon Wis 7
-— ; 7 ane one
Sere at aur .
- > (ar; i ve ere) |
: 28
’ a
-_
UNIVERSITY OF MICHIGAN jena
Sod 383 3 9015 009
02/02 99-913-01 cco
DEMCO